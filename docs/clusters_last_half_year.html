



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Clustering papers on Supervised Learning by Classification</title>
      
      
        
          
        
        
          
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="b1906f80-68f7-404c-ae78-7bbf3c7ee2c2" data-root-id="1087"></div>
            
          
        
      
      
        <script type="application/json" id="1176">
          {"122c2565-e98e-4698-9c09-9a5e8fbdaaca":{"roots":{"references":[{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1012","type":"HoverTool"},{"id":"1035","type":"PanTool"},{"id":"1036","type":"WheelZoomTool"},{"id":"1037","type":"BoxZoomTool"},{"id":"1038","type":"ResetTool"},{"id":"1039","type":"SaveTool"},{"id":"1040","type":"TapTool"}]},"id":"1041","type":"Toolbar"},{"attributes":{},"id":"1058","type":"BasicTickFormatter"},{"attributes":{},"id":"1021","type":"LinearScale"},{"attributes":{"margin":[20,20,20,20],"sizing_mode":"scale_both","style":{"color":"#BF0A30","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Click on a plot to see the info about the article.","width":150},"id":"1064","type":"Div"},{"attributes":{"children":[{"id":"1002","type":"Div"}]},"id":"1080","type":"Row"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Time Range:&lt;/h3&gt;&lt;p1&gt;Click on the button to change the time range of the plot.&lt;/p1&gt;"},"id":"1002","type":"Div"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Clustering of literature on supervised learning by classification from ACM Digital Library. \n    The dataset is extracted from &lt;a href=\"https://dl.acm.org/topic/ccs2012/10010147.10010257.10010258.10010259.10010263?expand=all&amp;startPage=\"&gt;here&lt;/a&gt;."},"id":"1006","type":"Div"},{"attributes":{},"id":"1038","type":"ResetTool"},{"attributes":{"source":{"id":"1011","type":"ColumnDataSource"}},"id":"1053","type":"CDSView"},{"attributes":{},"id":"1072","type":"UnionRenderers"},{"attributes":{"children":[{"id":"1003","type":"Div"},{"id":"1004","type":"Div"},{"id":"1005","type":"Div"}]},"id":"1081","type":"Row"},{"attributes":{"height":75,"margin":[20,20,20,20],"sizing_mode":"stretch_width","style":{"color":"#0269A4","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Keywords: Slide to specific cluster to see the keywords."},"id":"1062","type":"Paragraph"},{"attributes":{},"id":"1036","type":"WheelZoomTool"},{"attributes":{},"id":"1039","type":"SaveTool"},{"attributes":{"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1029","type":"Grid"},{"attributes":{"formatter":{"id":"1058","type":"BasicTickFormatter"},"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1025","type":"LinearAxis"},{"attributes":{"children":[{"id":"1078","type":"Row"},{"id":"1079","type":"Row"},{"id":"1080","type":"Row"},{"id":"1081","type":"Row"},{"id":"1082","type":"Row"},{"id":"1083","type":"Row"},{"id":"1084","type":"Row"},{"id":"1085","type":"Row"},{"id":"1086","type":"Row"}]},"id":"1087","type":"Column"},{"attributes":{"children":[{"id":"1008","type":"Div"},{"id":"1007","type":"Div"}]},"id":"1082","type":"Row"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"color":"#2e484c","font-family":"Julius Sans One, sans-serif;"},"text":"&lt;h1&gt;Clustering Literature on Supervised Learning by Classification (Last Half Year)&lt;/h1&gt;"},"id":"1076","type":"Div"},{"attributes":{"label":{"field":"labels"},"renderers":[{"id":"1052","type":"GlyphRenderer"}]},"id":"1061","type":"LegendItem"},{"attributes":{"children":[{"id":"1064","type":"Div"}]},"id":"1086","type":"Row"},{"attributes":{"text":"Clustering of the ACM papers on Supervised Learning by Classification"},"id":"1015","type":"Title"},{"attributes":{"text":"&lt;a href=\"clusters_last_month.html\" target=\"_blank\"&gt;&lt;button&gt;Last Month&lt;/button&gt;&lt;/a&gt;"},"id":"1003","type":"Div"},{"attributes":{"children":[{"id":"1074","type":"Slider"},{"id":"1075","type":"TextInput"}]},"id":"1083","type":"Row"},{"attributes":{"args":{"current_selection":{"id":"1064","type":"Div"},"source":{"id":"1011","type":"ColumnDataSource"}},"code":"\n        var titles = [];\n        var authors = [];\n        var abstracts = [];\n        var publicationDates = [];\n        var clusters = [];\n\n        cb_data.source.selected.indices.forEach(index =&gt; {\n            titles.push(source.data['title'][index]);\n            authors.push(source.data['author'][index]);\n            abstracts.push(source.data['abstract'][index]);\n            publicationDates.push(source.data['publication_date'][index]);\n            clusters.push(source.data['cluster'][index]);\n        });\n\n        var title = \"&lt;p1&gt;&lt;b&gt;Title:&lt;/b&gt; \" + (titles[0] ? titles[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var author = \"&lt;p1&gt;&lt;b&gt;Author:&lt;/b&gt; \" + (authors[0] ? authors[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var abstract = \"&lt;p1&gt;&lt;b&gt;Abstract:&lt;/b&gt; \" + abstracts[0].toString() + \"&lt;br&gt;\";\n        var publicationDate = \"&lt;p1&gt;&lt;b&gt;Publication Date:&lt;/b&gt; \" + publicationDates[0].toString() + \"&lt;/p1&gt;&lt;br&gt;\";\n        var cluster = \"&lt;p1&gt;&lt;b&gt;Cluster:&lt;/b&gt; \" + clusters[0].toString() + \"&lt;/p1&gt;\";\n\n        current_selection.text = title + author + abstract + publicationDate + cluster;\n        current_selection.change.emit();\n    "},"id":"1065","type":"CustomJS"},{"attributes":{"formatter":{"id":"1056","type":"BasicTickFormatter"},"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1030","type":"LinearAxis"},{"attributes":{"callback":null,"data":{"abstract":["The use of functional magnetic resonance imaging (fMRI) data in machine learning (ML)-based classification of autism spectrum disorder (ASD) has been a topic of increasing research interest in past years due to the noninvasiveness of the fMRI technique and its potential for providing valuable biomarkers. However, there are still controversies surrounding some fMRI data preprocessing steps, such as bandpass filtering and global signal regression (GSR). It still needs to be determined whether or how these preprocessing steps impact the classification accuracy of ML algorithms. This paper uses fMRI signals from the ABIDE-I dataset to train a long short-term memory (LSTM) network to classify subjects into ASD or healthy controls (HC). We considered 18 preprocessing pipelines comprising all combinations of with and without filtering, with and without global signal regression, and three different segment lengths of 1 min, 2 min, and 3 min. The best model was obtained when using a segment length of 2 min. Our results suggest that not filtering produces significantly higher classification accuracies than filtering, whereas there were no significant differences in classification accuracies when removing or not the global signal.","Writer identification based on handwriting recognition is considered one of the most common research areas in pattern recognition and biometrics. It has attracted much attention in recent decades due to the urgent need to develop biometric systems for many security applications. In this paper, Deep Writer Identification Network (DeepWINet), an effective deep Convolutional Neural Network (CNN) for writer identification, is proposed. The proposed model is evaluated in two different ways. In the first scenario, DeepWINet\u2019s CNN activation features, computed from the connected components of the writing, are passed to a customized nearest neighbor classifier for writer identification. In the second scenario, DeepWINet is evaluated as an end-to-end CNN network where the predicted results are averaged using an efficient strategy, Score Averaging Component-Decision Combiner. The proposed approach achieves competitive or the highest State-Of-The-Art performance on eight challenging handwritten databases with different languages.","Class-incremental continual learning is an important area of research, as static deep learning methods fail to adapt to changing tasks and data distributions. In previous works, promising results were achieved using replay and compressed replay techniques. In the field of regular replay, GDumb [23] achieved outstanding results but requires a large amount of memory. This problem can be addressed by compressed replay techniques. The goal of this work is to evaluate compressed replay in the pipeline of GDumb. We propose FETCH, a two-stage compression approach. First, the samples from the continual datastream are encoded by the early layers of a pre-trained neural network. Second, the samples are compressed before being stored in the episodic memory. Following GDumb, the remaining classification head is trained from scratch using only the decompressed samples from the reply memory. We evaluate FETCH in different scenarios and show that this approach can increase accuracy on CIFAR10 and CIFAR100. In our experiments, simple compression methods (e.g., quantization of tensors) outperform deep autoencoders. In the future, FETCH could serve as a baseline for benchmarking compressed replay learning in constrained memory scenarios.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201dco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","Text classification is a fundamental task in Text Mining (TM) with applications ranging from spam detection to sentiment analysis. One of the current approaches to this task is Graph Neural Network (GNN), primarily used to deal with complex and unstructured data. However, the scalability of GNNs is a significant challenge when dealing with large-scale graphs. Multilevel optimization is prominent among the methods proposed to tackle the issues that arise in such a scenario. This approach uses a hierarchical coarsening technique to reduce a graph, then applies a target algorithm to the coarsest graph and projects the output back to the original graph. Here, we propose a novel approach for text classification using GNN. We build a bipartite graph from the input corpus and then apply the coarsening technique of the multilevel optimization to generate ten contracted graphs to analyze the GNN\u2019s performance, training time, and memory consumption as the graph is gradually reduced. Although we conducted experiments on text classification, we emphasize that the proposed method is not bound to a specific task and, thus, can be generalized to different problems modeled as bipartite graphs. Experiments on datasets from various domains and sizes show that our approach reduces memory consumption and training time without significantly losing performance.","The growing demand for sustainable development brings a series of information technologies to help agriculture production. Especially, the emergence of machine learning applications, a branch of artificial intelligence, has shown multiple breakthroughs which can enhance and revolutionize plant pathology approaches. In recent years, machine learning has been adopted for leaf disease classification in both academic research and industrial applications. Therefore, it is enormously beneficial for researchers, engineers, managers, and entrepreneurs to have a comprehensive view about the recent development of machine learning technologies and applications for leaf disease detection. This study will provide a survey in different aspects of the topic including data, techniques, and applications. The paper will start with publicly available datasets. After that, we summarize common machine learning techniques, including traditional (shallow) learning, deep learning, and augmented learning. Finally, we discuss related applications. This paper would provide useful resources for future study and application of machine learning for smart agriculture in general and leaf disease classification in particular.","Social media's explosive growth brings with it a variety of societal risks ranging from severely harmful issues such as dangerous organizations and child sexual exploitation to moderately harmful content like displays of aggression, borderline nudity to benign or distasteful contents like gross videos and baity content. In recent times, the multitude and magnitude of these harms is being further exacerbated with the advent of generative AI [5]. Meta is committed to ensuring that Facebook is a place where people feel empowered to communicate and we take our role seriously in keeping abuse off the platform [7]. In this talk, I will describe practical challenges and lessons learned from tackling bad experiences for users on Facebook, particularly in the subjective, borderline and low quality spectrum of harms using state of the art, scalable machine learning approaches to content understanding, user behavior understanding and personalized ranking.","Addressing fairness in lesion classification from dermatological images is crucial due to variations in how skin diseases manifest across skin tones. However, the absence of skin tone labels in public datasets hinders building a fair classifier. To date, such skin tone labels have been estimated prior to fairness analysis in independent studies using the Individual Typology Angle (ITA). Briefly, ITA calculates an angle based on pixels extracted from skin images taking into account the lightness and yellow-blue tints. These angles are then categorised into skin tones that are subsequently used to analyse fairness in skin cancer classification. In this work, we review and compare four ITA-based approaches of skin tone classification on the ISIC18 dataset, a common benchmark for assessing skin cancer classification fairness in the literature. Our analyses reveal a high disagreement among previously published studies demonstrating the risks of ITA-based skin tone estimation methods. Moreover, we investigate the causes of such large discrepancy among these approaches and find that the lack of diversity in the ISIC18 dataset limits its use as a testbed for fairness analysis. Finally, we recommend further research on robust ITA estimation and diverse dataset acquisition with skin tone annotation to facilitate conclusive fairness assessments of artificial intelligence tools in dermatology. Our code is available at https://github.com/tkalbl/RevisitingSkinToneFairness.","Recognizing threats in baggage X-ray scans is one of the most crucial tasks for ensuring safety in high-risk areas, including airports, shopping malls, and cargoes, radiograph. Due to the rise in terrorist activity, particularly in the previous two decades, the identification of baggage threats has received the most attention. Nevertheless, this process is time-consuming and restricted by the security officer\u2019s inspection capabilities. To overcome this, several frameworks based on deep learning have been suggested to effectively detect contraband items. However, these approaches primarily suffer from the issue of class imbalance, where prohibited objects are rarely seen in the real world compared to harmless baggage content. This paper proposes a novel classification network optimized with the novel compound balanced affinity loss function to address the class imbalance. This proposed loss function is based on the synergic integration of max-margin learning and the effective sample representation. The suggested method is tested on two datasets, COMPASS-XP and SIXray, where it outperforms the state-of-the-art in terms of F1-score by 2.55% and 2.52%, respectively. Also, the proposed approach has surpassed the existing frameworks by attaining accuracy of 89.16% and 70.31%, respectively. To the best of our knowledge, this is the first contour-driven classification framework injected with a compound loss function for highly imbalanced threat classification.","Deep learning models have become increasingly prevalent in various domains, necessitating their deployment on resource-constrained devices. Quantization is a promising way to reduce the model complexity in that it keeps model architecture intact and enables the model to operate on specialized hardwares(e.g., NPU, DSP). Input resolution is also essential in making a trade-off between accuracy and computation.\nIn this paper, we conduct a joint analysis of input resolution and quantization precision on their influence on accuracy for three popular models: ResNet-18, ResNet-50, and MobileNet-V2. By exploring the combined configuration space, we found that better accuracy can be achieved by jointly optimizing the input resolution and quantization bit-width while maintaining the computational complexity.","The twin support vector machines (TWSVM) is a milestone in multi-plane classification with state-of-the-art performance on many classification problems. However, on large scale datasets, the learning speed of TWSVM is expensive. In this paper, we propose a fast twin support vector machines (FTWSVM). In our FTWSVM, a pair of hyperplanes are computed directly from the training dataset without numerical iterations. Experiments on several benchmark datasets show that our method can exhibit good generalization performance and fast learning compared to the fast support vector classifier (FSVC), which specializes in big data problems, and TWSVM, which generalizes well speed.","Deep neural networks have shown promising results on a wide variety of tasks using large-scale and well-annotated training datasets. However, data collected from real-world applications can suffer from two prevalent biases, i.e., long-tailed class distribution and label noise. Previous efforts on long-tailed learning and label-noise learning can only address a single type of data bias, leading to a severe deterioration of their performance. In this paper, we propose a distance-based sample selection algorithm called Stochastic Feature Averaging (SFA), which fits a Gaussian using the exponential running average of class centroids to capture uncertainty in representation space due to label noise and data scarcity. With SFA, we detect noisy samples based on their distances to class centroids sampled from this Gaussian distribution. Based on the identified clean samples, we then propose to train an auxiliary balanced classifier to improve the generalization for the minority class and facilitate the update of Gaussian parameters. Extensive experimental results show that SFA can enhance the performance of existing methods on both simulated and real-world datasets. Further, we propose to combine SFA with the sample-selection approach, distribution-robust, and noise-robust loss functions, resulting in significant improvement in performance over the baselines. Our code is available at https://github.com/HotanLee/SFA.","Despite its wide applications in criminal investigations and clinical communications with patients suffering from autism, automatic micro-expression recognition remains a challenging problem because of the lack of training data and imbalanced classes problems. In this study, we proposed a meta-learning-based multi-model fusion network (Meta-MMFNet) to solve the existing problems. The proposed method is based on the metric-based meta-learning pipeline, which is specifically designed for few-shot learning and is suitable for model-level fusion. The frame difference and optical flow features were fused, deep features were extracted from the fused feature, and finally in the meta-learning-based framework, weighted sum model fusion method was applied for micro-expression classification. Meta-MMFNet achieved better results than state-of-the-art methods on four datasets. The code is available at https://github.com/wenjgong/meta-fusion-based-method.","The increasing use of machine learning in high-stakes domains \u2013 where people\u2019s livelihoods are impacted \u2013 creates an urgent need for interpretable, fair, and highly accurate algorithms. With these needs in mind, we propose a mixed integer optimization (MIO) framework for learning optimal classification trees \u2013 one of the most interpretable models \u2013 that can be augmented with arbitrary fairness constraints. In order to better quantify the \u201cprice of interpretability\u201d, we also propose a new measure of model interpretability called decision complexity that allows for comparisons across different classes of machine learning models. We benchmark our method against state-of-the-art approaches for fair classification on popular datasets; in doing so, we conduct one of the first comprehensive analyses of the trade-offs between interpretability, fairness, and predictive accuracy. Given a fixed disparity threshold, our method has a price of interpretability of about 4.2 percentage points in terms of out-of-sample accuracy compared to the best performing, complex models. However, our method consistently finds decisions with almost full parity, while other methods rarely do.","Enhancing the interpretability of AI techniques is paramount for increasing their acceptability, especially in highly interdisciplinary fields such as remote sensing, in which scientists and practitioners with diverse backgrounds work together to monitor the Earth\u2019s surface. In this context, counterfactual explanations are an emerging tool to characterize the behaviour of machine learning systems, by providing a post-hoc analysis of a given classification model. Focusing on the important task of land cover classification from remote sensing data, we propose a counterfactual explanation approach called CFE4SITS (CounterFactual Explanation for Satellite Image Time Series). One of its distinctive features over existing strategies is the lack of prior assumption on the targeted class for a given counterfactual explanation. This inherent flexibility allows for the automatic discovery of relationship between classes. To assess the quality of the proposed approach, we consider a real-world case study in which we aim to characterize the behavior of a ready-to-use land cover classifier. To this end, we compare CFE4SITS to recent time series counterfactual-based strategies and, subsequently, perform an in-depth analysis of its behaviour.","Kernel functions are a key element in many machine learning methods to capture the similarity between data points. However, a considerable number of these functions do not meet all mathematical requirements to be a valid positive semi-definite kernel, a crucial precondition for kernel-based classifiers such as Support Vector Machines or Kernel Fisher Discriminant classifiers. In this paper, we propose a novel strategy employing a polar decomposition to effectively transform invalid kernel matrices to positive semi-definite matrices, while preserving the topological structure inherent to the data points. Utilizing polar decomposition allows the effective transformation of indefinite kernel matrices from Krein space to positive semi-definite matrices in Hilbert space, thereby providing an efficient out-of-sample extension for new unseen data and enhancing kernel method applicability across diverse classification tasks. We evaluate our approach on a variety of benchmark datasets and demonstrate its superiority over competitive methods.","The issue of imbalanced data in machine learning has gained significant attention in recent years. Imbalanced data, where one class has significantly fewer samples than others, can lead to poor performance for machine learning models, especially in detecting minority class samples. To address this problem, various resampling techniques have been proposed, including the popular SMOTE (Synthetic Minority Over-sampling TEchnique). However, SMOTE suffers from the overlapping problem and may misclassify samples near the separation boundaries. This paper presents a novel framework to optimise border-based-SMOTEs, including Borderline-SMOTE and SVM-SMOTE which were specifically developed to solve the problem of misclassifying border samples. The proposed method ensures that generated samples improve the decision boundaries and are free from overlapping issues. The proposed method is evaluated on synthetic and real-world datasets, and results demonstrate its effectiveness in enhancing the performance of machine learning models, particularly in classifying minority class samples.","Partial label learning (PLL) is a typical weakly supervised learning problem in which each instance is associated with a candidate label set, and among which only one is true. However, the assumption that the ground-truth label is always among the candidate label set would be unrealistic, as the reliability of the candidate label sets in real-world applications cannot be guaranteed by annotators. Therefore, a generalized PLL named Unreliable Partial Label Learning (UPLL) is proposed, in which the true label may not be in the candidate label set. Due to the challenges posed by unreliable labeling, previous PLL methods will experience a marked decline in performance when applied to UPLL. To address the issue, we propose a two-stage framework named Unreliable Partial Label Learning with Recursive Separation (UPLLRS). In the first stage, the self-adaptive recursive separation strategy is proposed to separate the training set into a reliable subset and an unreliable subset. In the second stage, a disambiguation strategy is employed to progressively identify the ground-truth labels in the reliable subset. Simultaneously, semi-supervised learning methods are adopted to extract valuable information from the unreliable subset. Our method demonstrates state-of-the-art performance as evidenced by experimental results, particularly in situations of high unreliability. Code and supplementary materials are available at https://github.com/dhiyu/UPLLRS.","In this paper, we present a prototype selection technique for imbalanced data, Fuzzy Rough Imbalanced Prototype Selection (FRIPS), to improve the quality of the artificial instances generated by the Synthetic Minority Over-sampling TEchnique (SMOTE). Using fuzzy rough set theory, the noise level of each instance is measured, and instances for which the noise level exceeds a certain threshold level are deleted. The threshold is determined using a wrapper approach that evaluates the training Area Under the Curve of candidate subsets. This proposal aims to clean noisy data before applying SMOTE, such that SMOTE can generate high quality artificial data.\nExperiments on artificial data show that FRIPS in combination with SMOTE outperforms state-of-the-art methods, and that it particularly performs well in the presence of noise.","Machine learning research relies to a large extent on experimental observations. The evaluation of classifiers is often carried out by empirical comparison with classifiers generated by different learning algorithms, allowing the identification of the best algorithm for the problem at hand. Nevertheless, previously to this evaluation, it is important to state if the classifiers have truly learned the domain class concepts, which can be done by comparing the classifiers\u2019 predictive measures with the ones from the baseline classifiers. A baseline classifier is the one constructed by a na\u00efve learning algorithm which only uses the class distribution of the dataset. However, finding na\u00efve classifiers in multi-label learning is not as straightforward as in single-label learning. This work proposes a simple way to find baseline multi-label classifiers. Three specific and one general na\u00efve multi-label classifiers are proposed to estimate the baseline values for multi-label predictive evaluation measures. Experimental results show the suitability of our proposal in revealing the learning power of multi-label learning algorithms.","Skilled employees are the most important pillars of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed to analyze attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource (HR) Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist HR departments in interpreting the predictions provided by machine learning models. In our experiments, we employ eight machine learning models to provide predictions. We further process the results achieved by the best-performing model by the SHAP explainability process and use the SHAP values to generate natural language explanations which can be valuable for HR. Furthermore, using \"What-if-analysis\", we aim to observe plausible causes for attrition of an individual employee. The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions.","When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.","The acquisition of Twitter by Elon Musk has spurred controversy and uncertainty among Twitter users. The move raised both praise and concerns, particularly regarding Musk's views on free speech. As a result, a large number of Twitter users have looked for alternatives to Twitter. Mastodon, a decentralized micro-blogging social network, has attracted the attention of many users and the general media. In this paper, we analyze the migration of 136,009 users from Twitter to Mastodon. We inspect the impact that this has on the wider Mastodon ecosystem, particularly in terms of user-driven pressure towards centralization. We further explore factors that influence users to migrate, highlighting the effect of users' social networks. Finally, we inspect the behavior of individual users, showing how they utilize both Twitter and Mastodon in parallel. We find a clear difference in the topics discussed on the two platforms. This leads us to build classifiers to explore if migration is predictable. Through feature analysis, we find that the content of tweets as well as the number of URLs, the number of likes, and the length of tweets are effective metrics for the prediction of user migration.","As an important branch of weakly supervised learning, partial label learning (PLL) tackles the problem where each training instance is associated with a set of candidate labels, among only one is correct. Most existing PLL algorithms elaborately designed loss functions and update strategies to learn potential ground-truth labels among candidate labels with deep neural networks. However, these algorithms are susceptible to the cumulative error caused by noisy label propagation when updating label confidences, this will make the deep models tend to overfit the noisy labels, thereby achieving poor generation performance. To remedy this issue, we propose a general framework multi-class partial hinge loss (MPHL) for PLL, which can disambiguate the candidate labels by optimizing the margin between the maximum modeling output from partial labels and that from non-partial ones. More importantly, the partial hinge loss can adaptively optimize the separation hyperplane to reduce the influence of cumulative error. Meanwhile, we introduce graph laplacian regularization to full mine the relationship between candidate labels of similar instances to constrain the separation hyperplane to improve the robustness of disambiguation. Extensive experimental results demonstrate that the multi-class partial hinge loss significantly outperforms the state-of-the-art counterparts.","In this work, we try to address the two challenging problems in machine learning (ML) which are: (a) the need for large amounts of labeled images for training supervised classifiers and (b) the supervised classification for time series data. We formulate the problem as an image classification task by transforming time series into domain-specific 2D features such as the scalogram and recurrence plot (RP). Such domain-specific features provide additional information to the models in contrast to raw time series data and enable us to take advantage of powerful state-of-the-art image classifiers for learning the patterns from these textured images. However, the requirement for large amounts of labeled image data is a major drawback in image classification. Thus, to address this problem, we propose to develop a multimodal fusion-deep reinforcement learning (MMF-DRL) approach as an alternative technique to traditional supervised image classifiers for the classification of time series. The two modalities scalograms and RP are fused together to make a multimodal dataset which is then fed into various models for comparison between supervised and RL approaches for time series classification. Our approach produces better accuracy than the state-of-the-art ChronoNet while needing fewer training examples. We validated our MMF-DRL approach using two different physiological time series datasets. Our results show the merit of using multiple modalities and RL in achieving better classification performance than training on a single modality. Moreover, with our approach, we got the highest accuracy of 90.20% and 89.63% respectively for the two datasets with less training data in contrast to the state-of-the-art SL model ChronoNet which gave 87.62% and 88.02% accuracy respectively for the two datasets with higher training data.","The aggregation of multiple opinions plays a crucial role in decision-making, such as in hiring and loan review, and in labeling data for supervised learning. Although majority voting and existing opinion aggregation models are effective for simple tasks, they are inappropriate for tasks without objectively true labels in which disagreements may occur. In particular, when voter attributes such as gender or race introduce bias into opinions, the aggregation results may vary depending on the composition of voter attributes. A balanced group of voters is desirable for fair aggregation results but may be difficult to prepare. In this study, we consider methods to achieve fair opinion aggregation based on voter attributes and evaluate the fairness of the aggregated results.\nTo this end, we consider an approach that combines opinion aggregation models such as majority voting and the Dawid and Skene model (D&amp;S model) with fairness options such as sample weighting. To evaluate the fairness of opinion aggregation, probabilistic soft labels are preferred over discrete class labels. First, we address the problem of soft label estimation without considering voter attributes and identify some issues with the D&amp;S model. To address these limitations, we propose a new Soft D&amp;S model with improved accuracy in estimating soft labels. Moreover, we evaluated the fairness of an opinion aggregation model, including Soft D&amp;S, in combination with different fairness options using synthetic and semi-synthetic data. The experimental results suggest that the combination of Soft D&amp;S and data splitting as a fairness option is effective for dense data, whereas weighted majority voting is effective for sparse data. These findings should prove particularly valuable in supporting decision-making by human and machine-learning models with balanced opinion aggregation.","Federated learning encounters a critical challenge of data heterogeneity, adversely affecting the performance and convergence of the federated model. Various approaches have been proposed to address this issue, yet their effectiveness is still limited. Recent studies have revealed that the federated model suffers severe forgetting in local training, leading to global forgetting and performance degradation. Although the analysis provides valuable insights, a comprehensive understanding of the vulnerable classes and their impact factors is yet to be established. In this paper, we aim to bridge this gap by systematically analyzing the forgetting degree of each class during local training across different communication rounds. Our observations are: (1) Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance. (2) When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold, indicating that the local model struggles to leverage a few samples of a specific class effectively to prevent forgetting. Motivated by these findings, we propose a novel and straightforward algorithm called Federated Knowledge Anchor (FedKA). Assuming that all clients have a single shared sample for each class, the knowledge anchor is constructed before each local training stage by extracting shared samples for missing classes and randomly selecting one sample per class for non-dominant classes. The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes. Extensive experimental results demonstrate that our proposed FedKA achieves fast and stable convergence, significantly improving accuracy on popular benchmarks.","Frauds using credit card are easily done by the fraudsters. Due to increase in fraud rates all over the world, various machine learning algorithms are being used by analysts and researchers to detect and analyze frauds in online transactions. However, training data set may have a few instances of one and more instances of another class in case of binary classification particular class which makes result biased. Hence, this paper sets an objective to give methodology which is able to detect fraud accurately in case for skewness of data. The proposed method compares different techniques to handle imbalance problem and chooses best approach out of these and uses XGBoost as classifier to predict whether transaction is fraudulent or not. The developed method is evaluated using European credit card fraud dataset and obtained better F1 score, recall and accuracy as 82.78%, 78.9% and 99.3% respectively as compared to other algorithms taken under study.","Tsetlin machine (TM) is a logic-based machine learning approach with the crucial advantages of being transparent and hardware-friendly. While TMs match or surpass deep learning accuracy for an increasing number of applications, large clause pools tend to produce clauses with many literals (long clauses). As such, they become less interpretable. Further, longer clauses increase the switching activity of the clause logic in hardware, consuming more power. This paper introduces a novel variant of TM learning - Clause Size Constrained TMs (CSC-TMs) - where one can set a soft constraint on the clause size. As soon as a clause includes more literals than the constraint allows, it starts expelling literals. Accordingly, oversized clauses only appear transiently. To evaluate CSC-TM, we conduct classification, clustering, and regression experiments on tabular data, natural language text, images, and board games. Our results show that CSC-TM maintains accuracy with up to 80 times fewer literals. Indeed, the accuracy increases with shorter clauses for TREC, IMDb, and BBC Sports. After the accuracy peaks, it drops gracefully as the clause size approaches a single literal. We finally analyze CSC-TM power consumption and derive new convergence properties.","Instance selection (IS) serves as a vital preprocessing step, particularly in addressing the complexities associated with high-dimensional problems. Its primary goal is the reduction of data instances, a process that involves eliminating irrelevant and superfluous data while maintaining a high level of classification accuracy. IS, as a strategic filtering mechanism, addresses these challenges by retaining essential instances and discarding hindering elements. This refinement process optimizes classification algorithms, enabling them to excel in handling extensive datasets. In this research, IS offers a promising avenue to strengthen the effectiveness of classification in various real-world applications.","This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as three other \"smart\" selection mechanisms -- Oort [51], TiFL [15] and gradient clustering [27] using four real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17-20 percentage points with 20-60% lower communication costs, and these benefits endure in the presence of straggler participants.","Over the past few decades, a lot of new neural network architectures and deep learning (DL)-based models have been developed to tackle problems more efficiently, rapidly, and accurately. For classification problems, it is typical to utilize fully connected layers as the network head. These dense layers used in such architectures have always remained the same \u2013 they use a linear transformation function that is a sum of the product of output vectors with weight vectors, and a trainable linear bias. In this study, we explore a different mechanism for the computation of a neuron\u2019s output. By adding a new feature, involving a product of higher order output vectors with their respective weight vectors, we transform the conventional linear function to higher order functions, involving powers over two. We compare and analyze the results obtained from six different transformation functions in terms of training and validation accuracies, on a custom neural network architecture, and with two benchmark datasets for image classification (CIFAR-10 and CIFAR-100). While the dense layers perform better in all epochs with the new functions, the best performance is observed with a quadratic transformation function. Although the final accuracy achieved by the existing and new models remain the same, initial convergence to higher accuracies is always much faster in the proposed approach, thus significantly reducing the computational time and the computational resources required. This model can improve the performance of every DL architecture that uses a dense layer, with remarkably higher improvement in larger architectures that incorporate a very high number of parameters and output classes.","Shapelets are subsequences that are effective for classifying time-series instances. Learning shapelets by a continuous optimization has recently been studied to improve computational efficiency and classification performance. However, existing methods have employed predefined and fixed shapelet lengths during the continuous optimization, despite the fact that shapelets and their lengths are inherently interdependent and thus should be jointly optimized. To efficiently explore shapelets of high quality in terms of interpretability and inter-class separability, this study makes the shapelet lengths continuous and learnable. The proposed formulation jointly optimizes not only a binary classifier and shapelets but also shapelet lengths. The derived SGD optimization can be theoretically interpreted as improving the quality of shapelets in terms of shapelet closeness to the time series for target / off-target classes. We demonstrate improvements in area under the curve, total training time, and shapelet interpretability on UCR binary datasets.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts, however they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","The robustness of graph classification models plays an essential role in providing highly reliable applications. Previous studies along this line primarily focus on seeking the stability of the model in terms of overall data metrics (e.g., accuracy) when facing data perturbations, such as removing edges. Empirically, we find that these graph classification models also suffer from semantic bias and confidence collapse issues, which substantially hinder their applicability in real-world scenarios. To address these issues, we present MGRL, a multi-view representation learning model for graph classification tasks that achieves robust results. Firstly, we proposes an instance-view consistency representation learning method, which utilizes multigranularity contrastive learning technique to perform semantic constraints on instance representations at both the node and graph levels, thus alleviating the semantic bias issue. Secondly, we proposes a class-view discriminative representation learning method, which employs the prototype-driven class distance optimization technique to adjust intra- and interclass distances, thereby mitigating the confidence collapse issue. Finally, extensive experiments and visualizations on eight benchmark dataset demonstrate the effectiveness of MGRL.","Orthopedic implant identification is an important and necessary step prior to performing revision surgery of different joints. The inability to identify an implant can lead to significant surgical difficulties with consequent unfavorable outcomes. This paper proposes a novel framework to identify the make and model of seven (7) different total shoulder arthroplasty implants utilizing plain X-ray images and Artificial intelligence. The proposed work classified implants with an accuracy of 91.48% and with an AUC (Area under curve) of 0.9932 showing higher effectiveness in orthopedic implant identification. Further work is required to enhance and progress this work, with a goal of greater accuracy and fewer errors.","Skip Abstract Section\nAbstract\nBreast cancer is a divergent and prominent cancer that is responsible for the morbidity and mortality of women throughout the world. This paper aims at early detection and accurate diagnosis of this fatal disease, which is one of the most important steps in breast cancer treatment. Therefore, various nested ensemble machine learning techniques are used to help doctors determine breast cancer at an early stage. The two-layer nested ensemble model has been proposed, which encompasses stacking and voting techniques to detect benign and malignant breast cancer tumors. A total of four two-layer nested ensemble models have been proposed. S(NaiveBayes)-V(3-Meta_Learner), S(BayesNet)-V(3-Meta_Learner), S(NaiveBayes)-V(4-Meta_Learner), and S(BayesNet)-V(4-Meta_Learner) have been designed to contain base learners and meta learners. The experiments have been conducted with the k-fold cross-validation technique for model evaluation. The proposed model is capable of classifying benign and malignant breast cancer tumors with 99.50% accuracy. The aforementioned four models have been compared with previous works in terms of classification accuracy, ROC, recall, precision, TP rate, FP rate, and F1 measure. The experiments showed that the proposed two-layer nested ensemble model S(BayesNet)-V(4-Meta_Learner) performed better than the other three models mentioned supra and competed with all the previously published works. This would help the scientific community and health practitioners diagnose breast cancer with early and accurate results.","The primary research objective of this study is to develop an algorithm pipeline for recognizing human locomotion activities using multimodal sensor data from smartphones, while minimizing prediction errors due to data differences between individuals. The multimodal sensor data provided for the 2023 SHL recognition challenge comprises three types of motion data and two types of radio sensor data. Our team, \u2018HELP,\u2019 presents an approach that aligns all the multimodal data to derive a form of vector composed of 106 features, and then blends predictions from multiple learning models which are trained using different number of feature vectors. The proposed neural network models, trained solely on data from a specific individual, yield F1 scores of up to 0.8 in recognizing the locomotion activities of other users. Through post-processing operations, including the ensemble of multiple learning models, it is expected to achieve a performance improvement of 10% or greater in terms of F1 score.","Binary classification models are ubiquitous, and reliably measuring their performance is critical for their proper usage. Ideally, the performance of supervised models is measured using high-quality labeled datasets that are sufficiently large and representative of the population. However, obtaining labels for all segments of the population can be difficult, and model performance typically varies across different segments of the population (e.g., in different countries). In this work, we present a novel methodology to estimate the performance of a binary classifier in segments of the population where labels are unavailable. The main idea is that if two segments are \"similar,'' then the performance of the classifier in these two segments would also be \"similar.'' Specifically, we define a way to measure similarity between segments, and propose a statistical model that describes the performance of the model in unlabeled segments as a function of the performance in labeled segments. With extensive numerical experiments on synthetic and real-world datasets, we demonstrate that the proposed method substantially improves over existing methods in both estimation accuracy and computational efficiency. We also showcase the application of our method on the Instagram Adult Classifier to improve the geographic coverage and usability of the model.","In pattern recognition and data mining a data set is named skewed or imbalanced if it contains a large number of objects of certain type and a very small number of objects of the opposite type. The imbalance in data sets represents a challenging problem for most classification methods, this is because the generalization power achieved for classic classifiers is not good for skewed data sets. Many real data sets are imbalanced, so the development of new methods to face this problem is necessary. The SVM classifier has an exceptional performance for data sets that are not skewed, however for imbalanced sets the optimal separating hyper plane is not enough to achieve acceptable results. In this paper a novel method that improves the performance of SVM for skewed data sets is presented. The proposed method works by exciting the support vectors and displacing the separating hyper plane towards majority class. According to the results obtained in experiments with different skewed data sets, the method enhances not only the accuracy but also the sensitivity of SVM classifier on this kind of data sets.","Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. In this study, we examine the various independent factors that affect the Bitcoin-Dollar exchange rate's volatility. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.","Geological disasters result in significant human and property losses. It is imperative to identify areas prone to geological disasters for prevention and monitoring purposes. Identifying disaster-prone areas can be approached as a machine-learning classification problem. Various factors such as elevation, slope, aspect, terrain undulation, vegetation coverage, landform, and soil moisture content can be utilized as input variables for the classification algorithm to determine the probability of landslide occurrence within a specific range. Previous research in this area has been limited and fails to encompass diverse geological environments. This paper addresses this gap by utilizing a dataset collected within a province, which exhibits ample diversity and coverage. The dataset incorporates both continuous and discrete variables, allowing for a comprehensive evaluation of different classification algorithms. The primary objective of this study is to identify the most suitable classification algorithm for those conditions. By comparing the accuracy, ROC curves, and training duration of AdaBoost, cart, gbdt, xgboost, and random forest on multiple test datasets, it was determined that random forest yielded the best performance. The findings of this research can serve as a valuable reference for future related studies.","Parkinson\u2019s disease (PD) is the second most common neurodegenerative disorder, as reported by the World Health Organization (WHO). In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit (SWEDD) and Healthy Control (HC). We use white matter (WM) and gray matter (GM) from the MRI and fractional anisotropy (FA) and mean diffusivity (MD) from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53% for the direct three-class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.","Exposure to UV rays due to global warming can lead to sunburn and skin damage, ultimately resulting in skin cancer. Early prediction of this type of cancer is crucial. A detailed review in this paper explores various algorithms, including machine learning (ML) techniques as well as deep learning (DL) techniques. While deep learning strategies, particularly CNNs, are commonly employed for skin cancer identification and classification, there is also some usage of machine learning and hybrid approaches. These techniques have proven to be effective classifiers of skin lesions, offering promising results for early detection. The paper analyzes various researchers\u2019 reviews on skin cancer diagnosis to identify a suitable methodology for improving diagnostic accuracy. A publicly available dataset of dermoscopic images retrieved from the ISIC archive has been trained and evaluated. Performance analysis is done, considering metrics such as test and validation accuracy. The results indicate that the RF(random forest) algorithm outperforms other machine learning algorithms in both scenarios, with accuracies of 58.57% without augmentation and 87.32% with augmentation. MobileNetv2, ensemble of Dense Net and Inceptionv3 exhibit superior performance. During training without augmentation, MobileNetv2 achieves an accuracy of 88.81%, while the ensemble model achieves an accuracy of 88.80%. With augmentation techniques applied, the accuracies improved to 97.58% and 97.50%, respectively. Furthermore, experiment with a customized convolutional neural network (CNN) model was also conducted, varying the number of layers and applying various hyperparameter tuning methodologies. Suitable architectures, including a CNN with 7 layers and batch normalization, a CNN with 5 layers, and a CNN with 3 layers were identified. These models achieved accuracies of 77.92%, 97.72%, and 98.02% on the raw data and augmentation datasets, respectively. The experimental results suggest that these techniques hold promise for integration into clinical settings, and further research and validation are necessary. The results highlight the effectiveness of transfer learning models, in achieving high accuracy rates. The findings support the future adoption of these techniques in clinical practice, pending further research and validation.","Explaining predictions made by inductive classifiers has become crucial with the rise of complex models acting more and more as black-boxes. Abductive explanations are one of the most popular types of explanations that are provided for the purpose. They highlight feature-values that are sufficient for making predictions. In the literature, they are generated by exploring the whole feature space, which is unreasonable in practice. This paper solves the problem by introducing explanation functions that generate abductive explanations from a sample of instances. It shows that such functions should be defined with great care since they cannot satisfy two desirable properties at the same time, namely existence of explanations for every individual decision (success) and correctness of explanations (coherence). The paper provides a parameterized family of argumentation-based explanation functions, each of which satisfies one of the two properties. It studies their formal properties and their experimental behaviour on different datasets.","In recent years, the imbalanced classification problem has received much attention. SMOTE is one of the most popular methods to improve the performance of unbalanced data classification models. SMOTE changes the data distribution of unbalanced data sets by adding a few generated class samples, but the SMOTE algorithm has some limitations of its own, which may lead to problems such as the generated samples are noisy, the generated samples aggravate the boundary blurring, etc., which are especially obvious in the presence of samples with label noise. Granular-ball computing is an efficient, robust and scalable modeling method developed in the field of granular computing in recent years, and we can obtain clear decision boundaries by dividing data sets through granular-ball. Accordingly, this paper proposes a method, called Granular-ball SMOTE(GBSMOTE),to solve the above problems by first dividing the data set by granular-ball computing and then using SMOTE oversampling inside the granular-ball. The experimental results show the effectiveness of the proposed method, which is more prominent in the samples with label noise.","Real-world applications of artificial intelligence that can potentially harm human beings should be able to express uncertainty about the made predictions. Probabilistic deep learning (DL) methods (e.g., variational inference [VI], VI last layer [VI-LL], Monte-Carlo [MC] dropout, stochastic weight averaging - Gaussian [SWA-G], and deep ensembles) can produce a predictive uncertainty but require expensive MC sampling techniques. Therefore, we evaluated if the probabilistic DL methods are uncertain when making incorrect predictions for an open-source driver intention recognition dataset and if a surrogate DL model can reproduce the uncertainty estimates. We found that all probabilistic DL methods are significantly more uncertain when making incorrect predictions at test time, but there are still instances where the models are very certain but completely incorrect. The surrogate DL models trained on the MC dropout and VI uncertainty estimates were capable of reproducing a significantly higher uncertainty estimate when making incorrect predictions.","Human-centric artificial intelligence struggles to build automated procedures that recognize emotions which can be integrated in artificial systems, such as user interfaces or social robots. In this context, this paper researches on building an Emotion Multi-modal Aggregator (EMmA) that will rely on a collection of open-source single source emotion classification methods aggregated to produce an emotion prediction. Although extendable, tested solution takes a video clip and divides into its frames and audio. Then a collection of primary classifiers are applied to each source and their results are combined in a final classifier utilizing machine learning aggregator techniques. The aggregator techniques that have been put to the test were Random Forest and k-Nearest Neighbors which, with an accuracy of 80%, have demonstrated superior performance over primary classifiers on the selected dataset.","Federated learning (FL), a decentralized machine learning technique, enhances privacy by enabling multiple devices to collaboratively train a model without transferring data to a central server. FL is used in Human Activity Recognition (HAR) problems, where multiple users generating private wearable data share models with a server to learn a useful global model. However, FL may compromise data privacy through model information sharing during training. Moreover, it adheres to a one-size-fits-all approach toward data privacy, potentially neglecting varied user preferences in collaborative scenarios such as HAR. In response to these challenges, this paper presents a collaborative learning framework integrating differential privacy (DP) and FL, thus providing a tailored approach to privacy protection. While some existing works integrate DP and FL, they do not allow clients to have different privacy preferences. In this work, we introduce a framework that allows different clients to have different privacy preferences and hence more flexibility in terms of privacy. In our framework, DP adds individualized noise to individual clients\u2019 gradient updates for privacy. However, such noised updates can also be interpreted as an attack on the FL system. Defending against these attacks might result in excluding honest private clients altogether from training, posing a fairness concern. On the other hand, not having any defensive measures might allow malicious users to attack the system, posing a security issue. Thus, to address security and fairness, our framework incorporates a client selection strategy that protects the global model from malicious clients and provides fair model access to honest private clients. We have demonstrated the effectiveness of our system on a HAR dataset and provided insights into our framework\u2019s privacy, utility, and fairness.","The automatic detection of mental disorders has been mainly performed through binary classifiers trained on the behavioral data collected through an interview setup. Such classifiers are usually trained by keeping the data from the participants having the disorder of interest in the positive class while the data from all other participants are kept in the negative class. In practice, it is well known that some mental disorders have common symptoms. Thus, the behavioral data may carry a mixed bag of attributes related to multiple disorders. As a result, the negative class may carry attributes related to the mental disorder of interest. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, the MDD detection performances are significantly improved. However, such improvement is not observed consistently for PTSD detection, which may attribute to PTSD being a subtype of MDD.","Social and political polarization has become a dramatically intensifying force that is having a huge impact on political discourse, public policies and electoral outcomes in the 21st century. Twitter is a social media platform that mirrors to a large extent the sociological notion of public opinion, and has notably fueled these polarization dynamics worldwide. A proper understanding of how different issues become polarized in Twitter and their interrelationship is therefore crucial for the development of effective policies and governance strategies in our democracies. This paper introduces TwiSP, a framework for analyzing polarization on controversial topics in Twitter. TwiSP utilizes a combination of two cutting-edge machine learning techniques: stance detection for identifying attitudes and perspectives and BERTopic for topic modeling. The outcome of TwiSP is a visual tree-like representation of all tweets related to conflicting topics (rooted in a particular topic), contrasting their relationship using different colors to denote the degree of polarization. As a case study, we show how the TwiSP framework can be used for analyzing polarized issues in the context of the COVID-19 vaccine, exploring the resulting degree of polarization and the key topics driving it. The results reveal the diversity of opinions and the presence of highly polarized clusters in social media discussions. We contend that the TwiSP framework provides a novel and valuable tool for decision makers, helping them to recognize contentious issues behind the dynamics of polarization and ultimately identifying potential opportunities for bridging divides.","Automatic modulation classification (AMC) plays a vital role in modern communication systems, which can support wireless communication systems with limited spectrum resource. This paper proposes an AMC method, which integrates gated recurrent unit (GRU) and convolutional neural network (CNN) to utilize the complementary input features of received signals for spatiotemporal feature extraction and classification. Different from other state-of-the-art (SoA) frameworks, the proposed AMC classifier, named as fusion GRU deep learning neural network (FGDNN), aggregates firstly temporal features with GRUs and then extracts spatial features with CNNs. The GRUs can store temporal dynamic features, and facilitate to capture the characteristics of correlation and dependence among input features. The method is tested extensively with comparisons in order to verify its effectiveness. Experiment results show that the recognition rates of our method outperform other deep learning frameworks.","Forests play a crucial role in sustaining life on earth by providing vital ecosystem services and supporting a wide range of species. The unprecedented increase in forest fires aka \u2018infernos\u2019 due to global warming i.e. rising temperatures and changing weather patterns, is quite alarming. Recently, machine learning and computer vision-based techniques are leveraged to proactively analyze forest fire events. To this end, we propose novel semi-supervised classification and segmentation techniques using autoencoders to analyse forest fires, that require significantly less labelling effort in contrast to the fully-supervised methods. In particular, semi-supervised classification of forest fire using Convolutional autoencoders is proposed. Further, Class Activation Map-based techniques and patch-wise extraction methods are envisaged for the segmentation task. Extensive experiments are carried out on two publicly available large datasets i.e. FLAME and Corsican datasets. The proposed models are found to be outperforming the state-of-the-art approaches.","Machine learning (ML) has become an important tool for the development of Industry 4.0. It assists the machining processes by monitoring and maintaining the conditions. Support vector machine (SVM) is one such algorithm of ML used to train and classify the data. The present work uses the SVM for predicting the surface roughness in the end milling of the low-carbon steel. The experiments were performed at nine different combinations of process parameters. Moreover, to monitor the cutting process online, the current drawn is measured using a current sensor. In this regard, a correlation between the current drawn and variation in surface roughness is reported. The average value of the surface roughness was predicted using the SVM at each combination. The results show that the SVM estimates the surface roughness with an approximate error of 0.4 %-10%. On the other hand, the surface roughness variation does not fit well with the current signals due to the variation in tool wear.","Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose a simple but effective Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header learns from different clients. The acquired global knowledge is then transferred to clients to substitute each client's local prediction header. We derive the non-convex convergence rate of FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH achieves significantly more advantageous performance in both model-homogeneous and -heterogeneous FL scenarios compared to seven state-of-the-art personalized FL models, beating the best-performing baseline by up to 8.87% (for model-homogeneous FL) and 1.83% (for model-heterogeneous FL) in terms of average test accuracy, while saving up to 85.53% of communication overhead.","The predictive performance of machine learning models tends to deteriorate in the presence of class imbalance. Multiple strategies have been proposed to address this issue. A popular strategy consists of oversampling the minority class. Classic approaches such as SMOTE utilize techniques like nearest neighbor search and linear interpolation, which can pose difficulties when dealing with datasets that have a large number of dimensions and intricate data distributions. As a way to create synthetic examples in the minority class, Generative Adversarial Networks (GANs) have been suggested as an alternative technique due to their ability to simulate complex data distributions. However, most GAN-based oversampling methods tend to ignore data uncertainty. In this paper, we propose a novel GAN-based oversampling method using evidence theory. An auxiliary evidential classifier is incorporated in the GAN architecture in order to guide the training process of the generative model. The objective is to push GAN to generate minority objects at the borderline of the minority class, near difficult-to-classify objects. Through extensive analysis, we demonstrate that the proposed approach provides better performance, compared to other popular methods.","Given a large convolutional neural network (CNN) with hundreds of layers, when can the input data be correctly classified? How many layers does each image require? We propose an architecture with a mid-network classifier to classify certain images at earlier points in the model. When the network is very confident about an image, having high activations, then that individual image will be classified early. The number of computations and the average number of convolutions will be reduced if certain images can be classified earlier. In addition, the mid-network classification task is more difficult because fewer features have been extracted at earlier points in the network. Thus, the output and mid-network classifier will work together to correctly classify each image as fast as possible while preserving the accuracy. This proposed method has been implemented into well known computer vision architectures, like ResNet and GoogLeNet Inception. We have achieved large runtime improvements while limiting the accuracy degradation.","Image classification is one of the most fundamental tasks in Computer Vision. In practical applications, the datasets are usually not as abundant as those in the laboratory and simulation, which is always called as Data Hungry. How to extract the information of data more completely and effectively is very important. Therefore, an Adaptive Data Augmentation Framework based on the tensor T-product Operator is proposed in this paper, to triple one image data to be trained and gain the result from all these three images together with only &lt;0.1% increase in the number of parameters. At the same time, this framework serves the functions of column image embedding and global feature intersection, enabling the model to obtain information in not only spatial but frequency domain, and thus improving the prediction accuracy of the model. Numerical experiments have been designed for several models, and the results demonstrate the effectiveness of this adaptive framework. Numerical experiments show that our data augmentation framework can improve the performance of original neural network model by 2%, which provides competitive results to state-of-the-art methods.","With the advent of the information age, there are more and more text data on the Internet. As the most widely distributed information carrier with the largest amount of data, it is particularly important to use text classification technology to organize and manage massive data scientifically. In this paper, a semi-supervised ensemble learning algorithm Heterogeneous-training is proposed and applied to the field of text classification. Based on the Tri-training algorithm, the Heterogeneous-training algorithm improves the traditional Tri-training algorithm by using different classifiers, dynamically updating the probability threshold and adaptively editing data. A large number of experiments show that our method always outperforms Tri-training algorithm in text classification on benchmark text data sets.","Machine Learning has revolutionized the categorization of vast legal documents, minimizing costs and improving evaluations. However, conventional models struggle with unseen data categories in real-world scenarios, a challenge termed Open Set Classification. Our study tackles the issue faced by the Court of Justice in S\u00e3o Paulo, Brazil, to identify recurring lawsuit themes from texts, as manual sorting is inefficient. We introduce a method to enhance confidence in text classification using an open dataset by converting multiclass challenges into binary ones with four confidence tiers. By testing various techniques, we found that combining doc2vec with the Support Vector Machine classifier delivers trustworthy results and robust performance. Ultimately, our method offers an effective solution for classifying legal texts confronting Open Set Classification issues in the legal sector.","The Hierarchical Inference (HI) paradigm has recently emerged as an effective method for balancing inference accuracy, data processing, transmission throughput, and offloading cost. This approach proves particularly efficient in scenarios involving resource-constrained edge devices like micro controller units (MCUs), tasked with executing tinyML inference. Notably, it outperforms strategies such as local inference execution, inference offloading, and split inference (i.e., inference execution distributed between two endpoints). Building upon the HI paradigm, this work explores different techniques aimed at further optimizing inference task execution. We propose three distinct HI approaches and evaluate their utility for image classification.","Imbalanced data has been the focus of ongoing classification research. It describes a scenario where the distribution of data samples is uneven, and one or more classes in the dataset are underrepresented as a result. When trained on such datasets, this mismatch has a negative impact on the performance of conventional learning models. The key problem is in finding appropriate samples for creating synthetic data, even though numerous strategies have been developed to overcome class imbalance during data pre-processing. In this study, we offer an efficient method for overcoming imbalance classification issues caused by oversampling called Informative Sample Selection (ISS). The main goal of ISS is to find useful samples from the minority class in the dataset that may be used to produce data that is synthetic. We conducted experiments on 22 imbalanced datasets to evaluate the performance of our suggested model. We assessed the performance of ISS in comparison to several cutting-edge techniques, including SMOTE, Borderline-SMOTE, ADASYN, safe-level SMOTE, and ROS. AUC and F-Measure were the evaluation measures employed in our study. The outcomes of our tests show that ISS works better than the current approaches, showing significant progress in tackling the challenges brought on by imbalanced data in classification.","In this paper, we propose a new general classification algorithm based on natural neighboring granular spheres, which has good noise immunity and self-adaptability. The old particle sphere generation algorithm is based on purity, and it can have good noise immunity and classification accuracy when the purity threshold is properly selected. However, when the quality of the data is unknown, the selection of the purity threshold will become a difficult problem. The old granular ball generaotr only considers the purity. When the purity reaches the purity threshold, even if the sample points inside the sphere should be divided into two balls, they will not continue to split, which may lead to a large difference between the actual distribution of the generated spheres and the sample points, and cause a negative impact on the next algorithm based on the sphere calculation. To address this situation, this paper proposes to continue the splitting of such balls by applying the natural neighbor-based clustering algorithm: LORE, which does not need parameter k, and thus can provide an effective basis for the granular ball generator.","Information-theoretic measures have been commonly applied to evaluate the relevance and redundancy in multi-label feature selection. However, the current multi-label feature selection methods based on information-theoretic measures neglect the dynamic changes in the relevance of selected features and candidate features. Furthermore, they also do not fully consider the influence of label redundancy on the relevance of candidate features. In this paper, we first propose a new feature relevance term named Dynamic Correlation Change (DCC), which uses two conditional mutual information terms to evaluate the dynamic changes in the relevance of selected features and candidate features. We then introduce a new label redundancy term named Label Redundancy with Interaction Information (LRII), which more accurately quantifies the influence of label redundancy on the relevance of candidate features. On this basis, we design a new multi-label feature selection method, called Maximum Dynamic Correlation Change and Minimum Label Redundancy (MDCCMLR), by combining DCC and LRII. Finally, we conduct extensive experiments in order to verify the performance of our method by comparing it with some state-of-the-art multi-label feature selection methods based on information-theoretic measures in terms of six evaluation metrics. The experimental results show that the MDCCMLR method outperforms the other comparison methods on all six evaluation metrics.","Many existing image and text sentiment analysis methods only consider the interaction between image and text modalities, while ignoring the inconsistency and correlation of image and text data, to address this issue, an image and text aspect level multimodal sentiment analysis model using transformer and multi-layer attention interaction is proposed. Firstly, ResNet50 is used to extract image features, and RoBERTa-BiLSTM is used to extract text and aspect level features. Then, through the aspect direct interaction mechanism and deep attention interaction mechanism, multi-level fusion of aspect information and graphic information is carried out to remove text and images unrelated to the given aspect. The emotional representations of text data, image data, and aspect type sentiments are concatenated, fused, and fully connected. Finally, the designed sentiment classifier is used to achieve sentiment analysis in terms of images and texts. This effectively has improved the performance of sentiment discrimination in terms of graphics and text.","NAVTEX is a crucial marine safety information broadcasting system for ensuring the safe navigation of ships, which plays a significant role in ship safety. However, the current manual reading and subject classification of NAVTEX suffer from low efficiency and accuracy. To enhance the processing efficiency of maritime safety information (MSI) and promote information and communication, achieving automated MSI classification with high confidence in the accuracy of the results becomes imperative. In the context of machine learning, this study proposes an adaptive weight TFIDF method to address the aforementioned challenges. The primary objective is to optimize the weights of keywords with prominent classification features in NAVTEX. Experimental results demonstrate that the adaptive weight-based TFIDF algorithm significantly improves the classification outcomes for NAVTEX. By enhancing the accuracy and efficiency of MSI classification, this approach facilitates the automation of NAVTEX analysis and promotes the reliability of the generated classification results.","Enduring stress can have negative impacts on human health and behavior. Widely used wearable devices are promising for assessing, monitoring and potentially alleviating high stress in daily life. Although numerous automatic stress recognition studies have been carried out in the laboratory environment with high accuracy, the performance of daily life studies is still far away from what the literature has in laboratory environments. Since the physiological signals obtained from these devices are time-series data, Recursive Neural Network (RNN) based classifiers promise better results than other machine learning methods. However, the performance of RNN-based classifiers has not been extensively evaluated (i.e., with several variants and different application techniques) for detecting daily life stress yet. They could be combined with CNN architectures, applied to raw data or handcrafted features. In this study, we created different RNN architecture variants and explored their performance for recognizing daily life stress to guide researchers in the field.","Architectural floor plan is an essential document to share the building information among designers, and engineers. Automatic floor plan image analysis is useful to extract various information from the floor plan. Wall segmentation is an important step in floor plan image analysis. However, few research works have been conducted for automatic wall recognition in an architectural floor plan. In this paper, a convolution neural network, namely WallNet, is proposed to recognize the multi-class walls. The WallNet consists of an encoder and a decoder. The encoder captures low-level features, as well as multiscale contextual information. Based on these extracted feature maps, the walls are detected. The proposed network is applied to recognize five different classes of walls: solid-wall, dot-wall, diagonal-wall, hollow-wall and gray-wall. The experimental results show that the proposed architecture can obtain a mean average precision of 72%, which is superior compared to the state-of-the-art techniques.","The recent pandemic has witnessed a parallel infodemic happening on social media platforms, leading to fear and anxiety within the population. Traditional machine learning (ML) frameworks for fake news detection are limited by the availability of data for training the model. By the time sufficient labeled datasets are available, the existing infodemic may itself come to an end. We propose a COVID-19 fake news detection framework using cross-domain classification techniques to achieve high levels of accuracy while reducing the waiting time for large training datasets to become available. We investigate the effectiveness of three approaches: Domain Adaptive Training, Transfer Learning, and Knowledge Distillation that reuse ML models from past infodemics to improve the accuracy in detecting COVID-19 fake news. Experiments with real-world datasets depict that Transfer Learning performs better than Domain Adaptive Training and Knowledge Distillation techniques.","Social media is awash with hateful content, much of which is often veiled with linguistic and topical diversity. The benchmark datasets used for hate speech detection do not account for such divagation as they are predominantly compiled using hate lexicons. However, capturing hate signals becomes challenging in neutrally-seeded malicious content. Thus, designing models and datasets that mimic the real-world variability of hate warrants further investigation.\nTo this end, we present GOTHate, a large-scale code-mixed crowdsourced dataset of around 51k posts for hate speech detection from Twitter. GOTHate is neutrally seeded, encompassing different languages and topics. We conduct detailed comparisons of GOTHate with the existing hate speech datasets, highlighting its novelty. We benchmark it with 10 recent baselines. Our extensive empirical and benchmarking experiments suggest that GOTHate is hard to classify in a text-only setup. Thus, we investigate how adding endogenous signals enhances the hate speech detection task. We augment GOTHate with the user's timeline information and ego network, bringing the overall data source closer to the real-world setup for understanding hateful content. Our proposed solution HEN-mBERT is a modular, multilingual, mixture-of-experts model that enriches the linguistic subspace with latent endogenous signals from history, topology, and exemplars. HEN-mBERT transcends the best baseline by 2.5% and 5% in overall macro-F1 and hate class F1, respectively. Inspired by our experiments, in partnership with Wipro AI, we are developing a semi-automated pipeline to detect hateful content as a part of their mission to tackle online harm.","Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstrates an average accuracy improvement of 3.10% on two synthetic noise datasets and 1.48% on three real-world noise datasets compared to the previous state-of-the-art. Extensive experiments and analyses show the effectiveness of each component in DyGen. Our code is available for reproducibility on GitHub.","For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model\u2014DWT-CompCNN\u2014is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted from the compressed images. Experiments are performed on two benchmark datasets, Tobacco-3482 and RVL-CDIP, which demonstrate that the proposed model is time and space efficient, and also achieves a better classification accuracy in compressed domain.","Stress detection is important for ensuring overall mental well-being of an individual. Literature suggests several approaches for prediction or classification of stress. However, the performance of these approaches varies a lot across subjects and tasks. Moreover, perception of stress is highly subjective and hence it is difficult to create a generic model/devices for prediction of stress. In this study, we have proposed an approach for creating a generic stress prediction model by combining the knowledge and variety from multiple public datasets containing galvanic skin response (GSR) data recorded during different context and activities. Most significant features are selected from these recorded signals and a voting based approach was finally adopted to develop a model for predicting mental stress. Proposed model has been validated using test data as well as a set of completely unseen data collected in our lab. We achieved an average classification accuracy of 89% (F-score 0.87) for test data and similar performance for completely unseen data as well. Results show that the proposed model outperforms the training models created using individual datasets. In addition, our model is created using skin response data recorded using off-the-shelf devices. Thus, our proposed model with selected feature set can be used for monitoring stress in real life scenarios and to create mass-market stress prediction products.","Immune repertoire classification, a typical multiple instance learning (MIL) problem, is a frontier research topic in computational biology that makes transformative contributions to new vaccines and immune therapies. However, the traditional instance-space MIL, directly assigning bag-level labels to instances, suffers from the massive amount of noisy labels and extremely low witness rate. In this work, we propose a noisy-label-learning formulation to solve the immune repertoire classification task. To remedy the inaccurate supervision of repertoire-level labels for a sequence-level classifier, we design a robust training strategy: The initial labels are smoothed to be asymmetric and are progressively corrected using the model's predictions throughout the training process. Furthermore, two models with the same architecture but different parameter initialization are co-trained simultaneously to remedy the known \"confirmation bias\" problem in the self-training-like schema. As a result, we obtain accurate sequence-level classification and, subsequently, repertoire-level classification. Experiments on the Cytomegalovirus (CMV) and Cancer datasets demonstrate our method's effectiveness and superior performance on sequence-level and repertoire-level tasks. Code available at https://github.com/TencentAILabHealthcare/NLL-IRC.","Methods to classify objects into two or more classes are at the core of various disciplines. When a set of objects with their true classes is available, a supervised classifier can be trained and employed to decide if, for example, a new patient has cancer or not. The choice of performance measure is critical in deciding which supervised method to use in any particular classification problem. Different measures can lead to very different choices, so the measure should match the objectives. Many performance measures have been developed, and one of them is the F-measure, the harmonic mean of precision and recall. Originally proposed in information retrieval, the F-measure has gained increasing interest in the context of classification. However, the rationale underlying this measure appears weak, and unlike other measures, it does not have a representational meaning. The use of the harmonic mean also has little theoretical justification. The F-measure also stresses one class, which seems inappropriate for general classification problems. We provide a history of the F-measure and its use in computational disciplines, describe its properties, and discuss criticism about the F-Measure. We conclude with alternatives to the F-measure, and recommendations of how to use it effectively.","Near infrared fluorescence optical imaging (NIR-FOI) is a relatively new imaging modality to diagnose arthritis in the hands. The acquired data has two spatial dimensions and one temporal dimension, which visualizes the time dependent distribution of an administered color agent. In accordance with previous work, we hypothesize that the distribution process allows a joint-wise classification into inflammatory affected and unaffected.\nIn this work, we present the first approach to objectively classify hand joint NIR-FOI image stacks by designing, training, and testing a neural network. Previously presented model architectures for spatio-temporal classification do not yield satisfying results when trained on NIR-FOI data. A recall value of 0.812 of the over- and a recall value of 0.652 of the underrepresented class is achieved, the model\u2019s robustness tested against small variations and its attention visualized in activation maps.\nEven though these results leave room for further improvement, they also indicate, that the model architecture can capture the latent features of the data. We are confident, that more available data will lead to a robust classification model and can support medical doctors in using NIR-FOI as a diagnostic tool for PsA.","The Human Mobility Signature Identification (HuMID) problem aims at determining whether the incoming trajectories were generated by a claimed agent from the historical movement trajectories of a set of individual human agents such as pedestrians and taxi drivers. The HuMID problem is significant, and its solutions have a wide range of real-world applications, such as criminal identification for police departments, risk assessment for auto insurance providers, driver verification in ride-sharing services, and so on. Though Deep neural networks (DNN) based HuMID models on spatial-temporal mobility fingerprint similarity demonstrate remarkable performance in effectively identifying human agents' mobility signatures, it is vulnerable to adversarial attacks as other DNN-based models. Therefore, in this paper, we propose a Spatial-Temporal iterative Fast Gradient Sign Method with L0 regularization - ST-iFGSM - to detect the vulnerability and enhance the robustness of HuMID models. Extensive experiments with real-world taxi trajectory data demonstrate the efficiency and effectiveness of our ST-iFGSM algorithm. We tested our method on both the ST-SiameseNet and an LSTM-based HuMID classification model. It shows that ST-iFGSM can generate successful attacks to fool the HuMID models with only a few steps of attack in a small portion of the trajectories. The generated attacks can be used as augmented data to update and improve the HuMID model accuracy significantly from 47.36% to 76.18% on testing samples after the attack(86.25% on the original testing samples).","Accurate integration of high-dimensional single-cell sequencing datasets is important for the construction of cell atlases and for the discovery of biomarkers. Because the performance of integration methods varies in different scenarios and on different datasets, it is important to provide end users with an automated system for the benchmarking and selection of the best integration among several alternatives. Here, we present a system that uses an ensemble of auditors, trained by supervised machine learning, which quantifies residual variability of integrated data and automatically selects the integration with the smallest difference between observed and expected batch effects. A rigorous and systematic validation was performed using 6 popular integration methods and 52 benchmark datasets. Algorithmic and data biases were uncovered and shortcomings of existing validation metrics were examined. Our results demonstrate the utility, validity, flexibility and consistency of the proposed approach.","In this paper we summarize the contributions of participants to the fifth Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenge organized at the HASCA Workshop of UbiComp/ISWC 2023. The goal of this machine learning/data science challenge is to recognize eight locomotion and transportation activities (Still, Walk, Run, Bike, Bus, Car, Train, Subway) from the motion (accelerometer, gyroscope, magnetometer) and GPS (GPS location, GPS reception) sensor data of a smartphone in a user-independent manner. The training data of a \u201ctrain\u201d user is available from smartphones placed at four body positions (Hand, Torso, Bag and Hips). The testing data originates from \u201ctest\u201d users with a smartphone placed at one, but unknown, body position. We introduce the dataset used in the challenge and the protocol of the competition. We present a meta-analysis of the contributions from 15 submissions, their approaches, the software tools used, computational cost and the achieved results. The challenge evaluates the recognition performance by comparing predicted to ground-truth labels at every 10 milliseconds, but puts no constraints on the maximum decision window length. Overall, five submissions achieved F1 scores above 90%, three between 80% and 90%, two between 70% and 80%, three between 50% and 70%, and two below 50%. While the task this year is facing the technical challenges of sensor unavailability, irregular sampling, and sensor diversity, the overall performance based on GPS and motion sensors is better than previous years (e.g. the best performance reported in SHL 2020, 2021 and 2023 are 88.5%, 75.4% and 96.0%, respectively). This is possibly due to the complementary between the GPS and motion sensors and also the removal of constraints on the decision window length. Finally, we present a baseline implementation to help understand the contribution of each sensor modality to the recognition task.","The last decades have witnessed significant progress in machine learning with applications in different safety-critical domains, such as medical, law, education, and transportation. In high-stake domains, machine learning predictions have far-reaching consequences on the end-users. With the aim of applying machine learning for societal goods, there have been increasing efforts to regulate machine learning by imposing interpretability, fairness, robustness, privacy, etc. in predictions. Towards responsible and trustworthy machine learning, we propose two research themes in our dissertation research: interpretability and fairness of machine learning classifiers. In particular, we design algorithms to learn interpretable rule-based classifiers, formally verify fairness, and explain the sources of unfairness. Prior approaches to these problems are often limited by scalability, accuracy, or both. To overcome these limitations, we closely integrate automated reasoning and formal methods with fairness and interpretability to develop scalable and accurate solutions.","We explore solutions for text classification applied to online cooking recipes, in a multitask, multilingual approach. The main objective is designing a solution that ensures high accuracy on the prediction tasks from, but not constrained to, 6 European Languages, considering also the cross-lingual transferability. The challenges of the problem are structured on two main dimensions: (1) data driven - such as imbalance and noise in the training data, and (2) solution driven - such as multilingualism, or the need to easily extend the model to new languages. We propose a solution focused on the XLM-R architecture, fine-tuned jointly on all tasks. We apply self-supervised domain adaptation via additional pre-training and analyze the enhancements produced by performing a 0-shot evaluation for underrepresented languages. Compared to basic language modeling solutions, we obtained an increase of 1.32% and 2.42%, respectively for the two most difficult classification tasks. In the 0-shot context, the absolute improvements are of 16.71% and 7.83% respectively, on underrepresented languages.","The selection of the optimum machine learning technique is a crucial step to detect faults efficiently in the predictive maintenance (PdM) area. Because the performance of the machine learning algorithm changes with respect to a data set, which has different characteristics, including feature number, data size and nonlinearity. The paper considers the problem of detecting faults observed in an autonomous electric drive without using any sensor information. More importantly, we aim to show the opportunities and explore the limitations of machine learning techniques in fault detection. Accordingly, the advantages and disadvantages of different types of machine learning methods including logistic regression, support vector machine, decision tree, navie Bayes, gradient boosting etc. for condition monitoring are discussed with an emphasis given to an autonomous electric drive train. Experimental comparison of machine learning algorithms suggests that the boosting methods yield promising performance in fault classification. The results are supported by statistical analysis.","Transformer-based pre-trained Language Models (PLMs) have emerged as the foundations for the current state-of-the-art algorithms in most natural language processing tasks, in particular when applied to context rich data such as sentences or paragraphs. However, their impact on the tasks defined in terms of abstract individual word properties, not necessary tied to their specific use in a particular sentence, has been inadequately explored, which is a notable research gap. Addressing this gap is crucial for advancing our understanding of natural language processing. To fill this void, we concentrate on classification of semantic relations: given a pair of concepts (words or word sequences) the aim is to identify the semantic label to describe their relationship. E.g. in the case of the pair green/colour, \u201cis a\u201d is a suitable relation while \u201cpart of\u201d, \u201cproperty of\u201d, and \u201copposite of\u201d are not suitable. This classification is independent of a particular sentence in which these concepts might have been used. We are first to incorporate a language model into both existing approaches to this task, namely path-based and distribution-based methods. Our transformer-based approaches exhibit significant improvements over the state-of-the-art and come remarkably close to achieving human-level performance on rigorous benchmarks. We are also first to provide evidence that the standard datasets over-state the performance due to the effect of \u201clexical memorisation.\u201d We reduce this effect by applying lexical separation. On the new benchmark datasets, the algorithmic performance remains significantly below human-level, highlighting that the task of semantic relation classification is still unresolved, particularly for language models of the sizes commonly used at the time of our study. We also identify additional challenges that PLM-based approaches face and conduct extensive ablation studies and other experiments to investigate the sensitivity of our findings to specific modelling and implementation choices. Furthermore, we examine the specific relations that pose greater challenges and discuss the trade-offs between accuracy and processing time.","The destruction of archaeological sites and the loss of archaeological landscapes remains a global concern as populations and urban areas continue to expand. Archaeological sites are not only significant to local communities, national identities, and modern tourist economies but also provide critical knowledge of past sociocultural interactions, settlement patterns, human-environment relationships, and risk mitigation strategies. While archaeological landscapes and site destruction have remained outside of traditional land use land cover change (LULCC) studies, they are a form of urban and agricultural land use. By conceptualizing archaeological site destruction within land change science, this study provides an innovative approach for assessing \u201cwhat's left\u201d of historically surveyed archaeological landscapes. Using a Random Forest algorithm and Landsat satellite data, this study quantifies archaeological site destruction attributed to LULCC in Peru's lower Moche Valley between 1985 and 2020. More than 400 archaeological sites previously recorded during the Chan Chan-Moche Valley Project (CCMVP, 1969\u20131974) are analyzed. Results indicate that less than a quarter of the original CCMVP sites remain on the landscape. The primary drivers of LULCC in the lower Moche Valley include population growth, migration, and government policies, while secondary drivers include heritage values. Positioning archaeological survey data within land change science and integrating machine learning techniques can benefit historic survey reassessments globally and provides significant knowledge of archaeological site destruction and the socioeconomic conditions that underly dynamic landscape changes.","From the perspective of a dialog system, the identification of the intention behind the segments in a dialog is important, as it provides cues regarding the information present in the segments and how they should be interpreted. The ISO 24617-2 standard for dialog act annotation defines a hierarchically organized set of general-purpose communicative functions that correspond to different intentions that are relevant in the context of a dialog. In this paper, we explore the automatic recognition of these functions. To do so, we propose to adapt existing approaches to dialog act recognition, so that they can deal with the hierarchical classification problem. More specifically, we propose the use of an end-to-end hierarchical network with cascading outputs and maximum a posteriori path estimation to predict the communicative function at each level of the hierarchy, preserve the dependencies between the functions in the path, and decide at which level to stop. Additionally, we rely on transfer learning processes to address the data scarcity problem. Our experiments on the Dialog-Bank show that this approach outperforms both flat and hierarchical approaches based on multiple classifiers and that each of its components plays an important role in the recognition of general-purpose communicative functions.","Dynamic early exiting has been proven to improve the inference speed of the pre-trained language model like BERT. However, all samples must go through all consecutive layers before early exiting and more complex samples usually go through more layers, which still exists redundant computation. In this paper, we propose a novel dynamic early exiting combined with layer skipping for BERT inference named SmartBERT, which adds a skipping gate and an exiting operator into each layer of BERT. SmartBERT can adaptively skip some layers and adaptively choose whether to exit. Besides, we propose cross-layer contrastive learning and combine it into our training phases to boost the intermediate layers and classifiers which would be beneficial for early exiting. To keep the consistent usage of skipping gates between training and inference phases, we propose a hard weight mechanism during training phase. We conduct experiments on eight classification datasets of the GLUE benchmark. Experimental results show that SmartBERT achieves 2-3\u00d7 computation reduction with minimal accuracy drops compared with BERT and our method outperforms previous methods in both efficiency and accuracy. Moreover, in some complex datasets like RTE and WNLI, we prove that the early exiting based on entropy hardly works, and the skipping mechanism is essential for reducing computation. Our codes are available at: https://github.com/HuBoren99/SmartBert.","Weeds are a significant threat to agricultural production. Weed classification systems based on image analysis have offered innovative solutions to agricultural problems, with convolutional neural networks (CNNs) playing a pivotal role in this task. However, CNNs are limited in their ability to capture global relationships in images due to their localized convolutional operation. Vision Transformers (ViT) and Pyramid Vision Transformers (PVT) have emerged as viable solutions to overcome this limitation. Our study aims to determine the effectiveness of CNN, PVT, and ViT in classifying weeds in image datasets. We also examine if combining these methods in an ensemble can enhance classification performance. Our tests were conducted on significant agricultural datasets, including DeepWeeds and CottonWeedID15. The results indicate that a maximum of 3 methods in an ensemble, with only 15 epochs in training, can achieve high accuracy rates of up to 99.17%. This study demonstrates that high accuracies can be achieved with ease of implementation and only a few epochs.","It is common to observe significant heterogeneity in clustered data across scientific fields. Cluster-wise conditional distributions are widely used to explore variations and relationships within and among clusters. This paper aims to capture such heterogeneity by employing cluster-wise finite mixture models. To address the heterogeneity among clusters, we introduce latent group structure and incorporate heterogeneous mixing proportions across different groups, accommodating the diverse characteristics observed in the data. The specific number of groups and their membership are unknown. To identify the latent group structure, we employ concave penalty functions to the pairwise differences of the preliminary consistent estimators for the mixing proportions. This approach enables the automatic division of clusters into finite subgroups. Theoretical results demonstrate that as the number of clusters and cluster sizes tend to infinity, the true latent group structure can be recovered with probability close to one, and the post-classification estimators exhibit oracle efficiency. We support our proposed approach\u2019s performance and applicability through extensive simulations and analysis of basic consumption expenditure among urban households in China.","Aspect-based sentiment classification is an important task in natural language processing research, and in response to the fact that most studies at this stage ignore the influence of contextual semantic information on the sentiment polarity of aspect words, our model proposed in this paper combines local aspect word feature extraction and global contextual semantic information extraction based on Bi-directional Long Short-Term Memory (BiLSTM), and after a multi-headed attention mechanism to enhance the local aspect word sentiment representation. Comparative experiments were conducted on the restaurant and laptop datasets of the SEMEVAL2014 evaluation task. The experimental results show that the model proposed in this paper achieves good classification results in the aspect-level sentiment analysis task of text reviews. The method provides a new idea for ABSA task development.","Text sentiment analysis is an important task in natural language processing (NLP), which aims to determine people's emotional tendency towards a certain topic or event by analyzing the language and emotion in the text. Aiming at the traditional emotion classification model can't fully capture the semantic information implied in short text comments, a two-channel emotion classification model based on CNN and BiLSTMl is proposed.Dynamic allocation weights introduced since the attention mechanism, build fusion BiLSTM and CNN's dual channel neural network architecture, and extract the bureau of emotional characteristics and emotional characteristics as global pay attention to the input feature fusion layer, through your emotions full text feature fusion module integration characteristic information and emotional polarity to break..Compared to the experimental results show that the model of emotion classification performance of the optimum Transformer model, this model (CNN-BiLSTM-AFF) on a public data set senti_weibo_100k accuracy, F1 value, the recall rate of 1.034%, 1.265% and 1.045% respectively.","The application of Train of EMU failures Detection System (TEDS) ensures the running safety of EMU. In order to reduce the manual workload and meet the requirements of fine classification monitoring, we researched the automatic classification technology, designed and implemented the corresponding methods, established the TEDS classification chart of all EMU trains at headquarters, and put forward the automatic calculation operation algorithm using multi-source data. Designed the generation scheme of local chart at the monitoring center, the system application function of automatic dispatching is developed, and the classification monitoring based on train running diagram was realized. The application shows that the method proposed in this paper have reduced the manual workload of work effectively, and the capability of abnormal detection has been enhanced, laid the technical foundation for the effective operation monitoring of EMU.","In multi-label classification, it is critical to capitalize on complicated data structures and semantic relationships. Metric learning serves as an effective strategy to provide a better measurement of distances between examples. Existing works on metric learning for multi-label classification mainly learn one single global metric that characterizes latent semantic similarity between multi-label instances. However, such single-semantics metric exploitation approaches can not capture the intrinsic properties of multi-label data possessed of rich semantics. In this paper, the first attempt towards multi-semantics metric learning for multilabel classification is investigated. Specifically, the proposed LIMIC approach simultaneously learns one global and multiple label-specific local metrics by exploiting label-specific side information. The global metric is learned to capture the commonality across all the labels and label-specific local metrics characterize the individuality of each semantic space. The combination of global metric and label-specific local metrics is utilized to construct latent semantic space for each label, in which similar intra-class instances are pushed closer and interclass instances are pulled apart. Furthermore, a metric-based label correlation regularization is constructed to maintain similarity between correlated label spaces. Extensive experiments on benchmark multi-label data sets validate the superiority of our proposed approach in learning effective distance metrics for multi-label classification.","Federated learning (FL) has recently been applied to skin lesion analysis, but the challenges of huge communication requirements and non-independent and identical distributions have not been fully addressed. The former problem arises from model parameter transfer between the server and clients, and the latter problem is due to differences in imaging protocols and operational customs. To reduce communication costs, dataset distillation methods have been adopted to distill thousands of real images into a few synthetic images (1 image per class) in each local client, which are then used to train a global model in the server. However, these methods often overlook the possible inter-client distribution drifts, limiting the performance of the global model. In this paper, we propose a generalizable dataset distillation-based federated learning (GDD-FL) framework to achieve communication-efficient federated skin lesion classification. Our framework includes the generalization dataset distillation (GDD) method, which explicitly models image features of the dataset into an uncertain Gaussian distribution and learns to produce synthetic images with features close to this distribution. The uncertainty in the mean and variance of the distribution enables the synthetic images to obtain diverse semantics and mitigate distribution drifts. Based on the GDD method, we further develop a communication-efficient FL framework that only needs to transmit a few synthesized images once for training a global model. We evaluate our approach on a large skin lesion classification dataset and compare it with existing dataset distillation methods and several powerful baselines. Our results show that our model consistently outperforms them, particularly in comparison to the classical FL method. All resources can be found at https://github.com/jcwang123/GDD-FL.","This paper proposes a novel approach for classifier ensemble by employing the concepts of multi-criteria decision-making (MCDM) and aggregation operators. In this framework, a heterogeneous ensemble process has been incorporated where we consider varied set of classifiers to train the model. Each considered classifier is trained on the training data and a score correspondent to it is generated by utilizing the MCDM process. Subsequently, during the training phase, the priority is generated among the classifiers. For the testing phase, these prioritized classifiers are combined using prioritized aggregation operator. The priority order determined during the training phase is used to ensemble the classifiers during the testing phase. The proposed method is tested on UCI benchmark datasets and outperforms existing state-of-the-art methods.","A fit person who is health conscious always considers weighing what they eat and takes the calories on the food they eat. There is a certain number of calories per day that helps bodybuilders or people who want to stay fit. Taking in considerations of eating Fruits to have the calories, macros and nutrients they need. This study presents fruit calorie estimation using CNN or Convolutional Neural Network, the program was able to detect all the fruits with recognition accuracy of 70% and the percentage difference calorie estimation for each fruit are as follows: apple has 30.58%, banana garnered 21.15%, grapes garnered 44.07% and orange has 32.20%.","Diffuse large B-cell lymphoma (DLBCL) is an aggressive and most common type of non-Hodgkin lymphoma. The two major molecular subtypes of DLBCL, i.e. germinal center B-cell-like (GCB) and activated B-cell-like (ABC) types of DLBCL, have different clinical outcomes when treated with combined therapy R-CHOP. Cell-of-origin (COO) is a published prognostic method. Up to now, this classification requires either complex gene expression analysis or multiple immunohistochemistry (IHC) stains requiring expert scoring and assessment. In this paper, we aim to develop an effective and tissue-saving COO classification method based on H&amp;E stained whole slide images (WSIs). Specifically, we develop a new approach named Cellular Features Based Interpretable Network (CellFiNet), by leveraging both interpretable cellular features derived from image tiles and attention based multi-instance learning (AMIL) framework to train a WSI classification model. In comparison with the conventional AMIL approach based on image embeddings derived from convolutional neural networks (CNNs), the proposed approach achieved comparable classification accuracy, while being favorable in terms of explainability, as the model behavior can be interpreted through both attention scores and biologically relevant feature importances at whole slide as well as image tile levels.","Voice signals are the essential input source for applications based on human and computer interaction technology. Gender identification through voice signals is one of the most challenging tasks. For voice signal based analysis, deep learning algorithms provide an alternative to traditional and conventional algorithms for classification. To identify the gender through voice signals of female, male and \u2018first-time\u2019 transgender, the deep learning algorithm is used to improve the robustness of the identification model with the Mel Frequency Cepstrum Coefficients (MFCC) as a feature of the voice signals. This article presents the identification accuracy of gender with the help of recorded live voice signals. The voice samples of the third gender are recorded in the Hindi language. These Hindi language voice samples of transgender are very low resources and are unavailable at any recognized sources. The simulation results do not depend on the duration of the signals and are text independent. The recurrent neural network \u2013 Bidirectional Long Short-term Memory (RNN \u2013 BiLSTM) algorithm has been simulated on the recorded voice signals. The simulation outcome is compared with the earlier reported results in the literature. The gender-wise average accuracy of the proposed model is achieved as 91.44%, 94.94%, and 96.11% for males, females, and transgender, respectively, using voice signals. The identification accuracy of transgender is high in comparison to other genders. On the other hand, the average accuracy of the proposed model is obtained as 94.16%.","The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.","This paper proposes a real-time voice activity detection (VAD) system that utilizes a compressed convolutional neural network (CNN) model. On general-purpose computers, the system is capable of accurately classifying the presence of speech in audio with low latency. Whereas, when implemented on small devices, the system is showing higher latency, which is presumably an indication of high-load computations in the preprocessing steps. The results of the evaluation indicate that the proposed VAD system is an improvement over the existing solutions, in terms of reducing the model size and improving the level of accuracy among different evaluation metrics. Furthermore, the proposed VAD system offers an extension of the applicability by training the CNN model on a different and more diverse data set. Moreover, the proposed architecture is capable of being compressed to approximately one-eleventh of the size, facilitating eventual deployment on small devices. In contrast to existing closed VAD solutions, the entire pipeline of the proposed VAD system is developed in Python and made available as open source, ensuring the verifiability and accessibility of the work.","In recent years, the prevalence of obesity and its related co-morbidities have been increasing significantly. Therefore, it is an important challenge to pursue an early prediction of obesity risk that could help in reducing the pace of obesity rise when appropriate interventions are placed, accordingly. The prediction and classification of obesity depend on different factors such as body mass index (BMI) and lifestyle aspects, including eating habits. By focusing on these lifestyles and eating habit factors, we can develop a more holistic approach to weight management and prevention of obesity. The aim of this paper is to propose a machine-learning model that can classify weight levels using lifestyle variables without relying on BMI which enables us to investigate how lifestyle factors affect different levels of weight categorization. Although BMI is the most widely used estimation of obesity, there are other factors that can contribute to gaining weight such as lifestyle factors. The accuracy of our lifestyle-based model reached 75% excluding weight, height, and family history. Our model could serve as a starting point for using an interpretable machine learning model to better understand the effect of lifestyle factors on obesity levels.","Past research has demonstrated that the explicit use of protected attributes in machine learning can improve both performance and fairness. Many machine learning algorithms, however, cannot directly process categorical attributes, such as country of birth or ethnicity. Because protected attributes frequently are categorical, they must be encoded as features that can be input to a chosen machine learning algorithm, e.g. support vector machines, gradient boosting decision trees or linear models. Thereby, encoding methods influence how and what the machine learning algorithm will learn, affecting model performance and fairness. This work compares the accuracy and fairness implications of the two most well-known encoding methods: one-hot encoding and target encoding. We distinguish between two types of induced bias that may arise from these encoding methods and may lead to unfair models. The first type, irreducible bias, is due to direct group category discrimination and the second type, reducible bias, is due to the large variance in statistically underrepresented groups. We investigate the interaction between categorical encodings and target encoding regularization methods that reduce unfairness. Furthermore, we consider the problem of intersectional unfairness that may arise when machine learning best practices improve performance measures by encoding several categorical attributes into a high-cardinality feature.","Emotion classification from text is the process of identifying and classifying emotions expressed in textual data. Emotions can be feelings such as anger, joy, suspense, sadness and neutral. Developing a machine learning model to identify emotions in a low-resourced language with a limited set of linguistic resources and annotated corpora is a challenge. This research proposes a Deep Learning Emotion Classification Framework to identify and classify emotions in low-resourced languages such as Hindi. The proposed framework combines a classification model and a low resource optimization technique in a novel way. An annotated corpus of Hindi short stories consisting of 20,304 sentences is used to train the models for predicting five categories of emotions: anger, joy, suspense, sadness, and neutral talk. To resolve the class imbalance in the dataset SMOTE technique is applied. The optimal classification model is selected through experimentation that compares machine learning models and pre-trained models. Machine learning and deep learning models are SVM, Logistic Regression, Random Forest, CNN, BiLSTM, and CNN+BiLSTM. The pre-trained models, mBERT, IndicBERT, and a hybrid model, mBERT+BiLSTM. The models are evaluated based on macro average recall, macro average precision, and macro average F1 score. Results demonstrate that the hybrid model mBERT+BiLSTM out perform other models with a test accuracy of 57%.","Graph representation learning (GRL) is a powerful tool for graph analysis, which has gained massive attention from both academia and industry due to its superior performance in various real-world applications. However, the majority of existing works for GRL are dedicated to node-based tasks and thus focus on producing node representations. Despite such methods can be used to derive edge representations by regarding edges as nodes, they suffer from sub-par result utility in practical edge-wise applications, such as financial fraud detection and review spam combating, due to neglecting the unique properties of edges and their inherent drawbacks. Moreover, to our knowledge, there is a paucity of research devoted to edge representation learning. These methods either require high computational costs in sampling random walks or yield severely compromised representation quality because of falling short of capturing high-order information between edges. To address these challenges, we present TER and AER, which generate high-quality edge representation vectors based on the graph structure surrounding edges and edge attributes, respectively. In particular, TER can accurately encode high-order proximities of edges into low-dimensional vectors in a practically efficient and theoretically sound way, while AER augments edge attributes through a carefully-designed feature aggregation scheme. Our extensive experimental study demonstrates that the combined edge representations of TER and AER can achieve significantly superior performance in terms of edge classification on 8 real-life datasets, while being up to one order of magnitude faster than 16 baselines on large graphs.","For training and testing enhancer-promoter interaction (EPI) classifiers, the question on which non-positive EPIs are selected as negative instances must be answered. Most previous methods use the dataset of the EPI classifier TargetFinder where negative EP pairs are sampled from non-positive EP pairs. Consequently, over 92% of EPIs in the TargetFinder-positive and negative sets of cell line GM12878 have a 2-fold or greater positive/negative class imbalance of promoter occurrences between the positive and negative EP pairs. This situation negatively impacts the predictability of EPI classifiers trained using the datasets.\nThus, we first proposed the condition that the negative EPIs should satisfy. Second, we devised a method called CBOEP (class balanced occurrences of enhancers and promoters), to generate negative EPI sets that approximately fulfil this condition for a given positive EPI set. CBOEP solves the finding problem by reducing it to the maximum-flow problem. Third, we applied the generated negative EPI sets to existing EPI classifiers, TransEPI and TargetFinder. The negative datasets lead to higher prediction performance than the existing negative EPI datasets. The source code is available at https://github.com/maruyama-lab-design/CBOEP.","Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on public datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using standard commercial hardware. Moreover, large-spread ensembles are more robust than traditional ensembles against evasion attacks, at the cost of an acceptable loss of accuracy in the non-adversarial setting.","Insect pests have always been a global agricultural problem because the severity and extent of their occurrence threaten crop yield. Recognizing them early can help farmers have efficient measures to handle them, which can help mitigate negative impacts from insect pests. However, insect pest recognition still relies heavily on experts, which is expensive and time-consuming. With the power of Deep Learning, we propose two methods to solve this task in this paper. First, we proposed a method that uses models pre-trained on the ImageNet dataset, including ResNet-50, EfficientNet-B4, and VisionTransformer-B16, respectively. We also change the structure of these models by adding a Dropout layer before the output layer of these pre-trained models to avoid overfitting. Second, we apply hierarchical learning for this task. In the latter approach, we first use the baseline model to create a confusion matrix. Through this matrix, we cluster classes that the baseline model misses to each other because of the similar appearance across classes into bigger classes, and we consider them as sub-datasets. Then, we build each model for each sub-dataset using the identical backbones as the baseline methods with the hope that it helps the method classify better in these classes. We do experiments to evaluate the performance of methods on the IP102 dataset. From experiments, our proposed method, which uses VisionTransformer-B16 backbone combined with hierarchical learning, gets the best accuracy of 74.50% on the IP102 dataset. When ensemble 3 above models and combine with hierarchical learning, we get the best accuracy of 76.24% on this dataset.","Recent research has revealed that deep neural networks often take dataset biases as a shortcut to make decisions rather than understand tasks, leading to failures in real-world applications. In this study, we focus on the spurious correlation between word features and labels that models learn from the biased data distribution of training data. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased word as biased example. Our analysis shows that biased examples are easier for models to learn, while at the time of prediction, biased words make a significantly higher contribution to the models' predictions, and models tend to assign predicted labels over-relying on the spurious correlation between words and labels. To mitigate models' over-reliance on the shortcut (i.e. spurious correlation), we propose a training strategy Less-Learn-Shortcut (LLS): our strategy quantifies the biased degree of the biased examples and downweights them accordingly. Experimental results on Question Matching, Natural Language Inference and Sentiment Analysis tasks show that LLS is a task-agnostic strategy and can improve the model performance on adversarial data while maintaining good performance on in-domain data.","Bibliographic references in scholarly documents are integral to discourse in humanities disciplines. While prior work has focused on reference extraction and parsing from these documents, little research has investigated the classification of footnotes containing bibliographic citations and author commentary using supervised machine learning methodologies. Using an historiographic dataset drawn from the JSTOR humanities archive, we train and compare the performance of a suite of single and hybrid machine learning classifiers on a novel, previously unexplored reference classification task in archival document analysis. Moreover, as a part of this analysis, we investigate the feasibility of using the grammar of these scholarly footnotes as training features for our machine learning models. In our work we compare the performance of traditional features previously used in reference mining and these novel, grammatical features inspired by natural language processing techniques. Our work demonstrates the superiority of hybrid models for classification of scholarly footnotes containing historiographic bibliographic references, the transferability of features from reference extraction to this research problem, and the viability of training machine learning models for this task utilizing novel, grammatical feature sets.","One of the main challenges in the industry is having trained and efficient operators in manufacturing lines. Smart adaptive guidance systems are developed that offer assistance to the operator during assembly. Depending on the operator\u2019s level of execution, the system should be able to serve a different guidance response. This paper investigates the assessment and classification of the operator\u2019s functional state using observed task execution times. Five different classifiers are studied for operator functional state classification on task execution time series. The experiments are based on an industry case and the ground truth is provided by an expert rule-based system. Three classification scenarios are defined that segment the problem on the level of the task, the individual, or the team. Furthermore, the investigation includes the evaluation of four distinct window-size configurations. The examination of how these scenarios and window-sizes influence the studied dataset across diverse classifiers reveals that achieving enhanced accuracy necessitates a larger input dimension. In this context, Convolutional Neural Networks predominantly exhibit superior performance compared to alternative classifiers. Careful attention needs to be paid to performance over classes and skills, but results confirm the validity of the approach for data-driven operator functional state classification.","This paper presents a data pre-processing algorithm to tackle class imbalance in classification problems by undersampling the majority class. It relies on a formalism termed Presumably Correct Decision Sets aimed at isolating easy (presumably correct) and difficult (presumably incorrect) instances in a classification problem. The former are instances with neighbors that largely share their class label, while the latter have neighbors that mostly belong to a different decision class. The proposed algorithm replaces the presumably correct instances belonging to the majority decision class with prototypes, and it operates under the assumption that removing these instances does not change the boundaries of the decision space. Note that this strategy opposes other methods that remove pairs of instances from different classes that are each other\u2019s closest neighbors. We argue that the training and test data should have similar distribution and complexity and that making the decision classes more separable in the training data would only increase the risks of overfitting. The experiments show that our method improves the generalization capabilities of a baseline classifier, while outperforming other undersampling algorithms reported in the literature.","Multi-metric learning is important for improving performance of learners. For complex data, multi metric learning algorithms need intensive research. Moreover, the existing multi-metric learning methods may lead to the distance not being comparable. To solve these shortcomings and characterize better complexity data, we propose a novel multi-metric learning framework, where each class is divided into several clusters, and then a local metric and two concentric hypers-pheres are trained jointly in a cluster, such that the samples of the same cluster distribute within one hypersphere, and the classification margin are as large as possible simultaneously. This will leads to intra-class compactness and inter-class dispersion. During the test phase, the relative distance in learned metric space is designed to make classification decisions. A new example is classified to the class of its closest hyper-sphere center. This ensures that the comparison of distances is meaningful and avoids effectively the limitation of k-nearest neighbors (kNN) classifiers. Moreover,some important properties the proposed algorithm are analyzed theoretically. Further, an alternating iterative algorithm is developed to solve the problem. Numerical experiments are carried out on different scales and types datasets. Experiment results confirm the feasibility and effectiveness of the proposed method.","Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized in part by difficulties in verbal and nonverbal social communication. Evidence indicates that autistic people, compared to neurotypical peers, exhibit differences in head movements, a key form of nonverbal communication. Despite the crucial role of head movements in social communication, research on this nonverbal cue is relatively scarce compared to other forms of nonverbal communication, such as facial expressions and gestures. There is a need for scalable, reliable, and accurate instruments for measuring head movements directly within the context of social interactions. In this study, we used computer vision and machine learning to examine the head movement patterns of neurotypical and autistic individuals during naturalistic, face\u2013to\u2013face conversations, at both the individual (monadic) and interpersonal (dyadic) levels. Our model predicts diagnostic status using dyadic head movement data with an accuracy of , highlighting the value of head movement as a marker of social communication. The monadic data pipeline had lower accuracy () compared to the dyadic approach, emphasizing the importance of studying back-and-forth social communication cues within a true social context. The proposed classifier is not intended for diagnostic purposes, and future research should replicate our findings in larger, more representative samples.","Events are the core element of information in descriptive corpus. Many progresses have been made in Event Detection (ED) to detection and extraction of key events information from massive unstructured texts, However, it is still a challenge to detect event information from data with unavoidable noisy labels. A robust Joint-training Graph Convolution Networks (JT-GCN) model is proposed to meet the challenge of ED tasks with noisy labels in this paper. Specifically, we first employ two Graph Convolution Networks with Edge Enhancement (EE-GCN) to make predictions simultaneously. A joint loss combining the detection loss and the contrast loss from two networks is then calculated for training. Meanwhile, a small-loss selection mechanism is introduced to mitigate the impact of mislabeled samples in networks training process. These two networks gradually reach an agreement on the ED tasks as joint-training progresses. Corrupted data with label noise are generated from the benchmark dataset ACE2005. Experiments on ED tasks has been conducted with symmetry label noise on different level. The experimental results show that the proposed model is robust to the impact of label noise and superior to present models for ED tasks.","Pneumonia is an important threat to human health, and different types of pneumonia have different treatment options, so the prediction and classification of pneumonia are important health issues. In this paper, chest X-ray images are used as data, and the final ensemble model can achieve excellent performance on these two tasks. In addition, this paper introduces the InceptionNeXt model to pneumonia prediction and classification problems for the first time, and finds that different model convolution kernels and perception fields may be more suitable for different medical image research tasks.","Agriculture is an important sector in India, and about 58% of the Indian population depends on it. This is why it is paramount it remains profitable and provides a high yield. One of the problems that lead to reduced productivity is the selection of the wrong crop. For maximum productivity, every crop needs specific environmental conditions like soil quality, water, etc. In our work, we have used various Machine learning techniques and based on their comparative analysis adopted the best model to predict the most suitable crop for a particular soil sample based on parameters like Nitrogen, Potassium, Phosphorus, ph. level, rainfall, temperature, and humidity. The dataset is pre-processed and optimized using pre-processing techniques. We have reviewed existing algorithms such as Decision Trees, Naive Bayes, Support Vector Machine (SVM), K Nearest Neighbor (KNN), and Random Forest to predict the most suitable crop and found Naive Bayes Classifier to be the best model, based on performance metrics of precision, recall, accuracy and F1 score.","Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.","Multi-label learning (MLL) usually requires assigning multiple relevant labels to each instance. While a fully supervised MLL dataset needs a large amount of labeling effort, using complementary labels can help alleviate this burden. However, current approaches to learning from complementary labels are mainly designed for multi-class learning and assume that each instance has a single relevant label. This means that these approaches cannot be easily applied to MLL when only complementary labels are provided, where the number of relevant labels is unknown and can vary across instances. In this paper, we first propose the unbiased risk estimator for the multi-labeled complementary label learning (MLCLL) problem. We also provide an estimation error bound to ensure the convergence of the empirical risk estimator. In some cases, the unbiased estimator may give unbounded gradients for certain loss functions and result in overfitting. To mitigate this problem, we improve the risk estimator by minimizing a proper loss function, which has been shown to improve gradient updates. Our experimental results demonstrate the effectiveness of the proposed approach on various datasets.","Recent research has shown that artificial intelligence (AI) models can exhibit bias in performance when trained using data that are imbalanced by protected attribute(s). Most work to date has focused on deep learning models, but classical AI techniques that make use of hand-crafted features may also be susceptible to such bias. In this paper we investigate the potential for race bias in random forest (RF) models trained using radiomics features. Our application is prediction of tumour molecular subtype from dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) of breast cancer patients. Our results show that radiomics features derived from DCE-MRI data do contain race-identifiable information, and that RF models can be trained to predict White and Black race from these data with 60\u201370% accuracy, depending on the subset of features used. Furthermore, RF models trained to predict tumour molecular subtype using race-imbalanced data seem to produce biased behaviour, exhibiting better performance on test data from the race on which they were trained.","Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be 'inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.","Constrained clustering is a semi-supervised task that employs a limited amount of labelled data, formulated as constraints, to incorporate domain-specific knowledge and to significantly improve clustering accuracy. Previous work has considered exact optimization formulations that can guarantee optimal clustering while satisfying all constraints, however these approaches lack interpretability. Recently, decision trees have been used to produce inherently interpretable clustering solutions, however existing approaches do not support clustering constraints and do not provide strong theoretical guarantees on solution quality. In thiswork, we present a novel SAT-based framework for interpretable clustering that supports clustering constraints and that also provides strong theoretical guarantees on solution quality. We also present new insight into the trade-off between interpretability and satisfaction of such user-provided constraints. Our framework is the first approach for interpretable and constrained clustering. Experiments with a range of real-world and synthetic datasets demonstrate that our approach can produce high-quality and interpretable constrained clustering solutions.","Finding the right business partner to drive innovation or acquire technology transfer is a labor and time-intensive process. To simplify this process, there is a need for improved methods of automated matchmaking that can quickly identify the best potential collaboration partners. This paper presents a novel approach for semi-automated business matchmaking between companies and research institutes, that is applied to a first case study. For this purpose, we compare two transformer-based text classification models and evaluate how dataset quality affects few-shot learning performance. Flair's TARS classifier performed very well in our use case, requiring only 40 examples per class to achieve an F1 score of about 90%. This is already very close to the Hugging Face standard text classifier, which achieved an F1 score of 92% with much more annotation effort. The results show that few-shot learning models like TARS can achieve accurate results even with few training samples compared to regular transformer-based language models. Our novel approach allows the time-consuming and labor-intensive task of manual partner matchmaking to be significantly reduced.","Node classification is an important task in many fields, e.g., predicting entity types in knowledge graphs, classifying papers in citation graphs, or classifying nodes in social networks. In many cases, it is crucial to explain why certain predictions are made. Towards this end, concept learning has been proposed as a means of interpretable node classification: given positive and negative examples in a knowledge base, concepts in description logics are learned that serve as classification models. However, state-of-the-art concept learners, including EvoLearner and CELOE exhibit long runtimes. In this paper, we propose to accelerate concept learning with graph sampling techniques. We experiment with seven techniques and tailor them to the setting of concept learning. In our experiments, we achieve a reduction in training size by over 90% while maintaining a high predictive performance.","We propose a joint model that performs instance-level feature selection and classification. For a given case, the joint model first skims the full feature vector, decides which features are relevant for that case, and makes a classification decision using only the selected features, resulting in compact, interpretable, and case-specific classification decisions. Because the selected features depend on the case at hand, we refer to this approach as context-aware feature selection and classification. The model can be trained on instances that are annotated by experts with both class labels and instance-level feature selections, so it can select instance-level features that humans would use. Experiments on several datasets demonstrate that the proposed model outperforms eight baselines on a combined classification and feature selection measure, and is able to better emulate the ground-truth instance-level feature selections. The supplementary materials are available at https://github.com/IIT-ML/IJCAI23-CFSC.","Lambani is an under-resourced Indo-Aryan language spoken by a nomadic tribe known as the \u2018Banjara people\u2019 across central and southern India. Due to its contact with several major languages of India, Lambani has been influenced both linguistically as well as culturally. One of the major influences has been observed in its phonemic inventory. This paper is a preliminary investigation into the acoustic characteristics of vowels of the language. The paper analyses spectral and temporal features of six Lambani vowels, viz. [inline-graphic not available: see fulltext] spoken in the Bagalkot district of Karnataka. The results obtained throw light on the distinctiveness of this variety. The paper then uses spectral and temporal features to explore both machine learning and deep learning approaches to classify Lambani vowel perceptual space. Results show that Fully Connected Dense Layer achieves better accuracy in classifying Lambani vowels.","A world of healthcare possibilities has been opened with the development of the Internet of Medical Things and related machine learning, deep learning, and artificial intelligence approaches. It has a broad range of uses: when linked to the Internet, common medical equipment and sensors may gather important data; deep learning and artificial intelligence algorithms use this data to understand symptoms and patterns and allow remote healthcare. There are a large number of people affected by thyroid disorders across the world. The ultrasound-based thyroid nodule detection using traditional methods increased the burden on the expertise. Therefore, alternate methods are required to overcome this problem. In order to facilitate early thyroid disorder detection, this research aims to offer an IoT-based ensemble learning framework. In the proposed ensemble model, three pre-trained models DeiT, Mixer-MLP and Swin Transformer, are used for feature extraction. The mRMR technique is used for relevant feature selection. A total of 24 machine learning models have been trained, and weighted average ensemble learning is employed using the Improved Jaya optimization algorithm and Coronavirus Herd Immunity optimization algorithm. The ensemble model with the improved Jaya optimization algorithm achieved excellent results. The best value for accuracy, precision, sensitivity, specificity, F2-score and ROC-AUC score are 92.83%, 87.76%, 97.66%, 88.89%, 0.9551 and 0.9357, respectively. The main focus of this research is to increase the specificity. A poor value of specificity can lead to a high false positive rate. This situation can increase anxiety and emotionally weaken the patient. The proposed ensemble model with the Improved Jaya optimization algorithm outperformed state-of-the-art techniques and can assist medical experts.","Insider threats refer to cyber-attacks originating from within an organization that can cause significant damage, such as intellectual property theft, sabotage, and sensitive data exposure. Traditional cybersecurity strategies tend to focus on external threats, leaving organizations vulnerable to insider attacks. In this paper, we propose an approach for insider threat classification with various classification models. Aggregated numerical features are generated using the access patterns of the employees of the organization. We used the CERT dataset for training and testing. The proposed method is evaluated with classification models like Logistic Regression, Decision Tree, Random Forest, and Xgboost. The experimental results of the model's performance, measured using evaluation metrics such as accuracy, recall, precision, and F1-Score, demonstrated improved accuracy and performance compared to existing works in terms of high recall, precision, and F1-Score values, and effectively outperformed pre-trained CNN models.","Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.","Improving the fairness of machine learning models is a nuanced task that requires decision makers to reason about multiple, conflicting criteria. The majority of fair machine learning methods transform the error-fairness trade-off into a single objective problem with a parameter controlling the relative importance of error versus fairness. We propose instead to directly optimize the error-fairness tradeoff by using multi-objective optimization. We present a flexible framework for defining the fair machine learning task as a weighted classification problem with multiple cost functions. This framework is agnostic to the underlying prediction model as well as the metrics. We use multiobjective optimization to define the sample weights used in model training for a given machine learner, and adapt the weights to optimize multiple metrics of fairness and accuracy across a set of tasks. To reduce the number of optimized parameters, and to constrain their complexity with respect to population subgroups, we propose a novel meta-model approach that learns to map protected attributes to sample weights, rather than optimizing those weights directly. On a set of real-world problems, this approach outperforms current state-of-the-art methods by finding solution sets with preferable error/fairness trade-offs.","In this article, we investigate the effects on authorship identification tasks (including authorship verification, closed-set authorship attribution, and closed-set and open-set same-author verification) of a fundamental shift in how to conceive the vectorial representations of documents that are given as input to a supervised learner. In \u201cclassic\u201d authorship analysis, a feature vector represents a document, the value of a feature represents (an increasing function of) the relative frequency of the feature in the document, and the class label represents the author of the document. We instead investigate the situation in which a feature vector represents an unordered pair of documents, the value of a feature represents the absolute difference in the relative frequencies (or increasing functions thereof) of the feature in the two documents, and the class label indicates whether the two documents are from the same author or not. This latter (learner-independent) type of representation has been occasionally used before, but has never been studied systematically. We argue that it is advantageous, and that, in some cases (e.g., authorship verification), it provides a much larger quantity of information to the training process than the standard representation. The experiments that we carry out on several publicly available datasets (among which one that we here make available for the first time) show that feature vectors representing pairs of documents (that we here call Diff-Vectors) bring about systematic improvements in the effectiveness of authorship identification tasks, and especially so when training data are scarce (as it is often the case in real-life authorship identification scenarios). Our experiments tackle same-author verification, authorship verification, and closed-set authorship attribution; while DVs are naturally geared for solving the 1st, we also provide two novel methods for solving the 2nd and 3rd that use a solver for the 1st as a building block. The code to reproduce our experiments is open-source and available online.1","In the classification of benign and malignant breast tumors, in addition to the extraction of features, the selection of classifier is also an important factor affecting the accuracy of classification. At present, the ensemble classifier has limitations of local optimization and weak scalability in the integration process, which affect the accuracy and stability of classification. In this study, an ensemble classifier based on adaptive weighted ensemble is proposed to classify benign and malignant breast tumors. First, the original ultrasonic RF signal is preprocessed by down-sampling, dilation, and adaptive decomposition. Then, based on the intrinsic modal function obtained by decomposition, the ring region of interest (ROI) containing the tissue surrounding the tumor is determined. Next, texture features are extracted based on ring ROIs. Weighted k-nearest neighbors (KNN), bagged trees, and Gaussian Naive Bayes (NB) are integrated by bagging method, and each classifier is adaptively weighted based on genetic algorithms during the integration process. Finally, benign and malignant breast tumors are classified by an ensemble classifier based on adaptive weights. Experiments based on the Open Access Series of Breast Ultrasound Data database show that the classification accuracy of the proposed adaptive weight-based ensemble classifier is 90%, which is improved by 10.77%, 8.43%, 1.12% and 5.88% compared with the weighted KNN, bagged trees and Gaussian NB alone, and voting-based ensemble classifier. The conclusion is that the proposed ensemble classifier based on adaptive weighting can effectively improve the classification accuracy of breast tumors, which is helpful for the diagnosis of clinical breast tumors.","Canonical Correlation Analysis (CCA) has been widely used in Steady-State Visually Evoked Potential (SSVEP) analysis, but there are still challenges in this research area, specifically regarding data quality and insufficiency. In contrast to most previous studies that primarily concentrate on the development of spatial or spectral templates for SSVEP data, this paper proposes a novel temporal filtering method based on a reinforcement learning (RL) algorithm for CCA on SSVEP data. The proposed method leverages RL to automatically and precisely detect and filter low-quality segments in the SSVEP data, thereby improving the accuracy of CCA. Additionally, the proposed RL-based Temporal Filtering is algorithm-independent and compatible with various CCA algorithms. The RL-based Temporal Filtering is evaluated using a wearable dataset consisting of 102 subjects. The experimental results demonstrate significant advancements in CCA accuracy, particularly when combined with the extended CCA (ECCA) algorithm. In addition to performance enhancement, the RL-based Temporal Filtering method provides visualizable filters, which can ensure the transparency of the filtering process and the reliability of the obtained results. By addressing data quality and insufficiency concerns, this novel RL-based Temporal Filtering approach demonstrates promise in advancing SSVEP analysis for various applications.","The growing availability of time series data has increased the usage of classifiers for this data type. Unfortunately, state-of-the-art time series classifiers are black-box models and, therefore, not usable in critical domains such as healthcare or finance, where explainability can be a crucial requirement. This paper presents a framework to explain the predictions of any black-box classifier for univariate and multivariate time series. The provided explanation is composed of three parts. First, a saliency map highlighting the most important parts of the time series for the classification. Second, an instance-based explanation exemplifies the black-box\u2019s decision by providing a set of prototypical and counterfactual time series. Third, a factual and counterfactual rule-based explanation, revealing the reasons for the classification through logical conditions based on subsequences that must, or must not, be contained in the time series. Experiments and benchmarks show that the proposed method provides faithful, meaningful, stable, and interpretable explanations.","Predicting students\u2019 academic performance is a critical research area, yet imbalanced educational datasets, characterized by unequal academic-level representation, present challenges for classifiers. While prior research has addressed the imbalance in binary-class datasets, this study focuses on multi-class datasets. A comparison of ten resampling methods (SMOTE, Adasyn, Distance SMOTE, BorderLineSMOTE, KmeansSMOTE, SVMSMOTE, LN SMOTE, MWSMOTE, Safe Level SMOTE, and SMOTETomek) is conducted alongside nine classification models: K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Support Vector Machine (SVM), Logistic Regression (LR), Extra Tree (ET), Random Forest (RT), Extreme Gradient Boosting (XGB), and Ada Boost (AdaB). Following a rigorous evaluation, including hyperparameter tuning and 10 fold cross-validations, KNN with SmoteTomek attains the highest accuracy of 83.7%, as demonstrated through an ablation study. These results emphasize SMOTETomek\u2019s effectiveness in mitigating class imbalance in educational datasets and highlight KNN\u2019s potential as an educational data mining classifier.","Multi-label Aspect Category Detection (MACD) is essential for aspect-based sentiment analysis, which aims to identify multiple aspect categories in a given sentence. Few-shot MACD is critical due to the scarcity of labeled data. However, MACD is a high-noise task, and existing methods fail to address it with only two or three training samples per class, which limits the application in practice. To solve above issues, we propose a group of Few-shot Sample-set Operations (FSO) to solve noisy MACD in fewer sample scenarios by identifying the semantic contents of samples. Learning interactions among intersection, subtraction, and union networks, the FSO imitates arithmetic operations on samples to distinguish relevant and irrelevant aspect contents. Eliminating the negative effect caused by noises, the FSO extracts discriminative prototypes and customizes a dedicated query vector for each class. Besides, we develop a multilabel architecture, which integrates with score-wise loss and multi-label loss to optimize the FSO for multilabel prediction, avoiding complex threshold training or selection. Experiments show that our method achieves considerable performance. Significantly, it improves by 11.01% at most and an average of 8.59% Macro-F in fewer sample scenarios.","In this work, we propose DocLangID, a transfer learning approach to identify the language of unlabeled historical documents. We achieve this by first leveraging labeled data from a different but related domain of historical documents. Secondly, we implement a distance-based few-shot learning approach to adapt a convolutional neural network to new languages of the unlabeled dataset. By introducing small amounts of manually labeled examples from the set of unlabeled images, our feature extractor develops a better adaptability towards new and different data distributions of historical documents. We show that such a model can be effectively fine-tuned for the unlabeled set of images by only reusing the same few-shot examples. We showcase our work across 10 languages that mostly use the Latin script. Our experiments on historical documents demonstrate that our combined approach improves the language identification performance, achieving 74% recognition accuracy on the four unseen languages of the unlabeled dataset.","To evaluate the robustness of non-classifier models, we propose probabilistic local equivalence, based on the notion of randomized smoothing, as a way to quantitatively evaluate the robustness of an arbitrary function. For a given function\nf\n, probabilistic local equivalence evaluates whether, when sampling a normally-distributed point\nx\n\u2032\nin a neighborhood of a point\nx\n, there is a probability\n&gt;\n0.5\nthat\nf\n(\nx\n\u2032\n)\nis equivalent to\nf\n(\nx\n)\n, according to a user-defined notion of equivalence. We use probabilistic local equivalence to evaluate the effect of data augmentation methods for improving robustness, including adversarial training, on a model\u2019s performance. We also use probabilistic local equivalence to evaluate the effect on robustness of model architecture, number of parameters, pre-training, quantization, and other model properties.","The heart, as the main organ of our human body, plays an important role in pumping blood through our body. Early prevention and prediction of cardiovascular disease (CVD) can save more lives, especially for ordinary people. Hence, this study proposes a voting ensemble-based prediction model for the risk of CVD in ordinary people. We first integrate 2 years of data from the Korea National Health and Nutrition Examination Survey (KNHANES) and then extract the experimental data. Thereafter, the extracted data is preprocessed with missing value imputation and data normalization. A filter-based feature selection approach is also applied to select the efficient attributes for the experiment, then split the data into training (80%) data and test (20%) data. Thenceforth, we use two kinds of hybrid data sampling techniques such as synthetic minority oversampling techniques (SMOTE) plus Tomek Links (SMOTETomek) and SMOTE plus Edited Nearest Neighbors (SMOTEENN) to solve the imbalance issue in the training data. Next, the voting ensemble-based prediction model is designed based on different machine learning algorithms such as logistic regression, support vector machine, and AdaBoost on the balanced training data with selected features and complete features. Lastly, the proposed model is evaluated on the test data and compared with other popularly used machine learning-based models. In the experimental results, the proposed voting ensemble-based prediction model with the SMOTEENN technique on selected features by using the filter-based feature selection approach achieved the best performance with the accuracy of 0.8102, recall 0.8102, g-mean 0.8102, and AUC 0.8102, respectively for the risk of CVD in ordinary people and outperformed other machine learning-based prediction models.","Human behavior recognition is one of the most important research directions in the field of computer vision, and it plays an important role in the fields of rehabilitative medicine, auxiliary security, and scene entertainment. To address the shortcomings of traditional HAR recognition methods with tedious feature extraction and severe overfitting, we propose a human behavior recognition model based on XGBoost and feature simplification methods with a limited data set. The model uses the XGBoost algorithm to classify the collected sensor data to recognize human behaviors. In addition, to improve the efficiency and accuracy of the model, we also propose a feature simplification method to reduce the computational complexity and the risk of model overfitting by reducing the number of features. Experimental results show that the model has high accuracy and computational efficiency and can be applied to different human behavior recognition scenarios.\nCCS Concepts: Computing methodologies\u223cMachine learning\u223cMachine learning approaches","The K-nearest neighbor interpolation method was used to fill in missing data of five indicators of coronary heart disease, diabetes, total cholesterol, triglycerides, and albumin;, and the SMOTE algorithm was used to balance the number of variable indicators. The Relief-F algorithm was used to remove 18 variable indicators and retain 42 variable indicators. LASSO and ridge regression algorithms were used to remove eight variable indicators and retain 52 variable indicators; The prediction accuracy, recall, and AUC values of the linear kernel support vector machine model filtered using Relief-F and LASSO features are high, and the prediction results are optimal; The test result of random forest screened by Relief-F and LASSO features is better than that of the support vector machine model. It is concluded that the random forest model screened by Relief-F features is better as a prediction of lung cancer typing. The research results provide theoretical data support for predicting lung cancer classification using machine learning methods.","Unexploded ordnance (UXO) dumped in water reservoirs pose a serious environmental and human safety hazard. Various ways of economically solving this problem are being sought. One of them is the use of machine learning methods for the automatic classification of dangerous objects based on the recorded signals. The paper presents the preliminary results on the use of machine learning methods applied to raw magnetometry data generated in a virtual environment based on the concept of a digital twin. This introduces a different approach to a standard approach, which is based on the inverse problem, where the signals are mapped to the magnetic dipole model. Conducted research points out that the highest performance can be obtained with neural networks, and a direct classification based on the raw signals allows to achieve accuracy of up to 93% when no remanent magnetization is present.","Sign Language Recognition (SLR) is a challenging task that aims to bridge the communication gap between the deaf and hearing communities. In recent years, deep learning-based approaches have shown promising results in SLR. However, the lack of interpretability remains a significant challenge. In this paper, we seek to understand which hand and pose MediaPipe Landmarks are deemed the most important for prediction as estimated by a Transformer model. We propose to embed a learnable array of parameters into the model that performs an element-wise multiplication of the inputs. This learned array highlights the most informative input features that contributed to solve the recognition task. Resulting in a human-interpretable vector that lets us interpret the model predictions. We evaluate our approach on public datasets called WLASL100 (SRL) and IPNHand (gesture recognition). We believe that the insights gained in this way could be exploited for the development of more efficient SLR pipelines.","State-of-the-art weakly supervised text classification methods, while significantly reduced the required human supervision, still requires the supervision to cover all the classes of interest. This is never easy to meet in practice when human explore new, large corpora without complete pictures. In this paper, we work on a novel yet important problem of weakly supervised open-world text classification, where supervision is only needed for a few examples from a few known classes and the machine should handle both known and unknown classes in test time. General open-world classification has been studied mostly using image classification; however, existing methods typically assume the availability of sufficient known-class supervision and strong unknown-class prior knowledge (e.g., the number and/or data distribution). We propose a novel framework \u00f8ur that lifts those strong assumptions. Specifically, it follows an iterative process of (a) clustering text to new classes, (b) mining and ranking indicative words for each class, and (c) merging redundant classes by using the overlapped indicative words as a bridge. Extensive experiments on 7 popular text classification datasets demonstrate that \u00f8ur outperforms strong baselines consistently with a large margin, attaining 23.33% greater average absolute macro-F1 over existing approaches across all datasets. Such competent accuracy illuminates the practical potential of further reducing human effort for text classification.","Planktons are the building blocks of marine food webs and key indicators of ocean health. Monitoring of plankton populations help study the biological diversity of microbial eukaryotes. Recent years have witnessed the wide usage of digital holographic microscopes (DHM) for in situ detection of underwater microplanktons. Holography has an edge over other imaging techniques due to its unique ability to provide a 3D hologram of the microplankton without disturbing its orientations. In this paper, a novel network architecture with 5.29 GFLOPs is developed for the classification of microplanktons in digital holographic images. The proposed method achieved a class-wise F1-scores above\n80\n%\nat a lower computational cost. The proposal provided competitive performance with respect to six baseline network architectures. This technique has the potential to be appealing for future applications of in situ classification of microplanktons.","Data irregularities, such as small disjuncts, class skew and imbalance, and outliers significantly affect the performance of classifiers. In this paper, we focus on identifying small disjuncts, which hitherto, has been addressed mainly by rule-based or inductive algorithms. Small disjuncts have been identified as distribution-based irregularities which provide significant learning, although they cover a subset of examples in the training set, which may be considered as being rare. Such samples are more error-prone than large disjuncts. Eliminating small disjuncts by removal or pruning is seen to affect the learning of the classifier adversely. Widely used non-rule-based learning algorithms like SVM, kNN, Logistic Regression, and Neural networks perform poorly in the presence of small disjuncts in the dataset. In this paper, a novel Sequential Ellipsoidal Partitioning method is proposed to identify small disjuncts in the dataset. This method is a supervised classifier that iteratively partitions the dataset into Minimum Volume Ellipsoids that contain points of the same label; this is performed based on the idea of Reduced Convex Hulls. By allowing an ellipsoid that contains points of one label to contain a few points of the other, such small disjuncts may be identified. As we discuss, the proposed technique is agnostic of underlying data distributions and is applicable as a supervised classifier when the datasets are highly skewed and imbalanced even. We demonstrate the performance of the approach using a few publicly available datasets.","This paper presents our solution for the Requests Sub-challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. Drawing upon the framework of self-supervised learning, we put forth an automated data augmentation technique for audio classification, accompanied by a multi-channel fusion strategy aimed at enhancing overall performance. Specifically, to tackle the issue of imbalanced classes in complaint classification, we propose an audio data augmentation method that generates appropriate augmentation strategies for the challenge dataset. Furthermore, recognizing the distinctive characteristics of the dual-channel HC-C dataset, we individually evaluate the classification performance of the left channel, right channel, channel difference, and channel sum, subsequently selecting the optimal integration approach. Our approach yields a significant improvement in performance when compared to the competitive baselines, particularly in the context of the complaint task. Moreover, our method demonstrates noteworthy cross-task transferability.","In this research project, we used the financial texts published by the Federal Open Market Committee (FOMC), known as the FOMC Minutes, for sentiment analysis. The pre-trained FinBERT model, a state-of-the-art transformer-based model trained for NLP tasks in finance, was utilized for that. The focus of this research has been on improving the predictive performance of complex financial sentences, as our problem analysis has shown that such sentences pose a significant challenge to existing models. To accomplish this objective the original FinBERT model was fine-tuned for domain-specific sentiment analysis. A strategy, referred to as Sentiment Focus (SF) was utilized to reduce the complexity of sentences, making them more amenable to accurate sentiment predictions.\nTo evaluate the efficacy of our method, we curated a manually labeled test dataset comprising 1375 entries. The results demonstrated an overall improvement of in accuracy when using SF-enhanced fine-tuned FinBERT over the original FinBERT model. In cases of complex sentences containing conjunctions like but, while, and though with contradicting sentiments, our fine-tuned model outperformed the original FinBERT by a margin of .","Skip Abstract Section\nAbstract\nIn a complex classification task, samples are represented by various types of multimodal features, including structured data, text, images, video, audio, etc. These data are usually high dimensionally, large-sized, structurally complex, and semantically inconsistent. The representation, translation, alignment, fusion and co-learning of multimodal data are core technical challenges to traditional classification tasks. Kernel functions are applied in dealing with multimodal data for extracting some nonlinear information. However, they cannot consider the aspects of complex structures and uncertain semantics in a multimodal classification task. Fuzzy granular computing emerges as a powerful vehicle to handle the structured and uncertain multimodal data. In this paper, we propose a framework of multimodal classification based on kernel functions and fuzzy granular computing. First, a fuzzy granulation based on kernel functions is introduced to extract nonlinear features for the multimodal classification. Then, a model of multimodal fuzzy classification including fuzzy granular representation, fusion and learning for multimodal data is constructed. Finally, we design an efficient fuzzy granular classification algorithm for big multimodal data based on the proposed model. Experimental results demonstrate the effectiveness of our proposed model and its corresponding algorithm.\nSkip Graphical abstract Section\nGraphical abstract","Covid-19 is a serious disease caused by the Sars-CoV-2 virus that has been first reported in China at late 2019 and has rapidly spread around the world. As the virus affects mostly the lungs, chest X-rays are one of the safest and most accessible ways of diagnosing the infection. In this paper, we propose the use of an approach for detecting Covid-19 in chest X-ray images through the extraction and classification of local and global percolation-based features. The method was applied in two datasets: one containing 2,002 segmented samples split into two classes (Covid-19 and Healthy); and another containing 1,125 non-segmented samples split into three classes (Covid-19, Healthy and Pneumonia). The 48 obtained percolation features were given as input to six different classifiers and then AUC and accuracy values were evaluated. We employed the 10-fold cross-validation method and evaluated the lesion sub-types with binary and multiclass classification using the Hermite Polynomial classifier, which had never been employed in this context. This classifier provided the best overall results when compared to other five machine learning algorithms. These results based in the association of percolation features and Hermite polynomial can contribute to the detection of the lesions by supporting specialists in clinical practices.","To maintain development consciousness, simplify project coordination, and prevent misinterpretation, communication is essential for software development teams. Instant private messaging, group chats, and sharing code are just a few of the capabilities that chat rooms provide to assist and meet the communication demands of software development teams. All of this is capacitated to happen in real-time. Consequently, chat rooms have gained popularity among developers. Gitter is one of these platforms that has gained popularity, and the conversations it contains may be a treasure trove of data for academics researching open-source software systems. This research made use of the GitterCom dataset, The largest collection of Gitter developer messages that have been carefully labelled and curated and perform multi-label classification for the \u2019Purpose\u2019 category in the dataset. An extensive empirical analysis is performed on 6 feature selection techniques, 14 machine learning classifiers, and BERT transformer layer architecture with layer-by-layer comparison. Consequently, we achieve proficient results through our research pipeline involving Extra Trees Classifier and Random Forest classifiers with AUC (OvR) median performance of 0.94 and 0.92 respectively. Furthermore, The research proposed research pipeline could be utilized for generic multi-label text classification on software developer forum text data.","Mangoes are a common agricultural product in Asia that are sold to other nations. Exported mangoes must meet the standards of different countries, mangoes are classified into different groups for export. A method segmentation for an automatic mango classification system is proposed in this study. The KNN model is applied to segment the mangoes, however, there are many different varieties of mangoes so segmentation is also difficult. Therefore, a self-training model is introduced to increase the accuracy of the KNN model and one can adapt to many mango species. The mangoes are rated by deducting penalty points for failing to meet the requirements that have been established. The system achieved more than 98.7% accuracy for segmentation and 96.67% for the whole classification system.","Meta-learning excels in few-shot learning by extracting shared knowledge from the observed tasks. However, it needs the tasks to adhere to the i.i.d. constraint, which is challenging to achieve due to complex task relationships between data content. Current methods that create tasks in a one-dimensional structure and use meta-learning to learn all tasks flatly struggle with extracting shared knowledge from tasks with overlapping concepts. To address this issue, we propose further constructing tasks from the same environment into hyper-tasks. Since the distributions of hyper-tasks and tasks in a hyper-task can both be approximated as i.i.d. due to further summarization, the meta-learning algorithm can capture shared knowledge more efficiently. Based on the hyper-task, we propose a hierarchical meta-learning paradigm to meta-learn the meta-learning algorithm. The paradigm builds a customized meta-learner for each hyper-task, which makes meta-learners more flexible and expressive. We apply the paradigm to three classic meta-learning algorithms and conduct extensive experiments on public datasets, which confirm the superiority of hierarchical meta-learning in the few-shot learning setting. The code is released at https://github.com/tuantuange/H-meta-learning.","In the recommendation systems, there are multiple business domains to meet the diverse interests and needs of users, and the click-through rate(CTR) of each domain can be quite different, which leads to the demand for CTR prediction modeling for different business domains. The industry solution is to use domain-specific models or transfer learning techniques for each domain. The disadvantage of the former is that the data from other domains is not utilized by a single domain model, while the latter leverage all the data from different domains, but the fine-tuned model of transfer learning may trap the model in a local optimum of the source domain, making it difficult to fit the target domain. Meanwhile, significant differences in data quantity and feature schemas between different domains, known as domain shift, may lead to negative transfer in the process of transferring. To overcome these challenges, we propose the Collaborative Cross-Domain Transfer Learning Framework (CCTL). CCTL evaluates the information gain of the source domain on the target domain using a symmetric companion network and adjusts the information transfer weight of each source domain sample using the information flow network. This approach enables full utilization of other domain data while avoiding negative migration. Additionally, a representation enhancement network is used as an auxiliary task to preserve domain-specific features. Comprehensive experiments on both public and real-world industrial datasets, CCTL achieved SOTA score on offline metrics. At the same time, the CCTL algorithm has been deployed in Meituan, bringing 4.37% CTR and 5.43% GMV lift, which is significant to the business.","Parkinson\u2019s disease is one of the most common neurodegenerative chronic diseases which can affect the patient\u2019s quality of life by creating several motor and non-motor impairments. The freezing of gait is one such motor impairment which can cause the inability to move forward despite the intention to walk. The identification of the freezing-of-gait events using sensor technology and machine-learning algorithms can result in an improvement in the quality of life and can decrease the risk of fall in Parkinson\u2019s patients. Our study focuses on a systematic performance evaluation of machine learning algorithms for developing a good fit and generalized model. In this work, we train time-domain and frequency-domain-transform-based features on fully connected artificial and deep neural network algorithm for classifying the events of freezing of gait in patients by using accelerometer data. We evaluate these algorithms for hyperparameters such as batch size, optimizer type, and window sizes in a step-wise process. We identify an optimal combination of parameters according to the accuracy and model fit optimality metrics, for artificial and deep neural network to classify freezing of gait events in Parkinson\u2019s patients. We were able to achieve classification accuracy of - with Adam optimizer, batch sizes (BS) of 256 and 8 and epochs of 60 and 40 for ANN and DNN respectively.","Detection of diseases in plants at an early stage is crucial to achieving high yields, preserving crop quality, and effective disease management. Existing research focuses mostly on leaf disease detection, despite the fact that disease may develop everywhere on the plant. We developed a new dataset using the PlantVillage dataset and other online sources. We used Convolutional Neural Network (CNN) architectures, Alexnet and MobileNet to analyze and evaluate the performance of the models on the new dataset (i.e., consists of over 50,000 images). The models were trained on the new dataset for 100 epochs. MobileNet outperformed the other two models, attaining 99.69% training accuracy, 94.37% validation accuracy, 96% average precision, 96% recall, and an F1-score. The MobileNet model predicted diseases that affect portions of the plant other than the leaf better. This work demonstrates detecting plant disease and provides a feasible technique for enhancing crop management.","Siamese Neural Networks (SNN) are known to perform well in resource-constrained scenarios where computation and data availability are limited. They utilise the similarity space of a given dataset to extract distinguishing features between dissimilar data samples. Such features have also been utilised for classification tasks. Though several works on enhancing the accuracies and inference times using such similarity spaces have been reported, there is still scope for investigations that can yield more efficient strategies. The Biological Immune System (BIS) is known for employing such a transformation to recognise and contain antigenic attacks. Concepts from a BIS can thus, aid in boosting the classification performance of SNNs. This paper summarizes such an attempt made in our work \"Immuno-Inspired Augmentation of Siamese Neural Network for Multi-class Classification\" [8] presented at IVCNZ 2022, first published in Lecture Notes in Computer Science, 2023, vol 13836, pages 486--500 by Springer. A novel SNN-based multi-class classification method augmented with an immuno-inspired approach that allows an SNN to plug class-specific characteristics into its architecture is presented herein. The empirical analyses and results conducted on three benchmark datasets, clearly indicate that this method delivers higher accuracies and lower inference times when compared to recent SNN-based multi-class classification techniques.","Accurate classification of Acute Myeloid Leukemia (AML) subtypes is crucial for clinical decision-making and patient care. In this study, we investigate the potential presence of age and sex bias in AML subtype classification using Multiple Instance Learning (MIL) architectures. To that end, we train multiple MIL models using different levels of sex imbalance in the training set and excluding certain age groups. To assess the sex bias, we evaluate the performance of the models on male and female test sets. For age bias, models are tested against underrepresented age groups in the training data. We find a significant effect of sex and age bias on the performance of the model for AML subtype classification. Specifically, we observe that females are more likely to be affected by sex imbalance dataset and certain age groups, such as patients with 72 to 86 years of age with the RUNX1::RUNX1T1 genetic subtype, are significantly affected by an age bias present in the training data. Ensuring inclusivity in the training data is thus essential for generating reliable and equitable outcomes in AML genetic subtype classification, ultimately benefiting diverse patient populations.","This paper proposes a multi-task model for the classification and grasp detection of surgical tools so that the tasks such as handing, collection (from the surgeon or other person), disinfection, sorting, and assembling of surgical tools can be automatized with the help of a robotic system, which will in-turn allow health-care workers to spend their time on other complex tasks. The multi-task model uses a feature extractor and the extracted features are processed further to produce the output corresponding to both tasks. To train the model, we have prepared a custom dataset consisting of 800 images with 8 different classes taken from two publicly available datasets namely the HOSPI-Tools Dataset and the Surgical Image dataset. The model was trained using transfer learning in two phases with three different pre-trained feature extractors namely: MobileNetV3-Large, Inception-v3, and EfficientNetV2-S. We have achieved the best results with EfficientNetV2-S as a feature extractor and the results are classification accuracy\u201499.75%, localization accuracy\u201490.375%, and detection accuracy\u201490.25%.","We investigate the generalization properties of a self-training algorithm with halfspaces. The approach learns a list of halfspaces iteratively from labeled and unlabeled training data, in which each iteration consists of two steps: exploration and pruning. In the exploration phase, the halfspace is found sequentially by maximizing the unsigned-margin among unlabeled examples and then assigning pseudo-labels to those that have a distance higher than the current threshold. These pseudo-labels are allegedly corrupted by noise. The training set is then augmented with noisy pseudolabeled examples, and a new classifier is trained. This process is repeated until no more unlabeled examples remain for pseudo-labeling. In the pruning phase, pseudo-labeled samples that have a distance to the last halfspace greater than the associated unsigned-margin are then discarded. We prove that the misclassification error of the resulting sequence of classifiers is bounded and show that the resulting semi-supervised approach never degrades performance compared to the classifier learned using only the initial labeled training set. Experiments carried out on a variety of benchmarks demonstrate the efficiency of the proposed approach compared to state-of-the-art methods.","Hyperspectral image(HSI) classification is a crucial topic within remote sensing. Recently, deep self-supervised learning methods have gained widespread use in HSI classification, effectively addressing the scarcity of labeled samples issue. In particular, masked image modeling and contrastive learning have achieved commendable performance in the field of self-supervised learning. Therefore, to better investigate the association and synergy between the two self-supervised learning methods, we propose a novel hybrid self-supervised learning framework (HSL) for HSI classification that conforms to the properties of hyperspectral data. The HSL exploits the efficacy of masked image modeling and contrastive learning, and combines masked image reconstruction and instance contrastive learning to improve performance. The HSL specifically employs an asymmetric encoder-decoder two-branch structure. The structure adopts the Vision Transformer as the backbone network to efficiently extract spatial spectral information. Experiments on two commonly used HSI datasets demonstrate that this pre-training task results in better modeling of the feature relationships between shallow and deep layers and achieves superior performance.","Evaluating speaker emotion in conversations is crucial for various applications requiring human-computer interaction. However, co-occurrences of multiple emotional states (e.g. 'anger' and 'frustration' may occur together or one may influence the occurrence of the other) and their dynamic evolution may vary dramatically due to the speaker's internal (e.g., influence of their personalized socio-cultural-educational and demographic backgrounds) and external contexts. Thus far, the previous focus has been on evaluating only the dominant emotion observed in a speaker at a given time, which is susceptible to producing misleading classification decisions for difficult multi-labels during testing. In this work, we present Self-supervised Multi- Label Peer Collaborative Distillation (SeMuL-PCD) Learning via an efficient Multimodal Transformer Network, in which complementary feedback from multiple mode-specific peer networks (e.g.transcript, audio, visual) are distilled into a single mode-ensembled fusion network for estimating multiple emotions simultaneously. The proposed Multimodal Distillation Loss calibrates the fusion network by minimizing the Kullback-Leibler divergence with the peer networks. Additionally, each peer network is conditioned using a self-supervised contrastive objective to improve the generalization across diverse socio-demographic speaker backgrounds. By enabling peer collaborative learning that allows each network to independently learn their mode-specific discriminative patterns,SeMUL-PCD is effective across different conversation environments. In particular, the model not only outperforms the current state-of-the-art models on several large-scale public datasets (e.g., MOSEI, EmoReact and ElderReact), but with around 17% improved weighted F1-score in the cross-dataset experimental settings. The model also demonstrates an impressive generalization ability across age and demography-diverse populations.","In this paper the first results of the process of extracting survival patterns in diagnosed women with invasive cervical cancer with classification techniques from data reported in population-based cancer registry of the municipality of Pasto (Colombia) for a time period of 10 years are presented. The generated knowledge will allow to understand the different socioeconomic and clinical factors affecting the survival of this population group. This knowledge will support effective decision making of government agencies and private health sector in relation to the approach of public policies and prevention programs designed to detect new cases of women with this disease early.","Learning from Label Proportions (LLP) is a machine learning problem where the training data are composed of bags of instances, and only the class label proportions for each bag are given. In some domains, we can directly obtain label distributions; for example, one can use census statistics and social media user information grouped by location to build a classifier for user demographics. However, label proportions are unavailable in many domains, such as product review sites. The solution is to modify the model fit on data from where label proportion are available domains (the source domain) to apply to a domain where the label distributions are not available (target domain). Such problems can be regarded as the unsupervised domain adaptation problems in an LLP setting. The goal of this paper is to introduce domain adaptation methods to the original LLP solutions such that the proposed model can classify instances from a new domain. We propose a model combining domain-adversarial neural network (DANN) and label regularization, which can be fit on the source-domain bags and predict labels for target-domain instances. This approach requires only label proportions in the source domain. Our experiments on both synthetic tasks and sentiment classification tasks indicate a noticeable improvement in accuracy as compared to using LLP without domain adaptation.","Haze classification plays a crucial role in air quality and visibility assessment. In contrast to traditional image classification, haze classification requires the classifier to capture the characteristics of different levels of haze. However, existing methods primarily focus on feature extraction while neglecting the interference of background information. To address this issue, this paper proposes a hard attention infused network (HAINet) for haze classification, consisting of an unsupervised segmentation module (USM) and a hybrid information fusion module (HIF). The USM is used to extract haze area information in an unsupervised manner, generating various forms of haze images. The HIA selects different various forms of haze images, as a hard attention mechanism, to reduce the impact of background and improve classification performance. We conduct experiments on two datasets, Hazel-level and Haze-Wild, in terms of performance comparison, ablation study, and case studies. The results show that our method effectively reduces the impact of background noise in haze images and consistently improves the classification performance.","Cautious classifiers are designed to make indeterminate decisions when the uncertainty on the input data or the model output is too high, so as to reduce the risk of making wrong decisions. In this paper, we propose two cautious decision-making procedures, by aggregating trees providing probability intervals constructed via the imprecise Dirichlet model. The trees are aggregated in the belief functions framework, by maximizing the lower expected discounted utility, so as to achieve a good compromise between model accuracy and determinacy. They can be regarded as generalizations of the two classical aggregation strategies for tree ensembles, i.e., averaging and voting. The efficiency and performance of the proposed procedures are tested on random forests and illustrated on three UCI datasets.","Smart speaker voice assistants (VAs) such as Amazon Echo and Google Home have been widely adopted due to their seamless integration with smart home devices and the Internet of Things (IoT) technologies. These VA services raise privacy concerns, especially due to their access to our speech. This work considers one such use case: the unaccountable and unauthorized surveillance of a user's emotion via speech emotion recognition (SER). This paper presents DARE-GP, a solution that creates additive noise to mask users' emotional information while preserving the transcription-relevant portions of their speech. DARE-GP does this by using a constrained genetic programming approach to learn the spectral frequency traits that depict target users' emotional content, and then generating a universal adversarial audio perturbation that provides this privacy protection. Unlike existing works, DARE-GP provides: a) real-time protection of previously unheard utterances, b) against previously unseen black-box SER classifiers, c) while protecting speech transcription, and d) does so in a realistic, acoustic environment. Further, this evasion is robust against defenses employed by a knowledgeable adversary. The evaluations in this work culminate with acoustic evaluations against two off-the-shelf commercial smart speakers using a small-form-factor (raspberry pi) integrated with a wake-word system to evaluate the efficacy of its real-world, real-time deployment.","Plant pathogens in maize create a severe impact that directly affects agricultural productivity. The foliar disease affects maize growth, where diagnosing and controlling them becomes challenging for farmers. Automatic and early detection of such conditions will aid in the prevention of yield loss by providing appropriate treatment. Leaf textures play a significant role in plant disease recognition, and analyzing them makes the task faster and more efficient. With the computer vision approach, we fused an image processing technique called Gabor filtering as a core pipeline for extracting textural features effectively. This paper proposes an enhanced Convolutional Neural Network (CNN) with Gabor filters called GF-CNN for maize disease classification. Several experiments have been conducted with both machine learning classifiers and CNN and a comparison study was made with the existing approaches. Furthermore, the analysis of the proposed method on maize Plant Village datasets shows that GF-CNN outperforms other existing models with improved accuracy of 99.25%. We also experimented by limiting training samples and attained a significant improvement. Thus, exploring Gabor\u2019s textural patterns for recognizing crop disease can increase the robustness of the classification model.","Extracellular action potentials (EAP) are one of the most important features in biological study. Many researchers have studied the classification of EAP by their differences in voltage and magnitude. However, most research ignored the fundamental origin of the EAP variation around the neurons in their classification and treated waveforms of different shapes as signals recorded from different neurons. In our research, we theoretically investigated the shapes of EAP by clustering the spatially-varied EAP around the neuron. We use an unsupervised machine-learning algorithm to classify all EAPs measured around the same neuron. To eliminate the influence of the non-characteristic part of the EAP curve, we also compared the classification results by eliminating the unchanged part at the front and end of the curve in the second group of our study. Our results illustrate the previously overlooked relationship between different shaped EAP and the biological structure of the neuron. The results show that EAP measured is closer to classical theory prediction in the axon while more eccentric, even with a shape similar to an intracellular action potential in the dendrite. Our research has important implications for further device design to record accurate electric signals and extracting biological related information from extracellular recordings.","In scenarios with long-tailed distributions, the model's ability to identify tail classes is limited due to the under-representation of tail samples. Class rebalancing, information augmentation, and other techniques have been proposed to facilitate models to learn the potential distribution of tail classes. The disadvantage is that these methods generally pursue models with balanced class accuracy on the data manifold, while ignoring the ability of the model to resist interference. By constructing noisy data manifold, we found that the robustness of models trained on unbalanced data has a long-tail phenomenon. That is, even if the class accuracy is balanced on the data domain, it still has bias on the noisy data manifold. However, existing methods cannot effectively mitigate the above phenomenon, which makes the model vulnerable in long-tailed scenarios. In this work, we propose an Orthogonal Uncertainty Representation (hOUR) of feature embedding and an end-to-end training strategy to improve the long-tail phenomenon of model robustness. As a general enhancement tool, OUR has excellent compatibility with other methods and does not require additional data generation, ensuring fast and efficient training. Comprehensive evaluations on long-tailed datasets show that our method significantly improves the long-tail phenomenon of robustness, bringing consistent performance gains to other long-tailed learning methods.","The original K-nearest neighbour (KNN) algorithm was meant to classify homogeneous complete data, that is, data with only numerical features whose values exist completely. Thus, it faces problems when used with heterogeneous incomplete (HI) data, which has also categorical features and is plagued with missing values. Many solutions have been proposed over the years but most have pitfalls. For example, some solve heterogeneity by converting categorical features into numerical ones, inflicting structural damage. Others solve incompleteness by imputation or elimination, causing semantic disturbance. Almost all use the same K for all query objects, leading to misclassification. In the present work, we introduce KNNHI, a KNN-based algorithm for HI data classification that avoids all these pitfalls. Leveraging rough set theory, KNNHI preserves both categorical and numerical features, leaves missing values untouched and uses a different K for each query. The end result is an accurate classifier, as demonstrated by extensive experimentation on nine datasets mostly from the University of California Irvine repository, using a 10-fold cross-validation technique. We show that KNNHI outperforms six recently published KNN-based algorithms, in terms of precision, recall, accuracy and F-Score. In addition to its function as a mighty classifier, KNNHI can also serve as a K calculator, helping KNN-based algorithms that use a single K value for all queries that find the best such value. Sure enough, we show how four such algorithms improve their performance using the K obtained by KNNHI. Finally, KNNHI exhibits impressive resilience to the degree of incompleteness, degree of heterogeneity and the metric used to measure distance.","The predict-then-optimize framework is fundamental in many practical settings: predict the unknown parameters of an optimization problem and then solve the problem using the predicted values of the parameters. A natural loss function in this environment is to consider the cost of the decisions induced by the predicted parameters in contrast to the prediction error of the parameters. This loss function is referred to as the smart predict-then-optimize (SPO) loss. In this work, we seek to provide bounds on how well the performance of a prediction model fit on training data generalizes out of sample in the context of the SPO loss. Because the SPO loss is nonconvex and non-Lipschitz, standard results for deriving generalization bounds do not apply. We first derive bounds based on the Natarajan dimension that, in the case of a polyhedral feasible region, scale at most logarithmically in the number of extreme points but, in the case of a general convex feasible region, have linear dependence on the decision dimension. By exploiting the structure of the SPO loss function and a key property of the feasible region, which we denote as the strength property, we can dramatically improve the dependence on the decision and feature dimensions. Our approach and analysis rely on placing a margin around problematic predictions that do not yield unique optimal solutions and then providing generalization bounds in the context of a modified margin SPO loss function that is Lipschitz continuous. Finally, we characterize the strength property and show that the modified SPO loss can be computed efficiently for both strongly convex bodies and polytopes with an explicit extreme point representation.\nFunding: O. El Balghiti thanks Rayens Capital for their support. A. N. Elmachtoub acknowledges the support of the National Science Foundation (NSF) [Grant CMMI-1763000]. P. Grigas acknowledges the support of NSF [Grants CCF-1755705 and CMMI-1762744]. A. Tewari acknowledges the support of the NSF [CAREER grant IIS-1452099] and a Sloan Research Fellowship.","Blood Pattern Analysis is a technique in forensic science that focuses on leftover bloodstains from the crime to recreate the event. However, the fluctuation in air resistance and drop deformity causes the calculations to deviate from the exact values. Therefore, machine learning models were constructed to overcome this limitation of calculations. A series of experiments was conducted by dropping porcine blood on paper across nine distinct heights: 20, 40, 60, 80, 100, 120, 140, 160, and 180 cm with four different drop volumes: 13, 16, 25, and 30 \u03bcL resulting in 36 classes. A simple simulation of a free-fall spherical object was also created to convert any drop height into impact velocity. Regarding both the empirical data and simulation, the correlation between the spreading factor and modified Reynold number, along with the number of spines and modified Weber number, were expressed as equations that can be used to determine drop height and drop volume. Concurrently, the same dataset used in physics calculations was used to train machine learning models that implement VGG-19 and XGBoost. For VGG-19, the inputs are images of bloodstains, while for XGBoost, the inputs are stain area, stain perimeter, and the number of spines. As a result, the accuracy for physics equations VGG-19 and XGBoost were 0.26, 0.56, and 0.49, respectively.","According to the characteristics of complex feature information garbage classification application, a garbage classification method based on multi-source information fusion based on Bayesian network is proposed.In this method, the training sample data is preprocessed by La Pullaras smoothing method to solve the problem of zero prior probability in traditional Bayesian method and eliminate the influence of zero value prior probability on fusion results.Then, according to the decision information of the image sensor, combined with the multi-source heterogeneous characteristic information of other sensors of different types, the multi-source information fusion model is established by using the improved Bayesian parameter estimation algorithm.Bayesian networks are established and Bayesian classifiers are constructed to simplify the fusion results. Finally, the discriminant results are obtained by calculating the maximum posterior probability estimate.Through comparative experiments, the average discrimination accuracy of the improved data fusion method for complex feature information garbage samples is increased from 89.5% to 98.5%, which proves that the method can fully integrate multi-source heterogeneous feature information, reduce the high fuzziness of the discrimination process of hazardous waste and recyclable waste, so as to obtain more accurate classification results.This has important theoretical significance and practical value for the classification of complex garbage in daily life.","As the latest representative of GNSS positioning technology, the PPP-RTK method, which is able to achieve centimeter-level positioning using a single receiver, has been recognized as a preferred alternative for emerging applications such as self-drive cars and unmanned ariel vehicles. Nevertheless, the performance of PPP-RTK faces serious challenges in urban environments due to the severe impact of multipath and non-line-of-sight (NLOS) reception. Presently, machine learning-based signal classification methods are increasingly prevalent, which have great potential to serve for detecting NLOS signals by leveraging a wide range of features and parameters. In this contribution, a novel NLOS signal detection method based on the machine learning algorithm is developed, aiming to improve the kinematic positioning performance of PPP-RTK in urban areas. A multilayer perceptron (MLP)-based signal classifier is proposed where the signal strength, satellite elevation and pseudorange consistency are considered as input and then mapped to the signal type labeled by the fish-eye camera. Furthermore, a new stochastic model derived from both the classification results and the prediction confidence is also developed and employed in PPP-RTK processing. Several vehicular experiments are conducted in diverse urban areas to verify the effectiveness of the proposed method. Results indicate that the proposed method outperforms the traditional PPP-RTK with the 3D positioning accuracy improved by 36.7\u201342.3%. Besides, the horizontal positioning availability within 0.1 m and 1 m is improved from 34.9% to 76.3% and 69.5% to 92.1%, respectively. In partly blocked areas, the proposed method is capable of providing continuous centimeter-level positions in both horizontal and vertical directions. Particularly, in urban canyon, the vertical positioning accuracy is dramatically improved by 80.3% with NLOS signals effectively mitigated.","Background: Breast cancer is one of the greatest health threats to women worldwide. Mammography is an effective and inexpensive tool for breast cancer early detection. Mammography-based breast cancer screening requires a lot of manpower from professional experts. Thus, computer-aided diagnosis tools, especially accurate classifiers which can distinguish the breast masses from the background tissues, are needed. However, since the sample size of publicly available mammography data sets is relatively small, the performance of the published breast mass identification models was not great, and the models were not well-embraced by clinical practice due to their low interpretability. Methods: In this work, using two independent and well-known mammography data sets, the CBIS-DDSM and the INbreast, we proposed a novel patch generation method for data augmentation and negative case generation. We implemented two successful deep learning models, the ResNet and the ViT, to classify the generated mass and non-mass patches. We also proposed to apply the patch-level model to the full-view mammogram screening in a sliding window manner and visualize/interpret the prediction results using a heatmap so that the clinic practice could potentially benefit from the well-trained model. Result: For the CBIS-DDSM dataset, we compared the performance of the ResNet and the ViT with and without data augmentation. The F1 score is 0.91, 0.86, 0.85, and 0.70, respectively. We also evaluated our models using other metrices such as accuracy, precision, recall, and ROC curve. The results show that the ResNet model outperforms the ViT model. And the data augmentation improves the overall performance of the models. The similar conclusions are further supported using the independent INbreast data. Furthermore, we also explored to use probability-based heatmaps to visualize the potential mass regions in mammogram images. Conclusion: The study shows that our patch-level data augmentation is effective in improving the classification performance of the deep learning models. The comparable performance on the CBIS-DDSM data and the independent INbreast data demonstrates the generalizability of our methods. The proposed heatmap visualization tool increases the interpretability of our results and could be a potential approach for clinic utilization.","Text classification is a fundamental task for natural language processing, and adapting text classification models across domains has broad applications. Self-training generates pseudoexamples from the model's predictions and iteratively train on the pseudo-examples, i.e., mininizes the loss on the source domain and the Gibbs entropy on the target domain. However, Gibbs entropy is sensitive to prediction errors, and thus, self-training tends to fail when the domain shift is large. In this paper, we propose Meta-Tsallis Entropy minimization (MTEM), which applies meta-learning algorithm to optimize the instance adaptive Tsallis entropy on the target domain. To reduce the computation cost of MTEM, we propose an approximation technique to approximate the Second-order derivation involved in the meta-learning. To efficiently generate pseudo labels, we propose an annealing sampling mechanism for exploring the model's prediction probability. Theoretically, we prove the convergence of the meta-learning algorithm in MTEM and analyze the effectiveness of MTEM in achieving domain adaptation. Experimentally, MTEM improves the adaptation performance of BERT with an average of 4 percent on the benchmark dataset.","The family orientation process in Cuban Schools for children with Affective \u2013 Behavioral Maladies (SABM) involves clustering and classification of mixed type data with non-symmetric similarity functions. To improve this process, this paper includes some novel characteristics in clustering and prototype selection. The proposed approach uses a hierarchical clustering based on compact sets, making it suitable for dealing with non-symmetric similarity functions, as well as with mixed and incomplete data. The proposal obtains very good results on the SABM data, and over repository databases. In addition, the proposed clustering method is able to detect the true partitions of data and it was significantly better with respect to others according to external validity indexes. In prototype selection, the proposal obtains a highly reduced prototype set, while maintains the original classifier accuracy.","The task of annotating a data point with labels most relevant to it from a large universe of labels is referred to as Extreme Classification (XC). State-of-the-art XC methods have applications in ranking, recommendation, and tagging and mostly employ a combination architecture comprised of a deep encoder and a high-capacity classifier. These two components are often trained in a modular fashion to conserve compute. This paper shows that in XC settings where data paucity and semantic gap issues abound, this can lead to suboptimal encoder training which negatively affects the performance of the overall architecture. The paper then proposes a lightweight alternative DEXA that augments encoder training with auxiliary parameters. Incorporating DEXA into existing XC architectures requires minimal modifications and the method can scale to datasets with 40 million labels and offer predictions that are up to 6% and 15% more accurate than embeddings offered by existing deep XC methods on benchmark and proprietary datasets, respectively. The paper also analyzes DEXA theoretically and shows that it offers provably superior encoder training than existing Siamese training strategies in certain realizable settings. Code for DEXA is available at https://github.com/Extreme-classification/dexa.","This paper proposes a texture-based domain-specific data augmentation technique applicable when training on small datasets for deep learning classification tasks. Our method focuses on label-preservation to improve generalization and optimization robustness over data-dependent augmentation methods using textures. We generate a small perturbation in an image based on a randomly sampled texture image. The textures we use are naturally occurring and domain-independent of the training dataset: regular, near regular, irregular, near stochastic and stochastic classes. Our method uses the textures to apply sparse, patterned occlusion to images and a penalty regularization term during training to help ensure label preservation. We evaluate our method against the competitive soft-label Mixup and RICAP data augmentation methods with the ResNet-50 architecture using the unambiguous \u201cBird or Bicyle\u201d and Oxford-IIT-Pet datasets, as well as a random sampling of the Open Images dataset. We experimentally validate the importance of label-preservation and improved generalization by using out-of-distribution examples and show that our method improves over competitive methods.","Skip Abstract Section\nAbstract\nNetwork slicing (Ns) is a key enabling technology to support the concurrent provisioning of better quality of service (QoS) in 5G networks. These services have become essential for a telecom service provider (SP) to offer better QoS and QoE (quality of experience). The QoS parameters are used to estimate the performance of the network, and QoE determines user satisfaction with the network services. The main challenges faced by the service provider are to select the appropriate slice for each service and accurately classify these services on a timely basis to satisfy the Service level agreement (SLA) while improving the QoS and QoE. To overcome this issue, machine learning (ML) is a good solution. In this paper, we have proposed a 5G-KPQI (5G-key performance and quality indicator) model that considers the 5G service-based dataset for the 5G services classification. Next, we used feature selection (FS) methods to rank and select the best feature subset, which increases the performance of ML models and also reduces the training time required by the models. We subsequently considered various ML models to classify the services. Results demonstrate that the 5G-KPQI model ranks the features using Relief-F and mrMR methods and also reduces the training time of the model, hence improving classification performance measured by precision, accuracy, F1-score, recall, MCC, and time. The evaluation of the key approach outperforms in high classification accuracy and less training time using decision tree (DT) and random forest (RF).","Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility. Our proposed model is rigorously tested in the context of the HuMob Challenge 2023---a competition designed to evaluate the performance of prediction models on standardized datasets to predict human mobility. The challenge leverages two datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a longitudinal period of 75 days. Geo-Former stands out as a top performer in the competition, securing a place in the top-3 ranking. Its success is underscored by performing well on both performance metrics chosen for the competition---the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of the GeoFormer on the HuMob Challenge 2023 underscores its potential to make substantial contributions to the field of human mobility prediction, with far-reaching implications for disaster preparedness, epidemic control, and beyond.","Attention, one of the most important features of modern CNNs, has been shown to improve the performance of mammogram classification, but our understanding of why attention offers improvements is rather limited. In this paper, we present the first comprehensive comparison of different combinations of baseline models and attention methods at multiple resolutions for whole mammogram image classification of masses and calcifications. Our findings indicate that attention generally helps to improve the baseline model scores, but the benefits are variable depending on the resolution and abnormality type. Furthermore, we find that pooling and overall model architecture (i.e., combination of baseline and attention) significantly impact mammogram classification scores. Specifically, scores are generally improved by architectural features that allow the model to retain as much information as possible while still focusing on relevant features. We also find that attention improves the correlation between model performance and LayerCAM activation in the region of interest. Our work provides insightful information to help guide the future construction of attention-based models for mammogram classification.","Graph neural networks (GNNs) are increasingly used in critical human applications for predicting node labels in attributed graphs. Their ability to aggregate features from nodes' neighbors for accurate classification also has the capacity to exacerbate existing biases in data or to introduce new ones towards members from protected demographic groups. Thus, it is imperative to quantify how GNNs may be biased and to what extent their harmful effects may be mitigated. To this end, we propose two new GNN-agnostic interventions namely, (i) PFR-AX which decreases the separability between nodes in protected and non-protected groups, and (ii) PostProcess which updates model predictions based on a blackbox policy to minimize differences between error rates across demographic groups. Through a large set of experiments on four datasets, we frame the efficacies of our approaches (and three variants) in terms of their algorithmic fairness-accuracy tradeoff and bench- mark our results against three strong baseline interventions on three state-of-the-art GNN models. Our results show that no single intervention offers a universally optimal tradeoff, but PFR-AX and PostProcess provide granular control and improve model confidence when correctly predicting positive outcomes for nodes in protected groups.","Mobile application (App) reviews which are provided by users through different App stores are considered as a rich information source for developers to inform about bugs, new feature requests, performance issues, etc. These feedbacks help developers improve the quality of their apps which in turn will significantly impact the user experience and the App\u2019s overall ratings. Popular Apps receive a high number of user reviews daily which makes their manual analysis a very tedious and time-consuming task. Automating the classification of user reviews will save developers time and help them better prioritize the issues that need to be handled. Since an App review is text data in which a user may report more than one issue, we propose a multi-label text classification model which uses neural language models. These models have shown high performance in various natural language processing problems. Experimental results confirm that neural language models outperform frequency-based methods in the context of App reviews classification. In fact, with RoBERTa, we could achieve a 0.87 average F1-score and a 0.16 hamming loss performances.","Automated credit risk assessment plays an important role in agricultural lending. However, credit risk assessment in the agricultural domain has unique challenges due to the impact of weather, pest outbreaks, commodities market dynamics, and other volatile forces that drive risk. Training a model to account for these factors requires immense data assets that are challenging to obtain. Indeed, even the best credit risk assessment models in this domain are trained using data from single-institutions that often focus on dedicated geographical regions, or singular commodities. Hence, most agricultural credit risk models exhibit poor out-of-domain performance. In this paper, we use a novel dataset describing nearly 100 thousand historical loans, sourced from 9 large agricultural lenders to train a Bayesian network model for loan delinquency classification. The proposed model exhibited improved calibration (relative improvement in Expected Calibration Error) in out-of-domain performance tests when compared to three state-of-the-art credit risk scoring approaches: Logistic regression (81 \u00b1 15% improvement), XGBoost (80 \u00b1 14% improvement), and an Artificial Neural Networks (7 \u00b1 2% improvement). We conclude that Bayesian networks provide better modeling of agricultural credit risk by combining (limited) data assets with expert domain knowledge. Our approach is likely to generalize to any credit risk assessment task where small sample sizes is of concern.","The ability to detect out-of-distribution (OOD) inputs is essential for safely deploying machine learning models in an open world. Most existing research on OOD detection, and more generally uncertainty quantification, has focused on multi-class classification. However, for many information retrieval (IR) applications, the classification of documents or images is by nature not multi-class but multi-label. This paper presents a pure theoretical analysis of the under-explored problem of OOD detection in multi-label classification using deep neural networks. First, we examine main existing approaches such as MSP (proposed in ICLR-2017) and MaxLogit (proposed in ICML-2022), and summarize them as different combinations of label-wise scoring and aggregation functions. Some existing methods are shown to be equivalent. Then, we prove that JointEnergy (proposed in NeurIPS-2021) is indeed the optimal probabilistic solution when the class labels are conditionally independent with each other for any given data sample. This provides a more rigorous explanation for the effectiveness of JointEnergy than the original joint-likelihood interpretation, and also reveals its reliance upon the assumption of label independence rather than the exploitation of label relationships as previously thought. Finally, we discuss potential future research directions in this area.","During the several years of production of an animated movie, review meetings take place daily, where supervisors and directors generate text notes about fixes needed for the movie. These notes are manually assigned to artistic departments for them to fixed. Being manual, many notes are not properly assigned and are never fixed, lowering the quality of the final movie. This paper presents a proposal for automating the distribution of these notes using multi-label text classification techniques. The comparison of the results obtained by fine-tuning several transformer-based language models is presented. A highest mean accuracy of 0.776 is achieved assigning several departments to each of the review notes in the test set with a BERT Multilingual model. A mean accuracy of 0.762 was reached in just 10 epochs and 10 min of training on an RTX-3090 with a DistilBERT transformer model.","This paper applies Natural Language Processing (NLP) methods to analyze the exposure to trauma experienced by witnesses in international criminal tribunals when testifying in court. One major contribution of this study is the creation of a substantially extended version of the Genocide Transcript Corpus (GTC) that includes 52,845 text segments of transcripts from three different genocide tribunals. Based on this data, we first examine the prevalence of trauma-related content in witness statements. Second, we are implementing a binary classification algorithm to automatically detect potentially traumatic content. Therefore, in a preparatory step, an Active Learning (AL) approach is applied to establish the ideal size for the training data set. Subsequently, this data is used to train a transformer model. In this case, the two models BERTbase and HateBERT are used for both steps, allowing for a comparison of a base-level model with a model that has already been pre-trained on data more relevant in the context of harmful vocabulary. In a third step, the study employs an Explainable Artificial Intelligence (XAI) model to gain a deeper understanding of the reasoning behind the model's classifications. Our results suggest that both BERTbase and HateBERT perform comparatively well on this classification task, with no model clearly outperforming the other. The classification outcomes further suggest that a reduced data set size can achieve equally high performance metrics and might be a preferable choice in certain use cases. The results can be used to establish more trauma-informed legal procedures in genocide-related tribunals, including the identification of potentially re-traumatizing examination approaches at an early stage.\nWarning: Due to the overall purpose of the study, this paper contains descriptions of violent events in Section 4.1 (Examples 1 and 2) and in Figure 3 that may be distressing for some readers.","As one of the major threats to the healthy development of various online platforms, fraud has become increasingly committed in the form of gangs since collusive fraudulent activities are much easier to obtain illicit benefits with lower exposure risk. To detect fraudsters in a gang, spatio-temporal graph neural network models have been widely applied to detect both temporal and spatial collusive patterns. However, a closer peek into real-world records of fraudsters can reveal that fraud gangs usually conduct community-level camouflage, specified by two types, i.e., temporal and spatial camouflage. Such camouflage can disguise gangs as benign communities by concealing collusive patterns and thus deceiving many existing graph neural network models. In the meantime, many existing graph neural network models suffer from the challenge of extreme sample imbalance caused by rare fraudsters hidden among massive users. To handle all these challenges, in this paper, we propose a generative adversarial network framework, named Adversarial Camouflage Detector, to detect fraudsters. Concretely, this ACD framework consists of four modules, in charge of community division, camouflage identification, fraudster detection, and camouflage generation, respectively. The first three modules form up a discriminator that uses spatio-temporal graph neural networks as the foundation model and enhance fraudster detection by amplifying the gangs' collusive patterns through automatically identifying and removing camouflage. Meanwhile, the camouflage generation module plays as the generator role that generates fraudsters samples by competing against the discriminator to alleviate the challenge of sample imbalance and increase the model robustness. The experimental result shows that our proposed method outperforms other methods on real-world datasets.","Label distribution learning (LDL) is a new machine learning paradigm for solving label ambiguity. Since it is difficult to directly obtain label distributions, many studies are focusing on how to recover label distributions from logical labels, dubbed label enhancement (LE). Existing LE methods estimate label distributions by simply building a mapping relationship between features and label distributions under the supervision of logical labels. They typically overlook the fact that both features and logical labels are descriptions of the instance from different views. Therefore, we propose a novel method called Contrastive Label Enhancement (ConLE) which integrates features and logical labels into the unified projection space to generate high-level features by contrastive learning strategy. In this approach, features and logical labels belonging to the same sample are pulled closer, while those of different samples are projected farther away from each other in the projection space. Subsequently, we leverage the obtained high-level features to gain label distributions through a well-designed training strategy that considers the consistency of label attributes. Extensive experiments on LDL benchmark datasets demonstrate the effectiveness and superiority of our method.","Significant work has been done on learning regular expressions from a set of data values. Depending on the domain, this approach can be very successful. However, significant time is required to learn these expressions and the resulting expressions can become either very complex or inaccurate in the presence of dirty data. The alternative of manually writing regular expressions becomes unattractive when faced with a large number of values that must be matched.\nAs an alternative, we propose learning from a large corpus of manually authored, but uncurated regular expressions mined from a public repository. The advantage of this approach is that we are able to extract salient features from a set of strings with limited overhead to feature engineering. Since the set of regular expressions covers a wide range of application domains, we expect them to be widely applicable.\nTo demonstrate the potential effectiveness of our approach, we train a model using the extracted corpus of regular expressions for the class of semantic type classification. While our approach yields results that are overall inferior to the state-of-the-art, our feature extraction code is an order of magnitude smaller, and our model outperforms a popular existing approach on some classes. We also demonstrate the possibility of using uncurated regular expressions for unsupervised learning.","This paper presents a LIghtweight Domain Adaptive Cell Segmentation (LIDACS) framework that achieves state-of-the-art results (0.9505 mIoU) in instance segmentation on the SegPC-21 challenge dataset featured in ISBI 2021, while being significantly parameter efficient than the existing methods. LIDACS is a hierarchical multi-stage approach that utilizes prior domain-specific information to perform statistical and empirical analysis. It also employs task-specific augmentations and improved transfer learning via shared representation to enable better data representation. LIDACS also applies a novel cell structure-based contrastive augmentation paired with cell cloning, increasing annotation density and promoting better stain color in-variance. Effectively, LIDACS is a lightweight architecture, efficient for practical deployment, that provides optimal generalization.","Glaciers play a critical role in the Earth\u2019s climate system, and accurate estimates of their behaviours are essential for understanding the impacts of climate change and informing policy decisions. One of the most important parameters for such a task is ice distribution, which is difficult to measure and predict using traditional physics-based models. In this study, we propose a deep learning approach to predict glacier thickness by learning directly from ice velocity and topography. Our approach overcomes the limitations of traditional physics-based models, such as computational cost and the need for expert knowledge to calibrate the models. In addition, deep learning models are flexible enough to explore the relevance of multimodality and multitasking to address the physical problem. Our results demonstrate the feasibility of quickly training a neural network model with sufficient training data and producing stable, high-quality ice thickness estimates. We highlight the importance of some specific input features suggested by geophysicists that have a positive impact on model stability.","Visual recognition methods assume models will be evaluated on the same class distribution as training data, but real-world data is often heavily class-imbalanced. To address this, the essential idea is to provide discriminative fitting abilities for classes with different sample sizes, i.e., the model achieves better generalization on less frequent classes, while maintaining high classification ability on the recurring classes. In this work, we propose to unify representation learning and classification learning with robust margin adjustment, which enforces a suitable margin in logit space and regularizes the distribution of embeddings. This procedure reduces representation bias in the feature space and reduces classification bias in the logit space at the same time. We further augment the under-represented tail classes on the feature level via re-balanced sampling from the robust prototype, calibrated with the knowledge from well-represented head classes and adaptive embedding uncertainty estimation. We conduct extensive experiments on a common long-tailed benchmark CIFAR100-LT. Experimental results demonstrate the advantage of the proposed AMDRG for the long-tailed recognition problem.","In this paper, we propose a generalization of classical Rough Sets, the Nearest Neighborhood Rough Sets, by modifying the indiscernible relation without using any similarity threshold. We also combine these Rough Sets with Compact Sets, to obtain a prototype selection algorithm for Nearest Prototype Classification of mixed and incomplete data as well as arbitrarily dissimilarity functions. We introduce a set of rules to a priori predict the performance of the proposed prototype selection algorithm. Numerical experiments over repository databases show the high quality performance of the method proposed in this paper according to classifier accuracy and object reduction.","The rapid development of the Internet has led to a geometric expansion of text information resources online. Among them, corpus, as the basic data source of natural language processing based on statistical language model, its construction and application have become a hot issue in current language processing research. After consulting a large number of relevant literature and materials, it was found that many researchers have provided new ideas for multi label corpus text classification methods. However, this article was adding its own understanding and taking this as the direction and basis. In the introduction, the research significance of text classification was introduced, and then academic research and analysis were carried out on the two key sentences of corpus text classification and natural language processing in multi tag corpus text classification. This article then utilized an algorithm model to provide a theoretical basis for the study of multi label corpus text classification methods; At the end of the article, a simulation comparative experiment would be conducted, and the experiment would be summarized and discussed; In the Enterprise L corpus, the difference in recall rates before and after the use of Entrance 1 was 5.5%, the difference in recall rates before and after the use of Entrance 2 was 7.8%, the difference in recall rates before and after the use of Entrance 3 was 3.3%, and the difference in recall rates before and after the use of Entrance 4 was 4.5%. At the same time, with the continuous research of natural language processing and machine learning, the research on text classification methods of multi tag corpus is also facing new opportunities and challenges.","Ensemble classifiers have been investigated by many in the artificial intelligence and machine learning community. Majority voting and weighted majority voting are two commonly used combination schemes in ensemble learning. However, understanding of them is incomplete at best, with some properties even misunderstood. In this paper, we present a group of properties of these two schemes formally under a geometric framework. Two key factors, every component base classifier\u2019s performance and dissimilarity between each pair of component classifiers are evaluated by the same metric\u2014the Euclidean distance. Consequently, ensembling becomes a deterministic problem and the performance of an ensemble can be calculated directly by a formula. We prove several theorems of interest and explain their implications for ensembles. In particular, we compare and contrast the effect of the number of component classifiers on these two types of ensemble schemes. Some important properties of both combination schemes are discussed. And a method to calculate the optimal weights for the weighted majority voting is presented. Empirical investigation is conducted to verify the theoretical results. We believe that the results from this paper are very useful for us to understand the fundamental properties of these two combination schemes and the principles of ensemble classifiers in general. The results are also helpful for us to investigate some issues in ensemble classifiers, such as ensemble performance prediction, diversity, ensemble pruning, and others.","Parkinson\u2019s Disease is the second most prevalent neurodegenerative disorder, currently affecting as high as 3% of the global population. Research suggests that up to 80% of patients manifest phonatory symptoms as early signs of the disease. In this respect, various systems have been developed that identify high risk patients by analyzing their speech using recordings obtained from natural dialogues and reading tasks conducted in clinical settings. However, most of them are centralized models, where training and inference take place on a single machine, raising concerns about data privacy and scalability. To address these issues, the current study migrates an existing, state-of-the-art centralized approach to the concept of federated learning, where the model is trained in multiple independent sessions on different machines, each with its own dataset. Therefore, the main objective is to establish a proof of concept for federated learning in this domain, demonstrating its effectiveness and viability. Moreover, the study aims to overcome challenges associated with centralized machine learning models while promoting collaborative and privacy-preserving model training.","Automated machine learning (AutoML) has allowed for many innovations in biomedical data science; however, most AutoML approaches do not support image or text data. To rectify this, we implemented four feature extractors in the Tree-based Pipeline Optimization Tool (TPOT) to make TPOT with Feature Extraction (TPOT-FE), an automated machine learning system that uses genetic programming (GP) to create ideal pipelines for a classification or regression task. These feature extractors enable TPOT-FE to build pipelines that can analyze non-tabular data, including text and images, which are increasingly common biomedical big data modalities that can contain rich quantities of information. We evaluate this approach on six image datasets and four text datasets, including three biomedical datasets, and show that TPOT-FE is able to consistently construct and optimize classification pipelines on all of the datasets.","This paper presents an automatic dialect identification in Ao using modulation-based approach. Ao is a low-resource, Tibeto-Burman tonal language spoken in Nagaland, a North-East state of India. This work aims to investigate dialect-specific characteristics to build a more robust DID system for classifying the three Ao dialects. In this direction, modulation-based representation is explored. Considering Ao is a tone language, the experiments were evaluated for 3 sec segment duration in order to capture the temporal information of the modulation spectrogram. In addition, the log Mel spectrogram is used as the feature for the baseline DID system. The proposed modulation spectrogram shows a significant performance of\n\u2248\n8\n%\nimprovement in accuracy over the baseline Ao DID system. Hence, the result indicates the effectiveness of modulation-based representation in automatically identifying the three dialects of Ao.","With the exponential increase of interdisciplinary research, identifying accurate disciplines of scientific documents has become increasingly important in various research management tasks. Interdisciplinary classification, which classifies documents into multiple disciplines, is essential for multidisciplinary research development. Due to the scarcity of labeled multidiscipline data, existing scientific document classification methods can't solve the interdisciplinary issue. Most of them also have the problem of explainability with curtly providing classification results. This study proposes an explainable transfer-learning-based classification method for interdisciplinary documents. First, we trained a single-discipline classification model using existing labeled single-discipline documents. Then, we transfer the knowledge learned from single-discipline classification to interdisciplinary classification to address the scarcity of labeled interdisciplinary data. We also added discipline co-occurrence information into our proposed model. Finally, we obtained our final model by training the transferred model with interdisciplinary data. In addition, keyword-based explanations for classifying texts are provided by employing layer-wise relevance propagation. Experiments on real-life NSFC data show the effectiveness of the proposed method, which can promote interdisciplinary development by constructing an efficient and fair classification for interdisciplinary review systems.","Online English teaching resources have recently surged, highlighting the exigency for efficient organization and categorization. This manuscript introduces an innovative strategy to classify university-level English teaching resources, employing a sophisticated density clustering algorithm. Initially, student discourse was mined within a teaching platform comment section, and in-depth textual analysis was conducted. Subsequently, the term frequency-inverse document frequency (TF\u2013IDF) feature extraction algorithm was enhanced, while emotive attributes were seamlessly integrated into the textual manifestation layer during the classification procedure. This enabled the distribution of topics and emotions to be acquired for each comment, facilitating subsequent analyses of emotion feature extraction and model training. An improved weight calculation was designed based on TF\u2013IDF to evaluate the importance of feature items for each corpus file. The simulation results demonstrate the proposed scheme's effectiveness. The algorithm facilitates faster scholarly access to educational resource information and effectively classifies data for high research adaptability.","We presented the Pyramid Swin Transformer, a versatile and efficient architecture tailored for object detection and image classification. This time we applied it to a wider range of tasks, such as object detection, image classification, semantic segmentation, and video recognition tasks. Our architecture adeptly captures local and global contextual information by employing more shift window operations and integrating diverse window sizes. The Pyramid Swin Transformer for Multi-task is structured in four stages, each consisting of layers with varying window sizes, facilitating a robust hierarchical representation. Different numbers of layers with distinct windows and window sizes are utilized at the same scale. Our architecture has been extensively evaluated on multiple benchmarks, including achieving 85.4% top-1 accuracy on ImageNet for image classification, 51.6\nA\nP\nbox\nwith Mask R-CNN and 54.3\nA\nP\nbox\nwith Cascade Mask R-CNN on COCO for object detection, 49.0 mIoU on ADE20K for semantic segmentation, and 83.4% top-1 accuracy on Kinetics-400 for video recognition. The Pyramid Swin Transformer for Multi-task outperforms state-of-the-art models in all tasks, demonstrating its effectiveness, adaptability, and scalability across various vision tasks. This breakthrough in multi-task learning architecture opens the door to new research and applications in the field.","Malignant brain tumors including parenchymal metastatic (MET) lesions, glioblastomas (GBM), and lymphomas (LYM) account for 29.7% of brain cancers. However, the characterization of these tumors from MRI imaging is difficult due to the similarity of their radiologically observed image features. Radiomics is the extraction of quantitative imaging features to characterize tumor intensity, shape, and texture. Applying machine learning over radiomic features could aid diagnostics by improving the classification of these common brain tumors. However, since the number of radiomic features is typically larger than the number of patients in the study, dimensionality reduction is needed to balance feature dimensionality and model complexity.\nAutoencoders are a form of unsupervised representation learning that can be used for dimensionality reduction. It is similar to PCA but uses a more complex and non-linear model to learn a compact latent space. In this work, we examine the effectiveness of autoencoders for dimensionality reduction on the radiomic feature space of multiparametric MRI images and the classification of malignant brain tumors: GBM, LYM, and MET. We further aim to address the class imbalances imposed by the rarity of lymphomas by examining different approaches to increase overall predictive performance through multiclass decomposition strategies.","Meta-learning has made tremendous progress in recent years and was demonstrated to be particularly suitable in low-resource settings where training data is very limited. However, meta-learning models still require large amounts of training tasks to achieve good generalisation. Since labelled training data may be sparse, self-supervision-based approaches are able to further improve performance on downstream tasks. Although no labelled data is necessary for this training, a large corpus of unlabelled text needs to be available. In this paper, we improve on recent advances in meta-learning for natural language models that allow training on a diverse set of training tasks for few-shot, low-resource target tasks. We introduce a way to generate new training data with the need for neither more supervised nor unsupervised datasets. We evaluate the method on a diverse set of NLP tasks and show that the model decreases in performance when trained on this data without further adjustments. Therefore, we introduce and evaluate two methods for regularising the training process and show that they not only improve performance when used in conjunction with the new training data but also improve average performance when training only on the original data, compared to the baseline.","Much of Earth's charismatic megafauna is endangered by human activities, particularly the rhino, which is at risk of extinction due to the poaching crisis in Africa. Monitoring rhinos' movement is crucial to their protection but has unfortunately proven difficult because rhinos are elusive. Therefore, instead of tracking rhinos, we propose the novel approach of mapping communal defecation sites, called middens, which give information about rhinos' spatial behavior valuable to antipoaching, management, and reintroduction efforts. This paper provides the first-ever mapping of rhino midden locations by building classifiers to detect them using remotely sensed thermal, RGB, and LiDAR imagery in passive and active learning settings. As existing active learning methods perform poorly due to the extreme class imbalance in our dataset, we design MultimodAL, an active learning system employing a ranking technique and multimodality to achieve competitive performance with passive learning models with 94% fewer labels. Our methods could therefore save over 76 hours in labeling time when used on a similarly-sized dataset. Unexpectedly, our midden map reveals that rhino middens are not randomly distributed throughout the landscape; rather, they are clustered. Consequently, rangers should be targeted at areas with high midden densities to strengthen anti-poaching efforts, in line with UN Target 15.7.","This paper introduces a binary classification network that utilizes the Informer Encoder to classify ping pong actions as either correct or incorrect. The dataset used in this study comprises 949 action videos capturing two fundamental ping pong stroke actions performed by athletes, including both correct and incorrect actions. The average frame count for each action is 38.62. Temporal skeletal data is extracted from the videos using a 2D pose estimation model, and a fully connected layer is employed to perform binary classification on the temporal skeletal data. During training and testing, the extracted skeletal data is segmented into temporal sequences of 39 frames for training and evaluation. On the test set, the Informer Encoder-based model achieves 100% accuracy, while the MLP-based model reaches 94%.","Arrhythmia categorization is an exciting research in the early prevention and detection of cardiovascular illnesses, using Electrocardiogram (ECG). In the case of ECG signals, time series data are obtained by changing the time. This type of signal has the drawback of requiring repeated acquisition of comparison data with the same size as the registration data. Resolving the issue of inconsistent data size is accomplished by the use of an additional classifier-based adversarial neural networks. Adversarial data synthesis using Generative Adversarial Networks (GANs) and the generation of additional training examples solves the basic problem of insufficient data labelling. Recent studies have used the GAN architecture to create synthetic adversarial ECG signals in order to boost the amount of training data already available. The arrhythmia detection system, on the other hand, has a fragmented Convolution Neural Network (CNN) classification architecture. No flexible structural design has yet been suggested that can simultaneously discover and order abnormalities. An exceptional Prioritized Feature Subset Vector-Associated Generative Adversarial Network (PFSV-AGAN) is proposed in this research in order at a time produce ECG indications for multiple classes and sense heart-related problems. Furthermore, the model is based on class-specific ECG signals in order to generate realistic adversarial cases. This research presents a framework for ECG signal abnormality identification that has an unbalanced distribution among classes and achieves high accuracy in abnormalities categorization. After training on datasets, the classification model reliably identifies abnormalities in the proposed model. The proposed model when compared to the traditional model exhibits better performance levels.","Ensemble methods are advanced learning algorithm proposed for generating base classifiers and accumulating them all together to derive a new classifier which is expected to perform better than the constituent classifier. This study proposes a novel ensemble technique where a base learning classifier is trained repeatedly by using different weightings over the training samples or examples, and the process is governed by the conceptualization of evolutionary processes and the aggregation operators. We utilize the evolutionary technique that can efficiently search a large weighing space for enriching suitable weights (chromosome) to the training samples. For finding an appropriate weighting, the crossover and mutation processes are applied on the weighting space to get the optimized set of weights which is accomplished through different generations. The considered base learning classifier is trained over the training examples along with their respective weightings by utilizing a learning algorithm, and for the finite number of generations, the weights are evolved and optimized through the evolutionary process. All the classifiers obtained in different generations of the evolutionary process are utilized for efficiently building the final ensemble. The set of classifiers obtained in different generations are combined together by utilizing the concept of priority-based averaging aggregation operator by availing priority to different generations. The classifier ensemble is done with two forms of operators: one without priority degree and the other with the priority degree. The proposed classifier ensemble algorithm is tested over the UCI benchmark dataset. The results obtained through the experimental process are more accurate, consistent, and reliable while comparing to other state-of-the-art methods, which ensures the efficacy of the proposed algorithm.","Unmanned Aerial Systems (UAS), commonly known as drones, have revolutionized various industries with their diverse applications. As the demand for seamless and intuitive drone control grows, researchers are exploring innovative approaches to improve human-swarm interaction. This paper presents a novel method for operating a swarm of drones in real time using wearable technology and machine learning. Through the integration of motion capture data and classification algorithms, we strive to achieve an intuitive level of control that is accessible to users with varying skill levels. While the full realization of this approach remains a work in progress, our research lays the groundwork for future endeavors in this domain. In this paper, we discuss the limitations of existing control methods and present our methodology for data preprocessing, model training and testing, and result analysis. Our findings indicate the potential of this approach and open avenues for refining the interaction between humans and drone swarms.","Applications involving Extreme Multi-Label Classification (XMLC) face several practical challenges with respect to scale, model size and prediction latency, while maintaining satisfactory predictive accuracy. In this paper, we propose a Multi-Label Factorization Machine (MLFM) model, which addresses some of the challenges in XMLC problems. We use behavioral ad targeting as a case study to illustrate the benefits of the MLFM model. Predicting user qualifications for targeting segments plays a major role in both personalization and real-time bidding. Considering the large number of segments and the prediction time requirements of real-world production systems, building scalable models is often difficult and computationally burdensome. To cope with these challenges, we (1) reformulate the problem of assigning users to segments as a multi-label classification (XMLC) problem, and (2) leverage the benefits of the conventional FM model and generalize its capacity to joint prediction across a large number of targeting segments. We have shown that the MLFM model is both effective and computationally efficient compared to several baseline models on publicly available datasets in addition to the targeting use case.","Data-driven bearing fault diagnosis methods have become increasingly crucial for the health management of rotating machinery equipment. However, in actual industrial scenarios, the scarcity of labeled data presents a challenge. To alleviate this problem, many transfer learning methods have been proposed. Some domain adaptation methods use models trained on source domain to generate pseudo labels for target domain data, which are further employed to refine models. Domain shift issues may cause noise in the pseudo labels, thereby compromising the stability of the model. To address this issue, we propose a Hierarchical Pseudo Label Domain Adversarial Network. In this method, we divide pseudo labels into three levels and use different training approach for diverse levels of samples. Compared with the traditional threshold filtering methods that focus on high-confidence samples, our method can effectively exploit the positive information of a great quantity of medium-confidence samples and mitigate the negative impact of mislabeling. Our proposed method achieves higher prediction accuracy compared with the-state-of-the-art domain adaptation methods in harsh environments.","The deep forest model, a random forest (RF) ensemble approach and an alternative to Deep Neural Network (DNN), has performance highly competitive to DNN in many classification tasks. However, deep forest model may encounter overfitting and characteristic dispersion issues as processing small-scale, class-imbalance or high-dimension data. Therefore, this paper proposes a Weighted Cascade Deep Forest framework, called WCDForest. In WCDForest, an equal multi-grained scanning module is used to scan each feature equally. Meanwhile, this framework adopts a class vector weighting module to emphasis the performance of each forest and each sliding window by weight. Furthermore, this study proposes a feature enhancement module to reduce the information loss in the first few cascade layers to improve the classification accuracy. Subsequently, systematic comparison experiments on 18 widely used public datasets demonstrate that the proposed model outperforms the state-of-the-art model. In particular, WCDForest improves the accuracy, precision, recall and F1-score by an average of 5.47%,7.04%,8.23% and 8.94%,respectively.","Bees play an important role as pollinating agents, contributing to the reproduction of many plant species around the world. Brazil is the home for different species of stingless bees, with around 200 registered species out of the more than 500 species classified worldwide. Each species constructs the entrance to its colony in an unique but similar way among colonies of the same species. In this work, we proposed a new dataset created in collaboration with stingless beekeepers from Brazil for the exploration of stingless bee species classification. The dataset consists of 158 samples distributed unequally among the 13 species: Boca de Sapo, Bor\u00e1, Bugia, Ira\u00ed, Japur\u00e1, Jata\u00ed, Lambe Olhos, Mandaguari, Mirim Droryana, Mirim Pregui\u00e7a, Mo\u00e7a Branca, Manda\u00e7aia, and Tubuna. The results presented in this work were obtained using deep learning models (i.e. CNN architectures) such as VGG and DenseNet, which are commonly used for image classification task in different application domains. Pre-trained models from ImageNet were used, along with transfer learning techniques, and due to the small size of the dataset, data augmentation techniques were applied, resulting in an expanded dataset of 1,106 samples. The experimental results demonstrated that the DenseNet model achieved the best results, reaching an accuracy of\n95\n%\n. The dataset created will be also made available as a contribution of these work. As far as we know, the stingless bee species identification task based on the colony entrance is addressed for the first time in this work.","Fake news is a major challenge in social media, particularly in the health domain where it can lead to severe consequences for both individuals and society as a whole. To contribute to combating this problem, we present a novel solution for improving the accuracy of detecting fake health news, utilizing a fine-tuned BERT model that integrates both user- and content-related socio-contextual information. Specifically, this information is combined with the textual content itself to form a socio-contextual input sequence for the BERT model. By fine-tuning such a model with respect to the health misinformation detection task, the resulting classifier can accurately predict the category to which each piece of content belongs, i.e., either \u201creal health news\u201d or \u201cfake health news\u201d. We validate our solution through a series of experiments conducted on distinct publicly available datasets constituted by health-related tweets. These results illustrate the superiority of the proposed solution compared to the standard BERT baseline model and other advanced models. Indeed, they show that the integration of socio-contextual information in the detection process positively contributes to increasing the overall accuracy of the fake health news detection task. The study also suggests, in a preliminary way, how such information could be used for the explainability of the model itself.","Neural architecture search (NAS), which automates the design of neural network (NN) architectures for scientific datasets, requires significant computational resources and time \u2014 often on the order of days or weeks of GPU hours and training time. We design the Analytics for Neural Network (A4NN) workflow, a composable workflow that significantly reduces the time and resources required to design accurate and efficient NN architectures. We introduce a parametric fitness prediction strategy and distribute training across multiple accelerators to decrease the aggregated NN training time. A4NN rigorously record neural architecture histories, model states, and metadata to reproduce the search for near-optimal NNs. We demonstrate A4NN\u2019s ability to reduce training time and resource consumption on a dataset generated by an X-ray Free Electron Laser (XFEL) experiment simulation. When deploying A4NN, we decrease training time by up to 37% and epochs required by up to 38%.","Customer churn prediction is an essential strategy for companies, especially in telecommunications. Such industries face the challenge that customers frequently switch operators. Due to the higher cost of acquiring new customers compared to retaining existing ones, companies put considerable effort into keeping their current customers. Improving service quality and identifying the point at which customers are likely to terminate their engagement with the company are crucial in retaining customers. Customer Churn Prediction aims to predict potential customer churn by building an effective predictive model. However, the model\u2019s performance is sensitive to unnecessary and irrelevant features. Feature selection is used to eliminate irrelevant features while emphasizing significant ones. This study suggests utilizing a feature selection method to identify significant features and enhance the accuracy of the customer churn prediction model. We propose employing a recently developed evolutionary computation method known as the gravitational search algorithm (GSA) for the feature selection approaches. We elaborate on GSA and the SVM as the classifier to find the optimum features and to improve the prediction accuracy. Our method produced higher precision and AUC scores than the baseline model (without feature selection).","Objective: The objective is to develop a predictive model utilizing Support Vector Machines (SVM) for the purpose of classifying the clinical stage of breast cancer.\nMaterials and Methods: Accurate determination of the clinical stage of breast cancer patients holds significant importance in selecting suitable treatment options and minimizing avoidable complications. In this study, we present the application of radiomics and SVM for breast cancer computed tomography (CT) to anticipate the preoperative clinical stage in breast cancer patients. The training dataset encompasses 166 cases obtained from the Affiliated Hospital of Xiangnan University, while the test dataset comprises 91 cases from Chenzhou Third People's Hospital. The integration of clinical parameters with radiomics exhibits the most superior diagnostic efficacy in forecasting the clinical stage of breast cancer. As part of the evaluation, various metrics were calculated, including the area under the curve (AUC), the accuracy (ACC), sensitivity (Sen), specificity (Spe), positive predictive value (PPV) and negative predictive value (NPV). To differentiate between the radiomics model, clinical data model, and fusion model, the Delong test was utilized. The precision of the prediction model was evaluated by generating a calibration curve using 1,000 bootstrap weight samples. Furthermore, the decision curve analysis (DCA) was conducted to assess the model's practicality.\nResults: The fusion model exhibits superior predictive performance compared to both the single radiomics model and clinical model. The fusion model's test sets of AUC, ACC, Sen, Spe, PPV, and NPV are 0.824, 0.780, 0.932, 0.652, 0.707, and 0.909, respectively.\nConclusion: The fusion model exhibits greater efficacy than both the single radiomics model and clinical model, and thus holds significant potential for facilitating the diagnosis of breast cancer stage and the development of individualized treatment plans.CCS","Surface electromyography (sEMG) signal is essential for accurately controlling prosthetic devices with numerous degrees of freedom in human-machine interfaces for robotics and assistive technologies. The controlling method of the upper-limb prosthesis device depends on electromyogram (EMG) pattern recognition, which requires the efficient blending of conventional signal processing and machine learning. This paper focuses on stacked ensemble models, one of the popular methods for reducing generalization error. The proposed work uses a dataset of sEMG signals from different upper-limb positions in subjects. The raw signals are transformed into correlated time-domain descriptors (cTDD) for feature extraction, which are then used to train the stacked ensemble framework. The framework includes four base classifiers (support vector machine (SVM), K-nearest neighbours (KNN), logistic regression (LR), and decision tree (DT)) and two meta-classifiers (random forest (RF) and multi-layer perceptrons (MLP). The performance of the meta-classifiers is evaluated on two test sets, showing superior classification accuracy compared to the basic classifiers. The proposed approach demonstrates the capability to accurately classify limb position invariant EMG signal classification for prosthetic device control.","Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose Crash-Former, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8% in F1-score on average when using \"sparse\" input data.","Severe limitations in data and technological availability have vastly affected NLP research into African languages. With Africa having over 2000 languages, the lack of NLP research is a massive flaw within the NLP field. African languages can hold the key to the next significant advancement in NLP research because some researchers suggest that 30% of current-day languages are derived from African languages. With Sentiment Analysis being a foundational part of NLP research, the release of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th International Workshop on Semantic Evaluation, has provided 14 new annotated datasets for Sentiment Analysis on African languages. We utilize these datasets to evaluate our approach: Delta TF-IDF features with conventional machine learning models. Delta TF-IDF results showed that our approach could provide promising results with the low resource task of sentiment analysis on African Languages. Since it utilized a significantly less data than its transformer counter parts.","Recently, MLP-based architectures achieved impressive results in image classification against CNNs and ViTs. However, there is an obvious limitation in that their parameters are related to image sizes, allowing them to process only fixed image sizes. Therefore, they cannot directly adapt dense prediction tasks (e.g., object detection and semantic segmentation) where images are of various sizes. Recent methods tried to address it but brought two new problems, long-range dependencies or important visual cues are ignored. This paper presents a new MLP-based architecture, Region-aware MLP (RaMLP), to satisfy various vision tasks and address the above three problems. In particular, we propose a well-designed module, Region-aware Mixing (RaM). RaM captures important local information and further aggregates these important visual clues. Based on RaM, RaMLP achieves a global receptive field even in one block. It is worth noting that, unlike most existing MLP-based architectures that adopt the same spatial weights to all samples, RaM is region-aware and adaptively determines weights to extract region-level features better. Impressively, our RaMLP outperforms state-of-the-art ViTs, CNNs, and MLPs on both ImageNet-1K image classification and downstream dense prediction tasks, including MS-COCO object detection, MS-COCO instance segmentation, and ADE20K semantic segmentation. In particular, RaMLP outperforms MLPs by a large margin (around 1.5% Apb or 1.0% mIoU) on dense prediction tasks. The training code could be found at https://github.com/xiaolai-sqlai/RaMLP.","Automatically classifying cough sounds is one of the most critical tasks for the diagnosis and treatment of respiratory diseases. However, collecting a huge amount of labeled cough dataset is challenging mainly due to high laborious expenses, data scarcity, and privacy concerns. In this work, our aim is to develop a framework that can effectively perform cough classification even in situations when enormous cough data is not available, while also addressing privacy concerns. Specifically, we formulate a new problem to tackle these challenges and adopt few-shot learning and federated learning to design a novel framework, termed F2LCough, for solving the newly formulated problem. We illustrate the superiority of our method compared with other approaches on COVID-19 Thermal Face &amp; Cough dataset, in which F2LCough achieves an average F1-Score of 86%. Our results show the feasibility of few-shot learning combined with federated learning to build a classification model of cough sounds. This new methodology is able to classify cough sounds in data-scarce situations and maintain privacy properties. The outcomes of this work can be a fundamental framework for building support systems for the detection and diagnosis of cough-related diseases.","One of the major difficulties in face recognition while comparing photographs of individuals of different ages is the influence of age progression on their facial features. As a person ages, the face undergoes many changes, such as geometrical changes, changes in facial hair, and the presence of glasses, among others. Although biometric markers like computed face feature vectors should ideally remain unchanged by such factors, face recognition becomes less reliable as the age range increases. Therefore, this investigation was carried out to examine how the use of Embedded Prototype Subspace Classifiers could improve face recognition accuracy when dealing with age-related variations using face feature vectors only.","This full-day tutorial introduces modern techniques for practical uncertainty quantification specifically in the context of multi-class and multi-label text classification. First, we explain the usefulness of estimating aleatoric uncertainty and epistemic uncertainty for text classification models. Then, we describe several state-of-the-art approaches to uncertainty quantification and analyze their scalability to big text data: Virtual Ensemble in GBDT, Bayesian Deep Learning (including Deep Ensemble, Monte-Carlo Dropout, Bayes by Backprop, and their generalization Epistemic Neural Networks), Evidential Deep Learning (including Prior Networks and Posterior Networks), as well as Distance Awareness (including Spectral-normalized Neural Gaussian Process and Deep Deterministic Uncertainty). Next, we talk about the latest advances in uncertainty quantification for pre-trained language models (including asking language models to express their uncertainty, interpreting uncertainties of text classifiers built on large-scale language models, uncertainty estimation in text generation, calibration of language models, and calibration for in-context learning). After that, we discuss typical application scenarios of uncertainty quantification in text classification (including in-domain calibration, cross-domain robustness, and novel class detection). Finally, we list popular performance metrics for the evaluation of uncertainty quantification effectiveness in text classification. Practical hands-on examples/exercises are provided to the attendees for them to experiment with different uncertainty quantification methods on a few real-world text classification datasets such as CLINC150.","Skip Abstract Section\nAbstract\nAir quality prediction is considered one of complex problems. This is due to volatility, dynamic nature, and high variability in space and time of particulates and pollutants. Meanwhile, designing an automated model for monitoring and predicting air quality becomes more and more relevant, particularly in urban regions. Air pollution can significantly affect the environment and eventually citizens\u2019 health. In this paper, one of the popular machine learning algorithms, the neural network algorithm, is employed to classify different species of air pollutants. To boost the performance of the traditional neural network, the war strategy optimization algorithm tunes the neural network\u2019s parameters. The experimental results demonstrate that the proposed optimized neural network based on the war strategy algorithm can accurately classify air pollutant species.","For a long time, images have proved perfect at both storing and conveying rich semantics, especially human emotions. A lot of research has been conducted to provide machines with the ability to recognize emotions in photos of people. Previous methods mostly focus on facial expressions but fail to consider the scene context, meanwhile scene context plays an important role in predicting emotions, leading to more accurate results. In addition, Valence-Arousal-Dominance (VAD) values offer a more precise quantitative understanding of continuous emotions, yet there has been less emphasis on predicting them compared to discrete emotional categories. In this paper, we present a novel Multi-Branch Network (MBN), which utilizes various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image. Experimental results on EMOTIC dataset, which contains large-scale images of people in unconstrained situations labeled with 26 discrete categories of emotions and VAD values, show that our proposed method significantly outperforms state-of-the-art methods with 28.4% in mAP and 0.93 in MAE. The results highlight the importance of utilizing multiple contextual information in emotion prediction and illustrate the potential of our proposed method in a wide range of applications, such as effective computing, human-computer interaction, and social robotics.","The imbalanced dataset\u2019s existing classification methods have low prediction accuracy for the minority class because of the little information present. Using over- and under-sampling techniques, we can improve the minority\u2019s ability to forecast outcomes. However, the minority class\u2019s accuracy of prediction is negatively impacted by the two methods due to the loss of vital information or the addition of irrelevant details for classification. SVM kernels have great abilities to handle asymmetric data, but when we need to use SVM kernels alone or as part of the ensemble technique for an unbalanced dataset, we don\u2019t have a strong reason to choose which kernel to use, and also how a particular kernel will act depends a lot on the data set. In this paper, we present a framework in which several kernel SVM (Linear, Polynomial, Sigmoid, RBF) classifiers were utilized as the base learners and one of the kernels (say RBF kernel) as meta learner using the Stacking Ensembles technique, which shows that stacked generalization of SVM kernels gives similar results as best performing kernel for an imbalanced dataset of software change proneness, using AUC, ROC, MCC, and BAS as an evaluation matrix.","In many practical binary classification applications, such as financial fraud detection or medical diagnosis, it is crucial to optimize a model's performance on high-confidence samples whose scores are higher than a specific threshold, which is calculated by a given false positive rate according to practical requirements. However, the proportion of high-confidence samples is typically extremely small, especially in long-tailed datasets, which can lead to poor recall results and an alignment bias between realistic goals and loss. To address this challenge, we propose a novel loss reweighting framework called Momentum Threshold-Oriented Loss (MTOL) for binary classification tasks and propose two instantiated losses of it. Given a limited FPR range, MTOL aims to improve the recall of binary classification models at that FPR range by incorporating a batch memory queue and momentum estimation mechanisms. The MTOL adaptively estimates thresholds of FPR during the model training iterations and up-weights the loss of samples in the threshold range, with little consumption of storage and computation. Our experimental results on various datasets, including CIFAR-10, CIFAR-100, Tiny-ImageNet, demonstrate the significant effect of MTOL in improving the recall at low FPR especially in class imbalance settings. These results suggest that MTOL is a promising approach in scenarios where the model's performance in the low FPR range is of utmost importance.","In the era of digital information, ensuring the accuracy and reliability of information is crucial, making fact-checking a vital process. Currently, English fact-checking has thrived due to various language processing tools and ample datasets. However, the same cannot be said for Vietnamese fact-checking, which faces significant challenges due to the lack of such resources. To address these challenges, we propose a model for checking Vietnamese facts by synthesizing three popular technologies: Knowledge Graph (KG), Datalog, and KG-BERT. The KG serves as the foundation for the fact-checking process, containing a dataset of Vietnamese information. Datalog, a logical programming language, is used with inference rules to complete the knowledge within the Vietnamese KG. KG-BERT, a Deep Learning (DL) model, is then trained on this KG to rapidly and accurately classify information that needs fact-checking. Furthermore, to put Vietnamese complex sentences into the fact-checking model, we present a solution for extracting triples from these sentences. This approach also contributes significantly to the ease of constructing foundational datasets for the Vietnamese KG. To evaluate the model's performance, we create a Vietnamese dataset comprising 130,190 samples to populate the KG. Using Datalog, we enrich this graph with additional knowledge. The KG is then utilized to train the KG-BERT model, achieving an impressive accuracy of 95%. Our proposed solution shows great promise for fact-checking Vietnamese information and has the potential to contribute to the development of fact-checking tools and techniques for other languages. Overall, this research makes a significant contribution to the field of data science by providing an accurate solution for fact-checking information in Vietnamese language contexts.","Face attribute classification (FAC) is a high-profile problem in biometric verification and face retrieval. Although recent research has been devoted to extracting more delicate image attribute features and exploiting the inter-attribute correlations, significant challenges still remain. Wavelet scattering transform (WST) is a promising non-learned feature extractor. It has been shown to yield more discriminative representations and outperforms the learned representations in certain tasks. Applied to the image classification task, WST can enhance subtle image texture information and create local deformation stability. This paper designs a scattering-based hybrid block, to incorporate frequency-domain (WST) and image-domain features in a channel attention manner (Squeeze-and-Excitation, SE), termed WS-SE block. Compared with CNN, WS-SE achieves a more efficient FAC performance and compensates for the model sensitivity of the small-scale affine transform. In addition, to further exploit the relationships among the attribute labels, we propose a learning strategy from a causal view. The cause attributes defined using the causality-related information can be utilized to infer the effect attributes with a high confidence level. Ablative analysis experiments demonstrate the effectiveness of our model, and our hybrid model obtains state-of-the-art results in two public datasets.","As a fast and inexpensive machining method applicable for creating a wide range of shapes and producing large batches, sheet metal punching is widely used e.g., in automotive, aerospace, electronics, and construction industries. A significant downside of sheet metal punching is the punching tool wear in use. A worn punch tool may impact the quality of the end product by causing imperfections and reduce the efficiency of the manufacturing process through increased scrap and by slowing down the production. Effective monitoring of punching tool wear is therefore essential for an efficient and cost-effective production of high-quality parts. The monitoring can be based on acceleration measurement which produces large amounts of raw data, making edge processing ideal as only the indication of the tool condition needs to be sent forward for decision support. Classification models for tool wear identification were built and compared in this study. The models are based on measured acceleration data. Two different open-source methods for time series feature extraction, namely TSFEL and MiniRocket, were tested and the classification results based on them compared. All methods used for building the models are computationally light and therefore applicable for real-time data processing at the edge. According to the results the MiniRocket algorithm is suitable for the task and superior compared to the TSFEL method. The classification accuracies based on the MiniRocket features are at best over 96.5 % and at worst around 84 %, whereas the corresponding accuracies are between 35 and 56 % for TSFEL feature based models. The use of the MiniRocket algorithm in building a model for punch tool monitoring shows very promising results. However, the dataset used was very limited. Therefore, further investigation is required based on an ampler dataset.","The Gene Ontology (GO) project is a major bioinformatics initiative with the aim of standardizing the representation of gene and gene product attributes across species and databases. The classes in GO are hierarchically structured in the form of a directed acyclic graph (DAG), what makes its prediction more complex. This work proposes an adapted Learning Classifier Systems (LCS) in order to predict protein functions described in the GO format. Hence, the proposed approach, called HLCS (Hierarchical Learning Classifier System) builds a global classifier to predict all classes in the application domain and its is expressed as a set of IF-THEN classification rules, which have the advantage of representing more comprehensible knowledge. The HLCS is evaluated in four different ion-channel data sets structured in GO terms and compared with a Ant Colony Optimisation algorithm, named hAnt-Miner. In the tests realized the HLCS outperformed the hAnt-Miner in two out of four data sets.","The three most important necessities for human life are food, shelter, and clothing. Young people who are technologically savvy have witnessed a significant scientific increase in the latter two areas. Despite this, farming is still regarded as a labor-intensive endeavour. Most farmers are uneducated and lack a scientific understanding of farming practices. Crop cultivation anywhere in the world is dependent on the climate, also known as seasons, and soil properties; however, increasing crop production is dependent on a variety of factors, most notably temperature. This work proposes a crop recommendation system to address the issue of increasing crop production. A vision of the perfect harvest before planting would be extremely beneficial to farmers and other stakeholders in making appropriate decisions about improving yields for local use, and it may inspire increased capacity and a wider range of product options for businesses. Precision agriculture is a modern farming strategy that advises farmers on the sorts of crops they should plant based on data collected through studies on soil features, soil types, and crop yields. This style of agriculture is also known as \"high-intensity agriculture\". Our system employed Machine Learning procedures to recommend the appropriate crops. This system then reduces the financial losses experienced by farmers because of establishing the ominous harvests. This problem is addressed in this paper by proposing a recommendation system using an ensemble model with majority voting and an accuracy of 99.4 percent.","Based on the network structure and training methods of extreme learning machines, extreme learning machine combining hidden-layer feature weighting and batch training (ELM-WB) is proposed to make full use of representation-level features for object images and human action videos classification. To solve the problem of insufficient fusion of multiple representation-level features in most classification methods, a double hidden layer structure in which the input layer and the second hidden layer are directly connected is designed. A loop training method of weighting coefficients and output weights is proposed based on the advantages of this structure. The proposed network structure and training method are combined to construct an extreme learning machine combining hidden-layer feature weighting (ELM-W), which can effectively fuse representation-level features to enhance the classification ability of representation-level features. On this basis, the principle of online sequential ELM (OS-ELM) is introduced to update the loop training formula of the two weights to reduce the memory consumption during the operation of the overall algorithm. ELM-WB is proposed by combining the loop training formula of two weight matrices with batch training. In order to test the feasibility of ELM-WB, experiments are conducted on Caltech 101, MSRC, UCF11 and UCF101 databases. Experimental results prove that the proposed ELM-WB can improve classification accuracy by fusing representation-level features. At the same time, ELM-WB can be used to perform classification tasks on databases of any size in a general-purpose computer without specific hardware.","The article provides a description of the most frequent bigrams and trigrams obtained using the n-gram analysis technique on a representative sample of Russian spoken language. N-gram analysis allows identifying frequent lists of sequences consisting of n graphical words, which is important for describing corpus material in various theoretical and applied aspects. The source data for applying this technique was a sample of 388 episodes of everyday speech communication from the ORD corpus (about 110 hours of audio). The results of the n-gram analysis in the form of frequency lists of word sequences allow constructing a typology of the most common bigrams and trigrams in Russian oral communication and lead the study equally to the levels of grammar, pragmatics, lexicon, and phraseology. The list of the most frequent bigrams and trigrams contains grammatical structures (U TEBYA, YA NE PONIMAYU, MNE KAZHETSYA), idioms (in a broad sense of the term) (VSYO RAVNO, TO ZHE SAMOE), introductory units (TAK SKAZAT\u2019, S DRUGOY STORONY), as well as a number of sequences typical only for oral speech, such as one-word pragmatic markers (NU VOT, KAK BY, NU V OBSHCEM), amplifications (DA-DA, TAK-TAK-TAK), and hesitations-vocalizations (E-E, M-M-M). The obtained frequency lists can be useful for solving many modern applied natural language processing tasks.","In industrial settings, it is often necessary to achieve language-level accuracy targets. For example, Amazon business teams need to build multilingual product classifiers that operate accurately in all European languages. It is unacceptable for the accuracy of product classification to meet the target in one language (e.g, English), while falling below the target in other languages (e.g, Portuguese). To fix such issues, we propose Language Aware Active Learning for Multilingual Models (LAMM), an active learning strategy that enables a classifier to learn from a small amount of labeled data in a targeted manner to improve the accuracy of Low-resource languages (LRLs) with limited amounts of data for model training. Our empirical results on two open-source datasets and two proprietary product classification datasets demonstrate that LAMM is able to improve the LRL performance by 4%--11% when compared to strong baselines.","Abstract: In the data stream learning scenario, the whole picture of the data can't be observed, and the data may change dynamically, thus increasing the complexity and imbalance of the data. Aiming at the characteristics of data class changes (appearance, disappearance, and reappearance) of multi-class data stream, a Matthews Adaptive XGBoost algorithm based on One-Vs-Rest strategy is proposed. For the three cases of class change, the One-Vs-Rest strategy is used to build the model, and a binary classification model is created for each class. Aiming at the problem that the model gradually forgets the knowledge of the class after the class disappears, a management mechanism based on class frequency is proposed. In view of the problem that the restarted model affects the overall performance of the ensemble after the class is reproduced, the sliding window is used to initialize it. Aiming at the problem of ensemble classifiers, a mechanism to adapt the number of base classifiers is proposed. Experiments on real and synthetic datasets show that the improved algorithm improves Kappa and PMAUC indicators by 1.03% and 0.82%, respectively.\nCCS CONCEPTS \u2022 Computing methodologies \u2022 Machine learning \u2022 Machine learning algorithms","The trade-off between privacy and accuracy presents a challenge for current federated learning (FL) frameworks, hindering their progress from theory to application. The main issues with existing FL frameworks stem from a lack of interpretability and targeted privacy protections. To cope with these, we proposed Disentangled Federated Learning for Privacy (DFLP) which employes disentanglement, one of interpretability techniques, in private FL frameworks. Since sensitive properties are client-specific in nature, our main idea is to turn this feature into a tool that strikes the balance between data privacy and FL model performance, enabling the sensitive attributes to be private. DFLP disentangles the client-specific and class-invariant attributes to mask the sensitive attributes precisely. To our knowledge, this is the first work that successfully integrates disentanglement and the nature of sensitive attributes to achieve privacy protection while ensuring high FL model performance. Extensive experiments validate that disentanglement is an effective method for accuracy-aware privacy protection in FL frameworks.","This paper proposes a multi-domain sample classification method based on Baidu API's general object recognition function. we used three datasets in the experiment,including CIFAR-10, CIFAR-100, and Mini-ImageNet. For an unknown sample belonging to these three datasets, we first predict which domain it may belong to by using the output results of Baidu API, and then obtain the label of the sample by training a model on that domain. Compared with existing methods, our method reduces the number of high-performance models that need to be trained and reduces the computational difficulty. Experimental results show that our method is more convenient and accurate.","Few-shot learning datasets contain a large number of classes with only a few examples in each. Existing datasets may contain thousands of classes, but very simple images (e.g. handwritten characters) such that a naive baseline can perform very well. Or they may be so complex, with large within-class variation and distracting background, that they are too difficult to enable meaningful learning with so few examples. To construct a customizable dataset of consistent natural images, we assemble a new dataset with each class containing a small subset from each of the 1000 classes of ImageNet-1k. To select subsets with clear within-class consistency we use an evolutionary approach to minimize the pairwise cosine-distance between features generated by a pre-trained VGG model. We train a classifier on these evolved image cliques and find that our evolved dataset provides a greater challenge than hand written digits, but not the extreme difficulty of a non-evolved subset of ImageNet. We find that pre-training our classifier on these evolved prototypical classes significantly improves performance on classifying random subsets ImageNet (relative to pre-training on similar random-class subsets), and conjecture that these prototypical classes may be beneficial for seeding concept learning. Dataset and code is publicly available at: https://github.com/lfrati/OmnImage","Learning with Noisy Labels (LNL) has become an appealing topic, as imperfectly annotated data are relatively cheaper to obtain. Recent state-of-the-art approaches employ specific selection mechanisms to separate clean and noisy samples and then apply Semi-Supervised Learning (SSL) techniques for improved performance. However, the selection step mostly provides a medium-sized and decent-enough clean subset, which overlooks a rich set of clean samples. To fulfill this, we propose a novel LNL framework ProMix that attempts to maximize the utility of clean samples for boosted performance. Key to our method, we propose a matched high confidence selection technique that selects those examples with high confidence scores and matched predictions with given labels to dynamically expand a base clean sample set. To overcome the potential side effect of excessive clean set selection procedure, we further devise a novel SSL framework that is able to train balanced and unbiased classifiers on the separated clean and noisy samples. Extensive experiments demonstrate that ProMix significantly advances the current state-of-the-art results on multiple benchmarks with different types and levels of noise. It achieves an average improvement of 2.48% on the CIFAR-N dataset.","To address the problem of low classification accuracy of liquid dangerous goods in daily security screening technology, we propose a two-layer feature extraction classification algorithm based on Ultra-Wideband centimeter wave detection, which is composed of shallow Wavelet Transform-Autoencoder (WT-AE) and deep Attention-Gated Recurrent Unit (Attention-GRU) network. In order to abstract the best description feature, the shallow autoencoder adds a classification constraint. In the classification stage, the deep algorithm Attention-GRU algorithm can further abstract the sequence composed of shallow features into deep features to improve the accuracy of classification. The experimental results show that the WT-AE algorithm with shallow constraint is more suitable for feature extraction of UWB centimeter-wave signals in this experimental scene than PCA and ICA feature extraction algorithms. Compared with KNN, Linear kernel SVM, Gaussian kernel SVM and decision tree algorithms for sequence processing, Attention-GRU has better processing effect and higher accuracy of classification. By comparing the test accuracy of other algorithms, the double-layer feature classification algorithm performs better in this experimental scene. The final test accuracy can reach 95.8%.","The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line (SPL). PLA design can be formulated as an interactive optimization problem with many conflicting factors. Incorporating Decision Makers\u2019 (DM) preferences during the search process may help the algorithms find more adequate solutions for their profiles. Interactive approaches allow the DM to evaluate solutions, guiding the optimization according to their preferences. However, this brings up human fatigue problems caused by the excessive amount of interactions and solutions to evaluate. A common strategy to prevent this problem is limiting the number of interactions and solutions evaluated by the DM. Machine Learning (ML) models were also used to learn how to evaluate solutions according to the DM profile and replace them after some interactions. Feature selection performs an essential task as non-relevant and/or redundant features used to train the ML model can reduce the accuracy and comprehensibility of the hypotheses induced by ML algorithms. This work aims to select features of an ML model used to prevent human fatigue in an interactive search-based PLA design approach. We applied four selectors and through results we were able to reduce 30% of features, obtaining an accuracy of 99%.","Among the causes of reduced production is a chicken disease, which can negatively affect consumer health. With the advancement of computer vision technology and profound innovations in the field of research, it has become increasingly important to analyze disease images collected by sensors in chickens to analyze the possibility of infection conveniently and efficiently. Consequently, research proposes to identify lesions using the Autoencoder and Yolov6 model to classify and detect diseases in chicken flocks. This model is suitable for different chicken breeds from many countries and regions. This method helps improve and enhance image recognition accuracy by incorporating the data enhancement method in the data preprocessing step. The results show that the value of val/mAP (average accuracy) obtained by the method proposed in this paper is 99.15%. Moreover, hit over 90% on the test dataset. This method can be applied to the early detection of disease-carrying chickens in the captive population, ensuring a quality food source for humans.","License Plate Recognition (LPR) plays a critical role in various applications, such as toll collection, parking management, and traffic law enforcement. Although LPR has witnessed significant advancements through the development of deep learning, there has been a noticeable lack of studies exploring the potential improvements in results by fusing the outputs from multiple recognition models. This research aims to fill this gap by investigating the combination of up to 12 different models using straightforward approaches, such as selecting the most confident prediction or employing majority vote-based strategies. Our experiments encompass a wide range of datasets, revealing substantial benefits of fusion approaches in both intra- and cross-dataset setups. Essentially, fusing multiple models reduces considerably the likelihood of obtaining subpar performance on a particular dataset/scenario. We also found that combining models based on their speed is an appealing approach. Specifically, for applications where the recognition task can tolerate some additional time, though not excessively, an effective strategy is to combine 4\u20136 models. These models may not be the most accurate individually, but their fusion strikes an optimal balance between accuracy and speed.","Pathological complete response (pCR) after neoadjuvant che-motherapy (NAC) in patients with breast cancer was found to improve survival, and it has a great prognostic value in the aggressive tumor subtype. This study aims to predict pCR before NAC treatment with a radiomic feature-based ensemble learning model using both positron emission tomography/computed tomography (PET/CT) images taken from the online QIN-Breast dataset. It studies the problem of constructing an end-to-end classification pipeline that includes a large-scale radiomic feature extraction, a hybrid iterative feature selection and a heterogeneous weighted ensemble classification. The proposed hybrid feature selection procedure can identify significant radiomic predictors out of 2153 features extracted from delineated tumour regions. The proposed weighted ensemble approach aggregates the outcomes of four weak classifiers (Decision tree, Naive Bayes, K-nearest neighbour, and Logistics regression) based on their importance. The empirical study demonstrates that the proposed feature selection-cum-ensemble classification method has achieved 92% and 88.4% balanced accuracy in PET and CT, respectively. The PET/CT aggregated model performed better and achieved 98% balanced accuracy and 94.74% F1-score. Furthermore, this study is the first classification work on the online QIN-Breast dataset.","Legal judgment prediction (LJP) is a significant task in legal intelligence, which aims to assist the judges and determine the judgment result based on the case's fact description. The judgment result consists of law articles, charge, and prison term. The law articles serve as the basis for the charge and the prison term, which can be divided into two types, named as charge-related law article and term-related law article, respectively. Recently, many methods have been proposed and made tremendous progress in LJP. However, the existing methods only focus on the prediction of the charge-related law articles, ignoring the term-related law articles (e.g., laws about lenient treatment), which limits the performance in the prison term prediction. In this paper, following the actual legal process, we expand the law article prediction as a multi-label classification task that includes both the charge-related law articles and term-related law articles and propose a novel multi-law aware LJP (ML-LJP) method to improve the performance of LJP. Given the case's fact description, firstly, the label (e.g., law article and charge) definitions in the Code of Law are used to transform the representation of the fact into several label-specific representations and make the prediction of the law articles and the charge. To distinguish the similar content of different label definitions, contrastive learning is conducted in the training. Then, a graph attention network (GAT) is applied to learn the interactions among the multiple law articles for the prediction of the prison term. Since numbers (e.g., amount of theft and weight of drugs) are important for LJP but often ignored by conventional encoders, we design a corresponding number representation method to locate and better represent these effective numbers. Extensive experiments on real-world dataset show that our method achieves the best results compared to the state-of-the-art models, especially in the task of prison term prediction where ML-LJP achieves a 10.07% relative improvement over the best baseline.","This paper explores how machine learning can help classify aid activities by sector using the OECD Creditor Reporting System (CRS). The CRS is a key source of data for monitoring and evaluating aid flows in line with the United Nations Sustainable Development Goals (SDGs), especially SDG17 which calls for global partnership and data sharing. To address the challenges of current labor-intensive practices of assigning the code and the related human inefficiencies, we propose a machine learning solution that uses ELECTRA to suggest relevant five-digit purpose codes in CRS for aid activities, achieving an accuracy of 0.9575 for the top-3 recommendations. We also conduct qualitative research based on semi-structured interviews and focus group discussions with SDG experts who assess the model results and provide feedback. We discuss the policy, practical, and methodological implications of our work and highlight the potential of AI applications to improve routine tasks in the public sector and foster partnerships for achieving the SDGs.","The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the properties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embedding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97\u201398%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble model\u2019s results are examined in terms of recall, accuracy, and precision","In recent years, the increasing use of online surveys for course evaluation in schools has led to an outpouring of evaluation texts. These texts, with their emotional polarity, can give schools the most direct feedback. Emotional analysis on course evaluation, therefore, has great implications. However, the not-so-rigid text grammar and rich text content pose a challenge for sentiment analysis in Chinese course evaluation. To solve this problem, this paper proposes a sentiment classification model BiLSTM-GCN-Att (BGAN). Here, BiLSTM is used to extract the features of the text and output the hidden state vector. Then, the deep biaffine attention mechanism is used to analyze the dependence of the text and generate a dependency matrix. Next, input the hidden state vector to the GCN. Finally, the softmax function is used as the output layer of the model to perform sentiment classification. The model proves effective and experimental results, showing that the BGAN achieved a maximum improvement of 11.02% and 14.47% in precision and F1-score respectively compared with the classical models.","Active learning has achieved remarkable success in minimizing labeling costs for classification tasks with all data samples drawn from known classes. However, in real scenarios, most active learning methods fail when encountering open-set annotation (OSA) problem, i.e., numerous samples from unknown classes. The main reason for such failure comes from existing query strategies that are unavoidable to select unknown class samples. To tackle such problem and select the most informative samples, we propose a novel active learning framework named OSA-CQ, which simplifies the detection work of samples from known classes and enhances the classification performance with an effective contrastive query strategy. Specifically, OSA-CQ firstly adopts an auxiliary network to distinguish samples using confidence scores, which can dynamically select samples with the highest probability from known classes in the unlabeled set. Secondly, by comparing the predictions between auxiliary network, classification, and feature similarity, OSA-CQ designs a contrastive query strategy to select these most informative samples from unlabeled and known classes set. Experimental results on CIFAR10, CIFAR100 and Tiny-ImageNet show the proposed OSA-CQ can select samples from known classes with high information, and achieve higher classification performance with lower annotation cost than state-of-the-art active learning algorithms.","A startup is a recently established business venture led by entrepreneurs, to create and offer new products or services. The discovery of promising startups is a challenging task for creditors, policymakers, and investors. Therefore, the startup survival rate prediction is required to be developed for the success/failure of startup companies. In this paper, the feature selection using the Convex Least Angle Regression Least Absolute Shrinkage and Selection Operator (CLAR-LASSO) is proposed to improve the classification of startup survival rate prediction. The Swish Activation Function based Long Short-Term Memory (SAFLSTM) is developed for classifying the survival rate of startups. Further, the Local Interpretable Model-agnostic Explanations (LIME) model interprets the predicted classification to the user. Existing research such as Hyper Parameter Tuning (HPT)-Logistic regression, HPT-Support Vector Machine (SVM), HPT-XGBoost, and SAFLSTM are used to compare the CLAR-LASSO. The accuracy of the CLAR-LASSO is 95.67% which is high when compared to the HPT-Logistic regression, HPT-SVM, HPT-XGBoost, and SAFLSTM.","With the rapid advancement in technology, the constant emergence of new applications and services has resulted in a drastic increase in Internet traffic, making it increasingly challenging for network analysts to maintain network security and classify traffic, especially when encrypted or tunneled. To address this issue, the proposed strategy aims to distinguish between regular traffic and traffic tunneled through a virtual private network and characterize traffic from seven different applications. The proposed approach utilizes various ensemble machine learning techniques, which are efficient and accurate and consume minimal computational time for training and prediction compared to conventional machine and deep learning models. These models were applied for both the classification and characterization of network traffic, deriving efficient results. The extreme and light gradient boosting algorithms performed well in multiclass classification, while AdaBoost and Light GBM performed well in binary classification. However, when all the datasets were merged and categorized into two classes and various feature engineering methods were applied, the proposed system achieved an accuracy of more than 99%, with minimal error scores using light GBM with min\u2013max scaling over stratified fivefold, thereby outperforming all existing approaches. This research highlights the efficiency and potential of the proposed model in detecting network traffic.","Deep neural networks (DNNs) achieve top performance through costly training on large datasets. Such resources may not be available in some scenarios, like IoT or healthcare. Extreme learning machines (ELMs) aim to alleviate this problem using single-layered networks, requiring fewer training resources. Current investigations have found that DNNs are prone to security and privacy threats, where malfunction of the network or training data extraction can be performed.\nDue to the increasing attention to ELMs and their lack of security investigations, we research the security implications of this type of network. Precisely, we investigate backdoor attacks in ELMs. We created a comprehensive experimental setup to evaluate their security in various datasets and scenarios. We conclude that ELMs are vulnerable to backdoor attacks with up to 97% attack success rate. Additionally, we adapt and evaluate the usage fine-pruning to ELMs.","This paper focuses on the impact of rule representation in Michigan-style Learning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A well-representation of the rules in an LFCS is crucial for improving its performance. However, conventional rule representations frequently need help addressing problems with unknown data characteristics. To address this issue, this paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive rule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates a fuzzy indicator as a new rule parameter that sets the membership function of a rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes. The fuzzy indicator is optimized with evolutionary operators, allowing the system to search for an optimal rule representation. Results from extensive experiments conducted on continuous space problems demonstrate that Adaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular and fuzzy-hypertrapezoidal rule representations in classification accuracy. Additionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and real-world problems with inherent uncertainty, such as missing values, leading to stable classification performance.","Quantum computing is a rapidly growing field of science with many potential applications. One such field is machine learning applied in many areas of science and industry. Machine learning approaches can be enhanced using quantum algorithms and work effectively, as demonstrated in this paper. We present our experimental attempts to explore Quantum Support Vector Machine (QSVM) capabilities and test their performance on the collected well-known images of handwritten digits for image classification called the MNIST benchmark. A variational quantum circuit was adopted to build the quantum kernel matrix and successfully applied to the classical SVM algorithm. The proposed model obtained relatively high accuracy, up to 99%, tested on noiseless quantum simulators. Finally, we performed computational experiments on real and recently setup IBM Quantum systems and achieved promising results of around 80% accuracy, demonstrating and discussing the QSVM applicability and possible future improvements.","This paper investigates the effectiveness of different deep learning HTR families, including LSTM, Seq2Seq, and transformer-based approaches with self-supervised pretraining, in recognizing ciphered manuscripts from different historical periods and cultures. The goal is to identify the most suitable method or training techniques for recognizing ciphered manuscripts and to provide insights into the challenges and opportunities in this field of research. We evaluate the performance of these models on several datasets of ciphered manuscripts and discuss their results. This study contributes to the development of more accurate and efficient methods for recognizing historical manuscripts for the preservation and dissemination of our cultural heritage.","Algal blooms pose a significant threat to aquatic ecosystems and human health. To address this issue, this paper proposes a machine learning-based approach for predicting harmful algal blooms (HABs) by analyzing environmental features. Algae, as primary organic matter and oxygen producers, play a vital role in the biosphere. However, the exponential increase in algal growth worldwide poses significant challenges to economic development and long-term sustainability. The paper employs three popular machine learning algorithms: Artificial Neural Network (ANN), Gradient Boosting Decision Tree (GBDT), and Support Vector Machine (SVM) to predict algal blooms. The research utilizes real-time data from two locations: the Sassafras River in the United States Chesapeake Bay and Lake Okeechobee in Florida, USA. These locations have experienced frequent HABs due to factors like chemical runoff and nutrient-rich conditions. By analyzing the collected data, the paper identifies and selects the most important features to optimize the prediction models\u2019 accuracy. Preliminary results demonstrate promising accuracy in predicting algal growth and identifying key characteristics associated with HABs. These findings contribute to a better understanding of algal blooms and pave the way for effective mitigation strategies to combat this global environmental challenge.","Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e., G2Pxy, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and external unknown proxies are generated via mixup to efficiently anticipate the distribution of novel classes. Using the generated proxies, a closed-set classifier can be transformed into an open-set one, by augmenting it with an extra proxy classifier. Under the constraints of both cross entropy loss and complement entropy loss, G2Pxy achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments on benchmark graph datasets. Moreover, G2Pxy does not have specific requirement on the GNN architecture and shows good generalizations.","In recent years, the interpretive this looks like that structure has gained significant attention. It refers to the human tendency to break down images into key parts and make classification decisions by comparing them to pre-existing concepts in their minds. However, most existing prototypical-based models assign prototypes directly to each category without considering that key parts with the same meaning may appear in images from different categories. To address this issue, we propose dividing prototypes with the same meaning into the same latent space (referred to as Basic Feature Domain) since different category parts only slightly affect the corresponding prototype vectors. This process of integrating prototypes based on the feature domain is referred to as prototype alignment. Additionally, we introduce the concept of part-aware optimization, which prioritizes prototypical parts of images over simple category labels during optimizing prototypes. Moreover, we present two feature aggregation methods, by row and by cluster, for the basic feature domain. We demonstrate competitive results compared to other state-of-the-art prototypical part methods on the CUB-2011-200 dataset and Stanford Cars dataset using our proposed self-explanatory part-aware proto-aligned network (PaProtoPNet).","In multi-dimensional classification (MDC), each training example is associated with multiple class variables from different class spaces. However, it is rather costly to collect labeled MDC examples which have to be annotated from several dimensions (class spaces). To reduce the labeling cost, we attempt to deal with the MDC problem under the semi-supervised learning setting. Accordingly, a novel MDC approach named PLAP is proposed to solve the resulting semi-supervised MDC problem. Overall, PLAP works under the label propagation framework to utilize unlabeled data. To further consider dependencies among class spaces, PLAP deals with each class space in a progressive manner, where the previous propagation results will be used to initialize the current propagation procedure, and all processed class spaces and the current one will be regarded as an entirety. Experiments validate the effectiveness of the proposed approach.","Deep learning has shown promise in accurate medical image analysis, but challenges remain. Data privacy concerns hinder the availability of large, high-quality medical datasets. Traditional deep learning approaches are computationally intensive and lack efficiency. This paper proposes the use of Federated Learning (FL) with ResNet-18, a deep neural network architecture. ResNet-18 addresses gradient issues using residual blocks and skip connections. FL enables collaborative training while preserving data privacy. The training process utilizes stochastic gradient descent and techniques such as data augmentation and regularization for improved model performance.","Increasing privacy concerns have led to decentralized and federated machine learning techniques that allow individual clients to consult and train models collaboratively without sharing private information. Some of these applications, such as medical and healthcare, require the final decisions to be interpretable. One common form of data in these applications is multivariate time series, where deep neural networks, especially convolutional neural networks based approaches, have established excellent performance in their classification tasks. However, promising results and performance of deep learning models are a black box, and their decisions cannot always be guaranteed and trusted. While several approaches address the interpretability of deep learning models for multivariate time series data in a centralized environment, less effort has been made in a federated setting. In this work, we introduce FLAMES2Graph, a new horizontal federated learning framework designed to interpret the deep learning decisions of each client. FLAMES2Graph extracts and visualizes those input subsequences that are highly activated by a convolutional neural network. Besides, an evolution graph is created to capture the temporal dependencies between the extracted distinct subsequences. The federated learning clients only share this temporal evolution graph with the centralized server instead of trained model weights to create a global evolution graph. Our extensive experiments on various datasets from well-known multivariate benchmarks indicate that the FLAMES2Graph framework significantly outperforms other state-of-the-art federated methods while keeping privacy and augmenting network decision interpretation.","Ensemble learning consists of combining the prediction of different learners to obtain a final output. One key step for their success is the diversity among the learners. In this paper, we propose to reach the diversity in terms of the classification complexity by guiding the sampling of instances in the Bagging algorithm with complexity measures. The proposed Complexity-driven Bagging algorithm complements the classic Bagging algorithm by considering training samples of different complexity to cover the complexity space. Besides, the algorithm admits any complexity measure to guide the sampling. The proposal is tested in 28 real datasets and for a total of 9 complexity measures, providing satisfactory and promising results and revealing that training with samples of different complexity, ranging from easy to hard samples, is the best strategy when sampling based on complexity.","We introduce Robust Training with Trust Scores (RT2S), a framework to train machine learning classifiers with potentially noisy labels. RT2S calculates a trust score for each training sample, which indicates the quality of its corresponding label. These trust scores are employed as sample weights during training and optionally during threshold optimization. The trust scores are generated from two sources: (i) the model's confidence in the observed label, leveraging out-of-fold prediction scores to detect anomalous labels in the training data, and (ii) the probability of the correct label, ascertained by a Large Language Model with the ability to identify biased label noise. We evaluate RT2S by training machine learning models on 6 product classification datasets that utilize low-quality labels generated by a rule-based classification engine acting as a surrogate labeler. Our experimental findings indicate that RT2S outperforms all baselines, and achieves an average accuracy improvement of 4.38% (max 7.18%) over rule-based classifiers in particular.","The rawly collected training data often comes with separate noisy labels collected from multiple imperfect annotators (e.g., via crowdsourcing). A typical way of using these separate labels is to first aggregate them into one and apply standard training methods. The literature has also studied extensively on effective aggregation approaches. This paper revisits this choice and aims to provide an answer to the question of whether one should aggregate separate noisy labels into single ones or use them separately as given. We theoretically analyze the performance of both approaches under the empirical risk minimization framework for a number of popular loss functions, including the ones designed specifically for the problem of learning with noisy labels. Our theorems conclude that label separation is preferred over label aggregation when the noise rates are high, or the number of labelers/annotations is insufficient. Extensive empirical results validate our conclusions.","The core objective of this research is to develop a methodology for selecting a supervised machine learning classification technique based on the specific categories of objects that need to be classified. The study focuses on product categories extracted from Amazon's Product Reviews database, which are utilized to evaluate the subjectivity of post-purchase feedback. The primary supervised machine learning methods are utilized to efficiently perform the classification task. The resulting insights will enable the prioritization and choice of the best approach based on the selected categories. In the context of accelerated technological adoption due to the COVID-19 pandemic, this research contributes by showcasing how AI/ML can play a pivotal role in enhancing decision-making processes across various sectors and highlighting the significance of adapting to emerging technologies for sustainable growth.","We present part of Huawei's efforts in building a Product Knowledge Graph (PKG). We want to identify which product attributes (i.e. properties) are relevant and important in terms of shopping decisions to product categories (i.e. classes). This is particularly challenging when the attributes and their values are mined from online product catalogues, i.e. HTML pages. These web pages contain semi-structured data, which do not follow a concerted format and use diverse vocabulary to designate the same features. We propose a system for key attribute identification (KATIE) based on fine-tuning pre-trained models (e.g., DistilBERT) to predict the applicability and importance of an attribute to a category. We also propose an attribute synonyms identification module that allows us to discover synonymous attributes by considering not only their labels' similarities but also the similarity of their values sets. We have evaluated our approach to Huawei categories taxonomy and a set of internally mined attributes from web pages. KATIE guarantees promising performance results compared to the most recent baselines.","Deep learning has been increasingly incorporated into various computational pathology applications to improve its efficiency, accuracy, and robustness. Although successful, most previous approaches for image classification have crucial drawbacks. There exist numerous tasks in pathology, but one needs to build a model per task, i.e., a task-specific model, thereby increasing the number of models, training resources, and cost. Moreover, transferring arbitrary task-specific model to another task is still a challenging problem. Herein, we propose a task-agnostic generative and general pathology image classifier, so called GPC, that aims at learning from diverse kinds of pathology images and conducting numerous classification tasks in a unified model. GPC, equipped with a convolutional neural network and a Transformer-based language model, maps pathology images into a high-dimensional feature space and generates pertinent class labels as texts via the image-to-text classification mechanism. We evaluate GPC on six datasets for four different pathology image classification tasks. Experimental results show that GPC holds considerable potential for developing an effective and efficient universal model for pathology image analysis.","Recently, Convolution Neural Networks (CNN) have achieved excellent performance in some areas of computer vision, including face recognition, character recognition, and autonomous driving. However, there are still many CNN-based models that cannot be deployed in real-world scenarios due to poor robustness. In this paper, focusing on the classification task, we attempt to evaluate and optimize the robustness of CNN-based models from a new perspective: the convolution kernel. Inspired by the discovery that the root cause of the model decision error lies in the wrong response of the convolution kernel, we propose a convolution kernel robustness evaluation metric based on the distribution of convolution kernel responses. Then, we devise the Convolution Kernel Robustness Calibrator, termed as CKR-Calibrator, to optimize key but not robust convolution kernels. Extensive experiments demonstrate that CKR-Calibrator improves the accuracy of existing CNN classifiers by 1%\u20134% in clean datasets and 1%\u20135% in corrupt datasets, and improves the accuracy by about 2% over SOTA methods. The evaluation and calibration source code is open-sourced at https://github.com/cym-heu/CKR-Calibrator.","In this paper, we consider the problem of Novel Class Discovery (NCD) in Open Set Recognition (OSR). Given a labeled and an unlabeled set for training, NCD aims to discover the novel categories in the unlabeled set with prior knowledge learned from the labeled set. Existing approaches tackle the NCD problems under a close-set setting, where only the existing categories from the labeled set and the novel categories from the unlabeled set will occur during the inference. This paper considers a more realistic open-set scenario. In the open-set setting, in addition to the existing and novel categories, some unknown categories absent from the training could be present during inference. To address NCD in the open-set scenario, we propose the General Inter-Intra (GII) loss, a unified approach for learning representations from both labeled and unlabeled samples. The proposed approach discovers novel categories in the training set (NCD) meanwhile recognizes the unknown categories (OSR). We evaluate GII with image and graph datasets, and the results indicate that our proposed approach is more effective than other NCD and OSR approaches.","The problem of long-tailed recognition (LTR) has received attention in recent years due to the fundamental power-law distribution of objects in the real-world. Most recent works in LTR use softmax classifiers that are biased in that they correlate classifier norm with the amount of training data for a given class. In this work, we show that learning prototype classifiers addresses the biased softmax problem in LTR. Prototype classifiers can deliver promising results simply using Nearest-Class-Mean (NCM), a special case where prototypes are empirical centroids. We go one step further and propose to jointly learn prototypes by using distances to prototypes in representation space as the logit scores for classification. Further, we theoretically analyze the properties of Euclidean distance based prototype classifiers that lead to stable gradient-based optimization which is robust to outliers. To enable independent distance scales along each channel, we enhance Prototype classifiers by learning channel-dependent temperature parameters. Our analysis shows that prototypes learned by Prototype classifiers are better separated than empirical centroids. Results on four LTR benchmarks show that Prototype classifier outperforms or is comparable to state-of-the-art methods. Our code is made available at https://github.com/saurabhsharma1993/prototype-classifier-ltr.","Occupant presence and their behaviour in the built environment significantly impact energy consumption in buildings. Currently, building systems are often operated based on assumed occupancy and fixed schedules, or occupants manually adjust them for their comfort, which sometimes leads to energy wastage. Also, the inherent complexity and unpredictability of occupancy patterns can contribute to disparities between simulated and actual energy consumption, underscoring the importance of selecting suitable methods for occupancy prediction. Various methods, such as occupancy cameras, thermal imagers, Passive Infrared Sensors, and Radio-Frequency Identification, can collect occupancy information. However, they often come with limitations including cost, complexity, and invasiveness. Hence, there is a growing interest in creating occupancy prediction models using an indirect approach based on indoor air quality (IAQ) data. However, this indirect approach must be further explored within the building simulation field. In this study, we apply an approach based on the novel QLattice algorithm for occupancy detection, utilizing a minimal sensing strategy with a comprehensive set of IAQ data. Furthermore, we compare the QLattice algorithm\u2019s performance with that of traditional machine learning (ML) algorithms such as Support Vector Machines (SVM), Decision Trees (DT), and XGBoost using metrics including accuracy, precision, recall, F1 score, AUC-ROC values, and computational time. The QLattice algorithm outperforms traditional ML algorithms in all evaluation metrics, achieving over 90% accuracy on the test dataset. Additionally, compared to traditional black-box ML algorithms, QLattice stands out for its explainability and interpretability, providing insights useful in decision-making.","This paper introduces a novel approach to address the challenges of transfer learning, which aims to efficiently train a classifier for a new domain using supervised information from similar domains. Traditional transfer learning methods may fail to maintain the discriminative features of the target domain due to the scarcity of labelled data and the use of irrelevant source domain data distribution subspace, resulting in poor metrics. To overcome these challenges, the proposed approach, called KDADP, transforms the data distribution of both the source and target domains into a lower-dimensional subspace while preserving their discriminatory information. The KDADP model maximizes between-class variance and minimizes within-class variance with L1 penalization, enabling the recovery of the most useful characteristics and reducing the model\u2019s complexity. Experimental results on three real-world domain adaptation datasets demonstrate that the proposed KDADP model significantly improves classification performance and outperforms state-of-the-art primitive, shallow, and deeper domain adaptation methods.","Support vector classification (SVC) is a well-known statistical technique for classification problems in machine learning and other fields. An important question for SVC is the selection of covariates (or features) for the model. Many studies have considered model selection methods. As is well-known, selecting one winning model over others can entail considerable instability in predictive performance due to model selection uncertainties. This paper advocates model averaging as an alternative approach, where estimates obtained from different models are combined in a weighted average. We propose a model weighting scheme and provide the theoretical underpinning for the proposed method. In particular, we prove that our proposed method yields a model average estimator that achieves the smallest hinge risk among all feasible combinations asymptotically. To remedy the computational burden due to a large number of feasible models, we propose a screening step to eliminate the uninformative features before combining the models. Results from real data applications and a simulation study show that the proposed method generally yields more accurate estimates than existing methods.","Graph neural networks (GNNs) have emerged as a powerful tool for analyzing graph data, where data are represented by nodes and edges. However, the conventional methods have limitations in analyzing graphs with diverse attributes and preserving crucial information during the graph embedding. As a result, there is a possibility of losing crucial information during the integration of individual nodes. To address this problem, we propose an attention-based readout with subgraphs for graph embedding that partitions the graph according to unique node attributes. This method ensures that important attributes are retained and prevents dilution of distinctive node features. The adjacency matrices and node feature matrices for the partitioned graphs go into a graph isomorphism network (GIN) to aggregate the features, where the attention mechanism merges the partitioned graphs to construct the whole graph embedding vector. Extensive experiments on six graph datasets demonstrate that the proposed method captures various local patterns and produces superior performance against the state-of-the-art methods for graph classification. Especially, on the challenging IMDB-MULTI dataset, our method achieves a significant performance gain of 27.87%p over the best method called MA-GCNN.","Convolutional Neural Network (CNN) is a widely used neural network in deep learning, and Graph Convolutional Network (GCN) is one of the most effective semi -supervised methods. It spread node information in a conversion way. In this article, we have studied the differences between CNN and GCN in the classification of high -spectrum image. Because the traditional GCN algorithm needs to build an adjacent matrix on all data, the calculation cost is very high, especially in large -scale remote sensing problems. MinigCNS uses a small -batch learning method to solve the problem of CCN calculation costs, and then it has not solved the problem of low efficiency of single model classification. This article studies the advantages of minigcns and CNN, and proposes a weighted fusion network FU-W, which weighs the minigcns and CNN weighted integration to break the bottleneck of single model performance. We experimented with the fusion algorithm on the two high -spectrum data sets, and its overall accuracy can reach 88.8%in Indian Pines. The experiment proves the superiority of the fusion strategy for a single CNN or GCN model.","This paper presents a methodology for developing a volcano-seismic event classification system using a multi-station deep learning approach to support monitoring the Nevados del Chill\u00e1n Volcanic Complex, which has been active since 2017. A convolutional network of multiple inputs processes the information from an event recorded up to five seismic stations. Each record is represented by its normalized spectrogram; thus, the network may receive from one to five spectrograms as input. The design includes entering additional information into the network, like the stations configuration and the event duration, information not provided by the spectrograms. Finally, this work includes the design and implementation of a relational database to access the continuous traces of events, showing different subsets of data quickly and efficiently. The results show that the classification of an event recorded up to five stations is substantially more effective than a single-station strategy. However, incorporating additional information of the signal does not significantly improve the classification performance.","In the foodservice industry, time is a crucial factor that impacts both consumers and management. Machine learning (ML) is increasingly used to improve the quality of services through prediction. In this study, we aim to develop a model for predicting meal duration using Random Forest Classification algorithm. The study uses data from the Point-of-Sale (POS) system of a full-service Thai hotpot restaurant, with a focus on two commercial areas in Bangkok. The variables that we used include the branch, the number of customers, the number of items, the day of the week, and the time of the day. As a result, the overall accuracy of the model was 86% and the F1-score was 0.81. The discussion of the potential use of this approach in connection with the existing system in a restaurant could also be beneficial, aiding the restaurant in planning management more efficiently and gaining a better understanding of consumer behavior. This study will discuss the results of the model along with additional perspectives for future work.","In the classification task, many improved algorithms have been developed based on Support Vector Machines (SVM). Since the recently proposed Fast Support Vector Classifier (FSVC) can handle large scale datasets, this paper improves FSVC by quantile, called QSVC, which uses quantile rather than average value of samples to represent all samples. The advantages of QSVC are as follows: 1) QSVC performs better on the skewed distribution; 2) and the robustness of quantile is better. Experiments show that our QSVC performs better in accuracy and speed than FSVC. For example,Table 2 shows that the average accuracy of QSVC is higher than that of FSVC and Liblinear, and it takes less time.","Often pieces of information are received sequentially over time. When did one collect enough such pieces to classify? Trading wait time for decision certainty leads to early classification problems that have recently gained attention as a means of adapting classification to more dynamic environments. However, so far results have been limited to unimodal sequences. In this pilot study, we expand into early classifying multimodal sequences by combining existing methods. Spatial-temporal transformers trained in the supervised framework of Classifier-Induced Stopping outperform exploration-based methods. We show our new method yields experimental AUC advantages of up to 8.7%.","While utilizing machine learning models, one of the most crucial aspects is how bias and fairness affect model outcomes for diverse demographics. This becomes especially relevant in the context of machine learning for medical imaging applications as these models are increasingly being used for diagnosis and treatment planning.\nIn this paper, we study biases related to sex when developing a machine learning model based on brain magnetic resonance images (MRI). We investigate the effects of sex by performing brain age prediction considering different experimental designs: model trained using only female subjects, only male subjects and a balanced dataset. We also perform evaluation on multiple MRI datasets (Calgary-Campinas(CC359) and CamCAN) to assess the generalization capability of the proposed models.\nWe found disparities in the performance of brain age prediction models when trained on distinct sex subgroups and datasets, in both final predictions and decision making (assessed using interpretability models). Our results demonstrated variations in model generalizability across sex-specific subgroups, suggesting potential biases in models trained on unbalanced datasets. This underlines the critical role of careful experimental design in generating fair and reliable outcomes.","Occupancy sensing and estimation in large commercial buildings has become a significant problem to be solved, with applications ranging from occupancy-based HVAC control to space planning, and security, etc. Thermal sensing is a promising technology to solve this problem, being easy to deploy in practice and allowing an actual occupancy count in a particular room without violating the data and privacy concerns. While initial strides have been made to solve this problem with thermal arrays, there are many problems that remain unsolved, including accuracy performance, overlapping of sensing areas that lead to under/over-counting, and data training requirements for different zones.\nIn this paper, we introduce TODOS 1, a novel system for estimating occupancy in intelligent buildings. TODOS uses a low-cost, low-power thermal sensor array along with a passive infrared sensor. We introduce a novel data processing pipeline that allows us to automatically extract features from the thermal images using an artificial neural network. Through an extensive experimental evaluation2, we show that TODOS provides occupancy detection accuracy of 98% to 100% under different scenarios. In addition, it solves the issue of occupancy over/under-counting by overlapping sensing areas when using multiple thermal sensors in large rooms. This is done by treating the entire area as a single input thermal image instead of partitioning the area into multiple thermal images individually processed. Furthermore, TODOS introduces a data augmentation technique that allows the generation of training data for rooms of different sizes and shapes, without requiring specific training data from each room. Using these data, TODOS can train specifically designed neural networks optimized for any room size and shape, and achieve almost the same level of occupancy detection accuracy in rooms where experimental labeled training data is available, making it a viable solution that generalizes to the different rooms in large buildings.","Performance of the pseudo-label (PL)-based self-supervised training depends greatly on the quality of estimated PLs. Recent studies have shown that label noise can remarkably impact downstream performance. Recently, research has demonstrated that mixup regularization is effective against noise memorization. In this work, we extend this previous study by exploring several recent forms of mixup, namely 2-step interpolation double mixup to enhance model robustness, mixup over speech frames for better recognition at the frame-level, moment exchange mixup to encourage utilization of moment information of speaker speech as they can reveal speaker style, and virtual mixup training to regularize the areas in-between training points to be locally-Lipschitz and enforce consistent predictions. We analyze their effect on the generalization of some state-of-the-art speaker verification (SV) systems and explore their combination via different multi-task learning-based approaches. Our results show that the proposed mixup formulations are aligned with the SV task and that our proposed multi-task learning-based approach can be beneficial to improve the performance and robustness of SV systems.","Abstract: The electromyogram (EMG), also known as an EMG, is used to assess nerve impulses in motor nerves, sensory nerves, and muscles. EMS is a versatile tool used in various biomedical applications. It is commonly employed to determine physical health, but it also finds utility in evaluating emotional well-being, such as through facial electromyography. Classification of EMG signals has attracted the interest of scientists since it is crucial for identifying neuromuscular disorders (NMDs). Recent advances in the miniaturization of biomedical sensors enable the development of medical monitoring systems. This paper presents a portable and scalable architecture for machine learning modules designed for medical diagnostics. In particular, we provide a hybrid classification model for NMDs. The proposed method combines two supervised machine learning classifiers with the discrete wavelet transform (DWT). During the online testing phase, the class label of an EMG signal is predicted using the classifiers\u2019 optimal models, which can be identified at this stage. The simulation results demonstrate that both classifiers have an accuracy of over 98%. Finally, the proposed method was implemented using an embedded CompactRIO-9035 real-time controller.","Conversation disentanglement aims to identify and group utterances from a conversation into separate threads. Existing methods primarily focus on disentangling multi-party conversations with three or more speakers, explicitly or implicitly incorporating speaker-related feature signals to disentangle. Most existing models require a large amount of human annotated data for model training, and often focus on pairwise relations between utterances, not accounting much for the conversational context. In this work, we propose a multi-task learning approach with a contrastive learning objective, DiSC, to disentangle conversations between two speakers -- a user and a virtual speech assistant, for a novel domain of e-commerce. We analyze multiple ways and granularities to define conversation \"threads''. DiSC jointly learns the relation between pairs of utterances, as well as between utterances and their respective thread context. We train and evaluate our models on multiple multi-threaded conversation datasets that were automatically created, without any human labeling effort. Experimental results on public datasets as well as real-world shopping conversations from a commercial speech assistant show that DiSC outperforms state-of-the-art baselines by at least 3%, across both automatic and human evaluation metrics. We also demonstrate how DiSC improves downstream dialog response generation in the shopping domain.","Mixing data augmentation methods have been widely used in text classification recently. However, existing methods do not control the quality of augmented data and have low model explainability. To tackle these issues, this paper proposes an explainable text classification solution based on attentive and targeted mixing data augmentation, ATMIX. Instead of selecting data for augmentation without control, ATMIX focuses on the misclassified training samples as the target for augmentation to better improve the model's capability. Meanwhile, to generate meaningful augmented samples, it adopts a self-attention mechanism to understand the importance of the subsentences in a text, and cut and mix the subsentences between the misclassified and correctly classified samples wisely. Furthermore, it employs a novel dynamic augmented data selection framework based on the loss function gradient to dynamically optimize the augmented samples for model training. In the end, we develop a new model explainability evaluation method based on subsentence attention and conduct extensive evaluations over multiple real-world text datasets. The results indicate that ATMIX is more effective with higher explainability than the typical classification models, hidden-level, and input-level mixup models.","Multi-class classification can be solved by decomposing it into a set of binary classification problems according to some encoding rules, e.g., one-vs-one, one-vs-rest, error-correcting output codes. Existing works solve these binary classification problems in the original feature space, while it might be suboptimal as different binary classification problems correspond to different positive and negative examples. In this paper, we propose to learn label-specific features for each decomposed binary classification problem to consider the specific characteristics containing in its positive and negative examples. Specifically, to generate the label-specific features, clustering analysis is respectively conducted on the positive and negative examples in each decomposed binary data set to discover their inherent information and then label-specific features for one example are obtained by measuring the similarity between it and all cluster centers. Experiments clearly validate the effectiveness of learning label-specific features for decomposition-based multi-class classification.","Deep Learning (DL) has enabled considerable increases in the accuracy of classification tasks in several domains, including Human Activity Recognition (HAR). It is well-known that when data distribution changes between the training and test datasets, the accuracy can drop, sometimes significantly. However, some variability sources in HAR, such as sensor orientation, are only sometimes considered when evaluating these models. Therefore, we must understand how much such changes could impact current DL architectures. In this paper, under an orientation variability scenario, we evaluate three common DL architectures, DeepConvLSTM, TinyHAR, and Attend-and-Discriminate, to quantify the performance drop attributed to this shift. Our results show that all architectures show performance drops on average, as expected, but participants are affected differently from them, so they would fall short for some in classification accuracy in real-life settings where orientation can change across the wearing sessions of one participant or across participants. The performance change is related to the difference in distribution distance.","Although Graph Neural Networks (GNNs) have been successful in node classification tasks, their performance heavily relies on the availability of a sufficient number of labeled nodes per class. In real-world situations, not all classes have many labeled nodes and there may be instances where the model needs to classify new classes, making manual labeling difficult. To solve this problem, it is important for GNNs to be able to classify nodes with a limited number of labeled nodes, known as few-shot node classification. Previous episodic meta-learning based methods have demonstrated success in few-shot node classification, but our findings suggest that optimal performance can only be achieved with a substantial amount of diverse training meta-tasks. To address this challenge of meta-learning based few-shot learning (FSL), we propose a new approach, the Task-Equivariant Graph few-shot learning (TEG) framework. Our TEG framework enables the model to learn transferable task-adaptation strategies using a limited number of training meta-tasks, allowing it to acquire meta-knowledge for a wide range of meta-tasks. By incorporating equivariant neural networks, TEG can utilize their strong generalization abilities to learn highly adaptable task-specific strategies. As a result, TEG achieves state-of-the-art performance with limited training meta-tasks. Our experiments on various benchmark datasets demonstrate TEG's superiority in terms of accuracy and generalization ability, even when using minimal meta-training data, highlighting the effectiveness of our proposed approach in addressing the challenges of meta-learning based few-shot node classification. Our code is available at the following link: https://github.com/sung-won-kim/TEG","Automated Machine Learning (AutoML) is a promising direction for democratizing AI by automatically deploying Machine Learning systems with minimal human expertise. The core technical challenge behind AutoML is optimizing the pipelines of Machine Learning systems (e.g. the choice of preprocessing, augmentations, models, optimizers, etc.). Existing Pipeline Optimization techniques fail to explore deep interactions between pipeline stages/components. As a remedy, this paper proposes a novel neural architecture that captures the deep interaction between the components of a Machine Learning pipeline. We propose embedding pipelines into a latent representation through a novel per-component encoder mechanism. To search for optimal pipelines, such pipeline embeddings are used within deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters of the pipeline embedding network using existing evaluations of pipelines on diverse collections of related datasets (a.k.a. meta-datasets). Through extensive experiments on three large-scale meta-datasets, we demonstrate that pipeline embeddings yield state-of-the-art results in Pipeline Optimization.","Imbalanced datasets are commonly observed in various real-world applications, presenting significant challenges in training classifiers. When working with large datasets, the imbalanced issue can be further exacerbated, making it exceptionally difficult to train classifiers effectively. To address the problem, over-sampling techniques have been developed to linearly interpolating data instances between minorities and their neighbors. However, in many real-world scenarios such as anomaly detection, minority instances are often dispersed diversely in the feature space rather than clustered together. Inspired by domain-agnostic data mix-up, we propose generating synthetic samples iteratively by mixing data samples from both minority and majority classes. It is non-trivial to develop such a framework, the challenges include source sample selection, mix-up strategy selection, and the coordination between the underlying model and mix-up strategies. To tackle these challenges, we formulate the problem of iterative data mix-up as a Markov decision process (MDP) that maps data attributes onto an augmentation strategy. To solve the MDP, we employ an actor-critic framework to adapt the discrete-continuous decision space. This framework is utilized to train a data augmentation policy and design a reward signal that explores classifier uncertainty and encourages performance improvement, irrespective of the classifier's convergence. We demonstrate the effectiveness of our proposed framework through extensive experiments conducted on seven publicly available benchmark datasets using three different types of classifiers. The results of these experiments showcase the potential and promise of our framework in addressing imbalanced datasets with diverse minorities.","Sentiment analysis is an essential task in understanding human-generated textual documents. While most research into sentiment analysis focuses on monolingual sentences, in multilingual communities, a significant proportion of social media text contains a mixture of languages or code-switching. Thus, it has become vital to research and build models that handle code-switched data. However, despite significant research and custom expert neural architectures proposed, the current literature is mainly limited to modeling single language pairs. To expand on existing work and baseline performance for this particular task, we perform multiple experiments: fine-tuning pre-trained multilingual models and fine-tuning monolingual BERT models on sentence and word-level translations. The experiments are performed across five datasets where English is code-switched with Spanish, Tamil, Telugu, Hindi, and Malayalam. Our best model outperforms the current best single model that works with multiple code-switched language pairs on standard classification metrics on a binary sentiment classification task. We further expand our experiment with a ternary sentiment classification task and produce results comparable to single language-pair-specific models.","Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply the methodology to analyze six label noise correction methods according to several fairness metrics on standard OpenML datasets. Our results suggest that the Hybrid Label Noise Correction [20] method achieves the best trade-off between predictive performance and fairness. Clustering-Based Correction [14] can reduce discrimination the most, however, at the cost of lower predictive performance.","Infertility is a global issue. Total fertility rate declined from over 5 live births per woman in 1950\u20131955 to 2.5 births per woman in 2010\u20132015. Female infertility is 37% globally and 12.5% in India. Female infertility can be reduced by identifying and treating the underlying cause early. Ovulatory diseases contribute 25% globally to female infertility. Various female pelvic imaging methods can diagnose ovulatory problems. Diagnostic ultrasound is chosen because it is radiation- and contrast-free and cost-effective. The intensity-based grouping and textural data were used for the detection of follicles and cysts in the ovary, which is based on machine learning (ML). Ovarian diagnosis was given a major boost thanks to the application of machine-learning algorithms, which permitted a success rate of 97% and significantly improved the overall quality of the process. Standard machine-learning strategies have been looked into for the purpose of ovarian classification. In order to determine which method of classification produces the most accurate findings, we constructed three distinct models utilising artificial neural networks, discriminant classifiers, and support vector machines. When the results of the various created classifiers were compared, it was discovered that SVM had the highest accuracy (98.5%). This ingenious tool, which may be classified as a decision support system, will assist the attending physician in reaching the appropriate determination and preventing an error in his or her interpretation.","To provide researcher and operation personnel with recommendations on the condition of equipment so as to ensure the safe, reliable, and smooth operation of the EAST-NBI (Experimental Advanced Superconducting Tokamak Neutral Beam Injection) power system, we propose a memory attention mechanism MacBERT (MLM as correction Bidirectional Encoder Representation from Transformers) text classification model. Firstly, we use MacBERT to generate word vectors containing context, which alleviates the masking differences in pre-training and fine-tuning phases. Secondly, the deep features are further extracted and important parts are highlighted through the memory attention module. Finally, the Linear layer and Softmax layer are used to find the label with the highest predicted probability. Experimental results show that the proposed model performs well in the classification of maintenance records for the EAST-NBI power system, which shows certain research significance.","This paper presents methods of prediction of casting mechanical parameters based on direct microstructure image analysis using deep neural networks and graphite forms recognition and classification. These methods are applied to predict tensile strength of iron-carbon alloys based on microstructure photos taken with the light-optical microscopy technique, but are general and can be adapted to other applications. In the first approach EfficientNet architecture is used. In the second approach graphite structures are separated, recognized using VGG19 network, counted and classified using support vector machines, decision trees, random forest, logistic regression, multi-layer perceptron and AdaBoost. Accuracy of the first approach is better. However, the second allows to create a classifier, for which the accuracy is also high, and can be easily analyzed by human expert.","Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (Out-Of-Candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.","The deployment of Deep Neural Networks (DNNs) on edge devices is hindered by the substantial gap between performance requirements and available computational power. While recent research has made significant strides in developing pruning methods to build a sparse network for reducing the computing overhead of DNNs, there remains considerable accuracy loss, especially at high pruning ratios. We find that the architectures designed for dense networks by differentiable architecture search methods are ineffective when pruning mechanisms are applied to them. The main reason is that the current methods do not support sparse architectures in their search space and use a search objective that is made for dense networks and does not focus on sparsity.\nThis paper proposes a new method to search for sparsity-friendly neural architectures. It is done by adding two new sparse operations to the search space and modifying the search objective. We propose two novel parametric SparseConv and SparseLinear operations in order to expand the search space to include sparse operations. In particular, these operations make a flexible search space due to using sparse parametric versions of linear and convolution operations. The proposed search objective lets us train the architecture based on the sparsity of the search space operations. Quantitative analyses demonstrate that architectures found through DASS outperform those used in the state-of-the-art sparse networks on the CIFAR-10 and ImageNet datasets. In terms of performance and hardware effectiveness, DASS increases the accuracy of the sparse version of MobileNet-v2 from 73.44% to 81.35% (+7.91% improvement) with a 3.87\u00d7 faster inference time.","Large-scale natural soundscapes are remarkably complex and offer invaluable insights into the biodiversity and health of ecosystems. Recent advances have shown promising results in automatically classifying the sounds captured using passive acoustic monitoring. However, the accuracy performance and lack of transferability across diverse environments remains a challenge. To rectify this, we propose a robust and flexible ecoacoustics sound classification grid search-based framework using optimised machine learning algorithms for the analysis of large-scale natural soundscapes. It consists of four steps: pre-processing including the application of spectral subtraction denoising to two distinct datasets extracted from the Australian Acoustic Observatory, feature extraction using Mel Frequency Cepstral Coefficients, feature reduction, and classification using a grid search approach for hyperparameter tuning across classifiers including Support Vector Machine, k-Nearest Neighbour, and Artificial Neural Networks. With 10-fold cross validation, our experimental results revealed that the best models obtained a classification accuracy of 96% and above in both datasets across the four major categories of sound (biophony, geophony, anthrophony, and silence). Furthermore, cross-dataset validation experiments using a pooled dataset highlight that our framework is rigorous and adaptable, despite the high variance in possible sounds at each site.","Gradient Boosting Decision Tree (GBDT) has achieved remarkable success in a wide variety of applications. The split finding algorithm, which determines the tree construction process, is one of the most crucial components of GBDT. However, the split finding algorithm has long been criticized for its bias towards features with a large number of potential splits. This bias introduces severe interpretability and overfitting issues in GBDT. To this end, we provide a fine-grained analysis of bias in GBDT and demonstrate that the bias originates from 1) the systematic bias in the gain estimation of each split and 2) the bias in the split finding algorithm resulting from the use of the same data to evaluate the split improvement and determine the best split. Based on the analysis, we propose unbiased gain, a new unbiased measurement of gain importance using out-of-bag samples. Moreover, we incorporate the unbiased property into the split finding algorithm and develop UnbiasedGBM to solve the overfitting issue of GBDT. We assess the performance of UnbiasedGBM and unbiased gain in a large-scale empirical study comprising 60 datasets and show that: 1) UnbiasedGBM exhibits better performance than popular GBDT implementations such as LightGBM, XGBoost, and Catboost on average on the 60 datasets and 2) unbiased gain achieves better average performance in feature selection than popular feature importance methods. The codes are available at https://github.com/ZheyuAqaZhang/UnbiasedGBM.","Few-shot open-set recognition (FSOSR) has become a great challenge, which requires classifying known classes and rejecting the unknown ones with only limited samples. Existing FSOSR methods mainly construct an ambiguous distribution of known classes from scarce known samples without considering the latent distribution information of unknowns, which degrades the performance of open-set recognition. To address this issue, we propose a novel loss function called multirelation margin (MRM) loss that can plug in few-shot methods to boost the performance of FSOSR. MRM enlarges the margin between different classes by extracting the multi-relationship of paired samples to dynamically refine the decision boundary for known classes and implicitly delineate the distribution of unknowns. Specifically, MRM separates the classes by enforcing a margin while concentrating samples of the same class on a hypersphere with a learnable radius. In order to better capture the distribution information of each class, MRM extracts the similarity and correlations among paired samples, ameliorating the optimization of the margin and radius. Experiments on public benchmarks reveal that methods with MRM loss can improve the unknown detection of AUROC by a significant margin while correctly classifying the known classes.","When employing supervised machine learning to analyze network traffic, the heart of the task often lies in developing effective features for the ML to leverage. We develop GGFAST, a unified, automated framework that can build powerful classifiers for specific network traffic analysis tasks, built on interpretable features. The framework uses only packet sizes, directionality, and sequencing, facilitating analysis in a payload-agnostic fashion that remains applicable in the presence of encryption.\nGGFAST analyzes labeled network data to identify n-grams (\"snippets\") in a network flow's sequence-of-message-lengths that are strongly indicative of given categories of activity. The framework then produces a classifier that, given new (unlabeled) network data, identifies the activity to associate with each flow by assessing the presence (or absence) of snippets relevant to the different categories.\nWe demonstrate the power of our framework by building---without any case-specific tuning---highly accurate analyzers for multiple types of network analysis problems. These span traffic classification (L7 protocol identification), finding DNS-over-HTTPS in TLS flows, and identifying specific RDP and SSH authentication methods. Finally, we demonstrate how, given ciphersuite specifics, we can transform a GGFAST analyzer developed for a given type of traffic to automatically detect instances of that activity when tunneled within SSH or TLS.","Idiomatic expressions are important natural parts of all languages and prominent parts of our daily speech. Idioms cannot be interpreted from the words that they are formed with directly and people may not understand the meaning. From past literature, it was noted that idiom affects Natural Language Processing research like machine translation, semantic analysis, and sentiment analysis. Other languages like English, Chinese, and Indian idioms are recognized through different methods in different research. As there is no standard method and research to identify Amharic idioms, this study is aimed to build a model to identify idioms for the Amharic language using a supervised machine learning approach. The study used 800 labeled expressions for training and 200 expressions for testing from Amharic idiom books \u201c\u12e8\u12a0\u121b \u1228\u129b \u1348\u120a\u1326\u127d\u201d and different Amharic documents. To measure the performance of the model, we used accuracy, precision, recall, and F-score. Finally, a 97.5% accuracy result was achieved from the testing dataset showing a promising result. The study contributes to the information systems discourse about improving the awareness and knowledge of researchers on Amharic idioms.","Speech emotion recognition (SER) is a crucial aspect of affective computing and human-computer interaction, yet effectively identifying emotions in different speakers and languages remains challenging. This paper introduces SER-Fuse, a multi-modal SER application that is designed to address the complexities of multiple speakers and languages. Our approach leverages diverse audio/speech embeddings and text embeddings to extract optimal features for multi-modal SER. We subsequently employ multi-feature fusion to integrate embedding features across modalities and languages. Experimental results archived on the English-Chinese emotional speech (ECES) dataset reveal that SER-Fuse attains competitive performance in the multi-lingual approach compared to the single-lingual approaches. Furthermore, we provide the implementation of SER-Fuse for download at https://github.com/nhattruongpham/SER-Fuse to support reproducibility and local deployment.","Skip Abstract Section\nAbstract\nThe earth\u2019s ecology is well balanced and protected by forests. On the other hand, forest fires affect forest resources, thus causing both economical and ecological losses. Hence, preserving forest resources from fires is very essential to reduce environmental disasters. Controlling forest fire at an early stage is necessary to control their spread. This requirement enforces the necessity of fast and reliable fire detection algorithms. In this paper, a color models aware dynamic feature extraction for forest fire detection using machine learning classifiers is proposed to achieve early detection of fire and reduced false alarm rate. The proposed algorithm extracts fire detection index, wavelet energy, and gray level co-occurrence matrix features from RGB, L*a*b*, and YCbCr color models respectively to train the machine learning classifiers. The performance of the proposed model is analysed using various machine learning algorithms and the standard classification metrics. The proposed color-aware feature extraction gives precision, recall, F1-score, and accuracy of 99, 95, 94, and 97% respectively for the K-nearest neighbourhood model. The support vector machine model delivers 98, 95, 93, and 96.5% respectively. The accuracy of the proposed model is improved by a minimum of 3%, and a maximum of 11% than other color models. Similarly, the false rate reduction is a minimum of 5% and a maximum of 17% than other models.","Large training data and expensive model tweaking are standard features of deep learning with images. As a result, data owners often utilize cloud resources to develop large-scale complex models, which also raises privacy concerns. Existing cryptographic solutions for training deep neural networks (DNNs) are too expensive, cannot effectively utilize cloud GPU resources, and also put a significant burden on client-side pre-processing. This article presents an image disguising approach: DisguisedNets, which allows users to securely outsource images to the cloud and enables confidential, efficient GPU-based model training. DisguisedNets uses a novel combination of image blocktization, block-level random permutation, and block-level secure transformations: random multidimensional projection (RMT) or AES pixel-level encryption (AES) to transform training data. Users can use existing DNN training methods and GPU resources without any modification to training models with disguised images. We have analyzed and evaluated the methods under a multi-level threat model and compared them with another similar method\u2014InstaHide. We also show that the image disguising approach, including both DisguisedNets and InstaHide, can effectively protect models from model-targeted attacks.","Smart buildings are generally equipped with thousands of heterogeneous sensors and control devices that impact the operation of their electrical systems. Analytical tools that aim to optimise the energy efficiency within such complex systems requires prior mapping or (classification) of diverse set of sensors according to a standard. Prior research primarily focuses on exploiting the similarities in sensor names (text metadata) to categorise them into identical classes (or groups). However, the sensors within and across buildings often follow distinct naming conventions by different vendors. In addition the definition of the classes or groups also varies significantly amongst researchers. This limits the usability and portability of prior techniques when applied across buildings. There are standard ontologies (Brick, Haystack etc.) that provide a set of standardized classes for the sensors in the buildings. The work herein follows a new avenue to address this challenging classification problem by (i) utilizing only time-series data of sensors and not text metadata, (ii) developing a simple, effective and hitherto unexplored Machine Learning (ML) model to classify the sensors into a set of standard Brick classes, and (iii) evaluating the model on a large proprietary dataset comprising of 129 buildings. Experimental results demonstrate promising performance of the presented data driven model, with average classification accuracy in terms of weighted F-score at 0.78 (\u00b10.14), and statistically significant improvements over prior methods.","Multi-view data containing complementary and consensus information can facilitate representation learning by exploiting the intact integration of multi-view features. Because most objects in the real world often have underlying connections, organizing multi-view data as heterogeneous graphs is beneficial to extracting latent information among different objects. Due to the powerful capability to gather information of neighborhood nodes, in this article, we apply Graph Convolutional Network (GCN) to cope with heterogeneous graph data originating from multi-view data, which is still under-explored in the field of GCN. In order to improve the quality of network topology and alleviate the interference of noises yielded by graph fusion, some methods undertake sorting operations before the graph convolution procedure. These GCN-based methods generally sort and select the most confident neighborhood nodes for each vertex, such as picking the top-k nodes according to pre-defined confidence values. Nonetheless, this is problematic due to the non-differentiable sorting operators and inflexible graph embedding learning, which may result in blocked gradient computations and undesired performance. To cope with these issues, we propose a joint framework dubbed Multi-view Graph Convolutional Network with Differentiable Node Selection (MGCN-DNS), which is constituted of an adaptive graph fusion layer, a graph learning module, and a differentiable node selection schema. MGCN-DNS accepts multi-channel graph-structural data as inputs and aims to learn more robust graph fusion through a differentiable neural network. The effectiveness of the proposed method is verified by rigorous comparisons with considerable state-of-the-art approaches in terms of multi-view semi-supervised classification tasks, and the experimental results indicate that MGCN-DNS achieves pleasurable performance on several benchmark multi-view datasets.","Existing studies have recognized the effect of noise of granulated datasets on classification performance. Whether this effect continues an aid in generating decisional rules for the tree-based learning models needs to be disclosed. This study conducts an experiment that investigates the effect of noisy data on rule generation performance (RGP). The unsupervised (equal-width interval, EWI) and 28 supervised (minimum description length, MDL) techniques were used to granulate datasets. The decision-tree based classification model that either included or did not include 24 EWI and 28 MDL noisy granulated datasets were used, followed by testing and comparison on classification accuracy and RGP. Main results are as follows. Removal of noisy granulated datasets with EWI is advantageous to decision tree generation when original classification accuracy (OCA) of datasets is higher than 90% or less than 70%, but not obvious between 70% and 90%. Contrariwise, those with MDL is neither highly related to improvement of generation rate nor simplicity for scales of both higher than 90% and less than 70%, but slightly related to those with OCA between 70% and 90%.","In recent years, numerous machine learning-based systems have actively propagated discriminatory effects and harmed historically disadvantaged groups through their decision-making. This undesired behavior highlights the importance of research topics such as fairness in machine learning, whose primary goal is to include fairness notions into the training process to build fairer models. In parallel, Differential Item Functioning (DIF) is a mathematical tool often used to identify bias in test preparation for candidate selection; DIF detection assists in identifying test items that disproportionately favor or disadvantage candidates solely because they belong to a specific sociodemographic group. This paper argues that transposing DIF concepts into the machine learning domain can lead to promising approaches for developing fairer solutions. As such, we propose DIF-SR, the first DIF-based Sample Reweighting method for weighting samples so that the assigned values help build fairer classifiers. DIF-SR can be seen as a data preprocessor that imposes more importance on the most auspicious examples in achieving equity ideals. We experimentally evaluated our proposal against two baseline strategies by employing twelve datasets, five classification algorithms, four performance measures, one multicriteria measure, and one statistical significance test. Results indicate that the sample weight computed by DIF-SR can guide supervised machine learning methods to fit fairer models, simultaneously improving group fairness notions such as demographic parity, equal opportunity, and equalized odds.","This paper provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.","With advances in sensing technology, multi-modal data collected from different sources are increasingly available. Multi-modal classification aims to integrate complementary information from multi-modal data to improve model classification performance. However, existing multi-modal classification methods are basically weak in integrating global structural information and providing trustworthy multi-modal fusion, especially in safety-sensitive practical applications (e.g., medical diagnosis). In this paper, we propose a novel Dynamic Poly-attention Network (DPNET) for trustworthy multi-modal classification. Specifically, DPNET has four merits: (i) To capture the intrinsic modality-specific structural information, we design a structure-aware feature aggregation module to learn the corresponding structure-preserved global compact feature representation. (ii) A transparent fusion strategy based on the modality confidence estimation strategy is induced to track information variation within different modalities for dynamical fusion. (iii) To facilitate more effective and efficient multi-modal fusion, we introduce a cross-modal low-rank fusion module to reduce the complexity of tensor-based fusion and activate the implication of different rank-wise features via a rank attention mechanism. (iv) A label confidence estimation module is devised to drive the network to generate more credible confidence. An intra-class attention loss is introduced to supervise the network training. Extensive experiments on four real-world multi-modal biomedical datasets demonstrate that the proposed method achieves competitive performance compared to other state-of-the-art ones.","Classification of normal vs. pathological infant cry is a socially relevant and challenging problem. Many feature sets, such as Mel Frequency Cepstral Coefficients (MFCC), Linear Frequency Cepstral Coefficients (LFCC), and Constant Q Cepstral Coefficients (CQCC) have been used for this task. However, an effective representation of the spectral and pitch components of a spectrum together is not achieved leaving scope for improvement. Also, the infant cry can be considered a melodic sound implying that the fundamental frequency and timbre-based features also carry vital information. This work proposes Constant Q Harmonic Coefficients (CQHC), and Constant Q Pitch Coefficients (CQPC) extracted by the decomposition of the Constant Q Transform (CQT) spectrum for the infant cry classification. This work uses Convolutional Neural Network (CNN) as the classifier along with traditional classifiers, such as Gaussian Mixture Models (GMM) and Support Vector Machines (SVM). The results using the CNN classifier are compared by considering the MFCC, LFCC, and CQCC feature sets as the baseline features. The feature-level fusion of MFCC with log-CQHC and MFCC with log-CQPC achieved a 5-fold accuracy of 98.73% and 98.96% respectively, surpassing the baseline MFCC. Furthermore, the fusion of MFCC with log-CQHC and log-CQPC feature sets resulted in improved classification accuracy of 3%, 4.7%, and 5.85% when compared with the baseline MFCC, LFCC, and CQCC feature sets, respectively. Further, our intensive experiments using three classifiers structures, namely, GMM, SVM, and CNN indicate superior results using the proposed feature extraction techniques.","Multi-view learning aims to leverage data acquired from multiple sources to achieve better performance compared to using a single view. However, the performance of multi-view learning can be negatively impacted by noisy or corrupted views in certain real-world situations. As a result, it is crucial to assess the confidence of predictions and obtain reliable learning outcomes. In this paper, we introduce CALM, an enhanced encoding and confidence evaluation framework for trustworthy multi-view classification. Our method comprises enhanced multi-view encoding, multi-view confidence-aware fusion, and multi-view classification regularization, enabling the simultaneous evaluation of prediction confidence and the yielding trustworthy classifications. Enhanced multi-view encoding takes advantage of cross-view consistency and class diversity to improve the efficacy of the learned latent representation, facilitating more reliable classification results. Multi-view confidence-aware fusion utilizes a confidence-aware estimator to evaluate the confidence scores of classification outcomes. The final multi-view classification results are then derived through confidence-aware fusion. To achieve reliable and accurate confidence scores, multivariate Gaussian distributions are employed to model the prediction distribution. The advantage of CALM lies in its ability to evaluate the quality of each view, reducing the influence of low-quality views on the multi-view fusion process and ultimately leading to improved classification performance and confidence evaluation. Comprehensive experimental results demonstrate that our method outperforms other trusted multi-view learning methods in terms of effectiveness, reliability, and robustness.","A time series is a sequence of sequentially ordered real values in time. Time series classification (TSC) is the task of assigning a time series to one of a set of predefined classes, usually based on a model learned from examples. Dictionary-based methods for TSC rely on counting the frequency of certain patterns in time series and are important components of the currently most accurate TSC ensembles. One of the early dictionary-based methods was WEASEL, which at its time achieved SotA results while also being very fast. However, it is outperformed both in terms of speed and accuracy by other methods. Furthermore, its design leads to an unpredictably large memory footprint, making it inapplicable for many applications. In this paper, we present WEASEL 2.0, a complete overhaul of WEASEL based on two recent advancements in TSC: Dilation and ensembling of randomized hyper-parameter settings. These two techniques allow WEASEL 2.0 to work with a fixed-size memory footprint while at the same time improving accuracy. Compared to 15 other SotA methods on the UCR benchmark set, WEASEL 2.0 is significantly more accurate than other dictionary methods and not significantly worse than the currently best methods. Actually, it achieves the highest median accuracy over all data sets, and it performs best in 5 out of 12 problem classes. We thus believe that WEASEL 2.0 is a viable alternative for current TSC and also a potentially interesting input for future ensembles.","Clinical text classification allows assigning labels to content-based data using machine learning algorithms. However, unlike other study domains, clinical texts present complex linguistic diversity, including abbreviations, typos, and numerical patterns that are difficult to represent by the most-used classification algorithms. In this sense, sequences of character strings and symbols, known as Regular Expressions (RegExs), offer an alternative to represent complex patterns from the texts and could be used jointly with the most commonly used classification algorithms for accurate text classification. Thus, a classification algorithm can label test texts when RegExs produce no matches. This work proposes a method that combines automatically-generated RegExs and supervised algorithms for classifying clinical texts. RegExs are automatically generated using alignment algorithms in a supervised manner, filtering out those that do not meet a minimum confidence threshold and do not contain specific keywords for the classification problem. At prediction time, our method assigns the class of the most confident RegEx that matches a test text. When no RegExs matches a test text, a supervised algorithm assigns a class. Three clinical datasets with textual information on obesity and smoking habits were used to assess the performance of four classifiers based on Random Forest (RF), Support Vector Machine (SVM), Naive Bayes (NB), and Bidirectional Encoder Representations from Transformers (BERT). Classification results indicate that our method, on average, improved the classifiers\u2019 performance by up to 12% in all performance metrics. These results show the ability of our method to generate confident RegExs that capture representative patterns from the texts for use with supervised algorithms.","Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of attacks and CPS themselves, anomaly detection in CPS is becoming more and more challenging. In our previous work, we proposed a digital twin-based anomaly detection method, called ATTAIN, which takes advantage of both historical and real-time data of CPS. However, such data vary significantly in terms of difficulty. Therefore, similar to human learning processes, deep learning models (e.g., ATTAIN) can benefit from an easy-to-difficult curriculum. To this end, in this paper, we present a novel approach, named digitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum learning to optimize its learning paradigm. LATTICE attributes each sample with a difficulty score, before being fed into a training scheduler. The training scheduler samples batches of training data based on these difficulty scores such that learning from easy to difficult data can be performed. To evaluate LATTICE, we use five publicly available datasets collected from five real-world CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art anomaly detectors. Evaluation results show that LATTICE outperforms the three baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also, on average, reduces the training time of ATTAIN by 4.2% on the five datasets and is on par with the baselines in terms of detection delay time.","Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBERT, and (3) proposing a systematic way to measure and mitigate biases. Our results show the better performance of our approach on zero-shot and full-training settings in comparison with strong baseline models, while also revealing the existence of biases in the resulting LLMs. Utilizing a targeted counterfactual data augmentation approach, we significantly reduce these biases without compromising performance.","In machine learning, the term \u201dclass imbalanced\u201d is frequently used. This is a crucial part of the field of machine learning. It is quite important in the classification process and has a significant impact on performance. That is why researchers are concentrating on it to overcome this difficulty. Various researchers have devised numerous methods till now. The approaches to addressing this imbalance issue found so far can be broadly categorized into three categories, which are the data-level approach, algorithm-level approach, and hybrid-level approach. To evaluate the most recent developments in resolving the negative effects of class imbalance, this study provides a comparative analysis of research that has been published within the last 5 years with an emphasis on high-class imbalance. In this study, an attempt has been made to provide a concise overview of what imbalance classification is, how it is created, and what the inconveniences are due to it. We have tried to provide a summary of several studies that have been published in the last few years and along with that a comparative analysis of all these approaches has been done."],"author":["Sotero, Roberto C and Sanchez-Bornot, Jose M and Shaharabi-Farahani, Iman and Iturria-Medina, Yasser","Chahi, Abderrazak and El-merabet, Youssef and Ruichek, Yassine and Touahni, Raja","NaN","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","NaN","Yao, Jianping and Tran, Son N. and Sawyer, Samantha and Garg, Saurabh","Senthil Kumar, Prathyusha","Kalb, Thorsten and Kushibar, Kaisar and Cintas, Celia and Lekadir, Karim and Diaz, Oliver and Osuala, Richard","Ahmed, Abdelfatah and Velayudhan, Divya and Hassan, Taimur and Bennamoun, Mohammed and Damiani, Ernesto and Werghi, Naoufel","Kim, Seonjun and Kim, Minjae and Lee, Youngki","Lv, Yan and Yin, Yu Jia and Guo, Wenwen and Bai, Lan","Li, Hao-Tian and Wei, Tong and Yang, Hao and Hu, Kun and Peng, Chong and Sun, Li-Bo and Cai, Xun-Liang and Zhang, Min-Ling","NaN","Jo, Nathanael and Aghaei, Sina and Benson, Jack and Gomez, Andres and Vayanos, Phebe","Dantas, Cassio F. and Drumond, Thalita F. and Marcos, Diego and Ienco, Dino","NaN","Miftahushudur, Tajul and Sahin, Halil Mertkan and Grieve, Bruce and Yin, Hujun","Shi, Yu and Xu, Ning and Yuan, Hua and Geng, Xin","Verbiest, Nele and Ramentol, Enislay and Cornelis, Chris and Herrera, Francisco","NaN","Mohiuddin, Karishma and Alam, Mirza Ariful and Alam, Mirza Mohtashim and Welke, Pascal and Martin, Michael and Lehmann, Jens and Vahdati, Sahar","Liu, Ruiqi and Xu, Ganggang and Shang, Zuofeng","He, Jiahui and Zia, Haris Bin and Castro, Ignacio and Raman, Aravindh and Sastry, Nishanth and Tyson, Gareth","Fan, Jinfu and Jiang, Zhencun and Xian, Yuanqing and Wang, Zhongjie","Asmita, Sharma and Pranshul, Lakhanpal and Marin, Litoiu and Lauren E., Sergio and Sumona, Mukhopadhyay","Ueda, Ryosuke and Takeuchi, Koh and Kashima, Hisashi","Chen, Jinqian and Zhu, Jihua and Zheng, Qinghai","Purwar, Archana and Manju, Ms.","Abeyrathna, K. Darshana and Abouzeid, Ahmed A. O. and Bhattarai, Bimal and Giri, Charul and Glimsdal, Sondre and Granmo, Ole-Christoffer and Jiao, Lei and Saha, Rupsa and Sharma, Jivitesh and Tunheim, Svein A. and Zhang, Xuan","NaN","Bhope, Rahul Atul and Jayaram, K. R. and Venkatasubramanian, Nalini and Verma, Ashish and Thomas, Gegi","Gundawar, Atharva and Lodha, Srishti and Vijayarajan, V. and Iyer, Balaji and Prasath, V. B. Surya","Yamaguchi, Akihiro and Ueno, Ken and Kashima, Hisashi","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","Ma, Guanghui and Hu, Chunming and Ge, Ling and Zhang, Hong","Mishra, Aakriti and Ramanathan, A. and Batta, Vineet and Malathy, C. and Kundu, Soumya Snigdha and Gayathri, M. and Vathana, D. and Kamineni, Srinath","Kuljeet Singh and Shastri, Sourabh and Kumar, Sachin and Mansotra, Vibhakar","Oh, Se Won and Jeong, Hyuntae and Chung, Seungeun and Lim, Jeong Mook and Noh, Kyoung Ju","Chen, Xu and Marazopoulou, Katerina and Lee, Wesley and Agarwal, Christine and Sukumaran, Jason and Hofleitner, Aude","NaN","NaN","Zhou, Jing-Wen and Fu, Shao-Feng and Li, Long-Hai and Dong, Jun-Zhe","Sahu, Sushanta Kumar and Chowdhury, Ananda S.","Nancy, V. Auxilia Osvin and Prabhavathy, P. and Arya, Meenakshi S. and Ahamed, B. Shamreen","Amgoud, Leila and Muller, Philippe and Trenquier, Henri","Xia, Tian and Shao, Yabin and Xia, Shuyin and Xiong, Yiping and Lian, Xiaoyu and Ling, Wu","NaN","NaN","Roy, Debaditya and Lekssays, Ahmed and Girdzijauskas, Sarunas and Carminati, Barbara and Ferrari, Elena","Gupta, Rohan Kumar and Sinha, Rohit","NaN","Sun, Siqi and Wang, Yongyu","Koottungal, Akash and Pandey, Shailesh and Nambiar, Athira","Airao, Jay and Gupta, Abhishek and Saraf, Gaurav and Nirala, Chandrakant K","Yi, Liping and Wang, Gang and Liu, Xiaoguang and Shi, Zhuan and Yu, Han","Grina, Fares and Elouedi, Zied and Lefevre, Eric","Paul, Jackson H. and Digh, Andy D.","Han, Feiyang and Miao, Yun and Sun, Zhaoyi and Wei, Yimin","Shen, Yuhao and Li, Bo and Xu, Xinlan and Luo, Bing and Zhang, Chao and Hao, Fei","NaN","Behera, Adarsh Prasad and Morabito, Roberto and Widmer, Joerg and Champati, Jaya Prakash","Gillala, Rekha and Mishra, Anand Kumar and Tyagi, Amit Kumar","Li, Chen and Shao, Yabin and Xia, Shuyin and Wang, Cheng and Xia, Tian and Peng, Xiaoli","Ma, Xi-Ao and Jiang, Wentian and Ling, Yun and Yang, Bailin","Yin, Xiuye and Chen, Liyong","Sun, Pengbo and Zuo, Yi and Wang, Yudi","NaN","Xu, Zhongguo and Jha, Naresh and Mehadi, Syed and Mandal, Mrinal","Sharma, Arnav and Sharma, Subhanjali and Bhardwaj, Utkarsh and Mistry, Sajib and Deb, Novarun and Krishna, Aneesh","Kulkarni, Atharva and Masud, Sarah and Goyal, Vikram and Chakraborty, Tanmoy","Zhuang, Yuchen and Yu, Yue and Kong, Lingkai and Chen, Xiang and Zhang, Chao","Bisen, Tejasvee and Javed, Mohammed and Kirtania, Shashank and Nagabhushan, P.","Jaiswal, Dibyanshu and Chatterjee, Debatri and B s, Mithun and Ramakrishnan, Ramesh Kumar and Pal, Arpan","Chen, Mingcai and Zhao, Yu and Wang, Zhonghuang and He, Bing and Yao, Jianhua","Christen, Peter and Hand, David J. and Kirielle, Nishadi","NaN","Hu, Mingzhi and Zhang, Xin and Li, Yanhua and Zhou, Xun and Luo, Jun","Zhao, Konghao and Bhandari, Sapan and Whitener, Nathan P and Grayson, Jason M and Khuri, Natalia","Wang, Lin and Gjoreski, Hristijan and Ciliberto, Mathias and Lago, Paula and Murao, Kazuya and Okita, Tsuyoshi and Roggen, Daniel","Ghosh, Bishwamittra","Negru, Vlad-Andrei and Lemnaru, Camelia and Potolea, Rodica","Caliskan, Abdullah and O'Brien, Conor and Panduru, Krishna and Walsh, Joseph and Riordan, Daniel","Roussinov, Dmitri and Sharoff, Serge and Puchnina, Nadezhda","Payntar, Nicole D.","NaN","Hu, Boren and Zhu, Yun and Li, Jiacheng and Tang, Siliang","Rozendo, Guilherme Botazzo and Roberto, Guilherme Freire and do Nascimento, Marcelo Zanchetta and Alves Neves, Leandro and Lumini, Alessandra","Liang, Chunhui and Ma, Wenqing","Zhou, Yu Sheng","Zeng, Meng and Zhang, Zhonglin","Kai, Yang and Miao, Zhang and Peng, Sun and Miaomiao, Qi","Mao, Jun-Xiang and Wang, Wei and Zhang, Min-Ling","Tian, Yuchen and Wang, Jiacheng and Jin, Yueming and Wang, Liansheng","Debnath, Chandrima and Guha, Debashree and Hait, Swati Rani and Guria, Soumita and Chakraborty, Debjani","Yumang, Analyn N and Banguilan, Dave Emilson S and Veneracion, Clark Kent S","Gu, Qiangqiang and Shaikh, Nazim and Lin, Ping-chang and Jayachandran, Srinath and Porwal, Prasanna and Li, Xiao and Nie, Yao","Singhal, Abhishek and Sharma, Devendra Kumar","Lee, Eunji and Kim, Sihyeon and Kim, Sundong and Jung, Soyeon and Kim, Heeja and Cha, Meeyoung","Andersen, Lasse R. and Jacobsen, Lukas J. and Campos, David","Khater, Tarek and Tawfik, Hissam and Singh, Balbir","Mougan, Carlos and Alvarez, Jose Manuel and Ruggieri, Salvatore and Staab, Steffen","Manisha and Clifford, William and McLaughlin, Eugene and Stynes, Paul","Wang, Hewen and Yang, Renchi and Huang, Keke and Xiao, Xiaokui","Koga, Tsukasa and Maruyama, Osamu","Calzavara, Stefano and Cazzaro, Lorenzo and Pibiri, Giulio Ermanno and Prezza, Nicola","Diep, Tuong-Nghiem and Tran, Thien-Phuc and Ho-Ngoc, Vinh-Phat and Yang, Tuan-Anh and Do, Trong-Le","Du, Yanrui and Yan, Jing and Chen, Yan and Liu, Jing and Zhao, Sendong and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Qin, Bing","Philips, James and Tabrizi, Nasseh","Besharati Moghaddam, Fatemeh and Lopez, Angel J. and Van Gheluwe, Casper and De Vuyst, Stijn and Gautama, Sidharta","NaN","Zhao, Yifeng and Yang, Liming","Mcdonald, Denisa Qori and Sariyanidi, Evangelos and Zampella, Casey J. and Dejardin, Ellis and Herrington, John D. and Schultz, Robert T. and Tunc, Birkan","Li, Mingxiang and Xing, Huange and Wang, Tengyun and Xiao, Kaiming","Luo, Kaiwen and Wang, Xiaomin and Sun, Fan","Kansal, Liza and Pandey, Anoushka and Shukla, Sanidhya Madhav and Dhaliwal, Parneeta","Chhabra, Parth and Neerkaje, Atula Tejaswi and Agarwal, Shivam and Sawhney, Ramit and Thakkar, Megh and Nakov, Preslav and Chava, Sudheer","Gao, Yi and Xu, Miao and Zhang, Min-Ling","Huti, Mohamed and Lee, Tiarna and Sawyer, Elinor and King, Andrew P.","Gunaratna, Kalpa and Srinivasan, Vijay and Jin, Hongxia","Shati, Pouya and Cohen, Eldan and McIlraith, Sheila","NaN","Baci, Alkid and Heindorf, Stefan","Wang, Juanyan and Bilgic, Mustafa","Dihingia, Leena and Bannulmath, Prashant and Chowdhury, Amartya Roy and Prasanna, S.R.M and Deepak, K.T and Sheikh, Tehreem","Sharma, Rohit and Mahanti, Gautam Kumar and Chakraborty, Chinmay and Panda, Ganapati and Rath, Adyasha","Rao, Talgan Kumar and Darapaneni, Narayana and Paduri, Anwesh Reddy and S, Amarnath G and Kumar, Arun and Ps, Guruprasad","Zhang, Jiayun and Zhang, Xiyuan and Zhang, Xinyang and Hong, Dezhi and Gupta, Rajesh K. and Shang, Jingbo","La Cava, William G","Corbara, Silvia and Moreo, Alejandro and Sebastiani, Fabrizio","Yao, Ruihan and Zhang, Yufeng and Li, Zhiyao and Zhu, Jingying","Ou, Liang and Do, Thomas and Tran, Xuan-The and Leong, Daniel and Chang, Yu-Cheng and Wang, Yu-Kai and Lin, Chin-Teng","Spinnato, Francesco and Guidotti, Riccardo and Monreale, Anna and Nanni, Mirco and Pedreschi, Dino and Giannotti, Fosca","Tariq, Muhammad Arham and Sargano, Allah Bux and Iftikhar, Muhammad Aksam and Habib, Zulfiqar","Zhao, Shiman and Chen, Wei and Wang, Tengjiao","Simsek, Furkan and Pfitzmann, Brian and Raetz, Hendrik and Otholt, Jona and Yang, Haojin and Meinel, Christoph","Bond, Jacob and Gupta, Siddhartha and Elvitigala, Thanura","Zheng, Huilin and Sherazi, Syed Waseem Abbas and Arif, Saba and Lee, Myung Jin and Lee, Jong Yun","Liang, Qiao and Hu, Cheng and Huang, Haiyan","Li, Dantong and Li, Guixin and Li, Shuang and Bang, Ashley","Blachnik, Marcin and undefinedciegienka, Piotr and Da\u0327browski, Daniel","NaN","Wang, Tianle and Wang, Zihan and Liu, Weitang and Shang, Jingbo","Shrihari, A. and Guha, Prithwijit and Kulkarni, Rishikesh Dilip","Niranjan, Ranjani and Rao, Sachit","Sun, Yanjie and Xu, Kele and Liu, Chaorun and Dou, Yong and Qian, Kun","NaN","Han, Fenggang and Zhang, Xiao and He, Linjie and Kong, Liru and Chen, Yumin","NaN","Akash, Bathini Sai and Kumar, Lov and Singh, Vikram and Patel, Anoop Kumar and Krishna, Aneesh","Trieu, Nguyen Minh and Thinh, Nguyen Truong","Guan, Yunchuan and Liu, Yu and Zhou, Ke and Huang, Junyuan","Zhang, Wei and Zhang, Pengye and Zhang, Bo and Wang, Xingxing and Wang, Dong","Site, Aditi and Nurmi, Jari and Lohan, Elena Simona","Konduru, S. and Amiruzzaman, M. and Avina, V. and Islam, M. R.","Pandey, Suraj Kumar and Nair, Shivashankar B","Sadafi, Ario and Hehr, Matthias and Navab, Nassir and Marr, Carsten","Semwal, Vijay Bhaskar and Prajapat, Yogesh Kumar and Jain, Rahul","Hadjadj, Lies and Amini, Massih-Reza and Louhichi, Sana","Fang, Xiaoqi and Zhang, Guoyun and Zhang, Guifeng and Zhou, Xuhui and Wu, Jianhui and Zhao, Lin","Anand, Sidharth and Devulapally, Naresh Kumar and Bhattacharjee, Sreyasee Das and Yuan, Junsong","NaN","Li, Xintian and Culotta, Aron","Li, Jingyu and Ma, Haokai and Li, Xiangxian and Qi, Zhuang and Meng, Xiangxu and Meng, Lei","NaN","Testa, Brian and Xiao, Yi and Sharma, Harshit and Gump, Avery and Salekin, Asif","Dhakshayani, J. and Surendiran, B.","Chen, Junming","Ma, Yanbiao and Jiao, Licheng and Liu, Fang and Yang, Shuyuan and Liu, Xu and Li, Lingling","Hamed, Ahmed and Tahoun, Mohamed and Nassar, Hamed","El Balghiti, Othman and Elmachtoub, Adam N. and Grigas, Paul and Tewari, Ambuj","Ukanchanakitti, Phatsakorn and Winaichatsak, Nattapong and Cho, Natthawin and Sumetpipat, Kanes","Wang, Xu and Yang, Guangxiang and Xiao, Zhenqi and Yu, Guangling","Li, Xin and Xu, Qi and Li, Xingxing and Xin, Hao and Yuan, Yilong and Shen, Zhiheng and Zhou, Yuxuan","Xie, Wentao and Liu, Qian and Su, Yongye and Yan, Yi and Huang, Shujun and Kuang, Qin and Hu, Pingzhao","Lu, Menglong and Huang, Zhen and Tian, Zhiliang and Zhao, Yunxiang and Fei, Xuanyu and Li, Dongsheng","NaN","Dahiya, Kunal and Yadav, Sachin and Sondhi, Sushant and Saini, Deepak and Mehta, Sonu and Jiao, Jian and Agarwal, Sumeet and Kar, Purushottam and Varma, Manik","Dash, Amanda and Albu, Alexandra Branzan","Anjali Rajak and Rakesh Tripathi","Solatorio, Aivin V.","Berghouse, Marc and Bebis, George and Tavakkoli, Alireza","Merchant, Arpit and Castillo, Carlos","Khlifi, Ghaith and Jenhani, Ilyes and Messaoud, Montassar Ben and Mkaouer, Mohamed Wiem","Teixeira, Ana Clara and Yazdanpanah, Hamed and Pezente, Aline and Ghassemi, Mohammad","Zhang, Dell and Taneva-Popova, Bilyana","NaN","NaN","Wang, Lewen and Zhao, Haozhe and Feng, Cunguang and Liu, Weiqing and Huang, Congrui and Santoni, Marco and Cristofaro, Manuel and Jafrancesco, Paola and Bian, Jiang","Wang, Yifei and Zhou, Yiyang and Zhu, Jihua and Liu, Xinyuan and Yan, Wenbiao and Tian, Zhiqiang","Mior, Michael J","Rai, Prakhar and Gehlot, Shiv and Gupta, Ritu and Gupta, Anubha","Lopez Uroz, Lorenzo and Benoit, Alexandre and Yan, Yajing and Lin-Kwong-Chon, Christophe and Giffard-Roisin, Sophie and Rabatel, Antoine","Su, Yulin and Chen, Boan and Feng, Ziming and Yan, Junchi","NaN","Yu, Haitao and Xiong, Feng and Chen, Zuhui","Wu, Shengli and Li, Jinlong and Ding, Weimin","Sarlas, Athanasios and Kalafatelis, Alexandros and Alexandridis, Georgios and Kourtis, Michail-Alexandros and Trakadas, Panagiotis","Kumar, Rachit and Romano, Joseph and Ritchie, Marylyn and Moore, Jason","Tzudir, Moakala and Sadashiv T.N., Rishith and Agarwal, Ayush and Prasanna, S. R. Mahadeva","Huang, Xiaoming and Zhu, Peihu and Chen, Yuwen and Ma, Jian","Yang, Qiujuan and Zhang, Jiaxiao","Wang, Chenyu and Endo, Toshio and Hirofuchi, Takahiro and Ikegami, Tsutomu","Biggs, Mikayla and Wang, Yaohua and Soni, Neetu and Priya, Sarv and Bathla, Girish and Canahuate, Guadalupe","NaN","Gordon, Lucia and Behari, Nikhil and Collier, Samuel and Bondi-Kelly, Elizabeth and Killian, Jackson A. and Ressijac, Catherine and Boucher, Peter and Davies, Andrew and Tambe, Milind","Luo, Jueling and Long, Hui and Xie, Si and Zhang, Yalu and Ma, Haodong and Meng, Guangyao","Shaik, Janbhasha and Bhavanam, S. Nagakishore","Debnath, Chandrima and Aishwaryaprajna and Hait, Swati Rani and Guha, Debashree and Chakraborty, Debjani","NaN","Pavlovski, Martin and Ravindran, Srinath and Gligorijevic, Djordje and Agrawal, Shubham and Stojkovic, Ivan and Segura-Nunez, Nelson and Gligorijevic, Jelena","Ping, Mingtian and Pi, Dechang and Chen, Zhiwei and Wang, Junlong","Huang, Jiande and Chen, Ping and Lu, Lijuan and Deng, Yuhui and Zou, Qiang","NaN","Upadhyay, Rishabh and Pasi, Gabriella and Viviani, Marco","Channing, Georgia and Patel, Ria and Olaya, Paula and Rorabaugh, Ariel and Miyashita, Osamu and Caino-Lores, Silvina and Schuman, Catherine and Tama, Florence and Taufer, Michela","Hendro, Hendro and Shiddiqi, Ary Mazharuddin","Guo, Yeang and Tao, Tan and Ronglin, Ronglin and Xiao, Liangfen and Ding, Lijuan and Li, Qing and Xie, Hui","Samui, Suman and Garai, Soumen and Ghosh, Anindya and Mukhopadhyay, Anand Kumar","Karimi Monsefi, Amin and Shiri, Pouya and Mohammadshirazi, Ahmad and Karimi Monsefi, Nastaran and Davies, Ron and Moosavi, Sobhan and Ramnath, Rajiv","Aryal, Saurav K. and Prioleau, Howard and Shah, Ujjawal and Acharya, Sameer","Lai, Shenqi and Du, Xi and Guo, Jia and Zhang, Kaipeng","Hoang, Ngan Dao and Tran-Anh, Dat and Luong, Manh and Tran, Cong and Pham, Cuong","Hast, Anders","Zhang, Dell and Sensoy, Murat and Makrehchi, Masoud and Taneva-Popova, Bilyana and Gui, Lin and He, Yulan","Gehad Ismail Sayed and Aboul Ella Hassanein","Ninh, Quoc-Bao and Nguyen, Hai-Chan and Huynh, Triet and Tran, Minh-Triet and Le, Trung-Nghia","Fatima, Zainab and Doulani, Khushbu and Adhikari, Mainak","Jiang, Chenzhi and Jin, Yin and Wang, Ningtao and Wu, Ruofan and Fu, Xing and Wang, Weiqiang","Duong, Huong T. and Ho, Van H. and Do, Phuc","Liu, Na and Zhang, Fan and Chang, Liang and Duan, Fuqing","Junttila, Jukka and Raunio, Kalle and Kokkonen, Petteri and Saarela, Olli","NaN","Bandi, Raswitha and Likhit, M. Sai Surya and Reddy, S. Rajavardhan and Bodla, Sathwik Raj and Venkat, Vempati Sai","Wu, Chao and Sang, Yu and Gao, Yakun","Khokhlova, Maria V. and Blinova, Olga V. and Bogdanova-Beglarian, Natalia and Sherstinova, Tatiana","Ye, Ze and Liu, Dantong and Pavani, Kaushik and Dasgupta, Sunny","Luo, Xincheng and Li, Daiwei and Zhang, Haiqing and Xu, Lang and Cai, Bo and Deng, Junyu","Zhou, Wenjie and Li, Piji and Han, Zhaoyang and Lu, Xiaozhen and Li, Juan and Ren, Zhaochun and Liu, Zhe","Cui, Yuwei and Song, Qingzeng and Xue, Yongjiang and Yu, Jing","Frati, Lapo and Traft, Neil and Cheney, Nick","Xiao, Ruixuan and Dong, Yiwen and Wang, Haobo and Feng, Lei and Wu, Runze and Chen, Gang and Zhao, Junbo","Wang, Siqi and Zhou, Dongmei and Cheng, Yongjian and Jiang, Meiqi","Arasaki, Caio and Wolschick, Lucas and Freire, Willian and Amaral, Aline","Nguyen, Khang Hoang and Nguyen, Huynh Vu Nhu and Tran, Hoang Ngoc and Quach, Luyl-Da","Laroca, Rayson and Zanlorensi, Luiz A. and Estevam, Valter and Minetto, Rodrigo and Menotti, David","Dholey, Moumita and Santosham, Ritesh J. M. and Ray, Soumendranath and Das, Jayanta and Chatterjee, Sanjoy and Ahmed, Rosina and Mukherjee, Jayanta","Liu, Yifei and Wu, Yiquan and Zhang, Yating and Sun, Changlong and Lu, Weiming and Wu, Fei and Kuang, Kun","Lee, Junho and Song, Hyeonho and Lee, Dongjoon and Kim, Sundong and Sim, Jisoo and Cha, Meeyoung and Park, Kyung-Ryul","Sachan, Shivangi and Doulani, Khushbu and Adhikari, Mainak","Jiao, Jiajia and Chen, Bo","Han, Peng and Chen, Zhiming and Jiang, Fei and Si, Jiaxin","Allu, Ramakrishna and Padmanabhuni, Venkata Nageswara Rao","Abbas, Gazy and Farooq, Umar and Singh, Parvinder and Khurana, Surinder Singh and Singh, Paramjeet","Tajalli, Behrad and Abad, Gorka and Picek, Stjepan","Shiraishi, Hiroki and Hayamizu, Yohei and Hashiyama, Tomonori","NaN","NaN","Tiwary, Sanjeeb and Darshana, Subhashree and Mohanty, Debabrata and Dash, Adyasha and Rupsa, Potnuru and Barik, Rabindra K","Zhang, Qin and Shi, Zelin and Zhang, Xiaolin and Chen, Xiaojun and Fournier-Viger, Philippe and Pan, Shirui","Li, Liangping and Gong, Xun and Wang, Chenzhong and Kong, Weiji","Huang, Teng and Jia, Bin-Bin and Zhang, Min-Ling","Wang, Chenhan","Younis, Raneen and Ahmadi, Zahra and Hakmeh, Abdul and Fisichella, Marco","NaN","Bhattacharya, Indranil and Ye, Ze and Pavani, Kaushik and Dasgupta, Sunny","Wei, Jiaheng and Zhu, Zhaowei and Luo, Tianyi and Amid, Ehsan and Kumar, Abhishek and Liu, Yang","St-Vincent Villeneuve, Alexandre and Plaisent, Michel","Er-Rahmadi, Btissam and Oncevay, Arturo and Ji, Yuanyi and Pan, Jeff Z.","Nguyen, Anh Tien and Kwak, Jin Tae","Bei, Yijun and Geng, Jinsong and Liu, Erteng and Gao, Kewei and Huang, Wenqi and Feng, Zunlei","Jia, Jingyun and Chan, Philip K.","Sharma, Saurabh and Xian, Yongqin and Yu, Ning and Singh, Ambuj","Nair, Ajith N and Tanwar, Harshwardhan and Arjunan, Pandarasamy and Anand, Prashant and Mahdavi, Ardeshir","Prakash, Jainendra and Ghorai, Mrinmoy and Sanodiya, Rakesh","Zou, Jiahui and Yuan, Chaoxia and Zhang, Xinyu and Zou, Guohua and Wan, Alan T. K.","Moon, Hyung-Jun and Cho, Sung-Bae","Shi, Jiechuan and Liu, Kun and Yuan, Hao and Wang, Can and Yang, Bo","Ferreira, Alejandro and Curilem, Millaray and Gomez, Walter and Rios, Ricardo","Kongnim, Pongjit and Cooharojananone, Nagul and Chavarnakul, Thira","Yin, Yu Jia and Lv, Yan and Guo, Wenwen and Bai, Lan","Cao, Alexander and Utke, Jean and Klabjan, Diego","Dibaji, Mahsa and Gianchandani, Neha and Nair, Akhil and Singhal, Mansi and Souza, Roberto and Bento, Mariana","Rajabi, Hamid and Ding, Xianzhong and Du, Wan and Cerpa, Alberto","Fathan, Abderrahim and Alam, Jahangir and Zhu, Xiaolin","Achmamad, Abdelouahad and Elfezazi, Mohamed and Chehri, Abdellah and Ahmed, Imran and Jbari, Atman and Saadane, Rachid","Vedula, Nikhita and Collins, Marcus and Rokhlenko, Oleg","Jiang, Songhao and Chu, Yan and Wang, Zhengkui and Ma, Tianxing and Wang, Hanlin and Lu, Wenxuan and Zang, Tianning and Wang, Bo","Jia, Bin-Bin and Liu, Jun-Ying and Hang, Jun-Yi and Zhang, Min-Ling","Khaked, Azhar Ali and Oishi, Nobuyuki and Roggen, Daniel and Lago, Paula","Kim, Sungwon and Lee, Junseok and Lee, Namkyeong and Kim, Wonjoong and Choi, Seungyoon and Park, Chanyoung","Pineda Arango, Sebastian and Grabocka, Josif","Lai, Kwei-Herng and Zha, Daochen and Chen, Huiyuan and Bendre, Mangesh and Chen, Yuzhong and Das, Mashweta and Yang, Hao and Hu, Xia","Aryal, Saurav K. and Prioleau, Howard and Aryal, Surakshya and Washington, Gloria","NaN","Athithan, Senthil and Sachi, Savya and Singh, Ajay Kumar","Han, Xin and Pan, Junjun and Liu, Zhimin and Zhao, Yuanzhe and Jiang, Caichao and Chen, Shiyong and Liu, Sheng and Xie, Yahong","NaN","He, Shuo and Feng, Lei and Yang, Guowu","Mousavi, Hamid and Loni, Mohammad and Alibeigi, Mina and Daneshtalab, Masoud","Napier, Thomas and Ahn, Euijoon and Allen-Ankins, Slade and Lee, Ickjai","Zhang, Zheyu and Zhang, Tianping and Li, Jian","Che, Yongjuan and An, Yuexuan and Xue, Hui","Piet, Julien and Nwoji, Dubem and Paxson, Vern","Abebe Fenta, Anduamlak and Gebeyehu, Seffi","Pham, Nhat Truong and Phan, Le Thi and Dang, Duc Ngoc Minh and Manavalan, Balachandran","Avudaiammal, R. and Rajangam, Vijayarajan and Durai Raji V. and Senthil Kumar S.","Chen, Keke and Gu, Yuechun and Sharma, Sagar","Rana, Mashud and Rahman, Ashfaqur and Almashor, Mahathir and McCulloch, John and Sethuvenkatraman, Subbu","Chen, Zhaoliang and Fu, Lele and Xiao, Shunxin and Wang, Shiping and Plant, Claudia and Guo, Wenzhong","Kuo, Tzu-Ming and Hung, Hsuan-Yu and Wu, Chienhsing","NaN","Hort, Max and Chen, Zhenpeng and Zhang, Jie M. and Harman, Mark and Sarro, Federica","Zou, Xin and Tang, Chang and Zheng, Xiao and Li, Zhenglai and He, Xiao and An, Shan and Liu, Xinwang","Pusuluri, Aditya and Kachhi, Aastha and Patil, Hemant A.","Zhou, Hai and Xue, Zhe and Liu, Ying and Li, Boang and Du, Junping and Liang, Meiyu and Qi, Yuankai","NaN","Flores, Christopher A. and Verschae, Rodrigo","Xu, Qinghua and Ali, Shaukat and Yue, Tao","NaN","Ahmed, Zahid and Das, Sufal"],"cluster":[5,2,5,5,4,5,5,1,5,3,5,5,2,1,5,5,5,5,5,3,5,5,5,5,2,1,5,0,5,5,0,2,5,4,5,5,3,3,5,4,5,0,5,2,4,3,3,4,1,5,5,5,4,5,5,3,2,2,3,4,5,5,4,5,2,5,2,2,4,5,1,3,5,5,4,5,5,5,5,1,0,5,5,5,5,3,2,5,5,2,5,5,4,3,5,5,5,5,5,5,1,2,4,5,5,3,1,5,2,0,3,5,5,5,5,5,5,1,5,5,3,4,0,5,3,3,5,1,4,3,5,2,5,5,4,5,3,1,5,4,2,4,5,5,5,4,5,5,4,2,2,0,4,5,2,5,2,3,5,5,3,0,5,3,5,5,5,5,5,5,5,1,5,5,4,5,5,4,5,5,5,4,5,0,4,2,5,0,5,5,5,5,5,5,5,3,5,5,5,5,5,2,5,2,5,5,3,3,4,5,0,2,5,4,3,5,3,3,5,5,2,5,5,5,4,2,5,5,5,5,4,5,5,5,5,4,3,1,4,5,5,0,5,2,5,3,5,5,4,5,4,5,5,5,5,5,2,5,4,3,5,5,5,5,3,1,5,5,2,5,4,5,5,0,5,4,2,5,5,5,5,1,5,4,3,5,5,0,5,4,5,5,3,1,5,5,2,4,2,5,5,4,2,5,5,5,2,5,4,5,1,5,5,5,5,5,5,5,5,0],"labels":["C-5","C-2","C-5","C-5","C-4","C-5","C-5","C-1","C-5","C-3","C-5","C-5","C-2","C-1","C-5","C-5","C-5","C-5","C-5","C-3","C-5","C-5","C-5","C-5","C-2","C-1","C-5","C-0","C-5","C-5","C-0","C-2","C-5","C-4","C-5","C-5","C-3","C-3","C-5","C-4","C-5","C-0","C-5","C-2","C-4","C-3","C-3","C-4","C-1","C-5","C-5","C-5","C-4","C-5","C-5","C-3","C-2","C-2","C-3","C-4","C-5","C-5","C-4","C-5","C-2","C-5","C-2","C-2","C-4","C-5","C-1","C-3","C-5","C-5","C-4","C-5","C-5","C-5","C-5","C-1","C-0","C-5","C-5","C-5","C-5","C-3","C-2","C-5","C-5","C-2","C-5","C-5","C-4","C-3","C-5","C-5","C-5","C-5","C-5","C-5","C-1","C-2","C-4","C-5","C-5","C-3","C-1","C-5","C-2","C-0","C-3","C-5","C-5","C-5","C-5","C-5","C-5","C-1","C-5","C-5","C-3","C-4","C-0","C-5","C-3","C-3","C-5","C-1","C-4","C-3","C-5","C-2","C-5","C-5","C-4","C-5","C-3","C-1","C-5","C-4","C-2","C-4","C-5","C-5","C-5","C-4","C-5","C-5","C-4","C-2","C-2","C-0","C-4","C-5","C-2","C-5","C-2","C-3","C-5","C-5","C-3","C-0","C-5","C-3","C-5","C-5","C-5","C-5","C-5","C-5","C-5","C-1","C-5","C-5","C-4","C-5","C-5","C-4","C-5","C-5","C-5","C-4","C-5","C-0","C-4","C-2","C-5","C-0","C-5","C-5","C-5","C-5","C-5","C-5","C-5","C-3","C-5","C-5","C-5","C-5","C-5","C-2","C-5","C-2","C-5","C-5","C-3","C-3","C-4","C-5","C-0","C-2","C-5","C-4","C-3","C-5","C-3","C-3","C-5","C-5","C-2","C-5","C-5","C-5","C-4","C-2","C-5","C-5","C-5","C-5","C-4","C-5","C-5","C-5","C-5","C-4","C-3","C-1","C-4","C-5","C-5","C-0","C-5","C-2","C-5","C-3","C-5","C-5","C-4","C-5","C-4","C-5","C-5","C-5","C-5","C-5","C-2","C-5","C-4","C-3","C-5","C-5","C-5","C-5","C-3","C-1","C-5","C-5","C-2","C-5","C-4","C-5","C-5","C-0","C-5","C-4","C-2","C-5","C-5","C-5","C-5","C-1","C-5","C-4","C-3","C-5","C-5","C-0","C-5","C-4","C-5","C-5","C-3","C-1","C-5","C-5","C-2","C-4","C-2","C-5","C-5","C-4","C-2","C-5","C-5","C-5","C-2","C-5","C-4","C-5","C-1","C-5","C-5","C-5","C-5","C-5","C-5","C-5","C-5","C-0"],"publication_date":["2023-10-18","2023-07-11","2023-11-22","2023-11-27","2023-11-27","2023-10-18","2023-10-21","2023-10-12","2023-09-07","2023-10-02","2023-11-03","2023-08-19","2023-09-25","2023-08-29","2023-09-18","2023-10-21","2023-11-22","2023-08-19","2023-12-13","2023-12-13","2023-10-21","2023-07-03","2023-10-24","2023-09-30","2023-09-11","2023-08-29","2023-10-27","2023-09-28","2023-08-19","2023-11-22","2023-11-27","2023-07-23","2023-10-21","2023-12-22","2023-08-19","2023-12-02","2023-12-01","2023-10-08","2023-08-04","2023-12-13","2023-10-21","2023-08-20","2023-12-12","2023-08-16","2023-08-19","2023-09-13","2023-09-07","2023-07-03","2023-10-08","2023-11-29","2023-11-20","2023-07-22","2023-11-14","2023-11-02","2023-10-27","2023-11-19","2023-11-01","2023-07-21","2023-11-02","2023-11-22","2023-10-02","2023-09-28","2023-09-13","2023-10-16","2023-11-15","2023-10-16","2023-10-09","2023-10-26","2023-11-28","2023-08-04","2023-08-04","2023-08-02","2023-10-08","2023-08-19","2023-10-06","2023-10-12","2023-08-04","2023-10-04","2023-10-08","2023-08-19","2023-12-04","2023-08-21","2023-07-23","2023-08-09","2023-08-19","2023-08-19","2023-11-27","2023-11-15","2023-08-20","2023-11-17","2023-07-26","2023-08-19","2023-12-01","2023-12-12","2023-12-19","2023-12-01","2023-08-09","2023-12-01","2023-10-11","2023-10-02","2023-08-29","2023-12-07","2023-08-04","2023-10-04","2023-11-21","2023-12-07","2023-08-19","2023-10-17","2023-10-21","2023-11-27","2023-08-05","2023-10-18","2023-08-02","2023-11-17","2023-09-28","2023-07-18","2023-08-19","2023-10-12","2023-10-21","2023-08-19","2023-12-04","2023-10-21","2023-08-19","2023-11-29","2023-12-11","2023-09-28","2023-08-04","2023-07-12","2023-09-06","2023-08-20","2023-11-28","2023-11-13","2023-11-01","2023-08-19","2023-08-25","2023-12-01","2023-11-16","2023-07-27","2023-11-15","2023-11-22","2023-10-09","2023-10-21","2023-12-12","2023-12-12","2023-10-27","2023-11-25","2023-10-31","2023-11-27","2023-11-20","2023-08-07","2023-10-21","2023-08-04","2023-10-11","2023-10-01","2023-07-24","2023-10-12","2023-07-31","2023-08-19","2023-12-15","2023-10-27","2023-12-13","2023-08-12","2023-10-29","2023-11-19","2023-09-27","2023-07-26","2023-08-09","2023-10-27","2023-12-01","2023-11-01","2023-12-06","2023-11-02","2023-11-14","2023-11-07","2023-08-19","2023-12-13","2023-08-04","2023-11-14","2023-12-01","2023-11-13","2023-12-01","2023-10-21","2023-11-19","2023-11-25","2023-08-09","2023-11-22","2023-09-07","2023-08-04","2023-08-19","2023-07-17","2023-11-11","2023-12-30","2023-09-26","2023-12-13","2023-08-29","2023-09-27","2023-08-29","2023-07-24","2023-11-29","2023-11-04","2023-07-11","2023-11-14","2023-08-27","2023-08-19","2023-08-19","2023-12-15","2023-07-07","2023-10-30","2023-10-16","2023-08-04","2023-11-20","2023-10-23","2023-11-27","2023-09-04","2023-09-13","2023-07-27","2023-12-15","2023-12-12","2023-11-29","2023-10-01","2023-08-19","2023-09-27","2023-11-14","2023-07-18","2023-12-01","2023-12-07","2023-09-28","2023-10-21","2023-10-13","2023-11-25","2023-10-17","2023-12-13","2023-07-06","2023-07-22","2023-11-29","2023-10-21","2023-08-20","2023-10-21","2023-10-03","2023-07-12","2023-08-19","2023-10-26","2023-09-25","2023-07-13","2023-11-27","2023-12-12","2023-07-18","2023-08-19","2023-09-28","2023-12-01","2023-11-20","2023-11-01","2023-07-29","2023-11-21","2023-07-12","2023-07-03","2023-08-25","2023-09-28","2023-08-19","2023-11-28","2023-08-19","2023-09-20","2023-08-04","2023-11-22","2023-10-21","2023-08-04","2023-12-06","2023-07-18","2023-12-01","2023-11-20","2023-09-26","2023-08-19","2023-11-15","2023-12-12","2023-08-08","2023-11-22","2023-12-04","2023-09-13","2023-09-13","2023-11-03","2023-10-09","2023-10-12","2023-11-15","2023-11-29","2023-12-14","2023-07-18","2023-08-19","2023-07-11","2023-10-08","2023-08-04","2023-08-04","2023-10-21","2023-10-01","2023-11-28","2023-07-29","2023-08-29","2023-07-03","2023-08-04","2023-09-09","2023-11-28","2023-08-19","2023-08-19","2023-09-01","2023-08-23","2023-12-07","2023-12-01","2023-08-21","2023-11-28","2023-08-10","2023-10-16","2023-11-27","2023-11-01","2023-10-27","2023-11-29","2023-10-27","2023-09-19","2023-11-22","2023-07-22","2023-08-19","2023-11-21"],"title":["Examining the Impact of FMRI Preprocessing Steps on Machine Learning-Based Classification of Autism Spectrum Disorder","An Effective DeepWINet CNN Model for Off-Line Text-Independent Writer Identification","FETCH: A Memory-Efficient Replay Approach for Continual Learning in Image Classification","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","Bipartite Graph Coarsening for Text Classification Using Graph Neural Networks","Machine Learning for Leaf Disease Classification: Data, Techniques and Applications","Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook","Revisiting Skin Tone Fairness in Dermatological Lesion Classification","Highly Imbalanced Baggage Threat Classification","A Joint Analysis of Input Resolution and Quantization Precision in Deep Learning","Fast Twin Support Vector Classification for Large Scale Problems","Stochastic Feature Averaging for Learning with Long-Tailed Noisy Labels","Meta-MMFNet: Meta-Learning-Based Multi-Model Fusion Network for Micro-Expression Recognition","Learning Optimal Fair Decision Trees: Trade-Offs Between Interpretability, Fairness, and Accuracy","Counterfactual Explanations for Remote Sensing Time Series Data: An Application to Land Cover Classification","Unlocking the Potential of Non-PSD Kernel Matrices: A Polar Decomposition-Based Transformation for Improved Prediction Models","Enhanced SVM-SMOTE with Cluster Consistency for Imbalanced Data Classification","Unreliable Partial Label Learning with Recursive Separation","Improving SMOTE with Fuzzy Rough Prototype Selection to Detect Noise in Imbalanced Classification Data","On the Estimation of Predictive Evaluation Measure Baselines for Multi-Label Learning","Retention is All You Need","Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory","Flocking to Mastodon: Tracking the Great Twitter Migration","A Multi-Class Partial Hinge Loss for Partial Label Learning","MMF-DRL: Multimodal Fusion-Deep Reinforcement Learning Approach with Domain-Specific Features for Classifying Time Series Data","Mitigating Voter Attribute Bias for Fair Opinion Aggregation","Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor","Credit Card Fraud Detection Using XGBoost for Imbalanced Data Set","Building Concise Logical Patterns by Constraining Tsetlin Machine Clause Size","Instance Selection Techniques for Large Volumes of Data","FLIPS: Federated Learning Using Intelligent Participant Selection","On the Performance of New Higher Order Transformation Functions for Highly Efficient Dense Layers","Time-Series Shapelets with Learnable Lengths","Graph-Based Text Classification by Contrastive Learning with Text-Level Graph Augmentation","Multi-View Robust Graph Representation Learning for Graph Classification","Harnessing the Potential of Deep Learning for Total Shoulder Implant Classification: A Comparative Study","BC-Net: Early Diagnostics of Breast Cancer Using Nested Ensemble Technique of Machine Learning","Multimodal Sensor Data Fusion and Ensemble Modeling for Human Locomotion Activity Recognition","Binary Classifier Evaluation on Unlabeled Segments Using Inverse Distance Weighting with Distance Learning","Enhancing the Performance of SVM on Skewed Data Sets by Exciting Support Vectors","Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility","Identification of High-Risk Areas for Geological Disasters Using Classification Methods under Complex Environmental Conditions","Multi-Modal Multi-Class Parkinson Disease Classification Using CNN and Decision Level Fusion","Comparative Study and Analysis on Skin Cancer Detection Using Machine Learning and Deep Learning Algorithms","Leveraging Argumentation for Generating Robust Sample-Based Explanations","GBSMOTE: A Robust Sampling Method Based on Granular-Ball Computing and SMOTE for Class Imbalance","Surrogate Deep Learning to Estimate Uncertainties for Driver Intention Recognition","Multimodal Emotion Classification Supported in the Aggregation of Pre-Trained Classification Models","Private, Fair and Secure Collaborative Learning Framework for Human Activity Recognition","Investigating the Effect of Data Impurity on the Detection Performances of Mental Disorders Through Spoken Dialogues","TwiSP: A Framework for Exploring Polarized Issues in Twitter","A Novel Deep Learning Automatic Modulation Classifier with Fusion of Multichannel Information Using GRU","Semi-Supervised Classification and Segmentation of Forest Fire Using Autoencoders","Machine Learning Algorithm-Based Prediction of Machined Surface Quality in End Milling Operation","FedGH: Heterogeneous Federated Learning with Generalized Global Header","Evidential Generative Adversarial Networks for Handling Imbalanced Learning","Checkpoint Classifier for CNN Image Classification","T-ADAF: Adaptive Data Augmentation Framework for Image Classification Network Based on Tensor T-Product Operator","Heterogeneous-Training: A Semi-Supervised Text Classification Method","Threshold-Based Classification to Enhance Confidence in Open Set of Legal Texts","Improved Decision Module Selection for Hierarchical Inference in Resource-Constrained Edge Devices","An Improved Oversampling Algorithms Based on Informative Sample Selection Strategy Solving Imbalance","An Adaptive Granular Ball Classifier Based on Natural Neighbor","Multi-Label Feature Selection via Maximum Dynamic Correlation Change and Minimum Label Redundancy","Image and Text Aspect Level Multimodal Sentiment Classification Model Using Transformer and Multilayer Attention Interaction","Classification Model for NAVTEX Navigational Warning Messages Based on Adaptive Weighted TF-IDF","Performance Exploration of RNN Variants for Recognizing Daily Life Stress Levels by Using Multimodal Physiological Signals","Multi-Class Wall Recognition in Complex Architectural Floor Plan Images Using a Convolutional Network","COVID-19 Fake News Detection Using Cross-Domain Classification Techniques","Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment","DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling","DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG 2000 Compressed Documents","GSR Based Generic Stress Prediction System","A Noisy-Label-Learning Formulation for Immune Repertoire Classification and Disease-Associated Immune Receptor Sequence Identification","A Review of the F-Measure: Its History, Properties, Criticism, and Alternatives","Automated Hand Joint Classification of Psoriatic Arthritis Patients Using Routinely Acquired Near Infrared Fluorescence Optical Imaging","ST-IFGSM: Enhancing Robustness of Human Mobility Signature Identification Model via Spatial-Temporal Iterative FGSM","An Ensemble Machine Learning Approach for Benchmarking and Selection of ScRNA-Seq Integration Methods","Summary of SHL Challenge 2023: Recognizing Locomotion and Transportation Mode from GPS and Motion Sensors","Interpretability and Fairness in Machine Learning: A Formal Methods Approach","Multitask, Cross-Lingual Recipe Classification Using Joint Fine-Tuning Mechanisms","Condition Monitoring of an Autonomous Electric Drive Train by Using Machine Learning Methods","Fine-Tuning Language Models to Recognize Semantic Relations","A Multi-Temporal Analysis of Archaeological Site Destruction Using Landsat Satellite Data and Machine Learning, Moche Valley, Peru","Automatic Recognition of the General-Purpose Communicative Functions Defined by the ISO 24617-2 Standard for Dialog Act Annotation (Extended Abstract)","SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference","Weeds Classification with Deep Learning: An Investigation Using CNN, Vision Transformers, Pyramid Vision Transformers, and Ensemble Strategy","Heterogeneous Analysis for Clustered Data Using Grouped Finite Mixture Models","Fusion Local and Global Aspect-Based Sentiment Analysis","Text Sentiment Classification Model Based on Fusion of DualChannel Features of CNN and BiLSTM","Automatic Classification of TEDS Monitoring Operation Technology Research","Label Specific Multi-Semantics Metric Learning for Multi-Label Classification: Global Consideration Helps","Communication-Efficient Federated Skin Lesion Classification with Generalizable Dataset Distillation","Multi-Criteria Decision-Making Based Classifier Ensemble by Using Prioritized Aggregation Operator","Fruit Calories Estimation Using Convolutional Neural Network","Cellular Features Based Interpretable Network for Classifying Cell-Of-Origin from Whole Slide Images for Diffuse Large B-Cell Lymphoma Patients","Low Resource Language Analysis Using Deep Learning Algorithm for Gender Classification","Explainable Product Classification for Customs","Compressed, Real-Time Voice Activity Detection with Open Source Implementation for Small Devices","Machine Learning for the Classification of Obesity Levels Based on Lifestyle Factors","Fairness Implications of Encoding Protected Categorical Attributes","A Deep Learning Emotion Classification Framework for Low Resource Languages","Efficient and Effective Edge-Wise Graph Representation Learning","CBOEP: Generating Negative Enhancer-Promoter Interactions to Train Classifiers","Verifiable Learning for Robust Tree Ensembles","Deep Learning Hierarchical Methods for Insect Pest Recognition on Plants","Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation","Bibliographic Reference Classification in Historiographic Documents Using Supervised Machine Learning and Grammatical Features","Data-Driven Operator Functional State Classification in Smart Manufacturing","Presumably Correct Undersampling","A Multi-Metric Small Sphere Large Margin Method for Classification","Predicting Autism from Head Movement Patterns during Naturalistic Social Interactions","A Robust Joint-Training Graph Neural Networks Model for Event Detection with Noisy Labels","An Ensemble Pneumonia Prediction and Classification Model Including InceptionNeXtPneumonia Prediction and Classification","Review of Machine Learning Techniques for Crop Recommendation","Learning Through Interpolative Augmentation of Dynamic Curvature Spaces","Unbiased Risk Estimator to Multi-Labeled Complementary Label Learning","An Investigation into Race Bias in Random Forest Models Based on Breast DCE-MRI Derived Radiomics Features","Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond","Optimal Decision Trees for Interpretable Clustering with Constraints","A Machine Learning Approach to Enterprise Matchmaking Using Multilabel Text Classification Based on Semi-Structured Website Content","Accelerating Concept Learning via Sampling","Context-Aware Feature Selection and Classification","Preliminary Analysis of Lambani Vowels and Vowel Classification Using Acoustic Features","An IoT and Deep Learning-Based Smart Healthcare Framework for Thyroid Cancer Detection","Insider Threat Detection: Using Classification Models","Navigating Alignment for Non-Identical Client Class Sets: A Label Name-Anchored Federated Learning Framework","Optimizing Fairness Tradeoffs in Machine Learning with Multiobjective Meta-Models","Same or Different? Diff-Vectors for Authorship Analysis","Adaptive Weighted Ensemble Classifier for Improving Breast Tumors Classification Based on Ultrasound RF Data","Improving CCA Algorithms on SSVEP Classification with Reinforcement Learning Based Temporal Filtering","Understanding Any Time Series Classifier with a Subsequence-Based Explainer","Comparing Different Oversampling Methods in Predicting Multi-Class Educational Datasets Using Machine Learning Techniques","Learning Few-Shot Sample-Set Operations for Noisy Multi-Label Aspect Category Detection","DocLangID: Improving Few-Shot Training to Identify the Language of Historical Documents","Probabilistic Local Equivalence Certification for Robustness Evaluation","A Voting Ensemble-Based Model to Predict the Risk of Cardiovascular Disease in Ordinary People","Human Activity Classification Based on Data Analysis and Feature Extraction","Classification Prediction of Lung Cancer Based on Machine Learning Method","Preliminary Study on Unexploded Ordnance Classification in Underwater Environment Based on the Raw Magnetometry Data","Interpreting Sign Language Recognition Using Transformers and MediaPipe Landmarks","WOT-Class: Weakly Supervised Open-World Text Classification","A Novel Network Architecture for Microplankton Classification in Digital Holographic Images","Handling Small Disjuncts and Class Skew Using Sequential Ellipsoidal Partitioning","Automatic Audio Augmentation for Requests Sub-Challenge","FinBERT-FOMC: Fine-Tuned FinBERT Model with Sentiment Focus Method for Enhancing Sentiment Analysis of FOMC Minutes","Multimodal Fuzzy Granular Representation and Classification","Detection of Covid-19 in Chest X-Ray Images Using Percolation Features and Hermite Polynomial Classification","Empirical Analysis of Multi-Label Classification on GitterCom Using BERT and ML Classifiers","A Study on An Automatic Self-Training Model for Mango Segmentation of Sorting System","Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning","A Collaborative Transfer Learning Framework for Cross-Domain Recommendation","Classification of Freezing of Gait Using Accelerometer Data: A Systematic Performance Evaluation Approach","Plant Disease Detection and Classification Using Deep Learning Models","Enhancing Siamese Neural Networks for Multi-Class Classification: An Immuno-Inspired Approach","A Study of Age and Sex Bias in Multiple Instance Learning Based Classification of Acute Myeloid Leukemia Subtypes","Training a Multi-Task Model for Classification and Grasp Detection of Surgical Tools Using Transfer Learning","Generalization Guarantees of Self-Training of Halfspaces under Label Noise Corruption","A Hybrid Self-Supervised Learning Framework For Hyperspectral Image Classification","Multi-Label Emotion Analysis in Conversation via Multimodal Knowledge Distillation","Detecting Survival Patterns in Women with Invasive Cervical Cancer with Decision Trees","Domain Adaptation for Learning from Label Proportions Using Domain-Adversarial Neural Network","Unsupervised Segmentation of Haze Regions as Hard Attention for Haze Classification","Cautious Decision-Making for Tree Ensembles","Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning","GF-CNN: An Enhanced Deep Learning Model with Gabor Filters for Maize Disease Classification","Classification of Theoretical Extracellular Action Potentials Based on Unsupervised Machine-Learning","Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning","\nKNNHI: Resilient KNN Algorithm for Heterogeneous Incomplete Data Classification and K Identification Using Rough Set Theory","Generalization Bounds in the Predict-Then-Optimize Framework","Predicting Blood Drop Height and Volume Using Physics Equations, VGG-19, and XGBoost","Research on Bayesian Network Garbage Classification Based on Multi-Source Information Fusion","Improving PPP-RTK-Based Vehicle Navigation in Urban Environments via Multilayer Perceptron-Based NLOS Signal Detection","Patch-Based Deep Learning Models for Breast Mammographic Mass Classification","Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification","Nearest Prototype Classification of Special School Families Based on Hierarchical Compact Sets Clustering","Deep Encoders with Auxiliary Parameters for Extreme Classification","Texture-Based Data Augmentation for Small Datasets","Classification of Services through Feature Selection and Machine Learning in 5G Networks","GeoFormer: Predicting Human Mobility Using Generative Pre-Trained Transformer (GPT)","Investigating the Impact of Attention on Mammogram Classification","Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification","Multi-Label Classification of Mobile Application User Reviews Using Neural Language Models","Bayesian Networks Improve Out-of-Distribution Calibration for Agribusiness Delinquency Risk Assessment","A Theoretical Analysis of Out-of-Distribution Detection in Multi-Label Classification","Language Models for Automatic Distribution of Review Notes in Movie Production","Uncovering Trauma in Genocide Tribunals: An NLP Approach Using the Genocide Transcript Corpus","Removing Camouflage and Revealing Collusion: Leveraging Gang-Crime Pattern in Fraudster Detection","Contrastive Label Enhancement","Learning from Uncurated Regular Expressions for Semantic Type Classification","LIDACS: A Lightweight Domain Adaptive Cell Segmentation Framework","Deep Learning Multimodal Methods for Geophysical Inversion\u202f: Application to Glacier Ice Thickness Estimation","Adaptive Embedding and Distribution Re-Margin for Long-Tail Recognition","Prototype Selection with Compact Sets and Extended Rough Sets","Text Classification Based on Natural Language Processing and Machine Learning in Multi Label Corpus","A Geometric Framework for Multiclass Ensemble Classifiers","Exploring Federated Learning for Speech-Based Parkinson\u2019s Disease Detection","Extending Tree-Based Automated Machine Learning to Biomedical Image and Text Data Using Custom Feature Extractors","Dialect Identification in Ao Using Modulation-Based Representation","A Transfer Learning Approach to Interdisciplinary Document Classification with Keyword-Based Explanation","Sentiment Distribution of Topic Discussion in Online English Learning: An Approach Based on Clustering Algorithm and Improved CNN","Pyramid Swin Transformer for Multi-Task: Expanding to More Computer Vision Tasks","Evaluating Autoencoders for Dimensionality Reduction of MRI-Derived Radiomics and Classification of Malignant Brain Tumors","Regularisation for Efficient Softmax Parameter Generation in Low-Resource Text Classifiers","Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats","Improving Table Tennis Training and Technique Analysis: Accurate Classification of Actions with Informer Encoder","Arrhythmia Detection Using ECG-Based Classification with Prioritized Feature Subset Vector-Associated Generative Adversarial Network","Evolutionary Ensembles Based on Prioritized Aggregation Operator","Intuitive Human-Swarm Interaction with Gesture Recognition and Machine Learning","Extreme Multi-Label Classification for Ad Targeting Using Factorization Machines","Cross-Domain Bearing Fault Diagnosis Method Using Hierarchical Pseudo Labels","WCDForest: A Weighted Cascade Deep Forest Model toward the Classification Tasks","Stingless Bee Classification: A New Dataset and Baseline Results","Leveraging Socio-Contextual Information in BERT for Fake Health News Detection in Social Media","Composable Workflow for Accelerating Neural Architecture Search Using In Situ Analytics for Protein Classification","Feature Selection Using Gravitational Search Algorithm in Customer Churn Prediction","SVM in Classification of Stage 0~II and III~IV with Breast Cancer\u202f: A Retrospective Cohort Study on a Bicentric Cohort","Heterogeneous Stacked Ensemble Framework for Surface Electromyography Signal Classification","CrashFormer: A Multimodal Architecture to Predict the Risk of Crash","Term Frequency Features vs Transformers: A Comparision for Sentiment Classification of African Languages","RaMLP: Vision MLP via Region-Aware Mixing","Federated Few-Shot Learning for Cough Classification with Edge Devices","Age-Invariant Face Recognition Using Face Feature Vectors and Embedded Prototype Subspace Classifiers","Uncertainty Quantification for Text Classification","Air Pollutants Classification Using Optimized Neural Network Based on War Strategy Optimization Algorithm","Multi-Branch Network for Imagery Emotion Prediction","SVM Kernel and It\u2019s Aggregation Using Stacking on Imbalanced Dataset","A Momentum Loss Reweighting Method for Improving Recall","Fact-Checking Vietnamese Information Using Knowledge Graph, Datalog, and KG-BERT","Scattering-Based Hybrid Network for Facial Attribute Classification","Feature Estimation for Punching Tool Wear at the Edge","Hierarchical Classification of Gene Ontology with Learning Classifier Systems","Voting Classifier-Based Crop Recommendation","Extreme Learning Machine Combining Hidden-Layer Feature Weighting and Batch Training for Classification","On the Most Frequent Sequences of Words in Russian Spoken Everyday Language (Bigrams and Trigrams): An Experience of Classification","LAMM: Language Aware Active Learning for Multilingual Models","Multi-Classification Data Stream Algorithm Based on One-Vs-Rest Strategy","Privacy-Preserving Federated Learning via Disentanglement","Research on Multi-Domain Sample Classification Method Based on Baidu API","OmnImage: Evolving 1k Image Cliques for Few-Shot Learning","ProMix: Combating Label Noise via Maximizing Clean Sample Utility","Classification Algorithm for Liquid Dangerous Goods Based on WT-AE and Attention-GRU Network","Feature Selection in an Interactive Search-Based PLA Design Approach","Combining Autoencoder and Yolov6 Model for Classification and Disease Detection in Chickens","Leveraging Model Fusion for Improved License Plate Recognition","Ensemble Methods With [18F]FDG-PET/CT Radiomics In Breast Cancer Response Prediction","ML-LJP: Multi-Law Aware Legal Judgment Prediction","Machine Learning Driven Aid Classification for Sustainable Development","Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model","A GCN- and Deep Biaffine Attention-Based Classification Model for Course Review Sentiment","Active Learning for Open-Set Annotation Using Contrastive Query Strategy","Convex Least Angle Regression Based LASSO Feature Selection and Swish Activation Function Model for Startup Survival Rate","Feature Engineering and Ensemble Learning-Based Classification of VPN and Non-VPN-Based Network Traffic over Temporal Features","Poster: Backdoor Attack on Extreme Learning Machines","Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems","Exploring the Capabilities of Quantum Support Vector Machines for Image Classification on the MNIST Benchmark","An Evaluation of Handwritten Text Recognition Methods for Historical Ciphered Manuscripts","Prediction of Algae Growth: A Machine Learning Perspective","G2Pxy: Generative Open-Set Node Classification on Graphs with Proxy Unknowns","Part-Aware Prototype-Aligned Interpretable Image Classification with Basic Feature Domain","Progressive Label Propagation for Semi-Supervised Multi-Dimensional Classification","Federated Learning with ResNet-18 for Medical Image Diagnosis","FLAMES2Graph: An Interpretable Federated Multivariate Time Series Classification Framework","Complexity-Driven Sampling for Bagging","RT2S: A Framework for Learning with Noisy Labels","To Aggregate or Not? Learning with Separate Noisy Labels","Framework for Choosing a Supervised Machine Learning Method for Classification Based on Object Categories\u202f: Classifying Subjectivity of Online Comments by Product Categories","KATIE: A System for Key Attributes Identification in Product Knowledge Graph Construction","GPC: Generative and General Pathology Image Classifier","CKR-Calibrator: Convolution Kernel Robustness Evaluation and Calibration","GII: A Unified Approach to Representation Learning in Open Set Recognition with Novel Category Discovery","Learning Prototype Classifiers for Long-Tailed Recognition","Explainable Occupancy Prediction Using QLattice","Transfer Learning: Kernel-Based Domain Adaptation with Distance-Based Penalization","Model Averaging for Support Vector Classifier by Cross-Validation","A Subgraph Embedded GIN with Attention for Graph Classification","Fu-W:A Hyperspectral Image Classification Algorithm Combining Mini Graph Convolutional Networks and Convolutional Neural Network","NaN","Forecasting Dining Times in a Full-Service Thai Hotpot Restaurant Using Random Forest Classifier","Fast Support Vector Classifier with Quantile","Early Classifying Multimodal Sequences","Studying the Effects of Sex-Related Differences on Brain Age Prediction Using Brain MR Imaging","TODOS: Thermal SensOr Data-Driven Occupancy Estimation System for Smart Buildings","Multi-Task Learning over Mixup Variants for the Speaker Verification Task","ML-Based Identification of Neuromuscular Disorder Using EMG Signals for Emotional Health Application","Disentangling User Conversations with Voice Assistants for Online Shopping","Explainable Text Classification via Attentive and Targeted Mixing Data Augmentation","Learning Label-Specific Features for Decomposition-Based Multi-Class Classification","Investigating the Effect of Orientation Variability in Deep Learning-Based Human Activity Recognition","Task-Equivariant Graph Few-Shot Learning","Deep Pipeline Embeddings for AutoML","Tackling Diverse Minorities in Imbalanced Classification","Baselining Performance for Multilingual Codeswitching Sentiment Classification","Systematic Analysis of the Impact of Label Noise Correction on ML Fairness","Ultrasound-Based Ovarian Cysts Detection with Improved Machine-Learning Techniques and Stage Classification Using Enhanced Classifiers","MacBERT Classification Model of Memory Attention Mechanism and Its Application to the Power System of EAST Neutral Beam Injection Facility","Prediction of Casting Mechanical Parameters Based on Direct Microstructure Image Analysis Using Deep Neural Network and Graphite Forms Classification","Partial-Label Learning with Mixed Closed-Set and Open-Set Out-of-Candidate Examples","DASS: Differentiable Architecture Search for Sparse Neural Networks","An Optimised Grid Search Based Framework for Robust Large-Scale Natural Soundscape Classification","Unbiased Gradient Boosting Decision Tree with Unbiased Feature Importance","Boosting Few-Shot Open-Set Recognition with Multi-Relation Margin Loss","GGFAST: Automating Generation of Flexible Network Traffic Classifiers","Automatic Idiom Identification Model for Amharic Language","SER-Fuse: An Emotion Recognition Application Utilizing Multi-Modal, Multi-Lingual, and Multi-Feature Fusion","Color Models Aware Dynamic Feature Extraction for Forest Fire Detection Using Machine Learning Classifiers","DisguisedNets: Secure Image Outsourcing for Confidential Model Training in Clouds","Automatic Classification of Sensors in Buildings: Learning from Time Series Data","Multi-View Graph Convolutional Networks with Differentiable Node Selection","Does Removal of Noisy Granulated Datasets Matter to Performance of Decision Tree Generation?","DIF-SR: A Differential Item Functioning-Based Sample Reweighting Method","Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey","DPNET: Dynamic Poly-Attention Network for Trustworthy Multi-Modal Classification","Constant-Q Based Harmonic And Pitch Features For Normal vs. Pathological Infant Cry Classification","CALM: An Enhanced Encoding and Confidence Evaluating Framework for Trustworthy Multi-View Learning","WEASEL 2.0: A Random Dilated Dictionary Transform for Fast, Accurate and Memory Constrained Time Series Classification","Combining Regular Expressions and Supervised Algorithms for Clinical Text Classification","Digital Twin-Based Anomaly Detection with Curriculum Learning in Cyber-Physical Systems","Leveraging Domain Knowledge for Inclusive and Bias-Aware Humanitarian Response Entry Classification","A Comparative Analysis on Recent Methods for Addressing Imbalance Classification"],"x":{"__ndarray__":"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","dtype":"float64","shape":[320]},"x_backup":{"__ndarray__":"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","dtype":"float64","shape":[320]},"y":{"__ndarray__":"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","dtype":"float64","shape":[320]},"y_backup":{"__ndarray__":"28GIfQJcOEC2SUVj7Tc4wNqQf2YQ8zdAK4cW2c5bPcCOzvkpjtsgwIEhq1s91yBAtT3VfPCFCkDhrG/9R2jeP+Fgb2JI/iLApGyRtBtdAsBoPBHEefhFwJChYweVuCXA46qy74pg8T9f0hito2I1wD9vKlJhhDxA8RExJZK0QUANx/MZUAszQBb59UNsKDzACoLHt3dtMcA1JsRcUsE2wHfYRGYu0BpAYabtX1lDQUAPYJFfPygzQEPIef8fAzzAQQ5KmGk/O0A/VYUGYtk4wM3NN6J7ViXAgkx8/zAzB0CNCMbBpVscwIwPs5dtUzPAtwiM9Q18HcCe6pCb4ZYHQHcSEf5FjD5AERssnKRxIsDUDKmieK0pwNcyGY7n8y1AoUs49BavEMCB7WDEPoE+QBlUG5yIJkXAocofwq68AEDr4jYawE84QIgfUsICjgtA071O6ssCJsD+MaXcGuTVP6YmwRvSCD5A5UUm4NcoM0DaN/dXj3M2wFqsl5XcN/u/FLNeDOW0EMBtjQjGweE7QHe688RzcjJAkbjH0odSQUDSbYlccD5GQNKsbB/yPi9AhHNXwE67GcAQ6EzaVDkyQF6DvvT2/yHAJqq3Bra6MMBG7X4V4KMkwM+Du7N2SzDA//ML4V661j+zJasi3Ew0QLA3MSQnGzNAkxraAGwUP8CsN2qF6TscwMlVLH5TECBAV3iXi/jmOUAkQiPYuPYlwEnyXN+Hfy5APGu3XWg2L0CpFhHF5PU2wDS/mgME4zZA5SoWvymcOkAjvhOzXow0wIXrUbge0TfADKzj+KFKLcDFH0WduU8lQCe/RSdL7Q3Ah1EQPL7VPkBioGtfQLs0wPXYlgFnIRdAtRoS91jKO0Cu7ZLdcY/yvzDgwD8ARA5AutdJfVlSRMDCRM2hVoLjPyXaRByhdfq/TYdOz7vJIUDSNCiaB7AYwIo5CDpalQTA5POKpx7NN0DYRdEDHxM0wP0EBv8R/BnAW7VrQloDL8C+2ebG9FQWQKuzWmCPrSHAIxXGFoJEPEDVsrW+SA5CQHqM8szLwRVAaDwRxHkAKkB72XbaGqE5wKNL7mb8cfo/2e4eoPt2IMC+hXXj3WEYQGBzDp4J9TpAeR7cnbUjOMDCFrt9VhkTwCDtf4C1+jhAJLa7B+h6MsCX5IBdTXI4QIYgByXMvDTAy/J1Gf4jPcAFpWjlXuguwH8yxofZrzFAL4UHza77KUAI6L6c2cY9wB1aZDvfczLAnuxmRj+yJcCjBP2FHpUywLHc0mpIZDHA72/QXn1sKUD+asSCsYQZwAfOGVHaizPA2djbHJ0p8j+yTL9EvIUbwC6RC87gxy5AA3gLJCgWIsAhzO1e7g84wP1mYroQUzZAY+yEl+DUE8CrWz0nvY85QGYTYFj+KDxAQZqxaDoDNkCd3bXfNesVwIBjz57LiDVAEeLK2TtzNsB40Oy6t/IwQDyGx34WS/s/8g+2M6em8b+zX3e685Q7QDF9ryE43ifAuVLPglCmJcD0pbc/F9UnQINTegFRi+i/FTduMT83DsDu6H+5Fq35v9VamIV2Rj9ApHGo34XJLkCjuJnAY54YwBqojH+fYS9ALJs5JLUwBUC7RPXWwG4nQDG2EOSg1CJAz/i+uFQ1IkD0GOWZlysywKimJOtwLCrAuoEC7+RTFkCfrYODvQUzQHQNMzSe4CvA91Vel4bG/b9R9SudDycTwHUhVn+ESSVAdsr+1NPC87/OoEbGD/oGwKlr7X2qyj/AkuwRaobMI0CjXBq/8FYzQNIcWfll8CHACI7LuKkBNsDeQUcGFEX9P7zoK0gzUjLAs33IW65ePMD4TzdQ4GUsQG7Ek93MqPm/KjqSy39AMEAhyaze4RYxwCU7NgLxyi3AhgDg2LObMcBEUgslkwslQHU8ZqAyrihAP3EA/b7fGsAitT8G4bAIwE35EFSNjhJAQdXo1QCVEkB5I/PIH0w4wDcWFAZlginAs32GP9x45r+Xdf9YiA4jwEZcABqlSx1Ada4oJQSDL0AiiPNwAkMmQBkAqrhxMylA424QrRWVIsCDTDJyFuYwwP+LsV3rnA3AEirdAq4wGsBUG5yIfq0LwB6M2CeAsjDAz4WRXtSqPkBHOgMjLx81QAlQdNm/HbC/aOkKthHXKECVuI5xxS0kwODLjp5sZBdARDLk2HoGIUAoY3yYvRwgwAjovpzZajFAkdCWcynuL8CgFFIjmZoPQPT5KCMuYEXA4LvNGydlLUCg/N07agxHQA8PYfw0xERA+bziqUcCL0DrOel94+1BQC6thsQ9IjJA46qy74ogCMDtDFNb6qQ/wKyPh767UT/A1ScUfZkjF0CzQpHu5+QoQHni3qHNNg3ADtdqD3spKMDDD86njg03wImZfR6jFkVA44i1+BRABkA+lj50QY1BQMHkRpG11h1ARWRYxRvpJEBW1jbF4zIsQOijjLgApD1AAU7v4v2gI0CH26FhMbIqQLuMrEbAogFAUH5BwXvtCcA1BdeBGIUaQPHQHP4/sw1ADVTGv8+wEsAo84++SWsmQIFB0qdVkDLAvLA1W3l1MMDi6ZWyDJVBQDb/VIH/8u6/OKJ71jUCIUA9kXHW8anyP8GknT8SkxDAV+nuOhtSG8A3p5IBoCoRQLnHLUGh4RzAH/MBgc6EDsB1myYisj4AwKRVLekoVxtACOV9HM1DRcDkdEggFEoVwB3J5T+kR0BAOWItPgUsMEACnN7F+307QPj6WpcaGSLAss+tIYL7CsAv3/qw3mAowCRfCaTExjPAFtOWhFVGCsCB6O7fYTcQwLiU88XelzjAGavN/6t6LMBj00ohkP84wDq81pQa8Pa/nrZGBOPUMUB5Wn7gKisgwNJzC12J7kFAuhaI+U0sA8DvqZz2lNwpwDF8REyJ4EVAGcdI9gi1KEAs+MhBZAQTQLa/sz16Ax/Au9bep6qAKsDTE5Z4QGkWwBuBeF2/+CVApics8YAaRsBD5zV2iUI9QIRlbOhmVyrAUvLqHAMSRkD3WtB7YzQ+wMZQTrSrZEDAK9zykZR8KkB8KTxodo0kwMb3xaUqDRZAPQ6D+StwNMCsNK09gQrpP9yAzw8jHDDAfT81XroZN0CJHGz7aMIEwBUb8zriZDfA0O0ljdFyPsAtzhjmBG0VwExPWOIBbRdADwu1pnmDPcAdkIR9O19CQCvY64JmjB5AqvHSTWLYLMBKIMq8+mUfwD90QX3LcEXAjlcgelIGMEAR4V8EjcU/wA5ORL+2KEZAYr68APucJMBTl4xjJJFGQDygbMoVZizALbRzmgWyP0Bck25L5BIhQLd6Tnrf0C7A6ZrJN9uYPcDKarqe6PoKwA71u7A1Cy3AVACMZ9AIOkBbQj7o2ewfwCOFsvD1pSlAqOSc2ENLLMB5kQn4NUo4QA==","dtype":"float64","shape":[320]}},"selected":{"id":"1073","type":"Selection"},"selection_policy":{"id":"1072","type":"UnionRenderers"}},"id":"1011","type":"ColumnDataSource"},{"attributes":{"text":"&lt;a href=\"clusters_last_half_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Half Year&lt;/button&gt;&lt;/a&gt;"},"id":"1004","type":"Div"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"end":6,"margin":[15,15,15,15],"sizing_mode":"stretch_width","start":0,"title":"Cluster #","value":6},"id":"1074","type":"Slider"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by Text:&lt;/h3&gt;&lt;p1&gt;Search keyword to filter out the plot. It will search abstracts, titles and authors. \n    Press enter when ready. Clear and press enter to reset the plot.&lt;/p1&gt;"},"id":"1007","type":"Div"},{"attributes":{"high":5,"low":0,"palette":["#1f77b4","#aec7e8","#ff7f0e","#ffbb78","#2ca02c","#98df8a"]},"id":"1013","type":"LinearColorMapper"},{"attributes":{"callback":{"id":"1065","type":"CustomJS"}},"id":"1040","type":"TapTool"},{"attributes":{},"id":"1031","type":"BasicTicker"},{"attributes":{},"id":"1026","type":"BasicTicker"},{"attributes":{},"id":"1073","type":"Selection"},{"attributes":{"args":{"out_text":{"id":"1062","type":"Paragraph"},"p":{"id":"1014","subtype":"Figure","type":"Plot"},"slider":{"id":"1074","type":"Slider"},"source":{"id":"1011","type":"ColumnDataSource"},"text":{"id":"1075","type":"TextInput"},"topics":["domain, information, imbalance, proposed, different, problem, world, challenges, use, algorithms","fairness, information, multiple, framework, bias, attributes, approaches, high, work, different, research","tasks, image, time, deep, multi, text, architecture, information, different, improve, new, cnn, analysis, layers, architectures","ensemble, proposed, time, multi, process, study, early, research, layer, architecture, making, compared, examples, different","graph, known, multi, text, nodes, domain, graphs, unknown, open, distribution, novel, neural, research, use, different","information, research, time, different, detection, multi, framework, text, proposed, confidence, local, deep, fusion, modalities, social, communication, compared"]},"code":"\n\t\t\t\tvar key = text.value;\n\t\t\t\tkey = key.toLowerCase();\n\t\t\t\tvar cluster = slider.value;\n                var clusters_count = slider.end;\n                var data = source.data; \n                \n                \n                x = data['x'];\n                y = data['y'];\n                x_backup = data['x_backup'];\n                y_backup = data['y_backup'];\n                labels = data['cluster'];\n                abstract = data['abstract'];\n                title = data['title'];\n                author = data['author'];\n                if (cluster == clusters_count) {\n                    out_text.text = 'Keywords: Slide to specific cluster to see the keywords.';\n                    for (i = 0; i &lt; x.length; i++) {\n\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key) || \n                        (title[i] &amp;&amp; title[i].toLowerCase().includes(key)) ||\n                        (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t}\n                    }\n                }\n                else {\n                    out_text.text = 'Keywords: ' + topics[Number(cluster)];\n                    for (i = 0; i &lt; x.length; i++) {\n                        if(labels[i] == cluster) {\n\t\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key)\n                            || (title[i] &amp;&amp; title[i].toLowerCase().includes(key))\n                            || (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t\t}\n                        } else {\n                            x[i] = undefined;\n                            y[i] = undefined;\n                        }\n                    }\n                }\n            source.change.emit();\n            "},"id":"1063","type":"CustomJS"},{"attributes":{"data_source":{"id":"1011","type":"ColumnDataSource"},"glyph":{"id":"1050","type":"Scatter"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1051","type":"Scatter"},"selection_glyph":null,"view":{"id":"1053","type":"CDSView"}},"id":"1052","type":"GlyphRenderer"},{"attributes":{"overlay":{"id":"1059","type":"BoxAnnotation"}},"id":"1037","type":"BoxZoomTool"},{"attributes":{"callback":null},"id":"1019","type":"DataRange1d"},{"attributes":{"callback":null,"point_policy":"follow_mouse","tooltips":[["Title","@title"],["Author","@author"],["Abstract","@abstract{safe}"],["Publication Date","@publication_date"],["Cluster","@cluster"]]},"id":"1012","type":"HoverTool"},{"attributes":{"below":[{"id":"1025","type":"LinearAxis"}],"center":[{"id":"1029","type":"Grid"},{"id":"1034","type":"Grid"},{"id":"1060","type":"Legend"}],"left":[{"id":"1030","type":"LinearAxis"}],"margin":[5,5,5,5],"plot_height":500,"plot_width":500,"renderers":[{"id":"1052","type":"GlyphRenderer"}],"sizing_mode":"scale_both","title":{"id":"1015","type":"Title"},"toolbar":{"id":"1041","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1017","type":"DataRange1d"},"x_scale":{"id":"1021","type":"LinearScale"},"y_range":{"id":"1019","type":"DataRange1d"},"y_scale":{"id":"1023","type":"LinearScale"}},"id":"1014","subtype":"Figure","type":"Plot"},{"attributes":{"callback":null},"id":"1017","type":"DataRange1d"},{"attributes":{"children":[{"id":"1014","subtype":"Figure","type":"Plot"}]},"id":"1085","type":"Row"},{"attributes":{"background_fill_alpha":{"value":0.6},"items":[{"id":"1061","type":"LegendItem"}]},"id":"1060","type":"Legend"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1051","type":"Scatter"},{"attributes":{"children":[{"id":"1006","type":"Div"}]},"id":"1079","type":"Row"},{"attributes":{"children":[{"id":"1062","type":"Paragraph"}]},"id":"1084","type":"Row"},{"attributes":{"fill_color":{"field":"cluster","transform":{"id":"1013","type":"LinearColorMapper"}},"line_alpha":{"value":0.3},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1050","type":"Scatter"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"margin":[15,15,15,15],"sizing_mode":"scale_both","title":"Search:"},"id":"1075","type":"TextInput"},{"attributes":{"dimension":1,"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1034","type":"Grid"},{"attributes":{},"id":"1035","type":"PanTool"},{"attributes":{"text":"&lt;a href=\"clusters_last_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Year&lt;/button&gt;&lt;/a&gt;"},"id":"1005","type":"Div"},{"attributes":{},"id":"1056","type":"BasicTickFormatter"},{"attributes":{"children":[{"id":"1076","type":"Div"}]},"id":"1078","type":"Row"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by the Clusters:&lt;/h3&gt;&lt;p1&gt;The slider below can be used to filter the target cluster. \nSimply slide the slider to the desired cluster number to display the plots that belong to that cluster. \nSlide back to the last cluster to show all the plots.&lt;/p1&gt;"},"id":"1008","type":"Div"},{"attributes":{},"id":"1023","type":"LinearScale"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1059","type":"BoxAnnotation"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.4.0"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('1176').textContent;
                  var render_items = [{"docid":"122c2565-e98e-4698-9c09-9a5e8fbdaaca","roots":{"1087":"b1906f80-68f7-404c-ae78-7bbf3c7ee2c2"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>