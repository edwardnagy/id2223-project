



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Clustering papers on Supervised Learning by Classification</title>
      
      
        
          
        
        
          
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="c1a1ffa6-2589-4153-89ff-86179dbf7dad" data-root-id="1087"></div>
            
          
        
      
      
        <script type="application/json" id="1176">
          {"6638c113-28a2-4ff8-95c5-f106ba7431f2":{"roots":{"references":[{"attributes":{"args":{"out_text":{"id":"1062","type":"Paragraph"},"p":{"id":"1014","subtype":"Figure","type":"Plot"},"slider":{"id":"1074","type":"Slider"},"source":{"id":"1011","type":"ColumnDataSource"},"text":{"id":"1075","type":"TextInput"},"topics":["measures, way, algorithms, fault, detection, mixture, proposed, multi, information, selection, support, svm, meta, damage, structures, instances","graphs, gnn, information, node, gnns, proposed, problem, demonstrate, novel, state, networks","sentiment, aspect, analysis, information, art, single, language, proposed, domain, compared, pre","text, sentiment, word, research, proposed, time, algorithms, deep, neural, challenge, cnn, attention, evaluate","proposed, cancer, breast, skin, clinical, accurate, work, detection, image, new, approaches, images, number, rate, support, values","generalization"]},"code":"\n\t\t\t\tvar key = text.value;\n\t\t\t\tkey = key.toLowerCase();\n\t\t\t\tvar cluster = slider.value;\n                var clusters_count = slider.end;\n                var data = source.data; \n                \n                \n                x = data['x'];\n                y = data['y'];\n                x_backup = data['x_backup'];\n                y_backup = data['y_backup'];\n                labels = data['cluster'];\n                abstract = data['abstract'];\n                title = data['title'];\n                author = data['author'];\n                if (cluster == clusters_count) {\n                    out_text.text = 'Keywords: Slide to specific cluster to see the keywords.';\n                    for (i = 0; i &lt; x.length; i++) {\n\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key) || \n                        (title[i] &amp;&amp; title[i].toLowerCase().includes(key)) ||\n                        (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t}\n                    }\n                }\n                else {\n                    out_text.text = 'Keywords: ' + topics[Number(cluster)];\n                    for (i = 0; i &lt; x.length; i++) {\n                        if(labels[i] == cluster) {\n\t\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key)\n                            || (title[i] &amp;&amp; title[i].toLowerCase().includes(key))\n                            || (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t\t}\n                        } else {\n                            x[i] = undefined;\n                            y[i] = undefined;\n                        }\n                    }\n                }\n            source.change.emit();\n            "},"id":"1063","type":"CustomJS"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1012","type":"HoverTool"},{"id":"1035","type":"PanTool"},{"id":"1036","type":"WheelZoomTool"},{"id":"1037","type":"BoxZoomTool"},{"id":"1038","type":"ResetTool"},{"id":"1039","type":"SaveTool"},{"id":"1040","type":"TapTool"}]},"id":"1041","type":"Toolbar"},{"attributes":{"text":"&lt;a href=\"clusters_last_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Year&lt;/button&gt;&lt;/a&gt;"},"id":"1005","type":"Div"},{"attributes":{"formatter":{"id":"1058","type":"BasicTickFormatter"},"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1030","type":"LinearAxis"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by the Clusters:&lt;/h3&gt;&lt;p1&gt;The slider below can be used to filter the target cluster. \nSimply slide the slider to the desired cluster number to display the plots that belong to that cluster. \nSlide back to the last cluster to show all the plots.&lt;/p1&gt;"},"id":"1008","type":"Div"},{"attributes":{},"id":"1026","type":"BasicTicker"},{"attributes":{"children":[{"id":"1008","type":"Div"},{"id":"1007","type":"Div"}]},"id":"1082","type":"Row"},{"attributes":{},"id":"1039","type":"SaveTool"},{"attributes":{"callback":{"id":"1065","type":"CustomJS"}},"id":"1040","type":"TapTool"},{"attributes":{},"id":"1072","type":"UnionRenderers"},{"attributes":{"children":[{"id":"1078","type":"Row"},{"id":"1079","type":"Row"},{"id":"1080","type":"Row"},{"id":"1081","type":"Row"},{"id":"1082","type":"Row"},{"id":"1083","type":"Row"},{"id":"1084","type":"Row"},{"id":"1085","type":"Row"},{"id":"1086","type":"Row"}]},"id":"1087","type":"Column"},{"attributes":{"fill_color":{"field":"cluster","transform":{"id":"1013","type":"LinearColorMapper"}},"line_alpha":{"value":0.3},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1050","type":"Scatter"},{"attributes":{"dimension":1,"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1034","type":"Grid"},{"attributes":{"background_fill_alpha":{"value":0.6},"items":[{"id":"1061","type":"LegendItem"}]},"id":"1060","type":"Legend"},{"attributes":{"callback":null,"data":{"abstract":["The use of functional magnetic resonance imaging (fMRI) data in machine learning (ML)-based classification of autism spectrum disorder (ASD) has been a topic of increasing research interest in past years due to the noninvasiveness of the fMRI technique and its potential for providing valuable biomarkers. However, there are still controversies surrounding some fMRI data preprocessing steps, such as bandpass filtering and global signal regression (GSR). It still needs to be determined whether or how these preprocessing steps impact the classification accuracy of ML algorithms. This paper uses fMRI signals from the ABIDE-I dataset to train a long short-term memory (LSTM) network to classify subjects into ASD or healthy controls (HC). We considered 18 preprocessing pipelines comprising all combinations of with and without filtering, with and without global signal regression, and three different segment lengths of 1 min, 2 min, and 3 min. The best model was obtained when using a segment length of 2 min. Our results suggest that not filtering produces significantly higher classification accuracies than filtering, whereas there were no significant differences in classification accuracies when removing or not the global signal.","Twitter Sentiment Analysis is the way of identifying sentiments and opinions in tweets. The main computational steps in this process are determining the polarity or sentiment of the tweet and then categorizing them into the positive tweet or negative tweet. The primary issue with Twitter sentiment analysis is the identification of the most suitable sentiment classifier that can correctly classify the tweets. Generally, base classification technique like Naive Bayes classifier, Random Forest classifier, SVMs and Logistic Regression are being used. In this paper, an ensemble classifier has been proposed that combines the base learning classifier to form a single classifier, with an aim of improving the performance and accuracy of sentiment classification technique. The results show that the proposed ensemble classifier performs better than stand-alone classifiers and majority voting ensemble classifier. In addition, the role of data pre-processing and feature representation in sentiment classification technique is also explored as part of this work.","Credit card fraud detection plays a crucial role in safeguarding the financial security of individuals and organizations. However, imbalanced datasets pose significant challenges to accurately identifying fraudulent transactions. In this research paper, we propose a novel approach that combines autoencoder (AE) and fully connected deep networks (FCDN) models to address this issue. The process involves three phases: training an AE on fraudulent transactions, utilizing another AE for dimensionality reduction, and using the encoded representations as input for FCDN classification. To further enhance the model\u2019s performance, we introduce an additional FCDN trained on the preprocessed data using the synthetic minority oversampling technique (SMOTE). The predictions from both AE, AE\u2013FCDN, and the FCDN are combined using a majority voting approach. We evaluate the proposed method using standard performance metrics, including accuracy, precision, recall, and F1-score. Our experimental results demonstrate the effectiveness and robustness of the integrated model architecture in accurately detecting credit card fraud. These findings provide valuable insights for improving financial security measures and mitigating potential losses associated with credit card fraud.","Wafer Bin Map (WBM) defect patterns are a critical aspect of identifying the root cause of manufacturing defects in the semiconductor industry. Semi-supervised learning (SSL) approaches have gained popularity for this purpose, as they can leverage both labeled and unlabeled data to improve model performance. However, SSL of WBM defect patterns is challenging due to class imbalance, where some defect classes have many more examples than others. Most of the existing SSL approaches assume a balanced dataset and often fail to provide satisfactory results when applied to imbalanced class problems. To address this issue, this work proposes a novel Dual-Head Convolutional Neural Network (CNN) architecture that contains two classifier heads. One classifier head maximizes overall classification scores, while the other aims to maximize per-class classification scores, providing equal attention to both majority and minority classes. The proposed CNN architecture uses pseudo-labels selected based on the outputs of these two classifiers to expand the labeled training set, which is then used to retrain the CNN. In this way, highly confident pseudo-labels are selected even from the minority classes, leading to better model training. Experiments show that the proposed approach is effective in handling class-imbalanced classification of WBM defect patterns, reporting state-of-the-art classification with an F1 score of 0.918, accuracy of 98.2% and a mean per-class accuracy of 91.7% using a lightweight ResNet-10 model as the backbone on the real-world public WBM dataset, WM-811K. The proposed approach\u2019s success suggests that it could be a valuable tool for improving the accuracy and reliability of WBM defect pattern classification in semiconductor manufacturing. The code is available at https://github.com/M-Siyamalan/SSL-DHCNN.\nHighlights\n\u2022\nNovel semi-supervised approach is proposed for wafer bin map defect classification.\n\u2022\nThe approach effectively handles imbalanced class semi-supervised classification.\n\u2022\nExperimental results show that the proposed approach outperforms other approaches.","Class-incremental continual learning is an important area of research, as static deep learning methods fail to adapt to changing tasks and data distributions. In previous works, promising results were achieved using replay and compressed replay techniques. In the field of regular replay, GDumb [23] achieved outstanding results but requires a large amount of memory. This problem can be addressed by compressed replay techniques. The goal of this work is to evaluate compressed replay in the pipeline of GDumb. We propose FETCH, a two-stage compression approach. First, the samples from the continual datastream are encoded by the early layers of a pre-trained neural network. Second, the samples are compressed before being stored in the episodic memory. Following GDumb, the remaining classification head is trained from scratch using only the decompressed samples from the reply memory. We evaluate FETCH in different scenarios and show that this approach can increase accuracy on CIFAR10 and CIFAR100. In our experiments, simple compression methods (e.g., quantization of tensors) outperform deep autoencoders. In the future, FETCH could serve as a baseline for benchmarking compressed replay learning in constrained memory scenarios.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201dco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","Social media's explosive growth brings with it a variety of societal risks ranging from severely harmful issues such as dangerous organizations and child sexual exploitation to moderately harmful content like displays of aggression, borderline nudity to benign or distasteful contents like gross videos and baity content. In recent times, the multitude and magnitude of these harms is being further exacerbated with the advent of generative AI [5]. Meta is committed to ensuring that Facebook is a place where people feel empowered to communicate and we take our role seriously in keeping abuse off the platform [7]. In this talk, I will describe practical challenges and lessons learned from tackling bad experiences for users on Facebook, particularly in the subjective, borderline and low quality spectrum of harms using state of the art, scalable machine learning approaches to content understanding, user behavior understanding and personalized ranking.","Addressing fairness in lesion classification from dermatological images is crucial due to variations in how skin diseases manifest across skin tones. However, the absence of skin tone labels in public datasets hinders building a fair classifier. To date, such skin tone labels have been estimated prior to fairness analysis in independent studies using the Individual Typology Angle (ITA). Briefly, ITA calculates an angle based on pixels extracted from skin images taking into account the lightness and yellow-blue tints. These angles are then categorised into skin tones that are subsequently used to analyse fairness in skin cancer classification. In this work, we review and compare four ITA-based approaches of skin tone classification on the ISIC18 dataset, a common benchmark for assessing skin cancer classification fairness in the literature. Our analyses reveal a high disagreement among previously published studies demonstrating the risks of ITA-based skin tone estimation methods. Moreover, we investigate the causes of such large discrepancy among these approaches and find that the lack of diversity in the ISIC18 dataset limits its use as a testbed for fairness analysis. Finally, we recommend further research on robust ITA estimation and diverse dataset acquisition with skin tone annotation to facilitate conclusive fairness assessments of artificial intelligence tools in dermatology. Our code is available at https://github.com/tkalbl/RevisitingSkinToneFairness.","Deep learning models have become increasingly prevalent in various domains, necessitating their deployment on resource-constrained devices. Quantization is a promising way to reduce the model complexity in that it keeps model architecture intact and enables the model to operate on specialized hardwares(e.g., NPU, DSP). Input resolution is also essential in making a trade-off between accuracy and computation.\nIn this paper, we conduct a joint analysis of input resolution and quantization precision on their influence on accuracy for three popular models: ResNet-18, ResNet-50, and MobileNet-V2. By exploring the combined configuration space, we found that better accuracy can be achieved by jointly optimizing the input resolution and quantization bit-width while maintaining the computational complexity.","The twin support vector machines (TWSVM) is a milestone in multi-plane classification with state-of-the-art performance on many classification problems. However, on large scale datasets, the learning speed of TWSVM is expensive. In this paper, we propose a fast twin support vector machines (FTWSVM). In our FTWSVM, a pair of hyperplanes are computed directly from the training dataset without numerical iterations. Experiments on several benchmark datasets show that our method can exhibit good generalization performance and fast learning compared to the fast support vector classifier (FSVC), which specializes in big data problems, and TWSVM, which generalizes well speed.","Functional magnetic resonance imaging (fMRI) is a non-invasive technique measuring brain activity by detecting blood flow changes, enabling the study of cognitive processes and brain states. However, the high dimensionality of resting-state (rs) fMRI data poses challenges for machine learning applications. Feature extraction (FE) and feature selection (FS) are critical for developing efficient machine learning models. Transforming raw data into meaningful features and selecting the most relevant ones, allows models to achieve improved generalization, accuracy, and robustness. Previous studies demonstrated the effectiveness of FE and FS methods for analyzing rs-fMRI data for Autism Spectrum Disorder (ASD) classification. In this study, we apply a random walks technique for correlation-based brain networks to extract features from rs-fMRI data, specifically the number of random walkers on each brain area. We then select significant features, i.e., brain areas with a statistically significant difference in the number of random walkers between neurotypical and ASD subjects. Our random walks-based FE and FS approach reduces the number of brain areas used in the classification and converts the functional connectivity matrix into a manageable vector, enabling faster computation. We examined 16 pipelines and tested support vector machines (SVM) and logistic regression for classification, identifying the optimal pipeline to consist of no filtering, no global signal regression (GSR), and FS, achieving a 76.54% classification accuracy with SVM. Our findings suggest that random walks capture a wide range of interactions and dynamics in brain networks, providing a deeper characterization of their structure and function, ultimately enhancing classification performance.","Kernel functions are a key element in many machine learning methods to capture the similarity between data points. However, a considerable number of these functions do not meet all mathematical requirements to be a valid positive semi-definite kernel, a crucial precondition for kernel-based classifiers such as Support Vector Machines or Kernel Fisher Discriminant classifiers. In this paper, we propose a novel strategy employing a polar decomposition to effectively transform invalid kernel matrices to positive semi-definite matrices, while preserving the topological structure inherent to the data points. Utilizing polar decomposition allows the effective transformation of indefinite kernel matrices from Krein space to positive semi-definite matrices in Hilbert space, thereby providing an efficient out-of-sample extension for new unseen data and enhancing kernel method applicability across diverse classification tasks. We evaluate our approach on a variety of benchmark datasets and demonstrate its superiority over competitive methods.","The issue of imbalanced data in machine learning has gained significant attention in recent years. Imbalanced data, where one class has significantly fewer samples than others, can lead to poor performance for machine learning models, especially in detecting minority class samples. To address this problem, various resampling techniques have been proposed, including the popular SMOTE (Synthetic Minority Over-sampling TEchnique). However, SMOTE suffers from the overlapping problem and may misclassify samples near the separation boundaries. This paper presents a novel framework to optimise border-based-SMOTEs, including Borderline-SMOTE and SVM-SMOTE which were specifically developed to solve the problem of misclassifying border samples. The proposed method ensures that generated samples improve the decision boundaries and are free from overlapping issues. The proposed method is evaluated on synthetic and real-world datasets, and results demonstrate its effectiveness in enhancing the performance of machine learning models, particularly in classifying minority class samples.","Feature selections facilitate classification learning in various data environments. Aiming at interval-valued decision systems (IVDSs), feature selections rely on information measures and similarity degrees, whereas current selection algorithms on credibility-based condition entropy and classical similarity degree are accompanied with some measurement limitations and advancement space. In this paper based on IVDSs, three coverage-credibility-based condition entropies and one geometry-probabilistic similarity degree are proposed across two dimensions of informationization and granulation, and they improve the existing condition entropy and similarity degree; accordingly, 4 \u00d7 2 feature selections emerge for optimization and applicability, and they systematically contain one initial selection algorithm and seven new/robuster algorithms. At first, three-way granular measures (i.e., credibility, coverage, and integrated coverage-credibility) are formulated in IVDSs, and three novel condition entropies are established by implementing three information structures on coverage-credibility. These condition entropies acquire in-depth improvements, hierarchical algorithms, size relationships, maximum/minimum conditions, and granulation non-monotonicity. Then, the probabilistic similarity degree is defined by a six-piecewise function with quadratic factors, and this new measure gains the geometry-probability mechanism and high-quality improvement. Furthermore, feature selections are determined by preserving condition entropies and by mining feature significances, so eight selection algorithms are obtained by combining condition entropies and similarity degrees. Finally, data experiments are performed to validate relevant uncertainty measures and feature selections, and seven constructional selection algorithms outperform three contrastive algorithms to achieve better classification performances.\nHighlights\n\u2022\n3 improved CEs are constructed by 3 information structures on coverage-credibilities.\n\u2022\n3 improved CEs gain mechanisms, algorithms, properties, granulation non-monotonicity.\n\u2022\nNew PSD gives the probability semantics, function reinforcement, quality improvement.\n\u2022\nNon-monotonic FSs and heuristic algorithms are designed by preserving 3 CEs on 2 SDs.\n\u2022\n7 combined FS algorithms outperform 3 current algorithms from classification effects.","In this paper, we present a prototype selection technique for imbalanced data, Fuzzy Rough Imbalanced Prototype Selection (FRIPS), to improve the quality of the artificial instances generated by the Synthetic Minority Over-sampling TEchnique (SMOTE). Using fuzzy rough set theory, the noise level of each instance is measured, and instances for which the noise level exceeds a certain threshold level are deleted. The threshold is determined using a wrapper approach that evaluates the training Area Under the Curve of candidate subsets. This proposal aims to clean noisy data before applying SMOTE, such that SMOTE can generate high quality artificial data.\nExperiments on artificial data show that FRIPS in combination with SMOTE outperforms state-of-the-art methods, and that it particularly performs well in the presence of noise.","Machine learning research relies to a large extent on experimental observations. The evaluation of classifiers is often carried out by empirical comparison with classifiers generated by different learning algorithms, allowing the identification of the best algorithm for the problem at hand. Nevertheless, previously to this evaluation, it is important to state if the classifiers have truly learned the domain class concepts, which can be done by comparing the classifiers\u2019 predictive measures with the ones from the baseline classifiers. A baseline classifier is the one constructed by a na\u00efve learning algorithm which only uses the class distribution of the dataset. However, finding na\u00efve classifiers in multi-label learning is not as straightforward as in single-label learning. This work proposes a simple way to find baseline multi-label classifiers. Three specific and one general na\u00efve multi-label classifiers are proposed to estimate the baseline values for multi-label predictive evaluation measures. Experimental results show the suitability of our proposal in revealing the learning power of multi-label learning algorithms.","Skilled employees are the most important pillars of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed to analyze attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource (HR) Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist HR departments in interpreting the predictions provided by machine learning models. In our experiments, we employ eight machine learning models to provide predictions. We further process the results achieved by the best-performing model by the SHAP explainability process and use the SHAP values to generate natural language explanations which can be valuable for HR. Furthermore, using \"What-if-analysis\", we aim to observe plausible causes for attrition of an individual employee. The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions.","This paper studies the effect of word representations on gender classification using deep learning. There are two main objectives: how well do popular deep learning architectures, namely LSTM and CNNs, perform on gender classification task and investigate how the choice of word representation effects the performance. Three networks, LSTM, CNN and LeNet-5, were trained on a dataset containing about 18000 names from India, Western countries, Sri Lanka and Japan. These names, encoded using the popular One-Hot representation and Word Embeddings in addition to Integer representation and an Enhanced Integer representation (proposed in this paper), were given as Input and the performance is evaluated on accuracy, training times and size of input layer. Experimental results show that LSTM in combination with word embedding derived from the proposed Enhanced Integer representation gives the best performance of about 85%. One-Hot representation is superior to Integer and Enhanced Integer representation but appears to perform lower than word embeddings.","This study investigates the realm of machine learning for the classification of different fire types using NASA's FIRMS MODIS satellite data for the Mediterranean basin. Concentrating on the Mediterranean basin and utilizing data spanning from 2019 to 2021 for model training, XGBoost and Random Forest models were subsequently validated for the 2022 data. The findings distinctly illustrate XGBoost's superior predictive precision as compared to Random Forest by showcasing an impressive overall F1 score surpassing 95% and 84% macro F1 score across various fire types. This study emphasizes the prospect of machine learning to improve worldwide wildfire monitoring and response by providing exact, real-time fire type forecasts.","Federated learning encounters a critical challenge of data heterogeneity, adversely affecting the performance and convergence of the federated model. Various approaches have been proposed to address this issue, yet their effectiveness is still limited. Recent studies have revealed that the federated model suffers severe forgetting in local training, leading to global forgetting and performance degradation. Although the analysis provides valuable insights, a comprehensive understanding of the vulnerable classes and their impact factors is yet to be established. In this paper, we aim to bridge this gap by systematically analyzing the forgetting degree of each class during local training across different communication rounds. Our observations are: (1) Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance. (2) When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold, indicating that the local model struggles to leverage a few samples of a specific class effectively to prevent forgetting. Motivated by these findings, we propose a novel and straightforward algorithm called Federated Knowledge Anchor (FedKA). Assuming that all clients have a single shared sample for each class, the knowledge anchor is constructed before each local training stage by extracting shared samples for missing classes and randomly selecting one sample per class for non-dominant classes. The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes. Extensive experimental results demonstrate that our proposed FedKA achieves fast and stable convergence, significantly improving accuracy on popular benchmarks.","Instance selection (IS) serves as a vital preprocessing step, particularly in addressing the complexities associated with high-dimensional problems. Its primary goal is the reduction of data instances, a process that involves eliminating irrelevant and superfluous data while maintaining a high level of classification accuracy. IS, as a strategic filtering mechanism, addresses these challenges by retaining essential instances and discarding hindering elements. This refinement process optimizes classification algorithms, enabling them to excel in handling extensive datasets. In this research, IS offers a promising avenue to strengthen the effectiveness of classification in various real-world applications.","This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as three other \"smart\" selection mechanisms -- Oort [51], TiFL [15] and gradient clustering [27] using four real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17-20 percentage points with 20-60% lower communication costs, and these benefits endure in the presence of straggler participants.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts, however they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","Artificial Intelligence (AI) use in automated Electrocardiogram (ECG) classification has continuously attracted the research community\u2019s interest, motivated by their promising results. Despite their great promise, limited attention has been paid to the robustness of their results, which is a key element for their implementation in clinical practice. Uncertainty Quantification (UQ) is a critical for trustworthy and reliable AI, particularly in safety-critical domains such as medicine. Estimating uncertainty in Machine Learning (ML) model predictions has been extensively used for Out-of-Distribution (OOD) detection under single-label tasks. However, the use of UQ methods in multi-label classification remains underexplored.\nThis study goes beyond developing highly accurate models comparing five uncertainty quantification methods using the same Deep Neural Network (DNN) architecture across various validation scenarios, including internal and external validation as well as OOD detection, taking multi-label ECG classification as the example domain. We show the importance of external validation and its impact on classification performance, uncertainty estimates quality, and calibration. Ensemble-based methods yield more robust uncertainty estimations than single network or stochastic methods. Although current methods still have limitations in accurately quantifying uncertainty, particularly in the case of dataset shift, incorporating uncertainty estimates with a classification with a rejection option improves the ability to detect such changes. Moreover, we show that using uncertainty estimates as a criterion for sample selection in active learning setting results in greater improvements in classification performance compared to random sampling.\nHighlights\n\u2022\nLarge comparison of Uncertainty Quantification (UQ) methods in multi-label setting.\n\u2022\nEnsemble methods are more robust for UQ and calibration under dataset shift.\n\u2022\nThe quality of current UQ methods degrade when dealing with dataset shifts.\n\u2022\nUQ for active learning improves performance faster than random sampling.","Orthopedic implant identification is an important and necessary step prior to performing revision surgery of different joints. The inability to identify an implant can lead to significant surgical difficulties with consequent unfavorable outcomes. This paper proposes a novel framework to identify the make and model of seven (7) different total shoulder arthroplasty implants utilizing plain X-ray images and Artificial intelligence. The proposed work classified implants with an accuracy of 91.48% and with an AUC (Area under curve) of 0.9932 showing higher effectiveness in orthopedic implant identification. Further work is required to enhance and progress this work, with a goal of greater accuracy and fewer errors.","Alzheimer disease (AD) is a chronic neurological disorder in which the loss of brain cells causes dementia. Early and accurate diagnosis of AD will lead to better treatment of the disease before irreversible brain damage has been occurred. This paper proposes the classification of Alzheimer's disease using 3D structural Magnetic Resonance Imaging (sMRI) images through 3D convolutional neural networks (CNNs). Most existing methods utilizing 3D subject-level CNNs for Alzheimer's disease classification design a single model which relies on a very large training dataset for improved generalization. Herein, we address this issue through 3D transfer learning which makes use of knowledge gained from a pre-trained task. We train 3D versions of five classical 2D image classification architectures\u2014ResNet, ResNeXt, SE-ResNet, SE-ResNeXt, and SE-Net\u2014by initializing each model with pre-trained weights from their 2D counterparts, and combine their predictions through a weighted average method. The weights assigned to each model of the ensemble are optimized to achieve a performance better than any single 3D CNN model. With a relatively smaller training dataset, the proposed model obtains 97.27%, 82.33%, 90.41%, 84.22%, 84.26%, and 77.1% accuracies for the Alzheimer\u2019s disease (AD) versus cognitively normal (CN), early mild cognitive impairment (EMCI) versus CN, late mild cognitive impairment (LMCI) versus CN, EMCI versus AD, LMCI versus AD, and EMCI versus LMCI classification tasks, outperforming current state-of-the-art methods, and indicating the effectiveness of our proposed model.","Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. In this study, we examine the various independent factors that affect the Bitcoin-Dollar exchange rate's volatility. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.","Graphical abstract\nDisplay Omitted\nAbstract\nA challenge in gas turbine fault diagnosis is that labeled fault samples are relatively rare and much fewer than normal samples. Conventional data augmentation techniques generate fault samples in original data spaces, resulting in the issue that synthetic fault samples highly overlap with normal samples. Aiming at the issue, a feature-level data augmentation method, namely feature-level SMOTE, is developed by integrating deep Siamese multi-head self-attention network (DSMHSA) with synthetic minority over-sampling technique (SMOTE) to reduce inter-class imbalance and overlap simultaneously. First, the DSMHSA maps original data into a feature space with better inter-class separability, in which inter-class samples stay far away from one another. Second, the SMOTE generates synthetic fault samples in the well-separable space, in order to balance the data set. Finally, the effectiveness of the developed feature-level SMOTE in imbalanced fault diagnosis has been evaluated through two case studies including the real gas turbine fault dataset and the public robot execution failures dataset. To be specific, its average balanced accuracy is 90.38% on the gas turbine dataset, yielding 9.67%, 13.94%, and 12.39% improvements compared to the OUPS, A-SUWO, and NRAS, respectively.","The automatic detection of mental disorders has been mainly performed through binary classifiers trained on the behavioral data collected through an interview setup. Such classifiers are usually trained by keeping the data from the participants having the disorder of interest in the positive class while the data from all other participants are kept in the negative class. In practice, it is well known that some mental disorders have common symptoms. Thus, the behavioral data may carry a mixed bag of attributes related to multiple disorders. As a result, the negative class may carry attributes related to the mental disorder of interest. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, the MDD detection performances are significantly improved. However, such improvement is not observed consistently for PTSD detection, which may attribute to PTSD being a subtype of MDD.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts; however, they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","In this study, we compare the classification accuracy achievable with linear support vector machine (L-SVM), K-nearest neighbor (KNN), and multilayer perceptron (MLP) methods for a multi-class EEG signal. This can be done in three phases. In phase one, band-pass filtering is applied to raw electroencephalogram (EEG) signals to decompose into five different frequency subbands. In phase two, we extract 10 important features from each subband. In phase three, these extracted feature sets are used as input to L-SVM, KNN, and MLP classifiers which categorize the sample data into three classes namely yoga, meditation, and combined yoga\u2013meditation. Various performance measures for each classifier are evaluated and then compared to know which classifier is effective in the classification of the EEG data into yoga, meditation, and combined yoga\u2013meditation groups. Performance measures such as confusion matrix, accuracy, sensitivity, specificity, precision, and F1 score are used to validate the performance of classifiers. Kruskal\u2013Wallis test has been conducted to compare the classification performance of the linear SVM, KNN, and MLP classifier models. By comparing the classification accuracy between the three classifiers, L-SVM achieved the highest accuracy of 91.67%.","Multi-view classification aims to efficiently utilize information from different views to improve classification performance. In recent researches, many effective multi-view learning methods have been proposed to perform multi-view data analysis. However, most existing methods only consider the correlations between views but ignore the potential correlations between samples. Normally, the views of samples belonging to the same category should have more consistency information and those belonging to different categories should have more distinctions. Therefore, we argue that the correlations and distinctions between the views of different samples also contribute to the construction of feature representations that are more conducive to classification. In order to construct a end-to-end general multi-view classification framework that can better utilize sample information to obtain more reasonable feature representation, we propose a novel joint long and short span self-attention network (JLSSAN). We designed two different self-attention spans to focus on different information. They enable each feature vector to be iteratively updated based on its attention to other views and other samples, which provides better integration of information from different views and different samples. Besides, we adopt a novel weight-based loss fusion strategy, which facilitates the model to learn more reasonable self-attention map between views. Our method outperforms the state-of-the-art methods by more than 3% in accuracy on multiple benchmarks, which demonstrates that our method is effective.\nHighlights\n\u2022\nA novel end-to-end unified multi-view classification framework is proposed.\n\u2022\nA long and short span self-attention layer is constructed.\n\u2022\nAn adaptive weight loss fusion strategy is designed.\n\u2022\nThe performance of our method outperforms the popular models.","Forests play a crucial role in sustaining life on earth by providing vital ecosystem services and supporting a wide range of species. The unprecedented increase in forest fires aka \u2018infernos\u2019 due to global warming i.e. rising temperatures and changing weather patterns, is quite alarming. Recently, machine learning and computer vision-based techniques are leveraged to proactively analyze forest fire events. To this end, we propose novel semi-supervised classification and segmentation techniques using autoencoders to analyse forest fires, that require significantly less labelling effort in contrast to the fully-supervised methods. In particular, semi-supervised classification of forest fire using Convolutional autoencoders is proposed. Further, Class Activation Map-based techniques and patch-wise extraction methods are envisaged for the segmentation task. Extensive experiments are carried out on two publicly available large datasets i.e. FLAME and Corsican datasets. The proposed models are found to be outperforming the state-of-the-art approaches.","Machine learning (ML) has become an important tool for the development of Industry 4.0. It assists the machining processes by monitoring and maintaining the conditions. Support vector machine (SVM) is one such algorithm of ML used to train and classify the data. The present work uses the SVM for predicting the surface roughness in the end milling of the low-carbon steel. The experiments were performed at nine different combinations of process parameters. Moreover, to monitor the cutting process online, the current drawn is measured using a current sensor. In this regard, a correlation between the current drawn and variation in surface roughness is reported. The average value of the surface roughness was predicted using the SVM at each combination. The results show that the SVM estimates the surface roughness with an approximate error of 0.4 %-10%. On the other hand, the surface roughness variation does not fit well with the current signals due to the variation in tool wear.","Credit scoring concerns with developing empirical model to support financial decision making process for financial institutions. It makes use of applicants\u2019 historical data and statistical or machine learning techniques to access the risk associated with an applicant. However, the data may have redundant and irrelevant information and features, which degrades the classification accuracy and increases the complexity. So, effective feature selection technique can resolve the problem of credit scoring dataset with huge number of features. In various studies, it is shown that ensemble classifier improves the classification performances as compared to its base classifiers. This study focuses to combine the benefits of feature selection and ensemble framework. For feature selection an approach based on feature clustering have been proposed in this study. Moreover, dataset with selected features is applied on five base classifiers and output obtained by base classifiers are aggregated by weighted voting approach for prediction of final output. For validating the proposed approach, three real world credit scoring datasets are utilized and results compared with some existing feature selection techniques in terms of classification accuracy and F1 -score.","Skip Abstract Section\nAbstract\nThe concealment of improvised explosive devices in dustbins aimed at destroying people and property is causing the mass removal of dustbins from public places and vehicular public transport in cities around the world. Such action of dustbin removal results in littering, stench, pests, contamination of water bodies, the spread of diseases, and increased greenhouse gases. The current solutions to the problem are blast-resistant dustbins which are bulky and expensive, and transparent dustbins which display the awful appearance of wastes in public places. This article proposes equipping dustbins with artificial intelligence-based classifiers to detect explosives concealed in wastes in public dustbins to minimise the risk to public safety. There was the need to construct a new database of explosive images to augment the existing TrashNet dataset. Then, through transfer learning using eight state-of-the-art convolutional neural networks as base models, the augmented dataset was used to search for optimum convolutional neural networks to detect explosives. One of the trained networks based on DenseNet-121 achieved the Top-1 accuracy of 80% with about 26 minutes learning time, which is 6.7% better than the Top-1 accuracy achieved by the base model on the benchmark ImageNet dataset. This finding demonstrates that the designed neural networks are promising cutting-edge techniques for detecting explosives concealed in dustbins to threaten public safety. To the best of our knowledge, this is the first time that convolutional neural networks have been proposed to identify explosives concealed in dustbins.\nSkip Graphical abstract Section\nGraphical abstract","With the advent of the information age, there are more and more text data on the Internet. As the most widely distributed information carrier with the largest amount of data, it is particularly important to use text classification technology to organize and manage massive data scientifically. In this paper, a semi-supervised ensemble learning algorithm Heterogeneous-training is proposed and applied to the field of text classification. Based on the Tri-training algorithm, the Heterogeneous-training algorithm improves the traditional Tri-training algorithm by using different classifiers, dynamically updating the probability threshold and adaptively editing data. A large number of experiments show that our method always outperforms Tri-training algorithm in text classification on benchmark text data sets.","3D printing has the potential to revolutionize industrial manufacturing through efficient and sustainable techniques. Fused Deposition Modeling (FDM) is a broadly deployed technique among various 3D printing methods. However, the surface quality of FDM is greatly influenced by multiple factors, making it challenging to unravel the relationship between printing quality and parameter settings. To break through this bottleneck, this study proposes an intelligent approach that combines Transfer Learning (TL)-based Feature Extractor (FE) and Gradient-Boosting Decision Trees (GBDT) to investigate the effects of FDM printing parameters on surface quality. Experiments are conducted in the laboratory to validate the effectiveness of the FE-GBDT, which is then compared with the exemplary Machine Learning (ML) algorithms. The results show that our proposed TL model can achieve high precision and accuracy over 0.9900, demonstrating the efficacy of FE-GBDT in deciphering the impact of FDM printing parameters on surface quality. The contribution of each parameter is evaluated and indicates that layer height could dramatically affect the surface quality with an importance score of 0.626. The results provide valuable insights for the 3D printing community, proving that the FE-GBDT approach offers improved generalization, faster training, enhanced feature extraction, addressing data scarcity, and the ability to leverage the strengths of both approaches for superior performance across various tasks.","Machine Learning has revolutionized the categorization of vast legal documents, minimizing costs and improving evaluations. However, conventional models struggle with unseen data categories in real-world scenarios, a challenge termed Open Set Classification. Our study tackles the issue faced by the Court of Justice in S\u00e3o Paulo, Brazil, to identify recurring lawsuit themes from texts, as manual sorting is inefficient. We introduce a method to enhance confidence in text classification using an open dataset by converting multiclass challenges into binary ones with four confidence tiers. By testing various techniques, we found that combining doc2vec with the Support Vector Machine classifier delivers trustworthy results and robust performance. Ultimately, our method offers an effective solution for classifying legal texts confronting Open Set Classification issues in the legal sector.","The Hierarchical Inference (HI) paradigm has recently emerged as an effective method for balancing inference accuracy, data processing, transmission throughput, and offloading cost. This approach proves particularly efficient in scenarios involving resource-constrained edge devices like micro controller units (MCUs), tasked with executing tinyML inference. Notably, it outperforms strategies such as local inference execution, inference offloading, and split inference (i.e., inference execution distributed between two endpoints). Building upon the HI paradigm, this work explores different techniques aimed at further optimizing inference task execution. We propose three distinct HI approaches and evaluate their utility for image classification.","Pulmonary Embolism (PE) \u2014 a non-cardiac cause of cardiac arrest is a strenuous job to perform as it is non-specific in presentation and shares various overlapping features with various other clinical disorders like Myocardial Infarction, Pneumonia, etc. This paper delineates a method to identify Pulmonary Embolism (PE) as a reason for Heart Failure using Deep Reinforcement Learning (DRL) algorithm. The methodology has been partitioned into two phases. Phase I acts towards the creation of a novel dataset as there was no data available for this particular problem statement. Phase II deals with the scope and application of the DRL algorithm on the above-invented dataset. The dataset formed is imbalanced in its essence. To effectively tackle the imbalanced dataset challenge, a cutting-edge imbalanced classification algorithm rooted in the power of Deep Reinforcement Learning (DRL) has been embraced. The classification model has been drawn up as a Sequential Decision-Making procedure and is resolved by making use of the DRL algorithm viz Double Deep Q-Network (DDQN). A classification action is performed by an agent on a single sample at each time step. Classification actions are assessed by the environment, based on the assessment, a reward is given to an agent. In order to make the agent more responsive towards the minority class samples, rewards belonging to the minority class are higher. Under the supervision of this reward system, the agent finally learns the optimal classification policy for this imbalanced dataset problem. Comparative analysis of the DDQN algorithm with other Deep Reinforcement Learning algorithms, including Dueling DQN, and Proximal Policy Optimization (PPO) algorithms has been performed in order to arrive at the best learning technique for the dataset. Furthermore, the DDQN algorithm has been evaluated against a selection of Machine Learning (ML) algorithms. From the experimentation, it is demonstrated that the DDQN model outperformed other approaches with an accuracy of 99.99%, G-mean 0.9999, Recall 1.0000, and Specificity 0.9999.","Skip Abstract Section\nAbstract\nThe disadvantages of modern methods of classifying objects and processes are considered. We propose a method of constructing three-dimensional classifications that allows the elimination of some of these shortcomings, based on the system-object approach, using the ideas of multidimensional classification and natural classification. Three basic system characteristics are used as classification planes: structural (node), functional (function), and substantive (object), which allows for the classification by types of functional request to the system from a higher-order system (supersystem) by types of system formation processes and by the obtained results. Each classification is a tree-type graph with one vertex that is common to all three planes. The formal description of the three-dimensional graph by means of descriptive logic is presented, which not only allows for the phenomena and objects of the subject area to be classified, but also for the cause-and-effect relations existing in this area to be traced. The procedures for the use of three-dimensional system-object classification for forecasting and management support are described. An example of three-dimensional classification for functional diagnostic devices is given.","Classification and differentiation of leukocyte sub-types are important in peripheral blood smear analysis. Fully-automated systems for leukocyte analysis are grouped into segmentation- and detection-based methods. The accuracy of classification depends on the accuracy of segmentation and detection steps. Real-world applications often produce inaccurate ROIs due to image quality factors, e.g., colour and lighting conditions, absence of standards, or even density and presence of overlapping cells. To this end, we investigated the scenario in-depth with ROIs simulating segmentation and detection methods and evaluating different image descriptors on two tasks: differentiation of leukocyte sub-types and leukaemia detection. The obtained results show that even simpler approaches can lead to accurate and robust results in both tasks when exploiting appropriate images for model training. Traditional handcrafted features are more effective when extracted from tight bounding boxes or masks, while deep features are more effective when extracted from large bounding boxes or masks.","Today's ever\u2010increasing generation of streaming data demands novel data mining approaches tailored to mining dynamic data streams. Data streams are non\u2010static in nature, continuously generated, and endless. They often suffer from class imbalance and undergo temporal drift. To address the classification of consecutive data instances within imbalanced data streams, this research introduces a new ensemble classification algorithm called Rarity Updated Ensemble with Oversampling (RUEO). The RUEO approach is specifically designed to exhibit robustness against class imbalance by incorporating an imbalance\u2010specific criterion to assess the efficacy of the base classifiers and employing an oversampling technique to reduce the imbalance in the training data. The RUEO algorithm was evaluated on a set of 20 data streams and compared against 14 baseline algorithms. On average, the proposed RUEO algorithm achieves an average\u2010accuracy of 0.69 on the real\u2010world data streams, while the chunk\u2010based algorithms AWE, AUE, and KUE achieve average\u2010accuracies of 0.48, 0.65, and 0.66, respectively. The statistical analysis, conducted using the Wilcoxon test, reveals a statistically significant improvement in average\u2010accuracy for the proposed RUEO algorithm when compared to 12 out of the 14 baseline algorithms. The source code and experimental results of this research work will be publicly available at https://github.com/vkiani/RUEO.","Architectural floor plan is an essential document to share the building information among designers, and engineers. Automatic floor plan image analysis is useful to extract various information from the floor plan. Wall segmentation is an important step in floor plan image analysis. However, few research works have been conducted for automatic wall recognition in an architectural floor plan. In this paper, a convolution neural network, namely WallNet, is proposed to recognize the multi-class walls. The WallNet consists of an encoder and a decoder. The encoder captures low-level features, as well as multiscale contextual information. Based on these extracted feature maps, the walls are detected. The proposed network is applied to recognize five different classes of walls: solid-wall, dot-wall, diagonal-wall, hollow-wall and gray-wall. The experimental results show that the proposed architecture can obtain a mean average precision of 72%, which is superior compared to the state-of-the-art techniques.","The recent pandemic has witnessed a parallel infodemic happening on social media platforms, leading to fear and anxiety within the population. Traditional machine learning (ML) frameworks for fake news detection are limited by the availability of data for training the model. By the time sufficient labeled datasets are available, the existing infodemic may itself come to an end. We propose a COVID-19 fake news detection framework using cross-domain classification techniques to achieve high levels of accuracy while reducing the waiting time for large training datasets to become available. We investigate the effectiveness of three approaches: Domain Adaptive Training, Transfer Learning, and Knowledge Distillation that reuse ML models from past infodemics to improve the accuracy in detecting COVID-19 fake news. Experiments with real-world datasets depict that Transfer Learning performs better than Domain Adaptive Training and Knowledge Distillation techniques.","Training deep learning models on long-tailed datasets is a challenging task since the classification performance of tail classes with fewer samples is always unsatisfactory. Currently, many long-tailed methods have achieved success. However, some methods always improve tail-class performance at the expense of head-class performance due to limited model capability. To address this issue, we propose a novel algorithm-level method inspired by information theory to balance the information space of each class and boost tail-class performance while minimizing head-class sacrifice. Our method involves actively eliminating the redundant feature information of head classes to save space for tail classes during training. Specifically, we use a bilateral-expert model and design a duplicate information disentanglement (DID) module that can extract duplicate and redundant information from bilateral-expert features. This allows us to develop a head diversity loss to decrease the extracted duplicate and redundant information of head classes and a tail distillation loss to increase the label information of tail classes. The joint result of these two losses allows our model to fully leverage the information space for improved tail-class performance without compromising head-class performance. The effectiveness and practicability of our method are verified by five datasets with long-tailed distributions for visual recognition or fault diagnosis tasks. Experimental results demonstrate that our method outperforms currently available mainstream methods, which we attribute to the effectiveness of our proposed DID module and the incorporation of two long-tailed losses.","This paper focuses on the classification problem of multi-view data, aiming to improve the classification accuracy of current algorithms on multi-view data. Previous multi-view classification algorithms are usually based on exploiting the complementarity of different views and fusing features from different views. A representative category is the graph-based method, which builds a graph matrix for each view, and then fuses the graph matrices of different views to obtain a unified graph. These methods have the following problems: firstly, the graph matrix is simply based on sample similarity usually; secondly, the learned graph matrix does not change dynamically; thirdly, the weight of the graph representation matrix for a single view cannot be learned in the unified graph matrix. Therefore, this paper designs a Two-step classification algorithm based on Dynamic Graph-ELM, called TSDGELM. In the TSDGELM, the dynamic Graph-ELM is used to obtain the graph representation matrix of each view to save the local neighbor information of the data, and then a joint graph learning algorithm is designed based on the GBS (Graph-Based System) mechanism to fuse the graph matrix of the single-view, and finally the united graph is input into the classifier. To evaluate the effectiveness of the proposed method in this work, we conduct a series of experiments on eight datasets, and the results demonstrate the superiority of the proposed method.","Stress detection is important for ensuring overall mental well-being of an individual. Literature suggests several approaches for prediction or classification of stress. However, the performance of these approaches varies a lot across subjects and tasks. Moreover, perception of stress is highly subjective and hence it is difficult to create a generic model/devices for prediction of stress. In this study, we have proposed an approach for creating a generic stress prediction model by combining the knowledge and variety from multiple public datasets containing galvanic skin response (GSR) data recorded during different context and activities. Most significant features are selected from these recorded signals and a voting based approach was finally adopted to develop a model for predicting mental stress. Proposed model has been validated using test data as well as a set of completely unseen data collected in our lab. We achieved an average classification accuracy of 89% (F-score 0.87) for test data and similar performance for completely unseen data as well. Results show that the proposed model outperforms the training models created using individual datasets. In addition, our model is created using skin response data recorded using off-the-shelf devices. Thus, our proposed model with selected feature set can be used for monitoring stress in real life scenarios and to create mass-market stress prediction products.","Graph neural networks (GNNs) have been shown to be useful in a variety of graph classification tasks, from bioinformatics to social networks. However, most GNNs represent the graph using local neighbourhood aggregation. This mechanism is inherently difficult to learn about the global structure of a graph and does not have enough expressive power to distinguish simple non-isomorphic graphs. To overcome the limitation, here we propose multi-head heat kernel convolution for graph representation. Unlike the conventional approach of aggregating local information from neighbours using an adjacency matrix, the proposed method uses multiple heat kernels to learn the local information and the global structure simultaneously. The proposed algorithm outperforms the competing methods in most benchmark datasets or at least shows comparable performance.","Facial expression recognition is a human emotion classification problem attracting much attention from scientific research. Classifying human emotions can be a challenging task for machines. However, more accurate results and less execution time are still the issues when extracting features of human emotions. To cope with these challenges, the authors propose an automatic system that provides users with a well-adopted classifier for recognizing facial expressions in a more accurate manner. The system is based on two fundamental machine learning stages, namely feature selection and feature classification. Feature selection is realized by active shape model (ASM) composed of landmarks while the feature classification algorithm is based on seven well-known classifiers. The authors have used CK+ dataset, implemented and tested seven classifiers to find the best classifier. The experimental results show that quadratic classifier (DA) provides excellent performance, and it outperforms the other classifiers with the highest recognition rate of 100% for the same dataset.","Plenty of models have been presented to handle the hypergraph node classification. However, very few of these methods consider contrastive learning, which is popular due to its great power to represent instances. This paper makes an attempt to leverage contrastive learning to hypergraph representation learning. Specifically, we propose a novel method called Collaborative Contrastive Learning (CCL), which incorporates a generated standard graph with the hypergraph. The main technical contribution here is that we develop a collaborative contrastive schema, which performs contrast between the node views obtained from the standard graph and hypergraph in each network layer, thus making the contrast collaborative. To be precise, in the first layer, the view from the standard graph is used to augment that from the hypergraph. Then, in the next layer, the augmented features are adopted to train a new representation to augment the view from the standard graph conversely. With this setting, the learning procedure is alternated between the standard graph and hypergraph. As a result, the learning on the standard graph and hypergraph is collaborative and leads to the final informative node representation. Experimental results on several widely used datasets validate the effectiveness of the proposed model.\nHighlights\n\u2022\nCCL is proposed to handle hypergraph node classification problem.\n\u2022\nCCL considers the contrast in each layer from GCN and HGCN.\n\u2022\nCCL exploits the convolutional networks on the standard graph and hypergraph.\n\u2022\nExperimental results demonstrate the superior performance of the proposed model.","The most common application of artificial immune networks (AINs) is on unsupervised learning tasks. This is due to the fact that AINs are inspired by the adaptive immune system, which consists of a network of antibodies that self-organises to form a memory of external antigens. The self-organising nature of AINs makes them a natural approach for solving problems involving learning and adapting to patterns or structures present in a dataset to form an abstract representation. Training AINs in this fashion means that the dataset need not have class labels because the typical aim of the learning process is not to perform classification. However, there have been attempts to use AINs for classification tasks by considering the resulting clusters of antibodies as representative of the classes present in a dataset. This has also been done when applying AINs to the task of recognising handwritten characters. However, in all the approaches found in the literature, the common method was to leave the task of discovering classes to the AINs. Doing so is contrary to how other models are trained to do classification tasks where data samples are provided along with their class labels to guide the learning process. Therefore, this paper presents a novel supervised learning approach to training AINs for multi-class classification. The proposed approach was tested on the MNIST handwritten digits dataset and achieved a classification accuracy of 99.45%.","Multi-layer perceptrons (MLPs) rank among the most popular and widely employed intelligent approaches for approximating the relationships between dependent and independent variables, demonstrating a wide range of successful applications. MLPs are flexible techniques capable of universally modeling and analyzing real-world problems in forecasting and classification domains with a desirable level of accuracy. In conventional MLPs, cost functions are formulated based on the error term. Subsequently, the learning process aims to estimate the unknown parameters to minimize the error-based cost function. The logic of the procedure is founded on the assumption that maximum generalization will be achieved from models displaying the highest accuracy within the training sample. While this learning process is rational and beneficial, a model's generalization capability depends simultaneously on the model's accuracy and the reliability level of that accuracy. In this manner, reliability is not taken into consideration when formulating the conventional cost function for MLPs. This paper introduces a reliability-based cost function for estimating the unknown weights and biases of MLP models during the learning process. The proposed cost function is designed to calculate the variation of the performances in dissimilar data situations. In the learning process of the proposed reliability-based multi-layer perceptron, in contrast to traditionally developed models, the goal is to minimize variation rather than error, or equivalently, to maximize reliability instead of accuracy. The generalizability of the proposed reliability-based MLP (EMLP) model in forecasting and classification domains is comprehensively evaluated using 30 benchmark data sets in each domain. Empirical results in the forecasting area indicate that, from a general perspective, the proposed EMLP model exhibits superior generalizability in 23 cases (76.67%) compared to traditional models. Furthermore, numerical results in the classification area reveal that the proposed model outperforms or matches the performance of the conventional MLP in 26 cases (86.67%). These outcomes clearly underscore the significance of reliability, a factor not considered in any of the conventional MLP modeling procedures. Therefore, the proposed MLP model represents a suitable alternative in modeling, especially when greater generalizability is desired.","One of the main challenges in target-dependent sentiment classification (TDSC) is dealing with sentences that contain multiple targets with varying polarities. Traditional sentiment analysis has shown the effectiveness of language characteristics. Therefore, we propose a method to extract target semantic-related tokens from sentences in order to simplify the sentiment classification task. To achieve this, we establish six grammatical principles that utilize grammatical knowledge to filter the relevant descriptions of targets. Since a target is typically a noun and acts as a subject, we summarize the six rules to extract the contexts contained in the objects and subordinate clauses. We use dependency parsing to analyze the grammatical relations between the target and its context. We design a data pre-processing method called Text Filtering (TF) to automate this procedure. After executing the TF algorithm, we pass the target-related words to a simple classifier to predict their sentiment polarities. Rather than feeding these features directly to a network and letting it learn features on its own, our approach employs dependency relations to extract context linked to the target. This provides the network with meaningful and representative features, resulting in superior results. We conduct ablation studies to investigate the effectiveness of the proposed TF algorithm. In the restaurant hard dataset, our approach improves accuracy by 13.76% and macro-F1 by 14.65% compared to a CNN-based method where TF is not implemented.\nHighlights\n\u2022\nIncorporate linguistic knowledge to the model by a two-step framework for effective handling of multiple targets.\n\u2022\nTarget-related contexts were extracted by the summarized rules which distinguish content and function words.\n\u2022\nA hierarchical and recursive data process method was designed specifically for TDSC named Text filtering (TF).","We present FOLD-SE, an efficient, explainable machine learning algorithm for classification tasks given tabular data containing numerical and categorical values. The (explainable) model generated by FOLD-SE is represented as a set of default rules. FOLD-SE uses a novel heuristic called Magic Gini Impurity for literal selection that we have devised. FOLD-SE uses a refined data comparison operator and eliminates the long tail effect. Thanks to these innovations, explainability provided by FOLD-SE is scalable, meaning that regardless of the size of the dataset, the number of learned rules and learned literals stay quite small while good accuracy in classification is maintained. Additionally, the rule-set constituting the model that FOLD-SE generates does not change significantly if the training data is slightly varied. FOLD-SE is competitive with state-of-the-art traditional machine learning algorithms such as XGBoost and Multi-Layer Perceptrons (MLP) w.r.t. accuracy of prediction while being an order of magnitude faster. However, unlike XGBoost and MLP, FOLD-SE generates explainable models. The FOLD-SE algorithm outperforms prior rule-learning algorithms such as RIPPER in efficiency, performance, and scalability, especially for large datasets. FOLD-SE generates a far smaller number of rules than earlier algorithms that learn default rules.","Text classification is a fundamental task in Text Mining (TM) with applications ranging from spam detection to sentiment analysis. One of the current approaches to this task is Graph Neural Network (GNN), primarily used to deal with complex and unstructured data. However, the scalability of GNNs is a significant challenge when dealing with large-scale graphs. Multilevel optimization is prominent among the methods proposed to tackle the issues that arise in such a scenario. This approach uses a hierarchical coarsening technique to reduce a graph, then applies a target algorithm to the coarsest graph and projects the output back to the original graph. Here, we propose a novel approach for text classification using GNN. We build a bipartite graph from the input corpus and then apply the coarsening technique of the multilevel optimization to generate ten contracted graphs to analyze the GNN\u2019s performance, training time, and memory consumption as the graph is gradually reduced. Although we conducted experiments on text classification, we emphasize that the proposed method is not bound to a specific task and, thus, can be generalized to different problems modeled as bipartite graphs. Experiments on datasets from various domains and sizes show that our approach reduces memory consumption and training time without significantly losing performance.","The growing demand for sustainable development brings a series of information technologies to help agriculture production. Especially, the emergence of machine learning applications, a branch of artificial intelligence, has shown multiple breakthroughs which can enhance and revolutionize plant pathology approaches. In recent years, machine learning has been adopted for leaf disease classification in both academic research and industrial applications. Therefore, it is enormously beneficial for researchers, engineers, managers, and entrepreneurs to have a comprehensive view about the recent development of machine learning technologies and applications for leaf disease detection. This study will provide a survey in different aspects of the topic including data, techniques, and applications. The paper will start with publicly available datasets. After that, we summarize common machine learning techniques, including traditional (shallow) learning, deep learning, and augmented learning. Finally, we discuss related applications. This paper would provide useful resources for future study and application of machine learning for smart agriculture in general and leaf disease classification in particular.","Geophysical reservoir characterization is a significant task in the oil and gas industry and elastic logs prediction of subsurface formations is a fundamental aspect of this process. However, elastic log prediction in a high-dimensional and complex geological environment, such as the Lower Indus Basin Pakistan, poses a significant challenge where traditional empirical methods often fail to provide competitively accurate results. Therefore, this study proposes a novel machine learning approach that combines unsupervised clustering (K-means) and ensemble-based machine learning (random forest) to improve prediction accuracy. By clustering data based on statistical similarity and ensemble algorithms to each cluster, the methodology addresses the challenges of sonic log prediction in the Lower Indus Basin (Pakistan). This approach was evaluated using real-world data, outperforming several baseline methods with a root mean square error of 98% accuracy. Its effectiveness to predict elastic log makes it a valuable tool in reservoir characterization, earthquake analysis, and geothermal energy exploration. Overall, combining this methodology with other techniques can enhance seismic data analysis and enable better decision-making in the oil and gas industry. This novel approach presents an effective solution for predicting sonic log in the Lower Indus Basin and contributes to advancements in geophysical reservoir characterization.\nHighlights\n\u2022\nA novel machine learning method is proposed to predict elastic log response.\n\u2022\nThis method integrates K-means clustering with random forest for prediction.\n\u2022\nThe accuracy of predictions significantly improved in complex geological settings.\n\u2022\nThis method can predict petrophysical parameters in complex geological environment.\n\u2022\nThis proposed approach effectively reduces cumbersome human efforts and save time.","Multi-source information fusion is an effective method to handle pattern classification problems. Dempster\u2013Shafer evidence theory (DSET) plays an important role in handling uncertainty problems in multi-source information fusion. However, highly conflicting evidence in DSET may cause counter-intuitive fusion results. Belief divergence theory is one of the solutions to conflict management, which is also beneficial for the improvement of accuracies of pattern classification. In this paper, a novel belief divergence measurement method, fractal belief Jensen\u2013Shannon (F B J S) divergence is proposed to better measure the discrepancy between Basic probability assignments (BPAs) and address the problem of highly conflicting evidence in DSET. The proposed F B J S divergence is the first belief divergence that incorporates the belief divergence theory and the concept of fractal. In addition, it has the properties of non-negativeness and symmetry. Then, based on F B J S divergence, a novel multi-source information fusion algorithm is proposed. Ultimately, the proposed algorithm is effectively applied to solve a pattern classification problem with a higher classification accuracy.","This paper introduces new flexible loss functions for binary classification in Gradient-Boosted Decision Trees (GBDT) that combine Dice-based and cross-entropy-based losses and offer link functions from either a generalized extreme value (GEV) or exponentiated exponential logistic (EEL) distribution. Testing 27 different GBDT models using XGBoost on a Freddie Mac mortgage loan database showed that the choice of the loss function is useful. Specifically, when the class imbalance ratio (IR) is less than 99, using a skewed GEV distribution-based link function in XGBoost enhances discriminatory power and classification accuracy while retaining a simple model structure, which is particularly important in credit scoring applications. In cases where class imbalances are severe, typically between IRs of 99 and 200, we found that an advanced loss function, which is composed of a symmetric hybrid loss function and a link derived from a positively skewed EEL distribution, outperforms other XGBoost variants. Based on our findings, the accuracy improvements of these proposed extensions result in lower misclassification costs, which are especially evident when IR is below 99, which results in higher profitability for the business. Furthermore, the study highlights the transparency associated with GBDT, which is also an integral component of financial applications. Researchers and practitioners can use these insights to create more accurate and discriminative machine learning models, with possible extensions to other GBDT implementations and machine learning techniques that take into account loss functions. The source code for the proposed approach is publicly available at https://github.com/jm-ml/flexible-losses-for-binary-classification-with-GBDT.","Highlights\n\u2022\nA novel hyperspectral band selection network is proposed for seed classification.\n\u2022\nBand attention and sparse constraint (SC) maximizes the removal of redundant bands.\n\u2022\nA new loss function is defined to solve the gradient update problem caused by SC.\n\u2022\nThe selected bands carry important spectrochemical information.\n\u2022\nThis method is also applicable to other hyperspectral data of food and agro-products.\nAbstract\nThe development of a real-time online system for rapid and nondestructive identification of seed varieties can greatly improve production efficiency in modern agriculture. Hyperspectral imaging (HSI) is a powerful tool for seed variety identification. Nevertheless, hyperspectral data are not only high in dimensionality but also contain redundant information, which is very unfriendly to real-time online applications. Selecting a few representative bands from the entire working spectral region can significantly reduce the equipment cost and computational load of HSI. In the field of food and agr-products quality evaluation, Band selection (BS) methods based on chemometrics have been dominant for a long time. Most of these methods, however, fail to take full account of the nonlinearities and global interactions between spectral bands, which may result in the selection of some adjacent bands that still retain more redundant information. In this paper, a novel BS network is proposed, which is composed of sparse band attention module and classification net module. The former is used to generate weight of each band, and sparse constraint is applied to the weights of redundant bands, while the latter is used to achieve high-performance classification with reweighted data. Furthermore, to solve the problem of gradient updating caused by sparse constraint, a auxiliary loss function is defined to assist optimization. Finally, comparative experiments is conducted on our maize seed hyperspectral dataset. The results demonstrate that the presented method selects a subset of informative bands with less redundant information to obtain better classification performance and outperforms several other existing BS methods.","Skip Background Section\nBackground\nSeismic signals are useful for earthquake detection and classification. Therefore, various artificial intelligence (AI) models have been used with seismic signals to develop automated earthquake detection systems. Our primary goal is to present an accurate feature engineering model for earthquake detection and classification using seismic signals.\nSkip Material and model Section\nMaterial and model\nWe have used a public dataset in this work containing three categories: (1) noise, (2) P waves, and (3) S waves. P and S waves are used to define earthquakes. We have presented two applied use cases using this dataset: (i) earthquake detection and (ii) wave classification. In this work, a new textural feature extractor has been presented by using a graph pattern similar to a butterfly. Thus, this feature extraction function is named Butterfly pattern (BFPat). We have created a new feature engineering architecture by deploying BFPat, statistics, and wavelet packet decomposition (WPD) functions. The recommended BFPat and statistics have been applied to the wavelet bands created by WPD and the raw seismic signals. Multilevel features have been extracted from both frequency and space domains. The used dataset contains signals with three channels. Using these three channels, seven signals have been created. Seven feature vectors have been created from 7 input signals used in this study. The most meaningful/informative features from the generated feature set are then selected using the iterative neighborhood component analysis feature selector method. Seven chosen feature vectors have been considered as inputs of the two shallow classifiers: k nearest neighbors (kNN) and support vector machine (SVM). A total of 14 (=7 \u00d7 2) results have been obtained in the classification phase. A majority voting process was applied in the last phase to choose the best results and improve the classification performance.\nSkip Results Section\nResults\nWe have presented two use cases for our new BFPat method in this work to obtain superior results. Our model reached an accuracy of 99.58% in detecting the earthquake detection and 93.13% accuracy in 3-class classifications of waves.\nSkip Conclusions Section\nConclusions\nOur recommended model has achieved over 90% classification performance for both cases. Also, we have presented the most valuable channel and combinations in our work. Our developed system is ready to be tested with a bigger database.","Dempster\u2013Shafer evidence theory (DSET) is extensively employed in multi-source data fusion applications. Nonetheless, when belief probability assignments (BPAs) exhibit considerable conflict, unexpected results can occur. To address this limitation, the high-order fractals are explored and a K-order fractal-based Kullback\u2013Leibler divergence (KO-FKL) is introduced, which defines the K-order as the optimal fractal epoch. This measure is employed to quantify the divergence between BPAs and demonstrates superior performance in assessing the conflict between two BPAs in numerical examples, compared to existing belief divergence methods. To utilize the KO-FKL divergence measure to real-world problems, a novel KO-FKL-based multi-source data fusion (KO-FKL-MSDF) algorithm is designed. Through comparisons with well-known related methods, our proposed KO-FKL-MSDF algorithm demonstrates superiority and enhanced robustness. Lastly, the KO-FKL-MSDF algorithm is applied to real-world classification problems, underlining its high practical applicability.\nHighlights\n\u2022\nHigh-order fractal BPA and KL divergence using continuous Pignistic process.\n\u2022\nOptimal fractal high-order K via proposed Difference of Deng entropy convergence.\n\u2022\nK-order fractal KL divergence outperforms existing measures in plentiful examples.\n\u2022\nKO-FKL multi-source data fusion algorithm via extensive validation and analysis.\n\u2022\nKO-FKL-MSDF algorithm excels in pattern classification on multiple datasets.","Remote Sensing (RS) has been widely utilized in various Earth Observation (EO) missions, including land cover classification and environmental monitoring. Unlike computer vision tasks on natural images, collecting remote sensing data is more challenging. To fully exploit the available data and leverage the complementary information across different data sources, we propose a novel approach called Multimodal Transformer for Remote Sensing (RsMmFormer) for image classification, which utilizes both Hyperspectral Image (HSI) and Light Detection and Ranging (LiDAR) data. In contrast to the conventional Vision Transformer (ViT), which does not incorporate the inherent biases and assumptions of convolutions, we improve our RsMmFormer model by incorporating convolutional layers. This allows us to integrate the favorable characteristics of convolutional neural networks (CNNs). Next, we introduce the Multi-scale Multi-head Self-Attention (MSMHSA) module, which enables learning detailed representations, facilitating the detection of small targets occupying only a few pixels in the remote sensing image. The proposed MSMHSA module facilitates the integration of Hyperspectral Imaging (HSI) and LiDAR data in a progressive and detailed manner, effectively attending to both global and local contexts using self-attention mechanisms. Comprehensive experiments conducted on popular benchmarks such as Trento and MUUFL showcase the effectiveness and superiority of our proposed RsMmFormer model for remote sensing image classification.","The acquisition of Twitter by Elon Musk has spurred controversy and uncertainty among Twitter users. The move raised both praise and concerns, particularly regarding Musk's views on free speech. As a result, a large number of Twitter users have looked for alternatives to Twitter. Mastodon, a decentralized micro-blogging social network, has attracted the attention of many users and the general media. In this paper, we analyze the migration of 136,009 users from Twitter to Mastodon. We inspect the impact that this has on the wider Mastodon ecosystem, particularly in terms of user-driven pressure towards centralization. We further explore factors that influence users to migrate, highlighting the effect of users' social networks. Finally, we inspect the behavior of individual users, showing how they utilize both Twitter and Mastodon in parallel. We find a clear difference in the topics discussed on the two platforms. This leads us to build classifiers to explore if migration is predictable. Through feature analysis, we find that the content of tweets as well as the number of URLs, the number of likes, and the length of tweets are effective metrics for the prediction of user migration.","SVM utilizes the hinge loss function and maximum margin to find the separating hyperplane. In SVM, only the boundary instances/support vectors confine the separating hyperplane, making it susceptible to noisy samples near the decision boundary. This work proposes a novel noise-robust eagle loss function and presents Eagle-SVM based on the proposed loss function. The formulation of the eagle loss function was motivated by examining the state-of-the-art loss assignment policy. It allocates the loss value as per instance significance. The more important instances are assigned higher loss values, whereas those corresponding to outliers and noise are assigned lower loss values. The experiments were conducted on the benchmark datasets downloaded from the UCI repository to compare the performance of the proposed variant of SVM with hinge loss SVM, pinball loss SVM, \u03f5-pinball loss SVM, SVM-CL, relabel SVM, 2medianSVM and 2meanSVM. The experimental results demonstrate that the eagle loss SVM outperforms all the state-of-the-art variants of SVM and is robust due to the incorporation of the novel loss assignment policy.\nHighlights\n\u2022\nA noise-robust loss function entitled Eagle Loss Function.\n\u2022\nNoise-robust EagleSVM using Eagle Loss Function.\n\u2022\nRobust classifiers towards feature noise and target noise.","Recognizing the species composition of an ecosystem is essential for conservation and land management. This study presents the software Class3Dp, a supervised classifier of vegetation species for coloured point clouds. Class3Dp is run through a graphical user interface (GUI) that allows for the selection of training samples from RGB or MS (multispectral) clouds and their classification based on geometric, spectral and neighbourhood features, along with different machine learning methods, obtaining the point cloud classified according to the classes (species) introduced. A case study is shown where a classification of ground and vegetation is carried out, obtaining an overall accuracy (OA) of 0.94 in the RGB classification and 0.95 in the MS. Points classified as vegetation were re-classified in the species Anthyllis cytisoides L., Chamaerops humilis L., Cistus monspeliensis L., Pistacia lentiscus L. and Quercus coccifera L., obtaining an OA of 0.86 in the RGB classification and 0.87 in the MS.\nHighlights\n\u2022\nClass3Dp is a supervised classifier software of coloured point clouds based on 3D and spectral information.\n\u2022\nThe software is designed to classify plant species in RGB and multispectral point clouds.\n\u2022\nClass3Dp calculates up to 48 features and supports five machine learning models.","Shapelets are subsequences that are effective for classifying time-series instances. Learning shapelets by a continuous optimization has recently been studied to improve computational efficiency and classification performance. However, existing methods have employed predefined and fixed shapelet lengths during the continuous optimization, despite the fact that shapelets and their lengths are inherently interdependent and thus should be jointly optimized. To efficiently explore shapelets of high quality in terms of interpretability and inter-class separability, this study makes the shapelet lengths continuous and learnable. The proposed formulation jointly optimizes not only a binary classifier and shapelets but also shapelet lengths. The derived SGD optimization can be theoretically interpreted as improving the quality of shapelets in terms of shapelet closeness to the time series for target / off-target classes. We demonstrate improvements in area under the curve, total training time, and shapelet interpretability on UCR binary datasets.","Skip Abstract Section\nAbstract\nBreast cancer is a divergent and prominent cancer that is responsible for the morbidity and mortality of women throughout the world. This paper aims at early detection and accurate diagnosis of this fatal disease, which is one of the most important steps in breast cancer treatment. Therefore, various nested ensemble machine learning techniques are used to help doctors determine breast cancer at an early stage. The two-layer nested ensemble model has been proposed, which encompasses stacking and voting techniques to detect benign and malignant breast cancer tumors. A total of four two-layer nested ensemble models have been proposed. S(NaiveBayes)-V(3-Meta_Learner), S(BayesNet)-V(3-Meta_Learner), S(NaiveBayes)-V(4-Meta_Learner), and S(BayesNet)-V(4-Meta_Learner) have been designed to contain base learners and meta learners. The experiments have been conducted with the k-fold cross-validation technique for model evaluation. The proposed model is capable of classifying benign and malignant breast cancer tumors with 99.50% accuracy. The aforementioned four models have been compared with previous works in terms of classification accuracy, ROC, recall, precision, TP rate, FP rate, and F1 measure. The experiments showed that the proposed two-layer nested ensemble model S(BayesNet)-V(4-Meta_Learner) performed better than the other three models mentioned supra and competed with all the previously published works. This would help the scientific community and health practitioners diagnose breast cancer with early and accurate results.","The North Atlantic Right Whale (NARW) population is currently teetering on the brink of extinction, with a mere approximate count of 350 individuals remaining. These animals have been protected under the Endangered Species Act since 1970. Today, the survival of right whales is imperiled primarily due to vessel collisions, net entanglements, and habitat degradation. This paper presents a novel system of animal-computer interaction founded on the identification of bioacoustic signatures. Initially, NARWs\u2019 vocalizations were transformed into spectrograms, which were subsequently inputted into a Convolutional Neural Network (CNN). To enhance robustness against environmental noise, techniques such as time warping, frequency masking, and time masking were employed. The outcomes of our study indicate that the proposed system holds potential for establishing a closed-loop interaction framework between vessels and NARWs. This framework could enable vessels to adapt their speed or avoid routes frequented by NARWs. Furthermore, this article discusses the potential benefits of employing networked sensors, such as Internet of Things (IoT) devices, to augment NARW monitoring and data collection efforts.","Airborne pollen identification is crucial to help patients prevent pollinosis symptoms. Existing data-driven methods rely on large-scale pollen images with simple backgrounds. In real scenarios, the background is complex and the data scale is small. Therefore, these methods suffer from two challenges: (1) Irrelevant information interference; (2) Incomplete feature attention. To overcome these challenges, we propose a prior knowledge-guided deep feature learning (PK-DFL) for real-world optical microscope image classification. Its main steps are as follows: Pollen location is designed to locate pollen grains based on color features, aiming to boost the accuracy of shape and texture prior feature extraction. Shape-texture awareness helps to extract the shape and texture of pollen grains via predefined feature extractors (i.e., a set of shape descriptors and an improved SFTA). These features are used to construct two types of prior knowledge, namely shape-texture attention maps (STA maps) and shape-texture feature vectors (STF vectors). Pollen classification uses a deep network (CNN) to classify pollen via imitating the pollen identification procedure of palynologists. It uses STA maps to weight pollen images and convolutional feature maps for instructing the CNN to focus on critical areas of pollen images (for the first challenge). STF vectors are employed to obtain the inter-class similarity of pollen via template matching. This information is further converted to soft targets that are used to supervise the CNN attending to comprehensive key features (for the second challenge). Extensive experiments on real-world datasets demonstrate the effectiveness of our PK-DFL (with accuracy and F1-score over 88%).\nHighlights\n\u2022\nA deep learning model for identifying allergic pollen like a palynologist.\n\u2022\nPollen location and predefined feature extractors for shape-texture extraction.\n\u2022\nAttention instruction manner for guiding CNNs to focus on critical areas.\n\u2022\nSoft target supervision manner for guiding CNNs to attend to key features.\n\u2022\nExtensive experiments for performance evaluation (accuracy over 88%).","In an actual industrial scenario, machines typically operate normally for the majority of the time, with malfunctions occurring only occasionally. As a result, there is very little recorded data on defects. Consequently, the fault diagnostic dataset becomes imbalanced, with a significantly lower number of fault samples compared to normal samples. Furthermore, with the rapid development of the manufacturing industry, the increasing complexity of machines and equipment leads to various challenges in collecting fault data, such as noise, within-class imbalance, multi-class imbalance, and time series imbalance. It is worth noting that this study is the first to comprehensively summarize these four specific challenges. Therefore, addressing these issues has become a critical research focus and a pain point in the field of fault diagnosis, and numerous solutions have emerged. This study provides a comprehensive overview of these solutions at three levels: data preprocessing, feature extraction, and classifier improvement. It also describes the applications of imbalanced data classification methods, including pure resampling techniques, as well as sampling techniques that combine resampling algorithms with feature extraction and classifier improvement in industrial scenarios. Finally, we summarize the challenges facing imbalanced data classification research and suggest potential directions for future studies.\nHighlights\n\u2022\nThis paper showcases using imbalance classification for diagnosing industrial faults.\n\u2022\nThis study is the first to comprehensively summarize these five specific challenges.\n\u2022\nChallenges include noise, class overlap, and imbalance within/multi-class/time series.\n\u2022\nStudy covers data pre-processing, feature extraction, and classifier improvement.\n\u2022\nStudy suggests the future research directions for imbalanced fault diagnosis.","The primary research objective of this study is to develop an algorithm pipeline for recognizing human locomotion activities using multimodal sensor data from smartphones, while minimizing prediction errors due to data differences between individuals. The multimodal sensor data provided for the 2023 SHL recognition challenge comprises three types of motion data and two types of radio sensor data. Our team, \u2018HELP,\u2019 presents an approach that aligns all the multimodal data to derive a form of vector composed of 106 features, and then blends predictions from multiple learning models which are trained using different number of feature vectors. The proposed neural network models, trained solely on data from a specific individual, yield F1 scores of up to 0.8 in recognizing the locomotion activities of other users. Through post-processing operations, including the ensemble of multiple learning models, it is expected to achieve a performance improvement of 10% or greater in terms of F1 score.","In pattern recognition and data mining a data set is named skewed or imbalanced if it contains a large number of objects of certain type and a very small number of objects of the opposite type. The imbalance in data sets represents a challenging problem for most classification methods, this is because the generalization power achieved for classic classifiers is not good for skewed data sets. Many real data sets are imbalanced, so the development of new methods to face this problem is necessary. The SVM classifier has an exceptional performance for data sets that are not skewed, however for imbalanced sets the optimal separating hyper plane is not enough to achieve acceptable results. In this paper a novel method that improves the performance of SVM for skewed data sets is presented. The proposed method works by exciting the support vectors and displacing the separating hyper plane towards majority class. According to the results obtained in experiments with different skewed data sets, the method enhances not only the accuracy but also the sensitivity of SVM classifier on this kind of data sets.","Parkinson\u2019s disease (PD) is the second most common neurodegenerative disorder, as reported by the World Health Organization (WHO). In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit (SWEDD) and Healthy Control (HC). We use white matter (WM) and gray matter (GM) from the MRI and fractional anisotropy (FA) and mean diffusivity (MD) from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53% for the direct three-class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.","The greatest significant contributor to cancer-related morbidity and mortality worldwide is malignant lung tumors. Lung cancer frequency has been seen to be on the rise recently. Lung cancer histopathology diagnosis is a crucial part of the patient\u2019s treatment. The current study aims to demonstrate the efficiency of convolutional neural networks for the identification of squamous cell carcinoma and adenocarcinoma of the lung and colon by investigating the diagnosis of histopathology images. Five state-of-the-art pre-trained (ImageNet) convolutional neural network architectures, VGG-19, InceptionResNetV2, DenseNet201, EfficientNetB6, and MobileNetV2, are employed in this investigation to tri-categorize lung cancer images (normal, adenocarcinoma, and squamous cell carcinoma), together with colon cancer images (normal and adenocarcinoma). Regularization strategies have been applied to fine-tune the learning rate for improving accuracy. The LC25000 dataset has been used to validate the proposed method. EfficientNetB6, VGG19, InceptionResNetV2, DenseNet201, and MobileNetV2 accuracy on test data is reported to be 93.12, 98.00, 97.92, 99.12, and 99.32 percent respectively.","The traditional k-mean clustering algorithm has some drawbacks, such as the need to manually determine the initial K value in advance, and the value may not match the real data distribution, and is susceptible to noise, thus causing classification errors. In this paper, we take the lead in improving the contour coefficient solving code and the k-mean clustering algorithm, so that the two improved codes can cooperate with each other to improve the accuracy of the results of the algorithm.\nFirstly, we use variance comparison to sub-classify the dataset, aiming to find the initial clustering center of the dataset, use the k-means clustering algorithm to classify the dataset, and finally introduce the contour coefficient to evaluate the classification results. Finally, we apply this algorithm to an example of artifact classification and train the improved algorithm with a large amount of data, and the results demonstrate that the contour coefficient-k-mean clustering algorithm yields high accuracy in the classification results.","Given a large convolutional neural network (CNN) with hundreds of layers, when can the input data be correctly classified? How many layers does each image require? We propose an architecture with a mid-network classifier to classify certain images at earlier points in the model. When the network is very confident about an image, having high activations, then that individual image will be classified early. The number of computations and the average number of convolutions will be reduced if certain images can be classified earlier. In addition, the mid-network classification task is more difficult because fewer features have been extracted at earlier points in the network. Thus, the output and mid-network classifier will work together to correctly classify each image as fast as possible while preserving the accuracy. This proposed method has been implemented into well known computer vision architectures, like ResNet and GoogLeNet Inception. We have achieved large runtime improvements while limiting the accuracy degradation.","Multi-dimensional classification (MDC) assumes that each instance has multiple heterogeneous class spaces simultaneously, and each class variable describes the semantic information of instances from a specific dimension. Recent studies have proven that encoding heterogeneous class spaces into a special logical-label space and employing the label enhancement technique to learn latent real-number labels (i.e., label distributions) of instances is an effective strategy for MDC. However, the adopted label enhancement methods can result that data whose features are quite different to each other have similar label distributions. To tackle this problem, we propose a novel probability-based label enhancement approach for MDC. Specifically, manifold structures of the feature and label distribution spaces are transformed into two different probability distributions, and we expect them to be close. Subsequently, it makes label distributions of samples whose features have large differences be more differentiated. Moreover, the logical-label mapping and reconstruction terms are designed to preserve the intrinsic information from the logical-label space. Besides, an improved multi-output support vector regression is developed as the prediction model, where we introduce mean squared error to reduce the risk of model underfitting. Experimental results on ten benchmark datasets clearly validate the superiority of our method over state-of-the-art MDC baselines.","Federated learning (FL), a decentralized machine learning technique, enhances privacy by enabling multiple devices to collaboratively train a model without transferring data to a central server. FL is used in Human Activity Recognition (HAR) problems, where multiple users generating private wearable data share models with a server to learn a useful global model. However, FL may compromise data privacy through model information sharing during training. Moreover, it adheres to a one-size-fits-all approach toward data privacy, potentially neglecting varied user preferences in collaborative scenarios such as HAR. In response to these challenges, this paper presents a collaborative learning framework integrating differential privacy (DP) and FL, thus providing a tailored approach to privacy protection. While some existing works integrate DP and FL, they do not allow clients to have different privacy preferences. In this work, we introduce a framework that allows different clients to have different privacy preferences and hence more flexibility in terms of privacy. In our framework, DP adds individualized noise to individual clients\u2019 gradient updates for privacy. However, such noised updates can also be interpreted as an attack on the FL system. Defending against these attacks might result in excluding honest private clients altogether from training, posing a fairness concern. On the other hand, not having any defensive measures might allow malicious users to attack the system, posing a security issue. Thus, to address security and fairness, our framework incorporates a client selection strategy that protects the global model from malicious clients and provides fair model access to honest private clients. We have demonstrated the effectiveness of our system on a HAR dataset and provided insights into our framework\u2019s privacy, utility, and fairness.","Data-driven fault diagnosis approaches have attracted considerable attention in the past few years, and promising diagnostic performance has been achieved with sufficient monitoring data. However, in real industrial scenarios, individual users often struggle to collect enough labeled data. Meanwhile, direct data aggregation from multiple users is not always feasible due to data privacy concerns and conflicts of interest. To solve this issue, a novel federated contrastive prototype learning scheme is proposed for collaborative fault diagnosis of rotating machinery. The collaborative modeling between the central server and multiple clients is implemented to establish a global fault diagnostic model with data privacy. A contrastive prototype learning module is designed to align the prototypes of the same classes across different clients while separating them away from other class prototypes, thus effectively eliminating distribution discrepancies across clients and learning domain-invariant discriminative features. To remove the bias of the global model during federated communication, an unbiased prototype learning module is constructed, which aligns the class prototypes of different clients to the global prototype center and enhances the generalization ability of the proposed approach under unseen conditions. Experimental results on two self-built testbeds and a laboratory dataset demonstrate that the proposed approach is a potential solution for real-world fault diagnosis applications.","Lung cancer (LC) remains a leading cause of death worldwide. Early diagnosis is critical to protect innocent human lives. Computed tomography (CT) scans are one of the primary imaging modalities for lung cancer diagnosis. However, manual CT scan analysis is time-consuming and prone to errors/not accurate. Considering these shortcomings, computational methods especially machine learning and deep learning algorithms are leveraged as an alternative to accelerate the accurate detection of CT scans as cancerous, and non-cancerous. In the present article, we proposed a novel transfer learning-based predictor called, Lung-EffNet for lung cancer classification. Lung-EffNet is built based on the architecture of EfficientNet and further modified by adding top layers in the classification head of the model. Lung-EffNet is evaluated by utilizing five variants of EfficientNet i.e., B0\u2013B4. The experiments are conducted on the benchmark dataset \u201cIQ-OTH/NCCD\u201d for lung cancer patients grouped as benign, malignant, or normal based on the presence or absence of lung cancer. The class imbalance issue was handled through multiple data augmentation methods to overcome the biases. The developed model Lung-EffNet attained 99.10% of accuracy and a score of 0.97 to 0.99 of ROC on the test set. We compared the efficacy of the proposed fine-tuned pre-trained EfficientNet with other pre-trained CNN architectures. The predicted outcomes demonstrate that EfficientNetB1 based Lung-EffNet outperforms other CNNs in terms of both accuracy and efficiency. Moreover, it is faster and requires fewer parameters to train than other CNN based models, making it a good choice for large-scale deployment in clinical settings and a promising tool for automated lung cancer diagnosis from CT scan images.\nHighlights\n\u2022\nWe developed a novel transfer learning framework using EfficientNetB1 for lung cancer classification.\n\u2022\nWe solved the severe imbalance issue by using augmentation method to overcome the skewness of data.\n\u2022\nWe compared the novel designed model with other advanced methods in terms of execution time and computational complexity to demonstrate the performance of EfficientNet over other classification models.\n\u2022\nOur proposed model Lung-EffNet demonstrates superior performance in comparison to existing methods and targeting lung cancer from CT scan images.","Social and political polarization has become a dramatically intensifying force that is having a huge impact on political discourse, public policies and electoral outcomes in the 21st century. Twitter is a social media platform that mirrors to a large extent the sociological notion of public opinion, and has notably fueled these polarization dynamics worldwide. A proper understanding of how different issues become polarized in Twitter and their interrelationship is therefore crucial for the development of effective policies and governance strategies in our democracies. This paper introduces TwiSP, a framework for analyzing polarization on controversial topics in Twitter. TwiSP utilizes a combination of two cutting-edge machine learning techniques: stance detection for identifying attitudes and perspectives and BERTopic for topic modeling. The outcome of TwiSP is a visual tree-like representation of all tweets related to conflicting topics (rooted in a particular topic), contrasting their relationship using different colors to denote the degree of polarization. As a case study, we show how the TwiSP framework can be used for analyzing polarized issues in the context of the COVID-19 vaccine, exploring the resulting degree of polarization and the key topics driving it. The results reveal the diversity of opinions and the presence of highly polarized clusters in social media discussions. We contend that the TwiSP framework provides a novel and valuable tool for decision makers, helping them to recognize contentious issues behind the dynamics of polarization and ultimately identifying potential opportunities for bridging divides.","Research on machine activity recognition (MAR) is drawing more attention because MAR can provide productivity monitoring for efficiency optimization, better maintenance scheduling, product design improvement, and potential material savings. A particular challenge of MAR for human-operated machines is the overlap when transiting from one activity to another: during transitions, operators often perform two activities simultaneously, e.g., lifting the fork already while approaching a rack, so the exact time when one activity ends and another begins is uncertain. Machine learning models are often uncertain during such activity transitions, and we propose a novel ensemble-based method adapted to fuzzy transitions in a forklift MAR problem. Unlike traditional ensembles, where models in the ensemble are trained on different subsets of data, or with costs that force them to be diverse in their responses, our approach is to train a single model that predicts several activity labels, each under a different context. These individual predictions are not made by independent networks but are made using a structure that allows for sharing important features, i.e., a context ensemble. The results show that the gated recurrent unit network can provide medium or strong confident context ensembles for 95% of the cases in the test set, and the final forklift MAR result achieves accuracies of 97% for driving and 90% for load-handling activities. This study is the first to highlight the overlapping activity issue in MAR problems and to demonstrate that the recognition results can be significantly improved by designing a machine learning framework that addresses this issue.","Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose a simple but effective Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header learns from different clients. The acquired global knowledge is then transferred to clients to substitute each client's local prediction header. We derive the non-convex convergence rate of FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH achieves significantly more advantageous performance in both model-homogeneous and -heterogeneous FL scenarios compared to seven state-of-the-art personalized FL models, beating the best-performing baseline by up to 8.87% (for model-homogeneous FL) and 1.83% (for model-heterogeneous FL) in terms of average test accuracy, while saving up to 85.53% of communication overhead.","Ensemble methods and conventional base class learners have effectively been applied in the realm of educational data mining to ameliorate the accuracy and consistency in prediction. Primarily in the contemporary study, researchers conducted empirical results on pedagogical real dataset acquired from University of Kashmir, using miscellaneous base classifiers viz. j48, random forest and random tree, to predict the performance of students. However, in the later phase, the pedagogical dataset was subjected to more proficient version of stacking viz. stackingC, with the principle objective to ameliorate the performance of students. Furthermore, the dataset was deployed with filtering procedures to corroborate any improvement in results, after the application of techniques such as synthetic minority oversampling technique (SMOTE) and spread sub-sampling method. Moreover, in case of ensemble stackingC, hybridization of predicted output was carried out with three base classifier vis-a- vis j48, random forest and random tree, and the classifier achieved paramount accuracy of 95.65% in predicting the actual class of students. The findings have by and large noticeably corroborated that the stackingC classifier, attained significant prediction accuracy of 95.96% when undergone through undersampling (spread sub-sampling) and 96.11% using oversampling (SMOTE). As a subject of corollary, it calls upon the researchers to broaden the canvas of literature by employing the analogous methods to uncover the diverse patterns hidden in academic datasets.","The predictive performance of machine learning models tends to deteriorate in the presence of class imbalance. Multiple strategies have been proposed to address this issue. A popular strategy consists of oversampling the minority class. Classic approaches such as SMOTE utilize techniques like nearest neighbor search and linear interpolation, which can pose difficulties when dealing with datasets that have a large number of dimensions and intricate data distributions. As a way to create synthetic examples in the minority class, Generative Adversarial Networks (GANs) have been suggested as an alternative technique due to their ability to simulate complex data distributions. However, most GAN-based oversampling methods tend to ignore data uncertainty. In this paper, we propose a novel GAN-based oversampling method using evidence theory. An auxiliary evidential classifier is incorporated in the GAN architecture in order to guide the training process of the generative model. The objective is to push GAN to generate minority objects at the borderline of the minority class, near difficult-to-classify objects. Through extensive analysis, we demonstrate that the proposed approach provides better performance, compared to other popular methods.","Deep learning-based approaches for three-dimensional (3D) grid understanding and processing tasks have been extensively studied in recent years. Despite the great success in various scenarios, the existing approaches fail to effectively utilize the velocity information in the flow field, resulting in the actual requirements of post-processing tasks being difficult to meet by the extracted features. To fully integrate structural information in the 3D grid and velocity information, this paper constructs a flow-field-aware network (FFANet) for 3D grid classification and segmentation tasks. The main innovations include: (i) using the self-attention mechanism to build a multi-scale feature learning network to learn the distribution feature of the velocity field and structure feature of different scales in the 3D flow field grid, respectively, for generating a global feature with more discriminative representation information; (ii) constructing a fine-grained semantic learning network based on a co-attention mechanism to adaptively learn the weight matrix between the above two features to enhance the effective semantic utilization of the global feature; (iii) according to the practical requirements of post-processing in numerical simulation, we designed two downstream tasks: 1) surface grid identification task and 2) feature edge extraction task. The experimental results show that the accuracy (Acc) and intersection-over-union (IoU) performance of the FFANet compared favourably to the 3D mesh data analysis approaches.","Deep NLP models are correlation-based learning, which has a critical limitation of over-fitting over spurious features and shows poor generalization capability in the out-of-distribution (OOD) setting. Existing methods encourage the model to exploit causal features and exclude spurious correlations through Counterfactually Augmented Data (CAD) and feature regularization. However, those methods still face challenges due to the low quality of counterfactual generation and the high cost of annotation. This paper proposes an improved method for OOD generalization motivated by causal inference tools. Specifically, taking the topic of the text as the confounder of the input and the label, the model fits the causal correlation between the representations and the label through the backdoor adjustment to alleviate the exploitation of the spurious correlations. The proposed method is evaluated on the counterfactual adversarial test set (movie review text) and the challenging test set with synonym perturbation (financial news text) provided in the previous work. The experimental results show that this method improves the OOD generalization capability of the sentiment classification models in these two attacks while preserving the predictive ability, especially in the case of long text.","Supervised and unsupervised classification is crucial in many areas where different types of data sets are common, such as biology, medicine, or industry, among others. A key consideration is that some units are more typical of the group they belong to than others. For this reason, fuzzy classification approaches are necessary. In this paper, a fuzzy supervised classification method, which is based on the construction of prototypes, is proposed. The method obtains the prototypes from an objective function that includes label information and a distance-based depth function. It works with any distance and it can deal with data sets of a wide nature variety. It can further be applied to data sets where the use of Euclidean distance is not suitable and to high-dimensional data (data sets in which the number of features p is larger than the number of observations n, often written as p &gt; &gt; n). In addition, the model can also cope with unsupervised classification, thus becoming an interesting alternative to other fuzzy clustering methods. With synthetic data sets along with high-dimensional real biomedical and industrial data sets, we demonstrate the good performance of the supervised and unsupervised fuzzy proposed procedures.\nHighlights\n\u2022\nNew fuzzy classification methodology based on the construction of prototypes\n\u2022\nDistance-based, it overcomes the curse of dimensionality\n\u2022\nIt can be applied to a large spectrum of data, when the Euclidean distance is not suitable\n\u2022\nIt identifies K observations, selected between the deepest observations\n\u2022\nSupervised and unsupervised approaches integrated in the objective function","Information-theoretic measures have been commonly applied to evaluate the relevance and redundancy in multi-label feature selection. However, the current multi-label feature selection methods based on information-theoretic measures neglect the dynamic changes in the relevance of selected features and candidate features. Furthermore, they also do not fully consider the influence of label redundancy on the relevance of candidate features. In this paper, we first propose a new feature relevance term named Dynamic Correlation Change (DCC), which uses two conditional mutual information terms to evaluate the dynamic changes in the relevance of selected features and candidate features. We then introduce a new label redundancy term named Label Redundancy with Interaction Information (LRII), which more accurately quantifies the influence of label redundancy on the relevance of candidate features. On this basis, we design a new multi-label feature selection method, called Maximum Dynamic Correlation Change and Minimum Label Redundancy (MDCCMLR), by combining DCC and LRII. Finally, we conduct extensive experiments in order to verify the performance of our method by comparing it with some state-of-the-art multi-label feature selection methods based on information-theoretic measures in terms of six evaluation metrics. The experimental results show that the MDCCMLR method outperforms the other comparison methods on all six evaluation metrics.","Many existing image and text sentiment analysis methods only consider the interaction between image and text modalities, while ignoring the inconsistency and correlation of image and text data, to address this issue, an image and text aspect level multimodal sentiment analysis model using transformer and multi-layer attention interaction is proposed. Firstly, ResNet50 is used to extract image features, and RoBERTa-BiLSTM is used to extract text and aspect level features. Then, through the aspect direct interaction mechanism and deep attention interaction mechanism, multi-level fusion of aspect information and graphic information is carried out to remove text and images unrelated to the given aspect. The emotional representations of text data, image data, and aspect type sentiments are concatenated, fused, and fully connected. Finally, the designed sentiment classifier is used to achieve sentiment analysis in terms of images and texts. This effectively has improved the performance of sentiment discrimination in terms of graphics and text.","NAVTEX is a crucial marine safety information broadcasting system for ensuring the safe navigation of ships, which plays a significant role in ship safety. However, the current manual reading and subject classification of NAVTEX suffer from low efficiency and accuracy. To enhance the processing efficiency of maritime safety information (MSI) and promote information and communication, achieving automated MSI classification with high confidence in the accuracy of the results becomes imperative. In the context of machine learning, this study proposes an adaptive weight TFIDF method to address the aforementioned challenges. The primary objective is to optimize the weights of keywords with prominent classification features in NAVTEX. Experimental results demonstrate that the adaptive weight-based TFIDF algorithm significantly improves the classification outcomes for NAVTEX. By enhancing the accuracy and efficiency of MSI classification, this approach facilitates the automation of NAVTEX analysis and promotes the reliability of the generated classification results.","Machinery fault diagnosis based on deep learning methods is cost-effective to guarantee safety and reliability of mechanical systems. Due to the variability of machinery working condition and difficulty of data obtaining under different health states, it is desirable to enhance the generalization capability to unseen working conditions for the fault diagnosis models trained by available data sets under limited number of working conditions. Considering that labeling industrial data is also a laborious work, this paper proposes a novel semi-supervised domain generalization model, termed domain-invariant feature fusion networks (DIFFN) for intelligent fault diagnosis under unseen target working conditions. The main contributions are that, intra-domain-invariant features are considered to capture the intrinsic semantic information within the domain and are fused with inter-domain-invariant features to enhance the discrimination and generalization abilities in fault diagnosis. First, a domain-invariant representation learning method is established to learn the inter- and intra-domain-invariant features using two network branches and fuse them via a fusion module. Second, a mutual learning strategy is designed to enable the network branches and the fusion module to learn from each other, thereby improving the discrimination of the extracted features for accurate fault diagnosis. Lastly, a feature divergence maximization strategy is embedded between the two network branches to improve the generalization ability of the fault diagnosis model. Experiments on two bearing data sets demonstrate that the proposed model has better diagnostic accuracy and stability over state-of-the-art semi-supervised domain generalization methods, indicating its great potential for application in generalization fault diagnosis of machinery under unseen target working conditions.\nHighlights\n\u2022\nDIFFN is proposed to realize semi-supervised generalization fault diagnosis.\n\u2022\nInter- and intra-domain-invariant features are sufficiently exploited.\n\u2022\nA mutual learning strategy is designed to promote the discrimination of features.\n\u2022\nFeature divergence maximization strategy enhances the feature diversification.\n\u2022\nBearing generalization diagnosis experiments validate the superiority of DIFFN.","Objective. Wireless sensor networks, crucial for various applications, face growing security challenges due to the escalating complexity and diversity of attack behaviours. This paper presents an advanced intrusion detection algorithm, leveraging feature-weighted Naive Bayes (NB), to enhance network attack detection accuracy. Methodology. Initially, a feature weighting algorithm is introduced to assign context-based weights to different feature terms. Subsequently, the NB algorithm is enhanced by incorporating Jensen\u2013Shannon (JS) divergence, feature weighting, and inverse category frequency (ICF). Eventually, the improved NB algorithm is integrated into the intrusion detection model, and network event classification results are derived through a series of data processing steps applied to corresponding network traffic data. Results. The effectiveness of the proposed intrusion detection algorithm is evaluated through a comprehensive comparative analysis using the NSL-KDD dataset. Results demonstrate a significant enhancement in the detection accuracy of various attack types, including normal, denial of service (DoS), probe, remote-to-local (R2L), and user-to-root (U2R). Moreover, the proposed algorithm exhibits a lower false alarm rate compared to other algorithms. Conclusion. This paper introduces a wireless network intrusion algorithm that not only ensures improved detection accuracy and rate but also reduces the incidence of false detections. Addressing the evolving threat landscape faced by wireless sensor networks, this contribution represents a valuable advancement in intrusion detection technology.","Enduring stress can have negative impacts on human health and behavior. Widely used wearable devices are promising for assessing, monitoring and potentially alleviating high stress in daily life. Although numerous automatic stress recognition studies have been carried out in the laboratory environment with high accuracy, the performance of daily life studies is still far away from what the literature has in laboratory environments. Since the physiological signals obtained from these devices are time-series data, Recursive Neural Network (RNN) based classifiers promise better results than other machine learning methods. However, the performance of RNN-based classifiers has not been extensively evaluated (i.e., with several variants and different application techniques) for detecting daily life stress yet. They could be combined with CNN architectures, applied to raw data or handcrafted features. In this study, we created different RNN architecture variants and explored their performance for recognizing daily life stress to guide researchers in the field.","Transformers with long-range dependency and data specificity act as an effective means of classifying insect pests in agricultural engineering. Although many methods have been proposed to confine the range of self-attention within a local region to reduce the computation complexity, none of them can reduce the number of model parameters. Moreover, the self-attention mechanism usually causes query tokens to focus excessively on image patches, which limits the effective receptive field and the long-range dependence. To address these issues, this paper establishes a novel Dilated-Windows-based Vision Transformer with Efficient-Suppressive-self-attention (DWViT-ES) architecture, which includes efficient-self-attention (ESA), dilated window (DW), and suppressive-self-attention (SSA) as its core components. The ESA simplifies the successive linear Transformations to reduce the number of model parameters and computational costs. Meanwhile, the DW and SSA expand the effective receptive field of self-attention mechanism to prevent query tokens from focusing on similar and close regions, thereby preventing the loss of useful information. Finally, experiments show that the DWViT-ES only has 19.6 M parameters and 3.5G FLOPs (over 20% reductions vs. 19.6 M and 4.5G of Swin-T). Meanwhile, the DWViT-ES training from scratch has 71.6% top-1 accuracy on the IP102 dataset (2.4% absolute improvement of Swin-T); after fine-tuning on Imagenet-1K, the DWViT-ES achieves 76.0% and 78.7% top-1 accuracy on IP102 and CPB (0.1% and 0.9% absolute improvement of Swin-T), respectively. Meanwhile, practical deployment on a mobile-embedded device is presented, which validates the feasibility of the DWViT-ES.","Intention recognition of non-cooperative target is an important basis for battlefield command decision-making. Recent advances suggest recognizing target intention from a perspective of data-driven. However, existing data-driven models do not consider complementary information between features to enhance their robustness in battlefield environments. To solve the problem, this paper constructs a novel neural network fusion model with information classification processing and information fusion to achieve target intention recognition. The model first designs the cross-classification processing method according to attributes\u2019 correlations and variation characteristics. Then, an interactive feature-level fusion method is proposed to model the fine-grained correlations between attributes to discover salient features. Finally, a decision-level fusion method based on Dempster\u2013Shafer theory is proposed to fuse the complementary information among attributes. The experimental results show that the recognition accuracy of the proposed model can reach 89.63%, and it can be maintained above 75% under the conditions of severe attribute missing or noise interference. It is demonstrated that the proposed model has higher accuracy and robustness in battlefield incomplete information environments.\nHighlights\n\u2022\nAn artificial neural network model with information classification processing and information fusion is constructed for target intention recognition.\n\u2022\nAn interactive feature-level fusion method is proposed to model the fine-grained correlations between attributes to discover salient features.\n\u2022\nA decision-level fusion method based on Dempster\u2013Shafer theory is proposed to fuse the complementary information among attributes.\n\u2022\nExperiments demonstrate that the proposed model has higher accuracy and robustness in battlefield incomplete information environments.","Origin: Warts are produced and developed on the human body due to infection induced by Human Papillomavirus. The most influenced zone of warts are hands and feet particularly, which is bit irritating and difficult to recoup in later stages. The major challenge in treating warts is the diversity of treatment method applicable on different patients, so it becomes difficult to recognize specific treatment method to be adopted in order to treat this infection. Ramifications of machine learning techniques in the medical domain have become crucial nowadays for early disease detection and developing expert systems. Objective: This research work focuses on enhancing predictive accuracy of J48, which is a binary decision tree based classifier by adding attributes based on genetic programming. These genetically tuned attribute construction not only just upgrades the classification capabilities of J48 classifier but also additionally expand the information space, intending J48 for giving more exact predictions for wart treatment method identification. Method: For their experimental setup, authors have chosen immunotherapy and cryotherapy datasets from UCI machine learning repositories, which includes instances of patients responses against treated with immunotherapy and cryotherapy methods for both plantar and common warts. The investigation has been led with the help of WEKA tool, which is an open source for performing data mining operations. Finding: After experimentation, it is found after inclusion of attributes generated through genetic programming, the classification accuracy of J48 can be increased by a substantial amount with less error rate. The result shows significant performance improvements in classification accuracy of J48 by 82.22% to 96.66% and 93.33% to 98.88% for immunotherapy and cryotherapy datasets, implemented with J48 and J48+GA respectively.","Feature selection, as an important pre-processing technique, can efficiently mitigate the issue of \u201cthe curse of dimensionality\u201d by selecting discriminative features especially for multi-label learning, a discriminative feature subset can improve the classification accuracy. The existing feature selection methods for multi-label classification address the problem of label ambiguity by with logical labels. However, the significance of each label is often different in many practical applications. Using logical label to train the model may result in unsatisfactory performance due to not considering the importance of related labels with each sample. To address this issue, a novel multi-label feature selection algorithm is proposed with two-step: label enhancement and label correlations-based feature selection with label enhancement. In the step of label enhancement, a framework of label enhancement based on deep forest is utilized to transform the logical label to label distribution, which contains rich semantic information and then guides a more correct exploration of semantic correlations. In the step of feature selection, a novel multi-label feature selection algorithm is proposed based on label distribution data. Firstly, the samples are divided into multiple different clusters by using spectral clustering in the label space. Then, the label correlations can be reflected by multiple different clusters. Finally, the l 2 , 1-norm is used to construct an objective function to achieve multi-label feature selection. Experimental results demonstrate that competitiveness of the proposed algorithm over six state-of-the-art multi-label feature selection algorithms on eighteen benchmark datasets in terms of six widely accepted evaluation metrics.","This article presents a novel automatic classification method for garment fabric pattern images using the vanilla Reset. The study begins by collecting industry-standard garment fabric images, which are further subjected to preprocessing techniques such as cropping, rotation, and contrast enhancement. These steps contribute to an expanded garment fabric image dataset. The dataset is then divided into a validation set and a training set for conducting image classification experiments. Different ResNet frameworks are employed to analyze the datasets and compare the results. The findings demonstrate that the classification model based on ResNet-34, serving as the backbone network, achieves the highest accuracy of 91.8% in garment fabric pattern classification. This performance surpasses the accuracy achieved by alternative backbone networks, namely AlexNet, VGG16, and GoogleNet, by a substantial margin. The superiority of ResNet-34 as a backbone network is thus affirmed. The proposed method's effectiveness is validated by the significant improvement in classification accuracy achieved by ResNet-34 compared to other backbone networks. These results highlight the potential of ResNet-34 in garment fabric pattern classification tasks. By leveraging the strengths of the ResNet architecture, our approach offers a promising solution for automating the classification of garment fabric patterns, contributing to efficiency and accuracy in the fashion industry. Overall, this study establishes the value of employing the ResNet-34 backbone network for garment fabric pattern image classification, as it outperforms competing networks and achieves remarkable classification accuracy. Future research can build upon these findings to explore further advancements in automatic garment fabric pattern classification.","Traditional techniques for network traffic classification are no longer effective in handling the complexities of dynamic network environments. Moreover, deep learning methods, while powerful, demand substantial spatial and computational resources, resulting in increased latency and instability. In this paper, we propose an innovative approach to network traffic classification utilising an LSTM structure. This approach incorporates network pruning, knowledge refinement, and Generative Adversarial Networks (GAN) to reduce model size, accelerate training speed without compromising accuracy, and address challenges associated with unbalanced datasets in classification problems. Our methodology involves the pruning of unimportant filters from the teacher model, followed by retraining and knowledge distillation to generate the student model. Experimental show that the size of the pruned teacher model is only 25.69% of the original, resulting in a noteworthy 28.16% improvement in training speed. Additionally, the classification performance of various unbalanced traffic categories, such as VoIP and streaming, shows significant enhancement.","Methods to classify objects into two or more classes are at the core of various disciplines. When a set of objects with their true classes is available, a supervised classifier can be trained and employed to decide if, for example, a new patient has cancer or not. The choice of performance measure is critical in deciding which supervised method to use in any particular classification problem. Different measures can lead to very different choices, so the measure should match the objectives. Many performance measures have been developed, and one of them is the F-measure, the harmonic mean of precision and recall. Originally proposed in information retrieval, the F-measure has gained increasing interest in the context of classification. However, the rationale underlying this measure appears weak, and unlike other measures, it does not have a representational meaning. The use of the harmonic mean also has little theoretical justification. The F-measure also stresses one class, which seems inappropriate for general classification problems. We provide a history of the F-measure and its use in computational disciplines, describe its properties, and discuss criticism about the F-Measure. We conclude with alternatives to the F-measure, and recommendations of how to use it effectively.","Highlights\n\u2022\nIntroduction of a novel model that integrates OBIA and the attention mechanism for precise orchard mapping.\n\u2022\nThe contribution of SAR is studied in orchard classification.\n\u2022\nThe model obtains more accurate classification results than RNN-based and CNN-based deep learning models.\n\u2022\nThe uncertainty of the super-pixel size on classification accuracy is investigated.\nAbstract\nReliable and accurate classification of orchards is important for the dynamic monitoring of large-scale orchards and food security evaluation. At present, the very similar spectral profiles of different fruit trees and the high susceptibility of optical data to interference by weather conditions limit the resolution of orchard classification. Synthetic Aperture Radar (SAR) imagery provides an advanced solution to this problem, with the advantages of being immune to weather conditions and advances in deep learning techniques. This paper presents an orchard classification model (STCM) with optical and SAR fusion, which integrates the advantages of the Simple Non-Iterative Clustering (SNIC) super-pixel algorithm with a deep learning algorithm based on a multi-headed attention mechanism, and it achieves the best classification accuracy of above 0.82 in comparison with existing deep learning models. Meanwhile, the model has exceptional classification accuracy and robustness in a study area with fragmented plots, many fruit tree species, and various distributions of optical images. In the absence of optical data, the classification accuracy of the STCM model using only SAR data is around 0.70, which makes the model have a promising potential application value. This study provides a technical solution for accurately obtaining different orchard categories in high-resolution remotely sensed orchard images. The study helps to improve the management and operation of orchards and provides a strong basis for decision-making in the fruit industry to enhance the sustainability of the global fruit industry.","Near infrared fluorescence optical imaging (NIR-FOI) is a relatively new imaging modality to diagnose arthritis in the hands. The acquired data has two spatial dimensions and one temporal dimension, which visualizes the time dependent distribution of an administered color agent. In accordance with previous work, we hypothesize that the distribution process allows a joint-wise classification into inflammatory affected and unaffected.\nIn this work, we present the first approach to objectively classify hand joint NIR-FOI image stacks by designing, training, and testing a neural network. Previously presented model architectures for spatio-temporal classification do not yield satisfying results when trained on NIR-FOI data. A recall value of 0.812 of the over- and a recall value of 0.652 of the underrepresented class is achieved, the model\u2019s robustness tested against small variations and its attention visualized in activation maps.\nEven though these results leave room for further improvement, they also indicate, that the model architecture can capture the latent features of the data. We are confident, that more available data will lead to a robust classification model and can support medical doctors in using NIR-FOI as a diagnostic tool for PsA.","Accurate integration of high-dimensional single-cell sequencing datasets is important for the construction of cell atlases and for the discovery of biomarkers. Because the performance of integration methods varies in different scenarios and on different datasets, it is important to provide end users with an automated system for the benchmarking and selection of the best integration among several alternatives. Here, we present a system that uses an ensemble of auditors, trained by supervised machine learning, which quantifies residual variability of integrated data and automatically selects the integration with the smallest difference between observed and expected batch effects. A rigorous and systematic validation was performed using 6 popular integration methods and 52 benchmark datasets. Algorithmic and data biases were uncovered and shortcomings of existing validation metrics were examined. Our results demonstrate the utility, validity, flexibility and consistency of the proposed approach.","In this paper we summarize the contributions of participants to the fifth Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenge organized at the HASCA Workshop of UbiComp/ISWC 2023. The goal of this machine learning/data science challenge is to recognize eight locomotion and transportation activities (Still, Walk, Run, Bike, Bus, Car, Train, Subway) from the motion (accelerometer, gyroscope, magnetometer) and GPS (GPS location, GPS reception) sensor data of a smartphone in a user-independent manner. The training data of a \u201ctrain\u201d user is available from smartphones placed at four body positions (Hand, Torso, Bag and Hips). The testing data originates from \u201ctest\u201d users with a smartphone placed at one, but unknown, body position. We introduce the dataset used in the challenge and the protocol of the competition. We present a meta-analysis of the contributions from 15 submissions, their approaches, the software tools used, computational cost and the achieved results. The challenge evaluates the recognition performance by comparing predicted to ground-truth labels at every 10 milliseconds, but puts no constraints on the maximum decision window length. Overall, five submissions achieved F1 scores above 90%, three between 80% and 90%, two between 70% and 80%, three between 50% and 70%, and two below 50%. While the task this year is facing the technical challenges of sensor unavailability, irregular sampling, and sensor diversity, the overall performance based on GPS and motion sensors is better than previous years (e.g. the best performance reported in SHL 2020, 2021 and 2023 are 88.5%, 75.4% and 96.0%, respectively). This is possibly due to the complementary between the GPS and motion sensors and also the removal of constraints on the decision window length. Finally, we present a baseline implementation to help understand the contribution of each sensor modality to the recognition task.","Micro-expressions are rapid and subtle facial movements that can reflect the most real emotional state hidden in the human heart. Classifying different micro-expressions is still challenging because of their short duration and low intensity. This paper proposes new neural network models, Simplified SE-DenseNet-cc and SE-ResNet-cc, incorporating Eulerian video magnification (EVM) to enlarge micro-expression movements. Important features can be selectively enhanced, and unimportant features can be compressed using SE-block. The experimental results show that our proposed methods perform better than most of the algorithms in CASME-II and SMIC.","It is common to observe significant heterogeneity in clustered data across scientific fields. Cluster-wise conditional distributions are widely used to explore variations and relationships within and among clusters. This paper aims to capture such heterogeneity by employing cluster-wise finite mixture models. To address the heterogeneity among clusters, we introduce latent group structure and incorporate heterogeneous mixing proportions across different groups, accommodating the diverse characteristics observed in the data. The specific number of groups and their membership are unknown. To identify the latent group structure, we employ concave penalty functions to the pairwise differences of the preliminary consistent estimators for the mixing proportions. This approach enables the automatic division of clusters into finite subgroups. Theoretical results demonstrate that as the number of clusters and cluster sizes tend to infinity, the true latent group structure can be recovered with probability close to one, and the post-classification estimators exhibit oracle efficiency. We support our proposed approach\u2019s performance and applicability through extensive simulations and analysis of basic consumption expenditure among urban households in China.","Plant diseases are a threat to the food supply as they reduce the yield, and reduce the quality of fruits and grains. Hence, early identification and classification of plant diseases are essential. This paper aims to classify mango plant leaves into healthy and diseased using convolutional neural networks (CNNs). The performance comparison of CNN architectures, AlexNet, VGG-16 and ResNet-50 for mango plant disease classification is provided. These models are trained using the Mendeley dataset, validation accuracies are found and compared with and without the use of transfer learning models. AlexNet (25 layers, 6.2 million parameters) produces a testing accuracy of 94.54% and consumes less training time. ResNet-50 (117 layers, 23 million parameters) and VGG-16 (16 layers, 138 million parameters) have given testing accuracies of 98.56% and 98.26% respectively. Therefore, based on the accuracies achieved and complexity, this paper recommends AlexNet followed by ResNet-50 and VGG-16 for plant leaf disease classification.","Predicting the secondary structure of proteins is a challenging task. A large variety approaches exist that include observation using equipment\u2019s and theoretical evaluation, in which the optimal structure is determined. The secondary structure determines 3D tertiary structure of protein, on which features and functionalities of protein depend. This paper use classification technique, Random Forest to build a model which is able to determine structure of unknown proteins. The dataset included the amide frequencies of proteins whose structure is known. Machine learning model is developed that can predict the structure of protein that still need to be exploited. The accuracy of the model is determined using ROC curve. The results confirm the performance of the model constructed using amides dataset.","Traditional SVM algorithms for multi-class (k &gt; 2 classes) classification tasks include \u201cone-against-one\u201d, \u201cone-against-rest\u201d, and \u201cone-against-one-against-rest\u201d, which build k(k\u22121)/2 or k classifiers for space partitioning and classification decision. However, they may cause a variety of problems, such as an imbalanced problem, a high temporal complexity, and trouble establishing the decision boundary. In this study, we use the notion of minimizing structural risks (SRM) to recognize k classes by designing only one optimization problem, which we call M3HS-SVM. The M3HS-SVM offers numerous benefits. In summary, the following points should be emphasized: (1) Rather than dividing the space with hyper-planes, M3HS-SVM describes the structural characteristics of various classes of data and trains the hyper-sphere classifier of each class based on the data distribution. (2) M3HS-SVM inherits all of the advantages of classical binary SVM, such as the maximization spirit, the use of kernel techniques to solve nonlinear separable problems, and excellent generalization ability. (3) In the dual problem, we develop an SMO algorithm to effectively reduce the complexity of time and space. We eventually validate the preceding statement with comprehensive experiments. The experiment findings show that our method outperforms other mainstream methods in terms of computing time and classification performance on synthetic datasets, UCI datasets, and NDC datasets.","With the development of artificial intelligence technology and edge computing technology, deep learning-based automatic modulation classification (AI-based AMC) deployed at edge devices using centralised or distributed learning methods for optimisation has emerged in recent years, and has made great progress in the recognition accuracy and recognisable range of wireless signals. However, the lack of sufficient explanation of these models leads to low accuracy and training efficiency of model training, and their applications and further improvements are limited. Researchers have started to propose interpretable methods for technical analysis of deep learning-based AMC. In this paper, based on the research and application development of interpretable methods in recent years, we review the applicable methods and existing research challenges of interpretable automatic modulation classification. And an interpretable AI-based automatic modulation classification framework is proposed to map the interpretability of automatic modulation classification results by obtaining the contribution of wireless signal features to deep learning network training. Experimental results show that the proposed method possesses the ability to explore the classification mechanism of non-transparent auto-modulated classification networks and has the potential to help edge devices train networks with lower energy consumption and higher accuracy.","This paper proposes a novel approach for classifier ensemble by employing the concepts of multi-criteria decision-making (MCDM) and aggregation operators. In this framework, a heterogeneous ensemble process has been incorporated where we consider varied set of classifiers to train the model. Each considered classifier is trained on the training data and a score correspondent to it is generated by utilizing the MCDM process. Subsequently, during the training phase, the priority is generated among the classifiers. For the testing phase, these prioritized classifiers are combined using prioritized aggregation operator. The priority order determined during the training phase is used to ensemble the classifiers during the testing phase. The proposed method is tested on UCI benchmark datasets and outperforms existing state-of-the-art methods.","Machine learning applications in remote sensing often require a labour-intensive feature engineering step, if only a small number of samples is available and transfer learning is not applicable. Here, we are introducing the concept of Spatial Variation Sequences, which allows to apply methodologies from automated time-series feature engineering to remote sensing applications of static images. The presented example application detects swimming pools from four-channel satellite images with an\nF\n1\n-score of 0.95, by generating spatial variation sequences from a modified swimming pool index. The automated feature engineering approach reduced the dimensionality of the classification problem by 99.7%. A more traditional approach using transfer learning on pre-trained Convolutional Neural Networks (CNN) was evaluated in parallel for comparison. The CNN approach boasted a higher performance of\nF\n1\n-score of 0.98 but required the use of pre-trained weights. The comparable performance of the FE and CNN approach demonstrates that time-series feature extraction is a valuable alternative to traditional remote sensing methods in the presence of data scarcity or the need of significant dimensionality reduction.","The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.","This paper proposes a real-time voice activity detection (VAD) system that utilizes a compressed convolutional neural network (CNN) model. On general-purpose computers, the system is capable of accurately classifying the presence of speech in audio with low latency. Whereas, when implemented on small devices, the system is showing higher latency, which is presumably an indication of high-load computations in the preprocessing steps. The results of the evaluation indicate that the proposed VAD system is an improvement over the existing solutions, in terms of reducing the model size and improving the level of accuracy among different evaluation metrics. Furthermore, the proposed VAD system offers an extension of the applicability by training the CNN model on a different and more diverse data set. Moreover, the proposed architecture is capable of being compressed to approximately one-eleventh of the size, facilitating eventual deployment on small devices. In contrast to existing closed VAD solutions, the entire pipeline of the proposed VAD system is developed in Python and made available as open source, ensuring the verifiability and accessibility of the work.","Due to the enormous amount of user-generated content being generated on the web, labeling such data is a time-consuming and expensive endeavor. As a result, we have limited annotated data and the vast majority of data are unlabeled. Analysis reveals that extracting (external) knowledge from unlabeled data and integrating it with knowledge extracted from labeled data is a beneficial task for text information processing, in particular text classification. In this paper, we present a hybrid approach for classifying sentiments that employs external knowledge, which is categorized as either general-purpose sentiment knowledge or domain-related knowledge. General-purpose sentiment knowledge is extracted from sentiment lexicons, whereas domain-related knowledge is extracted from unlabeled data from the same or related domains. Similar domains for a given domain are identified based on their similarity score in terms of overlapping features. The proposed approach utilizes both forms of external knowledge and combines them with logistic regression to train an improved classification model. The classification model uses the conventional gradient descent algorithm for optimization, and its convergence analysis indicates that it is convex and converges to the global optimum. The proposed approach is empirically evaluated and compared to three baselines and one state-of-the-art method using standard performance evaluation metrics on a multi-domain sentiment dataset. The experiment results are encouraging, demonstrating that the proposed approach considerably outperforms the baseline approaches and outperforms the state-of-the-art approach by up to 2% in terms of both f-score and accuracy.\nHighlights\n\u2022\nA hybrid approach for document-level sentiment classification that makes use of external knowledge.\n\u2022\nA domain-specific knowledge extraction approach from unlabeled text documents.\n\u2022\nA detailed convergence analysis of the proposed optimization model used in the proposed approach.","Weighting strategy prevails in machine learning. For example, a common approach in robust machine learning is to exert low weights on samples which are likely to be noisy or quite hard. This study summarizes another less-explored strategy, namely, perturbation. Various incarnations of perturbation have been utilized but it has not been explicitly revealed. Learning with perturbation is called perturbation learning and a systematic taxonomy is constructed for it in this study. In our taxonomy, learning with perturbation is divided on the basis of the perturbation targets, directions, inference manners, and granularity levels. Many existing learning algorithms including some classical ones can be understood with the constructed taxonomy. Alternatively, these algorithms share the same component, namely, perturbation in their procedures. Furthermore, a family of new learning algorithms can be obtained by varying existing learning algorithms with our taxonomy. Specifically, three concrete new learning algorithms are proposed for robust machine learning. Extensive experiments on image classification and text sentiment analysis verify the effectiveness of the three new algorithms. Learning with perturbation can also be used in other various learning scenarios, such as imbalanced learning, clustering, regression, and so on.","For training and testing enhancer-promoter interaction (EPI) classifiers, the question on which non-positive EPIs are selected as negative instances must be answered. Most previous methods use the dataset of the EPI classifier TargetFinder where negative EP pairs are sampled from non-positive EP pairs. Consequently, over 92% of EPIs in the TargetFinder-positive and negative sets of cell line GM12878 have a 2-fold or greater positive/negative class imbalance of promoter occurrences between the positive and negative EP pairs. This situation negatively impacts the predictability of EPI classifiers trained using the datasets.\nThus, we first proposed the condition that the negative EPIs should satisfy. Second, we devised a method called CBOEP (class balanced occurrences of enhancers and promoters), to generate negative EPI sets that approximately fulfil this condition for a given positive EPI set. CBOEP solves the finding problem by reducing it to the maximum-flow problem. Third, we applied the generated negative EPI sets to existing EPI classifiers, TransEPI and TargetFinder. The negative datasets lead to higher prediction performance than the existing negative EPI datasets. The source code is available at https://github.com/maruyama-lab-design/CBOEP.","Insect pests have always been a global agricultural problem because the severity and extent of their occurrence threaten crop yield. Recognizing them early can help farmers have efficient measures to handle them, which can help mitigate negative impacts from insect pests. However, insect pest recognition still relies heavily on experts, which is expensive and time-consuming. With the power of Deep Learning, we propose two methods to solve this task in this paper. First, we proposed a method that uses models pre-trained on the ImageNet dataset, including ResNet-50, EfficientNet-B4, and VisionTransformer-B16, respectively. We also change the structure of these models by adding a Dropout layer before the output layer of these pre-trained models to avoid overfitting. Second, we apply hierarchical learning for this task. In the latter approach, we first use the baseline model to create a confusion matrix. Through this matrix, we cluster classes that the baseline model misses to each other because of the similar appearance across classes into bigger classes, and we consider them as sub-datasets. Then, we build each model for each sub-dataset using the identical backbones as the baseline methods with the hope that it helps the method classify better in these classes. We do experiments to evaluate the performance of methods on the IP102 dataset. From experiments, our proposed method, which uses VisionTransformer-B16 backbone combined with hierarchical learning, gets the best accuracy of 74.50% on the IP102 dataset. When ensemble 3 above models and combine with hierarchical learning, we get the best accuracy of 76.24% on this dataset.","We propose a self-attention Vision Transformer (ViT) model tailored for breast cancer histology image classification. The proposed architecture uses a stack of transformer layers, with each layer consisting of a multi-head self-attention mechanism and a position-wise feed-forward network, and it is trained with different strategies and configurations, including pretraining, resize dimension, data augmentation, patch overlap, and patch size, to investigate their impact on performance on the histology image classification task. Experimental results show that pretraining on ImageNet and using geometric and color data augmentation techniques significantly improve the model\u2019s accuracy on the task. Additionally, a patch size of 16 \n\u00d7\n 16 and no patch overlap were found to be optimal for this task. These findings provide valuable insights for the design of future ViT-based models for similar image classification tasks.","Sentiment analysis is a technique that analyzes the attitudes and emotions of people towards some product, service etc. Sentiment analysis of some product or service can be beneficial in predicting future scope of it. However, manually analyzing a large number of documents in a limited time can be a tedious and challenging task. Hence, several attempts have been made in the literature to solve this problem and several sentiment analysis techniques have been proposed. However, these approaches do not consider or do not give much weighted to\u2018emoticons\u2019 present in the sentence. Emotions are very popular these days and have become an integral part of written communication. Hence, in this paper, we propose a novel algorithm, based on \u2018emoticon score learning\u2019 for identifying sentiment of a given sentence. We test the proposed algorithm on 1000 tweets. Experimental results show that the proposed algorithm is effective in sentiment classification and give accuracy of 91.1%. Additionally, the proposed algorithm is able to detect sentences consisting of both positive and negative sentiments.","Bibliographic references in scholarly documents are integral to discourse in humanities disciplines. While prior work has focused on reference extraction and parsing from these documents, little research has investigated the classification of footnotes containing bibliographic citations and author commentary using supervised machine learning methodologies. Using an historiographic dataset drawn from the JSTOR humanities archive, we train and compare the performance of a suite of single and hybrid machine learning classifiers on a novel, previously unexplored reference classification task in archival document analysis. Moreover, as a part of this analysis, we investigate the feasibility of using the grammar of these scholarly footnotes as training features for our machine learning models. In our work we compare the performance of traditional features previously used in reference mining and these novel, grammatical features inspired by natural language processing techniques. Our work demonstrates the superiority of hybrid models for classification of scholarly footnotes containing historiographic bibliographic references, the transferability of features from reference extraction to this research problem, and the viability of training machine learning models for this task utilizing novel, grammatical feature sets.","One of the main challenges in the industry is having trained and efficient operators in manufacturing lines. Smart adaptive guidance systems are developed that offer assistance to the operator during assembly. Depending on the operator\u2019s level of execution, the system should be able to serve a different guidance response. This paper investigates the assessment and classification of the operator\u2019s functional state using observed task execution times. Five different classifiers are studied for operator functional state classification on task execution time series. The experiments are based on an industry case and the ground truth is provided by an expert rule-based system. Three classification scenarios are defined that segment the problem on the level of the task, the individual, or the team. Furthermore, the investigation includes the evaluation of four distinct window-size configurations. The examination of how these scenarios and window-sizes influence the studied dataset across diverse classifiers reveals that achieving enhanced accuracy necessitates a larger input dimension. In this context, Convolutional Neural Networks predominantly exhibit superior performance compared to alternative classifiers. Careful attention needs to be paid to performance over classes and skills, but results confirm the validity of the approach for data-driven operator functional state classification.","Real-world data usually obeys a long-tailed distribution, where a few classes have higher number of samples compared to the other classes. Recent studies have been proposed to alleviate the extreme data imbalance from different perspectives. In this paper, we experimentally find that due to the easily confusing visual features between some head- and tail classes, the cross-entropy model is prone to misclassify tail samples to similar head classes. Therefore, to alleviate the influence of the confusion on model performance and improve the classification of tail classes, we propose a Similarity Window Reweighting and Margin (SWRM) algorithm, where the SWRM consists of Similarity Window Reweighting (SWR) and Similarity Window Margin (SWM) algorithms. For the confusable head- and tail classes, SWR assigns larger weights to tail classes and smaller weights to head classes. Therefore, the model can enlarge the importance of tail classes and effectively improve their classification. Moreover, SWR considers the difference in label frequency and the impact of category similarity simultaneously, so that the weight coefficients are more reasonable and efficacious. SWM generates adaptive margins that are proportional to the ratio of the classifier\u2019s weight norm, thus promoting the learning of tail classifier with small weight norm. Our SWRM effectively eliminates the confusion between head- and tail classes and alleviates the misclassification issues. Extensive experiments on three long-tailed datasets, i.e., CIFAR100-LT, ImageNet-LT and Places-LT, verify our proposed method\u2019s effectiveness and superiority over comparative methods.","Nowadays, many classification algorithms have been applied to various industries to help them work out their problems met in real-life scenarios. However, in many binary classification tasks, samples in the minority class only make up a small part of all instances, which leads to the datasets we get usually suffer from high imbalance ratio. Existing models sometimes treat minority classes as noise or ignore them as outliers encountering data skewing. In order to solve this problem, we propose a bagging ensemble learning framework A S E (Anomaly Scoring Based Ensemble Learning). This framework has a scoring system based on anomaly detection algorithms which can guide the resampling strategy by divided samples in the majority class into subspaces. Then specific number of instances will be under-sampled from each subspace to construct subsets by combining with the minority class. And we calculate the weights of base classifiers trained by the subsets according to the classification result of the anomaly detection model and the statistics of the subspaces. Experiments have been conducted which show that our ensemble learning model can dramatically improve the performance of base classifiers and is more efficient than other existing methods under a wide range of imbalance ratio, data scale and data dimension. A S E can be combined with various classifiers and every part of our framework has been proved to be reasonable and necessary.\nHighlights\n\u2022\nIntroduce a scoring system based on anomaly detection to the resampling strategy.\n\u2022\nThe proposed weighting functions are intuitive and easy to understand.\n\u2022\nPropose an efficient ensemble learning framework.\n\u2022\nExcellent performance on different real-world imbalanced classification tasks.","Examples from living systems at various levels of the biological hierarchy and also from natural food products show that ultra-weak photon emission (UPE) has potential applications in the rating of vital functions and quality testing. In this study, the UPE of chicken eggs has been tested regarding the possibility of egg quality verification. The UPE from intact eggs and separated egg parts were subjected to supervised and unsupervised classification methods according to different housing types. The results of unsupervised egg grouping substantially agreed with the types of hen rearing. The Cohen\u2019s Kappa test score for the K-means method was up to K = 0 . 63. Supervised Support Vector Machine (SVM) classifier with radial kernel function achieved a relatively high accuracy (AC), up to 88%, also confirmed by the value of the K-statistics up to 0.81. This study shows that the best result of egg types classification can be obtained using UPE emission data from all egg parts.\nHighlights\n\u2022\nBiophoton emission of egg components can be used as a measure of the egg quality.\n\u2022\nOrganic housing type eggs are characterised by the highest levels of photon emission.\n\u2022\nUltra-weak photon emission of egg components allows classification of egg types.","Breast cancer is a major cause of concern on a global scale due to its high incidence rate. It is one of the leading causes of death for women, if left untreated. Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is increasingly being used in the evaluation of breast cancer. Prior studies neglected to take into account breast cancer characteristics and features that might be helpful for distinguishing the four molecular subtypes of breast cancer. The use of breast DCE-MRI to identify the molecular subtypes is now the focus of research in breast cancer analysis. It offers breast cancer patients a better chance for an early and effective treatment plan. A manually annotated dataset of 1359 DCE-MRI images was used in this study, with 70% used for training and the remaining for testing. Twelve deep features were extracted from this dataset. The dataset was initially preprocessed through placing the ROIs by a radiologist experienced in breast MRI interpretation, then deep features are extracted using the proposed convolutional neural network (CNN). Finally, the deep features extracted are classified into molecular subtypes of breast cancer using the support vector machine (SVM). The effectiveness of the predictive model was assessed using accuracy and area under curve (AUC) measures. The test was performed on unseen held-out data. The maximum achieved accuracy and AUC were 99.78% and 100% respectively, with substantially a low complexity rate.","Highlights\n\u2022\nPresent an overview of ASC methods covering earlier works and recent advances.\n\u2022\nReview core techniques including data processing, feature acquisition, and modeling.\n\u2022\nSummarize available resources for ASC and analyze ASC tasks in DCASE challenges.\n\u2022\nDiscuss limitations and open challenges of current ASC algorithms.\n\u2022\nProvide suggestions for future research.\nAbstract\nAcoustic scene classification (ASC) has gained significant interest recently due to its diverse applications. Various audio signal processing and machine learning methods have been proposed for ASC. The volume and scope of ASC publications covering theories, algorithms, and applications have also been expanded. However, no recent comprehensive surveys exist to collect and organize the knowledge, impeding the ability of researchers and its applications. To fill this gap, we present an up-to-date overview of ASC methods, covering earlier works and recent advances. In this work, we first define a general framework for ASC, starting with a historical review of previous research in the ASC field. Then, we review core techniques for ASC that have achieved good performance. Focus on machine learning based ASC systems, this work summarizes and groups the existing techniques in terms of data processing, feature acquisition, and modeling. Furthermore, we provide a summary of the available resources for ASC research and analyze ASC tasks in Detection and Classification of Acoustic Scenes and Events (DCASE) challenges. Finally, we discuss limitations of the current ASC algorithms and open challenges to possible future developments toward practical applications of ASC systems.","In this study, the authors combined the research on loose particle signal and component signal identification with the research on loose particle material identification for the first time, providing comprehensive and reliable loose particle detection results. Based on this, a signal detection and material identification method for loose particles inside sealed relays based on fusion classification model is proposed. Due to the limitations of technical means and confidentiality management, the authors made a real sealed relay sample, and took it as the research object. Through the steps of data acquisition, signal processing, feature engineering, and model training, the dedicated component identification feature library and material identification feature library was constructed, respectively, the component identification model and material identification model based on parameter-optimized SVM with linear kernel and XGBoost was trained, respectively. For the seal relay to be tested, through the steps of data acquisition, signal processing and feature engineering, the data set to be tested was created. The component identification model was used to identify component signals with loose particle signals, and the material identification model was used to identify the materials of loose particles. The majority voting process was used to convert the classification results into identification results, resulting in loose particle detection and material identification results. In addition, the general procedure steps of the proposed method for physical testing were given, and the identification accuracy for device-level loose particle detection was newly proposed. The loose particle testing event containing thirty-seven identification tasks shows that, the achieved identification accuracy was 97.30%, and 92.16% of the average classification accuracy was achieved by the component identification model, 80.41% of the average classification accuracy was achieved by the material identification model. This effectively demonstrates the feasibility and practicality of the proposed method in this paper. It is an important supplement to the loose particle detection research, and provides references for signal detection in similar fields.\nHighlights\n\u2022\nFirst combine the loose particle signal detection and material identification study.\n\u2022\nFirst construct the dedicated feature library and perform feature optimization.\n\u2022\nTrain the optimal component identification model and material identification model.\n\u2022\nNewly add majority voting steps to obtain the identification results.\n\u2022\nNewly propose the identification accuracy for device-level loose particle detection.","The aim of this research is to evaluate the performance of a classification model on nonlinear data. The study utilizes accuracy, precision, sensitivity, and specificity metrics based on data from e-commerce X sellers. The classification model is developed using the Support Vector Machine (SVM) approach, employing different kernel functions such as linear, polynomial, and Radial Basis Function (RBF). By comparing the performance scores of each model, the best model is determined. The results indicate that the SVM model with a linear kernel outperforms the others, demonstrating the highest performance scores. This approach is applied to predict the status of sellers on e-commerce X.","A world of healthcare possibilities has been opened with the development of the Internet of Medical Things and related machine learning, deep learning, and artificial intelligence approaches. It has a broad range of uses: when linked to the Internet, common medical equipment and sensors may gather important data; deep learning and artificial intelligence algorithms use this data to understand symptoms and patterns and allow remote healthcare. There are a large number of people affected by thyroid disorders across the world. The ultrasound-based thyroid nodule detection using traditional methods increased the burden on the expertise. Therefore, alternate methods are required to overcome this problem. In order to facilitate early thyroid disorder detection, this research aims to offer an IoT-based ensemble learning framework. In the proposed ensemble model, three pre-trained models DeiT, Mixer-MLP and Swin Transformer, are used for feature extraction. The mRMR technique is used for relevant feature selection. A total of 24 machine learning models have been trained, and weighted average ensemble learning is employed using the Improved Jaya optimization algorithm and Coronavirus Herd Immunity optimization algorithm. The ensemble model with the improved Jaya optimization algorithm achieved excellent results. The best value for accuracy, precision, sensitivity, specificity, F2-score and ROC-AUC score are 92.83%, 87.76%, 97.66%, 88.89%, 0.9551 and 0.9357, respectively. The main focus of this research is to increase the specificity. A poor value of specificity can lead to a high false positive rate. This situation can increase anxiety and emotionally weaken the patient. The proposed ensemble model with the Improved Jaya optimization algorithm outperformed state-of-the-art techniques and can assist medical experts.","This paper presents a novel study on soil image classification, leveraging the synergistic potential of transfer learning and convolutional neural networks (CNNs). The proposed approach combines the strengths of the MobileNetV2 architecture with a customized CNN model for accurate and efficient soil type recognition. The pre-trained MobileNetV2 is used to capture generic features before fine-tuning it with a dedicated soil image dataset comprising four distinct classes: red, clay, black, and yellow soils. To enhance the model\u2019s capacity for discerning intricate soil textures, a specially designed CNN architecture is incorporated. The model\u2019s performance is rigorously evaluated on a dataset of 108 images, each sized at 256\u2009\u00d7\u2009256 pixels, achieving an exceptional accuracy rate of 100% on the test dataset. The promising results demonstrate the efficacy of the proposed methodology in soil image classification tasks, offering potential applications in precision agriculture, environmental monitoring, and land management. While these findings showcase remarkable accuracy, further investigations are recommended to assess the model\u2019s generalization across diverse environmental conditions and an expanded range of soil image datasets.","Imbalanced data distribution is a common feature in real-world datasets. For imbalanced data, the imbalanced characteristics of the classes have two negative effects on classification results, one of which is that the minority class is highly likely masked by the majority class so as to weaken the ability of the classifiers to identify the minority class. Another effect is that irrelevant attributes hidden in imbalanced data can create much noise to interfere the classifiers, thereby leading to that the classifiers could mistakenly treat noise as the minority classes. In this scenario, the performance of the classifiers is rapidly declined and the classifiers obtain incorrect classification results. To address this issue, this paper proposed a conformal transformation twin-hypersphere with fuzzy. The critical thought is that using conformal transformation to explore the regions containing minority classes, by so doing, minority classes can be more likely to be noticed by the classifier. Using the proposed fuzzy function assesses the contributions of points to the hypersphere training, through evaluating the contributions, noise can be determined, thereby increasing the ability of the classifier to noise resistance. Results on the synthetic and real datasets show that the proposed method outperforms the competitors in classification accuracy and noise resistance. Results also imply that the proposed method does not exhibit exponential calculation time, meaning that the method is suitable for the classification of large-scale imbalanced datasets. We demonstrate that conformal transformation can assist those non-linear kernels to find those hard-to-observe regions containing minority classes, thereby strengthening the adaptability of the classifiers to imbalanced data following complex distributions. Moreover, the non-linear kernels using conformal transformation can adapt to the situation where different sub-regions in sample space require different nonlinearities.","The growing availability of time series data has increased the usage of classifiers for this data type. Unfortunately, state-of-the-art time series classifiers are black-box models and, therefore, not usable in critical domains such as healthcare or finance, where explainability can be a crucial requirement. This paper presents a framework to explain the predictions of any black-box classifier for univariate and multivariate time series. The provided explanation is composed of three parts. First, a saliency map highlighting the most important parts of the time series for the classification. Second, an instance-based explanation exemplifies the black-box\u2019s decision by providing a set of prototypical and counterfactual time series. Third, a factual and counterfactual rule-based explanation, revealing the reasons for the classification through logical conditions based on subsequences that must, or must not, be contained in the time series. Experiments and benchmarks show that the proposed method provides faithful, meaningful, stable, and interpretable explanations.","Time series imaging technique: Gramian Angular Field (GAF), and a deep stacked Autoencoder (SAE) are employed to develop a multi-class classifier for the classification and authentication of water samples of bottled water brands: Aquafina (AF), Bisleri (BS), Kingfisher (KF), Oasis (OS), Dolphin (DL) and McDowell (MD) that are attainable in Indian market. The electronic tongue is an artificial taste sensor that is used in the present wok to taste the mineral water samples and subsequently produce one-dimensional current waveforms (CWFs). GAF is used to transform the 1D CWFs into images that are used to train the deep SAE based classifier. The trained classifier is tested on the test GAF images belonging to the water samples of six unknown mineral water brands. Results show that the classifier exhibits satisfactory performance with high classification rate of 93.9%.","Predicting students\u2019 academic performance is a critical research area, yet imbalanced educational datasets, characterized by unequal academic-level representation, present challenges for classifiers. While prior research has addressed the imbalance in binary-class datasets, this study focuses on multi-class datasets. A comparison of ten resampling methods (SMOTE, Adasyn, Distance SMOTE, BorderLineSMOTE, KmeansSMOTE, SVMSMOTE, LN SMOTE, MWSMOTE, Safe Level SMOTE, and SMOTETomek) is conducted alongside nine classification models: K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Support Vector Machine (SVM), Logistic Regression (LR), Extra Tree (ET), Random Forest (RT), Extreme Gradient Boosting (XGB), and Ada Boost (AdaB). Following a rigorous evaluation, including hyperparameter tuning and 10 fold cross-validations, KNN with SmoteTomek attains the highest accuracy of 83.7%, as demonstrated through an ablation study. These results emphasize SMOTETomek\u2019s effectiveness in mitigating class imbalance in educational datasets and highlight KNN\u2019s potential as an educational data mining classifier.","To evaluate the robustness of non-classifier models, we propose probabilistic local equivalence, based on the notion of randomized smoothing, as a way to quantitatively evaluate the robustness of an arbitrary function. For a given function\nf\n, probabilistic local equivalence evaluates whether, when sampling a normally-distributed point\nx\n\u2032\nin a neighborhood of a point\nx\n, there is a probability\n&gt;\n0.5\nthat\nf\n(\nx\n\u2032\n)\nis equivalent to\nf\n(\nx\n)\n, according to a user-defined notion of equivalence. We use probabilistic local equivalence to evaluate the effect of data augmentation methods for improving robustness, including adversarial training, on a model\u2019s performance. We also use probabilistic local equivalence to evaluate the effect on robustness of model architecture, number of parameters, pre-training, quantization, and other model properties.","Class imbalance problem commonly exists in multi-label classification (MLC) tasks. It has non-negligible impacts on the classifier performance and has drawn extensive attention in recent years. Borderline oversampling has been widely used in single-label learning as a competitive technique in dealing with class imbalance. Nevertheless, the borderline samples in multi-label data sets (MLDs) have not been studied. Hence, this paper deeply discussed the borderline samples in MLDs and found they have different neighboring relationships with class borders, which makes their roles different in the classifier training. For that, they are divided into two types named the self-borderline samples and the cross-borderline samples. Further, a novel MLDs resampling approach called Multi-Label Borderline Oversampling Technique (MLBOTE) is proposed for multi-label imbalanced learning. MLBOTE identifies three types of seed samples, including interior, self-borderline, and cross-borderline samples, and different oversampling mechanisms are designed for them, respectively. Meanwhile, it regards not only the minority classes but also the classes suffering from one-vs-rest imbalance as those in need of oversampling. Experiments on eight data sets with nine MLC algorithms and three base classifiers are carried out to compare MLBOTE with some state-of-art MLDs resampling techniques. The results show MLBOTE outperforms other methods in various scenarios.\nHighlights\n\u2022\nA new borderline oversampling technique for multi-label imbalanced learning.\n\u2022\nDefining self-borderline and cross-borderline samples in multi-label data sets.\n\u2022\nHandling one-vs-rest imbalance in multi-label imbalanced learning.\n\u2022\nPerforming competitively in the experiments with C4.5, RBF kernel SVM and linear SVM.","Breast cancer (BC) is the most common cancer amongst women that threatens the health of women, initial diagnosis of BC becomes essential. Though there were several means to diagnose BC, the standard way is pathological analysis. Precise diagnosis of BC necessitates experienced histopathologists and needs more effort and time for completing this task. Recently, machine learning (ML) was successfully implemented in text classification, image recognition, and object recognition. With the emergence of computer aided diagnoses (CAD) technology, ML was effectively implemented for BC diagnosis. Histopathological image classification depends on deep learning (DL), particularly convolution neural network (CNN), which frequently needs a large amount of labelled training models, whereas the labelled data was hard to obtain. This study develops an Aquila Optimizer(AO) with Hybrid ResNet-DenseNet Enabled Breast Cancer Classification on Histopathological Images (AOHRD-BC2HI). The proposed AOHRD-BC2HI technique inspects the histopathological images for the diagnosis of breast cancer. To accomplish this, the presented AOHRD-BC2HI technique uses hybridization of Resnet with Densenet (HRD) model for feature extraction. Moreover, the HRD method can be enforced for feature extracting procedure in which the DenseNet (feature value memory by concatenation) and ResNet (refinement of feature value by addition) were interpreted. For BC detection and classification, the DSAE model is utilized. The AO algorithm is exploited to improve the detection performance of DSAE model. The experimental validation of the presented AOHRD-BC2HI approach is tested using benchmark dataset and the results are investigated under distinct measures.Also the proposed model achieved the accuracy of 96%. The comparative result reports the improved performance of the presented AOHRD-BC2HI technique over other recent methods.","Unexploded ordnance (UXO) dumped in water reservoirs pose a serious environmental and human safety hazard. Various ways of economically solving this problem are being sought. One of them is the use of machine learning methods for the automatic classification of dangerous objects based on the recorded signals. The paper presents the preliminary results on the use of machine learning methods applied to raw magnetometry data generated in a virtual environment based on the concept of a digital twin. This introduces a different approach to a standard approach, which is based on the inverse problem, where the signals are mapped to the magnetic dipole model. Conducted research points out that the highest performance can be obtained with neural networks, and a direct classification based on the raw signals allows to achieve accuracy of up to 93% when no remanent magnetization is present.","This paper describes the classification of facial expressions using EEG data. The entire procedure aims at controlling an electric wheelchair with a Brain Computer Interface (BCI) headset. The goal is to help the people who are suffering from locked-in syndrome to move or to pass the necessary signals. The headset consists of the electroencephalogram (EEG) cap comprising 16 electrodes attached to the amplifier out of which 14 electrodes are used for data acquisition while two are used as reference and ground. The EEG cap is placed on the head of the subject and various expressions (blink, eyebrows raise, smile, etc.) are performed on the subject. Muscle activities due to facial expressions can be observed from the recorded EEG signals. Expressions are classified and necessary signals are generated. The features are extracted using the wavelet packet transform processing method and classified primarily using Support Vector Machine (SVM).","The feature selection problem has become a key undertaking within machine learning. For classification problems, it is known to reduce the computational complexity of parameter estimation, but it also adds an important contribution to the explainability aspects of the results. An evolution strategy for feature selection is proposed in this paper. Feature weights are evolved with decision trees that use the Nash equilibrium concept to split node data. Trees are maintained until the variation in probabilities induced by feature weights stagnates. Predictions are made based on the information provided by all the trees. Numerical experiments illustrate the performance of the approach compared to other classification methods.","Uploading research articles to a database can be a complex process with multiple HTML fields. The complexity of this process makes users less efficient and productive. This study explored the use of the Multilayer Perceptron (MLP) algorithm using language-independent features (count and Boolean features) to create a multi-class text classifier that can classify 10 research article components (e.g., title, authors, abstract, etc.). The text classifier was developed to pave the way for a streamlined manual data entry process for uploading research articles to a database by implementing a single textarea in favor of using multiple HTML fields. The text samples were obtained from multiple sources using web scraping technology, consolidated, cleaned, and standardized. The 12 language-independent features were generated based on the textual formats of sample texts (e.g., count of capitalized letters, digits, punctuation, checking the existence of a URL pattern, etc.). Recursive feature elimination with cross validation (RFECV) was used to determine the optimal number of input features. The hyperparameter values of the model were determined through the grid search technique. A trial-and-error process was conducted to determine the number of hidden layers. The model achieved 95%, 94%, and 95% scores for micro, macro, and weighted average f1-scores, respectively. The model performed well in classifying research article components. However, it is sensitive to textual format (e.g., lower or upper case, punctuation used, etc.). For subsequent research in this area, this study recommends investigating the use of both language-dependent and language-independent features to address the limitations of the current model.","The pre-trained model based on the Transformer architecture is currently the most widely used model in the field of Natural Language Processing (NLP), and feature fusion technology is the process of aggregating features from different sources to form an augmented feature representation that contains more information. In multi-modal or multi-branch NLP models, feature fusion is a commonly used technique, but for models with only a single feature source, feature fusion technology can be difficult to apply. Therefore, this paper proposes a new probabilistic-controlled late fusion encoder-decoder architecture, called the Feature Fusion Gate (FFG), based on both feature fusion technology and Mixup technology to aggregate the feature representations from the last two layers of the NLP pre-trained model to better capture semantic information in samples. During the aggregation process, FFG utilizes controlled noise as a regularization technique to help the model achieve better generalization performance. Experimental results on eight NLP benchmark datasets show that FFG outperforms three other baseline methods and consistently achieves significant performance improvements across DistilBERT, BERT and RoBERTa.","Sign Language Recognition (SLR) is a challenging task that aims to bridge the communication gap between the deaf and hearing communities. In recent years, deep learning-based approaches have shown promising results in SLR. However, the lack of interpretability remains a significant challenge. In this paper, we seek to understand which hand and pose MediaPipe Landmarks are deemed the most important for prediction as estimated by a Transformer model. We propose to embed a learnable array of parameters into the model that performs an element-wise multiplication of the inputs. This learned array highlights the most informative input features that contributed to solve the recognition task. Resulting in a human-interpretable vector that lets us interpret the model predictions. We evaluate our approach on public datasets called WLASL100 (SRL) and IPNHand (gesture recognition). We believe that the insights gained in this way could be exploited for the development of more efficient SLR pipelines.","This paper presents our solution for the Requests Sub-challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. Drawing upon the framework of self-supervised learning, we put forth an automated data augmentation technique for audio classification, accompanied by a multi-channel fusion strategy aimed at enhancing overall performance. Specifically, to tackle the issue of imbalanced classes in complaint classification, we propose an audio data augmentation method that generates appropriate augmentation strategies for the challenge dataset. Furthermore, recognizing the distinctive characteristics of the dual-channel HC-C dataset, we individually evaluate the classification performance of the left channel, right channel, channel difference, and channel sum, subsequently selecting the optimal integration approach. Our approach yields a significant improvement in performance when compared to the competitive baselines, particularly in the context of the complaint task. Moreover, our method demonstrates noteworthy cross-task transferability.","In this research project, we used the financial texts published by the Federal Open Market Committee (FOMC), known as the FOMC Minutes, for sentiment analysis. The pre-trained FinBERT model, a state-of-the-art transformer-based model trained for NLP tasks in finance, was utilized for that. The focus of this research has been on improving the predictive performance of complex financial sentences, as our problem analysis has shown that such sentences pose a significant challenge to existing models. To accomplish this objective the original FinBERT model was fine-tuned for domain-specific sentiment analysis. A strategy, referred to as Sentiment Focus (SF) was utilized to reduce the complexity of sentences, making them more amenable to accurate sentiment predictions.\nTo evaluate the efficacy of our method, we curated a manually labeled test dataset comprising 1375 entries. The results demonstrated an overall improvement of in accuracy when using SF-enhanced fine-tuned FinBERT over the original FinBERT model. In cases of complex sentences containing conjunctions like but, while, and though with contradicting sentiments, our fine-tuned model outperformed the original FinBERT by a margin of .","Skip Abstract Section\nAbstract\nIn a complex classification task, samples are represented by various types of multimodal features, including structured data, text, images, video, audio, etc. These data are usually high dimensionally, large-sized, structurally complex, and semantically inconsistent. The representation, translation, alignment, fusion and co-learning of multimodal data are core technical challenges to traditional classification tasks. Kernel functions are applied in dealing with multimodal data for extracting some nonlinear information. However, they cannot consider the aspects of complex structures and uncertain semantics in a multimodal classification task. Fuzzy granular computing emerges as a powerful vehicle to handle the structured and uncertain multimodal data. In this paper, we propose a framework of multimodal classification based on kernel functions and fuzzy granular computing. First, a fuzzy granulation based on kernel functions is introduced to extract nonlinear features for the multimodal classification. Then, a model of multimodal fuzzy classification including fuzzy granular representation, fusion and learning for multimodal data is constructed. Finally, we design an efficient fuzzy granular classification algorithm for big multimodal data based on the proposed model. Experimental results demonstrate the effectiveness of our proposed model and its corresponding algorithm.\nSkip Graphical abstract Section\nGraphical abstract","Latent Dirichlet allocation model (LDA) has been widely used in topic modeling. Recent works have shown the effectiveness of integrating neural network mechanisms with this generative model for learning text representation. However, one of the significant setbacks of LDA is that it is based on a Dirichlet prior that has a restrictive covariance structure. All its variables are considered to be negatively correlated, which makes the model restrictive. In a practical sense, topics can be positively or negatively correlated. To address this problem, we proposed a generalized Dirichlet variational autoencoder (GD-VAE) for topic modeling. The Generalized Dirichlet (GD) distribution has a more general covariance structure than the Dirichlet distribution because it takes into account both positively and negatively correlated topics in the corpus. Our proposed model leverages rejection sampling variational inference using a reparameterization trick for effective training. GD-VAE compares favorably to recent works on topic models on several benchmark corpora. Experiments show that accounting for topics\u2019 positive and negative correlations results in better performance. We further validate the superiority of our proposed framework on two image data sets. GD-VAE demonstrates its significance as an integral part of a classification architecture. For reproducibility and further research purposes, code for this work can be found at https://github.com/hormone03/GD-VAE.\nHighlights\n\u2022\nWe propose GD-VAE to capture correlations and learn complex distributions.\n\u2022\nWe show that capturing all correlations leads to improved performance in GD-VAE.\n\u2022\nWe address training instability by introducing a weighted objective function.\n\u2022\nThe comprehensive experiments show that GD-VAE outperformed state-of-the-art models.\n\u2022\nWe demonstrate the effectiveness of GD-VAE on data augmentation with image data sets.","Covid-19 is a serious disease caused by the Sars-CoV-2 virus that has been first reported in China at late 2019 and has rapidly spread around the world. As the virus affects mostly the lungs, chest X-rays are one of the safest and most accessible ways of diagnosing the infection. In this paper, we propose the use of an approach for detecting Covid-19 in chest X-ray images through the extraction and classification of local and global percolation-based features. The method was applied in two datasets: one containing 2,002 segmented samples split into two classes (Covid-19 and Healthy); and another containing 1,125 non-segmented samples split into three classes (Covid-19, Healthy and Pneumonia). The 48 obtained percolation features were given as input to six different classifiers and then AUC and accuracy values were evaluated. We employed the 10-fold cross-validation method and evaluated the lesion sub-types with binary and multiclass classification using the Hermite Polynomial classifier, which had never been employed in this context. This classifier provided the best overall results when compared to other five machine learning algorithms. These results based in the association of percolation features and Hermite polynomial can contribute to the detection of the lesions by supporting specialists in clinical practices.","To maintain development consciousness, simplify project coordination, and prevent misinterpretation, communication is essential for software development teams. Instant private messaging, group chats, and sharing code are just a few of the capabilities that chat rooms provide to assist and meet the communication demands of software development teams. All of this is capacitated to happen in real-time. Consequently, chat rooms have gained popularity among developers. Gitter is one of these platforms that has gained popularity, and the conversations it contains may be a treasure trove of data for academics researching open-source software systems. This research made use of the GitterCom dataset, The largest collection of Gitter developer messages that have been carefully labelled and curated and perform multi-label classification for the \u2019Purpose\u2019 category in the dataset. An extensive empirical analysis is performed on 6 feature selection techniques, 14 machine learning classifiers, and BERT transformer layer architecture with layer-by-layer comparison. Consequently, we achieve proficient results through our research pipeline involving Extra Trees Classifier and Random Forest classifiers with AUC (OvR) median performance of 0.94 and 0.92 respectively. Furthermore, The research proposed research pipeline could be utilized for generic multi-label text classification on software developer forum text data.","Data irregularities, such as small disjuncts, class skew and imbalance, and outliers significantly affect the performance of classifiers. In this paper, we focus on identifying small disjuncts, which hitherto, has been addressed mainly by rule-based or inductive algorithms. Small disjuncts have been identified as distribution-based irregularities which provide significant learning, although they cover a subset of examples in the training set, which may be considered as being rare. Such samples are more error-prone than large disjuncts. Eliminating small disjuncts by removal or pruning is seen to affect the learning of the classifier adversely. Widely used non-rule-based learning algorithms like SVM, kNN, Logistic Regression, and Neural networks perform poorly in the presence of small disjuncts in the dataset. In this paper, a novel Sequential Ellipsoidal Partitioning method is proposed to identify small disjuncts in the dataset. This method is a supervised classifier that iteratively partitions the dataset into Minimum Volume Ellipsoids that contain points of the same label; this is performed based on the idea of Reduced Convex Hulls. By allowing an ellipsoid that contains points of one label to contain a few points of the other, such small disjuncts may be identified. As we discuss, the proposed technique is agnostic of underlying data distributions and is applicable as a supervised classifier when the datasets are highly skewed and imbalanced even. We demonstrate the performance of the approach using a few publicly available datasets.","Medical imaging classification is an area that has taken relevance in recent years due to the capability to support the medical specialist at the time of diagnosis. However, there are different instruments to obtain images from the body, and each body organ is captured differently due to its chemical composition. In this way, there are some difficulties in working with different imaging modalities. Firstly, using different functions or methods to extract features from the images is necessary. Secondly, the classification performance depends on the relevant features extracted from the images, and thirdly, it is necessary to find the classifier that performs with the minimum error. Following the concept of Auto-Machine Learning (AutoML), where the feature engineering and the hyperparameter tuning of the classifier are done automatically, this work proposes an automated approach for feature extraction and image classification based on Genetic Programming. The approach modifies the functions and their parameters and the hyperparameters for the classifier. The results show that the approach can deal with different imaging modalities, demonstrating that feature extraction is necessary to increase the classification performance. For X-ray images, it achieves a classification accuracy of 0.99, and for computerized tomography, it achieves an accuracy of 0.96. On the other hand, the solutions given by the approach are easily reproducible and easy to interpret.","Parkinson\u2019s disease is one of the most common neurodegenerative chronic diseases which can affect the patient\u2019s quality of life by creating several motor and non-motor impairments. The freezing of gait is one such motor impairment which can cause the inability to move forward despite the intention to walk. The identification of the freezing-of-gait events using sensor technology and machine-learning algorithms can result in an improvement in the quality of life and can decrease the risk of fall in Parkinson\u2019s patients. Our study focuses on a systematic performance evaluation of machine learning algorithms for developing a good fit and generalized model. In this work, we train time-domain and frequency-domain-transform-based features on fully connected artificial and deep neural network algorithm for classifying the events of freezing of gait in patients by using accelerometer data. We evaluate these algorithms for hyperparameters such as batch size, optimizer type, and window sizes in a step-wise process. We identify an optimal combination of parameters according to the accuracy and model fit optimality metrics, for artificial and deep neural network to classify freezing of gait events in Parkinson\u2019s patients. We were able to achieve classification accuracy of - with Adam optimizer, batch sizes (BS) of 256 and 8 and epochs of 60 and 40 for ANN and DNN respectively.","Highlights\n\u2022\nComprehensive wheat lodging analysis in terms of ratio, location, and angle was conducted.\n\u2022\nAuto crop plot dataset generation method was developed.\n\u2022\nImbalanced data challenge was addressed by changing the conventional loss function.\n\u2022\nEfficientNet-B7 produced exceptional performance in identifying and categorizing wheat lodging.\n\u2022\nLRCN gave a high performance for the classification of concatenated dataset.\nAbstract\nCrop lodging in agricultural fields is one of the major factors that limit cereal crop yields. Wheat, the most popular cereal crop in most countries, is also affected by this phenomenon, which may result in a significant decrease in both yield and quality. Therefore, addressing wheat lodging is crucial for producers. This study aims to detect and identify wheat lodging through aerial images and classify its severity based on ratio, angle and location of the lodging. To achieve this goal, a multi-task approach was proposed involving three phases. First, automatic dataset generation methodology was conducted on orthomosaic imagery of three dates. Next, a comprehensive assessment of wheat lodging (ratio, angle and location) was performed, which has received little research attention. Third, applying and improving selected classification models for classifying image datasets was conducted. Combining convolutional neural networks and temporal sequences in a single model provided an opportunity to use spatiotemporal information extracted from the wheat image datasets. Time dependency and individual dates were both considered in the classification task. The limited number of data and imbalanced classes challenges, resulting from real field conditions data collection, were overcome by applying a new loss function to the classifier models. The overall accuracy of wheat lodging classification reached over 91% in these two states using the proposed approach. Based on this research, wheat lodging was detected more accurately by the proposed models despite the small and imbalanced dataset. The developed methodology paves the way for comprehensive and automatic wheat lodging detection, and the methodology can be adapted for similar crops that suffer lodging issues with suitable modifications.","We explore solutions for text classification applied to online cooking recipes, in a multitask, multilingual approach. The main objective is designing a solution that ensures high accuracy on the prediction tasks from, but not constrained to, 6 European Languages, considering also the cross-lingual transferability. The challenges of the problem are structured on two main dimensions: (1) data driven - such as imbalance and noise in the training data, and (2) solution driven - such as multilingualism, or the need to easily extend the model to new languages. We propose a solution focused on the XLM-R architecture, fine-tuned jointly on all tasks. We apply self-supervised domain adaptation via additional pre-training and analyze the enhancements produced by performing a 0-shot evaluation for underrepresented languages. Compared to basic language modeling solutions, we obtained an increase of 1.32% and 2.42%, respectively for the two most difficult classification tasks. In the 0-shot context, the absolute improvements are of 16.71% and 7.83% respectively, on underrepresented languages.","Handwritten character recognition is a significant image classification task. We present a model that is the first of it\u2019s kind as it is the first ever deep learning model designed to classify all basic and compound Bangla handwritten characters along with all Bangla numerals under the same filters. In this work, we propose a new architecture that can potentially ensure the network to learn sufficient number of filters with fewer parameters and time complexity. Furthermore, we also devised a technique to select a specific portion of the network that has almost the same learning capability as the entire network. Moreover, we demonstrated how this technique can enhance classification accuracy while making the neural network unbiased in terms of view point. Our proposed model is also a demonstration of managing variable amount of filters without adding the load on number of parameters required. Through the coarse of this work we came up with a image classifier that can classify all meaningful Bangla handwritten characters and numerals of different shapes. Consequently, we have achieved an accuracy rate of 97.21%. The paper provides conclusive results as well as adequate proof behind all the methodologies presented.","Fault detection and classification is an important part of assessing the structural and system health status. The classification and detection of faults and faulty units is mostly done with statistical methods. After the data are measured and collected, the use of statistical software is necessary. Currently, many statistical software packages are being developed for the R programming language, as a result of R implementation being open source and free to use. This paper focuses on the rebmix R package, which concentrates on mixture model estimation. Mixture models, in particular Gaussian mixture models, are the main driver for many practical applications, such as clustering and classification. Hence, in this paper, we have expanded the rebmix for the estimation of the Gaussian mixtures. The results acquired on three different fault classification datasets were promising. Additionally, the process of obtaining those results is shown in detail, giving the researchers in the fault classification field useful resources for their research.\nHighlights\n\u2022\nREBMIX algorithm is derived for Gaussian mixture model estimation.\n\u2022\nMain methods and classes of the corresponding R package rebmix are described.\n\u2022\nThree different datasets for fault detection and classification are processed.\n\u2022\nThe R package rebmix has achieved better results than other popular R packages.","Weeds are a significant threat to agricultural production. Weed classification systems based on image analysis have offered innovative solutions to agricultural problems, with convolutional neural networks (CNNs) playing a pivotal role in this task. However, CNNs are limited in their ability to capture global relationships in images due to their localized convolutional operation. Vision Transformers (ViT) and Pyramid Vision Transformers (PVT) have emerged as viable solutions to overcome this limitation. Our study aims to determine the effectiveness of CNN, PVT, and ViT in classifying weeds in image datasets. We also examine if combining these methods in an ensemble can enhance classification performance. Our tests were conducted on significant agricultural datasets, including DeepWeeds and CottonWeedID15. The results indicate that a maximum of 3 methods in an ensemble, with only 15 epochs in training, can achieve high accuracy rates of up to 99.17%. This study demonstrates that high accuracies can be achieved with ease of implementation and only a few epochs.","Fine-grained image classification is a challenging task due to the small inter-class variance, the large intra-class difference, and the small training data. Traditional methods typically rely on large-scale training samples with annotated part annotations, making them costly and severely limiting their application area. In this paper, we propose an effective and weakly supervised fine-grained classification framework. In this framework, a discriminative class-specific spectral feature is learned by intra-class spectral coupling and inter-class spectral decoupling under the weak supervision of image-level category labels, and then the new input images are classified based on the learned class-specific spectral feature. Different from existing strong supervised methods, the proposed technique creatively combines weak supervision of the image-level category labels with unsupervised spectral graph decomposition, not relying on large-scale training samples with dense part annotations, which are heavily labor-consuming. The performance of the proposed methods has been verified on four kinds of typical datasets: the JAFFE dataset, the Yale database, the UCI-CMU face database, and the neural foramina dataset. The satisfactory classification results have been achieved by the proposed method in expression recognition on the JAFFE dataset (with a mean accuracy of 95.31%), face recognition on the Yale database (with a mean accuracy of 98.79%), object recognition on the UCI-CMU face database (with a mean accuracy of 96.96%), and disease grading on the neural foramina dataset (with a mean accuracy of 92.09%). Compared with most state-of-the-art methods, the proposed method has superior classification performance in the small data set.\nHighlights\n\u2022\nFully mine and exploit the discriminative potentials of region correlations for fine-grained image classification in weak supervision.\n\u2022\nSpectral graph captures the internal region structure to ensure the image\u2019s comparison in a natural part-based fashion.\n\u2022\nIntra-class spectral synchronization aligns the spectral representations of with-class images to enhance intra-class similarity.","Text sentiment analysis is an important task in natural language processing (NLP), which aims to determine people's emotional tendency towards a certain topic or event by analyzing the language and emotion in the text. Aiming at the traditional emotion classification model can't fully capture the semantic information implied in short text comments, a two-channel emotion classification model based on CNN and BiLSTMl is proposed.Dynamic allocation weights introduced since the attention mechanism, build fusion BiLSTM and CNN's dual channel neural network architecture, and extract the bureau of emotional characteristics and emotional characteristics as global pay attention to the input feature fusion layer, through your emotions full text feature fusion module integration characteristic information and emotional polarity to break..Compared to the experimental results show that the model of emotion classification performance of the optimum Transformer model, this model (CNN-BiLSTM-AFF) on a public data set senti_weibo_100k accuracy, F1 value, the recall rate of 1.034%, 1.265% and 1.045% respectively.","Time series classification is a supervised task in the field of temporal data mining. Time series naturally tend to be highly dimensional, requiring the use of reduction techniques such as discretization. eMODiTS is a data-driven method for symbolically discretizing time series, which determines the best scheme by modifying the number of time (word segments) and values (alphabet) cuts, generating a unique alphabet set for every word segment. However, due to the high computational cost required, a surrogate model is incorporated to minimize this cost, using the K-Nearest Neighbors approach for regression and Dynamic Time Warping (DTW) as the similarity measure. Results suggest that the surrogate model effectively estimates the objective functions\u2019 values similarly to the original ones, leading to similar classification rates. It is validated with the statistical test where there is no significant statistical difference between the surrogate and original models. The surrogate model produces modified acceptance index (\nd\nj\n) values regarding predicting ability, indicating that the predictive performance is on average. On the other hand, the Mean Squared Error (MSE) consistently stays below 0.15, demonstrating that even when surrogate models cannot estimate the same values as the original model, the similarity of the values remains clear.","Multi-label learning has attracted a great deal of research interests as it has a wide range of real-world applications. Although many multi-label learning methods have been proposed, very few of them have addressed the problem of class imbalance distribution in multi-label data. Moreover, most of the existing class imbalance multi-label learning algorithms only focus on solving the class imbalance problem, without taking into account the correlations among labels. To address these issues simultaneously, we propose to combine the well-known ensemble of classifier chain (ECC) algorithm with various binary-class imbalance learning techniques such as sampling, cost-sensitive learning, and threshold moving. This approach creates a new algorithm family called ECC++, designed specifically for class imbalance multi-label learning. ECC is already an excellent ensemble high-order binary relevance multi-label learning algorithm that is well-suited to exploiting correlations among labels. Combining it with binary-class imbalance learning techniques enables each link in a classifier chain (CC) to overcome the negative effect of skewed data distribution. ECC++ is a dynamic algorithm family that can be extended arbitrarily by applying any new binary-class imbalance learning techniques. To demonstrate the effectiveness and superiority of the proposed ECC++ algorithm family, we developed several ECC++ family members using some popular binary-class imbalance learning techniques. We then compared them with several state-of-the-art class imbalance multi-label learning algorithms on twelve benchmark and four real-world multi-label datasets. Our experimental results showed the effectiveness and superiority of the proposed ECC++ algorithm family over existing class imbalance multi-label learning algorithms. In conclusion, the proposed ECC++ algorithm family combines the strengths of the well-established ECC algorithm and binary-class imbalance learning techniques, resulting in a superior methodology for class imbalance multi-label learning.","Federated learning (FL) has recently been applied to skin lesion analysis, but the challenges of huge communication requirements and non-independent and identical distributions have not been fully addressed. The former problem arises from model parameter transfer between the server and clients, and the latter problem is due to differences in imaging protocols and operational customs. To reduce communication costs, dataset distillation methods have been adopted to distill thousands of real images into a few synthetic images (1 image per class) in each local client, which are then used to train a global model in the server. However, these methods often overlook the possible inter-client distribution drifts, limiting the performance of the global model. In this paper, we propose a generalizable dataset distillation-based federated learning (GDD-FL) framework to achieve communication-efficient federated skin lesion classification. Our framework includes the generalization dataset distillation (GDD) method, which explicitly models image features of the dataset into an uncertain Gaussian distribution and learns to produce synthetic images with features close to this distribution. The uncertainty in the mean and variance of the distribution enables the synthetic images to obtain diverse semantics and mitigate distribution drifts. Based on the GDD method, we further develop a communication-efficient FL framework that only needs to transmit a few synthesized images once for training a global model. We evaluate our approach on a large skin lesion classification dataset and compare it with existing dataset distillation methods and several powerful baselines. Our results show that our model consistently outperforms them, particularly in comparison to the classical FL method. All resources can be found at https://github.com/jcwang123/GDD-FL.","A fit person who is health conscious always considers weighing what they eat and takes the calories on the food they eat. There is a certain number of calories per day that helps bodybuilders or people who want to stay fit. Taking in considerations of eating Fruits to have the calories, macros and nutrients they need. This study presents fruit calorie estimation using CNN or Convolutional Neural Network, the program was able to detect all the fruits with recognition accuracy of 70% and the percentage difference calorie estimation for each fruit are as follows: apple has 30.58%, banana garnered 21.15%, grapes garnered 44.07% and orange has 32.20%.","In multi-label classification, the expansion of output dimension seriously interferes learning performance, and even fails to build a joint prediction model. In order to restrain the proliferation of multi-label classifier\u2019s hypothesis space, the current works focus on the application of global positive label correlation. However, the \u201cblack or white\u201d mechanism ignore other possible forms of label correlation, such as negative or neutral correlation. By introducing the doctrine of the mean, three-way decision (3WD) theory provides a solution for in-depth research on local label correlation, and aims to handle the uncertainty of multi-label learning tasks. In this paper, a novel learning algorithm for multi-label joint classification, namely ML-3WD, is proposed by considering the 3WD label correlation from the perspective of samples. According to the weights of different features on any label, the comprehensive loss of each sample to three action strategies can be measured. Obviously, the 3WD rules for any label variable in multi-label output space is obtained. By aggregating the cutting thresholds between different labels, the division principles of 3WD label correlation are further established. Given any multi-label sample, the local fuzzy membership to co-occurrence or mutual state for label pair is examined based on kernelized fuzzy rough sets. The 3WD local label relevance of each sample is confirmed, that is, positive, negative or neutral. The global application strategy for multi-label classification is utilized to avoid over-fitting induced by local mining strategy. Based on the integral mean of the distribution of 3WD local label relevance in multi-label sample space, two different versions of empirical label relevance are constructed. By constraining the relative position between sub-separation hyperplanes, the 3WD label correlation distribution-based model for multi-label joint classification is designed. The experiment results on fifteen real world multi-label datasets reflect that our algorithm achieves good classification ability and versatility. The impact of core parameters on learning performance is also dissected.\nHighlights\n\u2022\nThe doctrine of the mean in three-way decision theory, which accords with human behavior cognition, inspires us to enrich the \u201dblack or white\u201d mining mechanism on label correlation. By adding buffer processing to the determined correlation, three possible forms for label correlation are first considered, they are positive, negative or neutral. A multi-label classification algorithm is designed according to 3WD label correlation from the perspective of samples, where global empirical label relevance is explicitly applied to restrict the sub-separation hyperplanes of different labels.","Diffuse large B-cell lymphoma (DLBCL) is an aggressive and most common type of non-Hodgkin lymphoma. The two major molecular subtypes of DLBCL, i.e. germinal center B-cell-like (GCB) and activated B-cell-like (ABC) types of DLBCL, have different clinical outcomes when treated with combined therapy R-CHOP. Cell-of-origin (COO) is a published prognostic method. Up to now, this classification requires either complex gene expression analysis or multiple immunohistochemistry (IHC) stains requiring expert scoring and assessment. In this paper, we aim to develop an effective and tissue-saving COO classification method based on H&amp;E stained whole slide images (WSIs). Specifically, we develop a new approach named Cellular Features Based Interpretable Network (CellFiNet), by leveraging both interpretable cellular features derived from image tiles and attention based multi-instance learning (AMIL) framework to train a WSI classification model. In comparison with the conventional AMIL approach based on image embeddings derived from convolutional neural networks (CNNs), the proposed approach achieved comparable classification accuracy, while being favorable in terms of explainability, as the model behavior can be interpreted through both attention scores and biologically relevant feature importances at whole slide as well as image tile levels.","Counterfactually-Augmented Data (CAD) \u2013 minimal editing of sentences to flip the corresponding labels \u2013 has the potential to improve the Out-Of-Distribution (OOD) generalization capability of language models, as CAD induces language models to exploit domain-independent causal features and exclude spurious correlations. However, the empirical results of CAD\u2019s OOD generalization are not as efficient as anticipated.In this study, we attribute the inefficiency to the myopia phenomenon caused by CAD: language models only focus on causal features that are edited in the augmentation operation and exclude other non-edited causal features. Therefore, the potential of CAD is not fully exploited. To address this issue, we analyze the myopia phenomenon in feature space from the perspective of Fisher\u2019s Linear Discriminant, then we introduce two additional constraints based on CAD\u2019s structural properties (dataset-level and sentence-level) to help language models extract more complete causal features in CAD, thereby mitigating the myopia phenomenon and improving OOD generalization capability. We evaluate our method on two tasks: Sentiment Analysis and Natural Language Inference, and the experimental results demonstrate that our method could unlock the potential of CAD and improve the OOD generalization performance of language models by 1.0% to 5.9%.\nHighlights\n\u2022\nExclusion of non-edited causal features causes CAD inefficiency in OOD generalization.\n\u2022\nThis inefficiency is analyzed in feature space by Fisher\u2019s linear discriminant.\n\u2022\nTwo constraints based on CAD structural properties help to extract causal features.\n\u2022\nCAD\u2019s potential for OOD generalization is unlocked.","In recent years, the prevalence of obesity and its related co-morbidities have been increasing significantly. Therefore, it is an important challenge to pursue an early prediction of obesity risk that could help in reducing the pace of obesity rise when appropriate interventions are placed, accordingly. The prediction and classification of obesity depend on different factors such as body mass index (BMI) and lifestyle aspects, including eating habits. By focusing on these lifestyles and eating habit factors, we can develop a more holistic approach to weight management and prevention of obesity. The aim of this paper is to propose a machine-learning model that can classify weight levels using lifestyle variables without relying on BMI which enables us to investigate how lifestyle factors affect different levels of weight categorization. Although BMI is the most widely used estimation of obesity, there are other factors that can contribute to gaining weight such as lifestyle factors. The accuracy of our lifestyle-based model reached 75% excluding weight, height, and family history. Our model could serve as a starting point for using an interpretable machine learning model to better understand the effect of lifestyle factors on obesity levels.","Emotion classification from text is the process of identifying and classifying emotions expressed in textual data. Emotions can be feelings such as anger, joy, suspense, sadness and neutral. Developing a machine learning model to identify emotions in a low-resourced language with a limited set of linguistic resources and annotated corpora is a challenge. This research proposes a Deep Learning Emotion Classification Framework to identify and classify emotions in low-resourced languages such as Hindi. The proposed framework combines a classification model and a low resource optimization technique in a novel way. An annotated corpus of Hindi short stories consisting of 20,304 sentences is used to train the models for predicting five categories of emotions: anger, joy, suspense, sadness, and neutral talk. To resolve the class imbalance in the dataset SMOTE technique is applied. The optimal classification model is selected through experimentation that compares machine learning models and pre-trained models. Machine learning and deep learning models are SVM, Logistic Regression, Random Forest, CNN, BiLSTM, and CNN+BiLSTM. The pre-trained models, mBERT, IndicBERT, and a hybrid model, mBERT+BiLSTM. The models are evaluated based on macro average recall, macro average precision, and macro average F1 score. Results demonstrate that the hybrid model mBERT+BiLSTM out perform other models with a test accuracy of 57%.","Text classification first needs to convert the text into embedding vectors. Considering that static word embedding models such as Word2vec do not consider the position information of word and the difference of its role in different documents, while dynamic word embedding models such as Bert consume a large amount of time. An improved word embedding model based on pre-trained Word2vec is proposed, which achieves better classification accuracy and much lower classification time than Bert. At first, the concept of Term Document Frequency (TDF) is proposed on the basis of TF-IDF, and the TF-IDF-TDF of each word in different documents is calculated. Then, The positional encoding is added. Finally, in order to reduce the misleading of words with low importance, a filter is designed to set the embedding vector with low importance to zero. Considering that the sequence length that the deep learning model can handle is limited, and the text sequence exceeding the Maximum Sequence Length (MSL) set by the deep learning model will be directly truncated and discarded, an adaptive segmentation model is proposed, which can set different segmentation strategies for different texts according to the length of the text and the MSL. In order to maintain the continuity of adjacent text after segmentation, an adjacent-segment-vector-attended co-attention network is designed. In addition, the multi-channel convolution and the capsule network are designed to further extract deep hidden features. Multiple comparative experiment results show that the proposed model achieves the best Accuracy and Micro-F1 on five long text baseline datasets and six short text baseline datasets. In addition, when the MSL is not set too large compared with the document length in the dataset, the classification results of the proposed model are not affected by it.\nHighlights\n\u2022\nAn pre-trained Word2vec based embedding model is proposed.\n\u2022\nAn adaptive segmented text classification model is proposed.\n\u2022\nAn adjacent-segment-vector-attended co-attention network is designed.\n\u2022\nThe multi-channel convolution and capsule network are used to extract deep hidden features.","Facial Micro-Expression (ME) is one of the pre-dominating non-verbal clues to demystify the true emotional states that people try to conceal cautiously. But emotion recognition from spontaneous ME images limits the high accuracy due to short duration and low intensity, lack of sufficient samples and consistencies among publicly available ME datasets. In this study, we have proposed two highly effective, lightweight, and generalized single-channel DLRRF-MER, and multi-channel DLH-3C-FUSION fusion models inspired by deep dense convolutional models and texture-based feature descriptors Local Binary Pattern (LBP) and Histogram of Oriented Gradients (HOG) to recognize ME from apex frame by constructing a composite dataset from five publicly available ME datasets CASME, CASMEII, CAS(ME)2, SAMM and MMEW. Pre-training has been done on a new composition of five facial macro expressions datasets CK+, MUGFE, OuluCasia, SFEW, and RAF-DB. The proposed models are fine-tuned on the target ME dataset rigorously with Stratified 5-Fold and 10-Fold, Leave-One-Subject-Out, and Leave-One-Dataset-Out(LODO) cross-validations(CV). In all evaluations, our proposed algorithms show remarkable improvement in effectiveness which surpasses the state-of-the-art accuracies and results in higher generalization capacity.","Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on public datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using standard commercial hardware. Moreover, large-spread ensembles are more robust than traditional ensembles against evasion attacks, at the cost of an acceptable loss of accuracy in the non-adversarial setting.","The aim of ordinal classification is to predict the ordered labels of the output from a set of observed inputs. Interval-valued data refers to data in the form of intervals. For the first time, interval-valued data and interval-valued functional data are considered as inputs in an ordinal classification problem. Six ordinal classifiers for interval data and interval-valued functional data are proposed. Three of them are parametric, one of them is based on ordinal binary decompositions and the other two are based on ordered logistic regression. The other three methods are based on the use of distances between interval data and kernels on interval data. One of the methods uses the weighted k-nearest-neighbor technique for ordinal classification. Another method considers kernel principal component analysis plus an ordinal classifier. And the sixth method, which is the method that performs best, uses a kernel-induced ordinal random forest. They are compared with na\u00efve approaches in an extensive experimental study with synthetic and original real data sets, about human global development, and weather data. The results show that considering ordering and interval-valued information improves the accuracy. The source code and data sets are available at https://github.com/aleixalcacer/OCFIVD.\nHighlights\n\u2022\nSix ordinal classifiers for interval data-valued data are proposed.\n\u2022\nOrdinal methods for interval-valued functional data are also proposed.\n\u2022\nConsidering ordering and interval-valued information improves the accuracy.\n\u2022\nA kernel-induced ordinal random forest performs best.","Accurate transformer fault diagnosis is crucial for maintaining the power system stability. Due the complex operation condition of the transformer, its faults are with the characteristic of multi-class faults, class-imbalance, and limited diagnosis data of availability. Additionally, some fault samples are only with overheating or discharge labels when collected, it is a challenge that how to how to use these samples. To address these issues, in this paper, a novel transformer fault diagnosis method based on a hybrid model of Res-Variational-Auto-Encoder (ResVAE) and ensemble learning (EL) model is proposed. Through a self-strengthening strategy, fault characteristics are extracted category-by-category by using a residual convolutional neural network, and low dimensional characteristics are mapped into characteristic fusion samples by VAE. Based on this strategy, an offline pre-training model is built based on ResVAE and EL. The hybrid model can obtain more information from offline source domain, enabling the EL to diagnose multiple fault types as well as undetermined faults. Considering 11 categories of imbalanced classification scenarios with limited sample sizes, the comparison is made between eight expansion and six diagnosis algorithms. The results show that the offline pre-training EL model increased the diagnostic accuracy up to 11.224% compared with tradition ratios method. The ResVAE-EL model achieves the highest diagnostic accuracy of 91.011%, which is 10.112% higher than that of the single offline pre-training model.","This paper presents a data pre-processing algorithm to tackle class imbalance in classification problems by undersampling the majority class. It relies on a formalism termed Presumably Correct Decision Sets aimed at isolating easy (presumably correct) and difficult (presumably incorrect) instances in a classification problem. The former are instances with neighbors that largely share their class label, while the latter have neighbors that mostly belong to a different decision class. The proposed algorithm replaces the presumably correct instances belonging to the majority decision class with prototypes, and it operates under the assumption that removing these instances does not change the boundaries of the decision space. Note that this strategy opposes other methods that remove pairs of instances from different classes that are each other\u2019s closest neighbors. We argue that the training and test data should have similar distribution and complexity and that making the decision classes more separable in the training data would only increase the risks of overfitting. The experiments show that our method improves the generalization capabilities of a baseline classifier, while outperforming other undersampling algorithms reported in the literature.","Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized in part by difficulties in verbal and nonverbal social communication. Evidence indicates that autistic people, compared to neurotypical peers, exhibit differences in head movements, a key form of nonverbal communication. Despite the crucial role of head movements in social communication, research on this nonverbal cue is relatively scarce compared to other forms of nonverbal communication, such as facial expressions and gestures. There is a need for scalable, reliable, and accurate instruments for measuring head movements directly within the context of social interactions. In this study, we used computer vision and machine learning to examine the head movement patterns of neurotypical and autistic individuals during naturalistic, face\u2013to\u2013face conversations, at both the individual (monadic) and interpersonal (dyadic) levels. Our model predicts diagnostic status using dyadic head movement data with an accuracy of , highlighting the value of head movement as a marker of social communication. The monadic data pipeline had lower accuracy () compared to the dyadic approach, emphasizing the importance of studying back-and-forth social communication cues within a true social context. The proposed classifier is not intended for diagnostic purposes, and future research should replicate our findings in larger, more representative samples.","Under real-world conditions, faulty samples of key components (e.g., bearings and cutting tools, etc.) are typically limited and sparse. Additionally, their historical data is characterized by time-series and imbalance characteristics. In other words, the training samples are not only limited and noisy, but also exhibit both within-class and between-class imbalance. These factors present significant challenges in the realm of fault monitoring modeling. To tackle these challenges, this paper presents an innovative fault diagnosis method rooted in the extended NI-MWMOTE and LS-SVM. NI-MWMOTE stands as an advanced noise-immunity majority weighted minority oversampling technique, originally introduced in our prior research, and it has exhibited exceptional competitiveness in noisy imbalanced benchmark datasets. It champions an adaptive noise processing strategy leveraging the distribution characteristics of noisy imbalanced data and the essence of machine learning. Specifically, it employs Euclidean distance and neighbor density to differentiate between spurious noise and true noise, and it determines the optimal processing strategy based on misclassification error and iteration. Furthermore, it employs unsupervised aggregative hierarchical clustering, misclassification error, and majority-weighted minority oversampling in a collaborative manner to address both within-class and between-class imbalanced problems. The primary contribution of our paper lies in the context of the monitoring scenario mentioned above. We have expanded the hyper-parameter range of NI-MWMOTE, corrected and optimized its built-in noise function to enhance the interpretability of the model, and successfully applied it in conjunction with LS-SVM to this particular setting. Notably, this marks the pioneering endeavor within our established knowledge sphere into the domain of tool wear state monitoring. The results suggest that, when compared to 11 well-known algorithms, our framework demonstrates significant competitiveness in real-world scenarios characterized under data-limited and noise-imbalanced scenarios for bearings and cutting tools fault diagnosis. This establishes a solid theoretical and practical foundation for similar scenarios.","Pneumonia is an important threat to human health, and different types of pneumonia have different treatment options, so the prediction and classification of pneumonia are important health issues. In this paper, chest X-ray images are used as data, and the final ensemble model can achieve excellent performance on these two tasks. In addition, this paper introduces the InceptionNeXt model to pneumonia prediction and classification problems for the first time, and finds that different model convolution kernels and perception fields may be more suitable for different medical image research tasks.","Braille character recognition(BCR) is a basic step in building and designing any Braille assistive technology. Each Braille character is represented by a 2 \u00d7 3 matrix of raised dots (called a cell), which can be read by touch. This study introduces a generalized recognition approach based on an ensemble of transfer learning models for BCR. The study experiments are performed on two benchmark English Braille datasets (handwritten Braille \u2013 Omniglot (HBO), and Braille character (BC)), and a new dataset of Arabic Braille characters collected by our group called Arabic Braille (AB). First, we investigate the performance of 17- transfer learning models on the three datasets. Then, we build three ensemble approaches based on majority voting from the most effective two, three, and four models in each dataset. The experimental results reveal that the ensemble of DarkNet-53, GoogleNet, SqueezeNet, and DenseNet-201 is a more generalizable ensemble approach for BCR. It achieves a higher F1 score and lesser generalization error ( E t e s t ) value than each individual transfer learning model. The F1 scores of the introduced ensemble reached 89.42%, 99.58%, and 97.11% on the HBO, BC, and AB datasets, respectively, with E t e s t values of 10.47%, 0.43%, and 3.23%. While the F1 scores of the DarkNet-53 which is the most effective single model on the three datasets are 87.54%, 99.14%, and 94.73, with E t e s t values of 12.79%, 0.85%, and 5.31%, respectively.","Recent research has shown that artificial intelligence (AI) models can exhibit bias in performance when trained using data that are imbalanced by protected attribute(s). Most work to date has focused on deep learning models, but classical AI techniques that make use of hand-crafted features may also be susceptible to such bias. In this paper we investigate the potential for race bias in random forest (RF) models trained using radiomics features. Our application is prediction of tumour molecular subtype from dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) of breast cancer patients. Our results show that radiomics features derived from DCE-MRI data do contain race-identifiable information, and that RF models can be trained to predict White and Black race from these data with 60\u201370% accuracy, depending on the subset of features used. Furthermore, RF models trained to predict tumour molecular subtype using race-imbalanced data seem to produce biased behaviour, exhibiting better performance on test data from the race on which they were trained.","Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be 'inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.","Finding the right business partner to drive innovation or acquire technology transfer is a labor and time-intensive process. To simplify this process, there is a need for improved methods of automated matchmaking that can quickly identify the best potential collaboration partners. This paper presents a novel approach for semi-automated business matchmaking between companies and research institutes, that is applied to a first case study. For this purpose, we compare two transformer-based text classification models and evaluate how dataset quality affects few-shot learning performance. Flair's TARS classifier performed very well in our use case, requiring only 40 examples per class to achieve an F1 score of about 90%. This is already very close to the Hugging Face standard text classifier, which achieved an F1 score of 92% with much more annotation effort. The results show that few-shot learning models like TARS can achieve accurate results even with few training samples compared to regular transformer-based language models. Our novel approach allows the time-consuming and labor-intensive task of manual partner matchmaking to be significantly reduced.","The burner combustion tuning is a complex problem that has been studied through flame monitoring and characterization. It has been observed that the flame electromagnetic spectrum and flickering contain specific flame information in combustion processes. This information is helpful for combustion stoichiometry tuning on burners. This paper described a method for selecting the best flame feature subset that can be computed from the scanner signal, in order to get the flame index and induce combustion stoichiometry on burners under specific combustion conditions. We propose a method for selecting a reduced subset with only the useful flame features for flame index classification. To extract the most relevant flame features we use a feature subset selection (FSS) algorithm and to determine the combustion state in burners, five flame indices were defined that represent the most common flame states in oil fuel-fired boilers. FSS includes complete, sequential, and random searches in order to eliminate redundant and noisy flame features to decrease the flame feature set dimension. A probabilistic neural network (PNN) algorithm was implemented for flame feature clustering. Signals from the actual flame scanner system and relevant variables from the boiler data acquisition system were used by the algorithms to calculate the burner flame index. A set of parametric tests was done in a heavy oil-fired boiler under well-known flame and index conditions to train and test the flame classifier. The results showed that only the four more relevant features are enough to classify flames with a good performance (92.3% accuracy), which is useful for burner combustion monitoring and optimization.\nHighlights\n\u2022\nA new approach to defining/selecting critical features in the combustion process.\n\u2022\nA new approach to classifying flames in industrial heavy oil-fired boilers.\n\u2022\nThe proposed algorithms are tested &amp; evaluated in a real industrial process.\n\u2022\nThe overall methodology ensures that the combustion process guarantees safety.","Node classification is an important task in many fields, e.g., predicting entity types in knowledge graphs, classifying papers in citation graphs, or classifying nodes in social networks. In many cases, it is crucial to explain why certain predictions are made. Towards this end, concept learning has been proposed as a means of interpretable node classification: given positive and negative examples in a knowledge base, concepts in description logics are learned that serve as classification models. However, state-of-the-art concept learners, including EvoLearner and CELOE exhibit long runtimes. In this paper, we propose to accelerate concept learning with graph sampling techniques. We experiment with seven techniques and tailor them to the setting of concept learning. In our experiments, we achieve a reduction in training size by over 90% while maintaining a high predictive performance.","A progressive neurodegenerative disease affecting motor neurons, Amyotrophic Lateral Sclerosis (ALS) requires early diagnosis as quickly as possible. For such situations, surface electromyography (S-EMG) is widely used as a non-invasive diagnostic tool to measure muscles' activity through electrodes placed on the skin's surface. Artificial intelligence (AI) approaches can be employed to analyze captured signals and distinguish abnormal patterns. However, previous work focused primarily on spatial information. It does not consider temporal information, effectively capturing the dynamic nature of muscle activity and identifying subtle abnormalities that might indicate ALS. Therefore, we fill the gap in this study by proposing a combination of CNN, Long-Short-Term Memory Networks (LSTM), and attention mechanisms to exploit temporal information in EMG signals. Stability assessment using K-fold cross-validation ensures reliable model performance. Our results demonstrate that combining spatial and temporal information can enhance performance and acquire 98.15% and 98.45% for CNN and LSTM, and CNN, LSTM, and Attention combination. In addition, our proposed model remains stable compared to previous work.","Lambani is an under-resourced Indo-Aryan language spoken by a nomadic tribe known as the \u2018Banjara people\u2019 across central and southern India. Due to its contact with several major languages of India, Lambani has been influenced both linguistically as well as culturally. One of the major influences has been observed in its phonemic inventory. This paper is a preliminary investigation into the acoustic characteristics of vowels of the language. The paper analyses spectral and temporal features of six Lambani vowels, viz. [inline-graphic not available: see fulltext] spoken in the Bagalkot district of Karnataka. The results obtained throw light on the distinctiveness of this variety. The paper then uses spectral and temporal features to explore both machine learning and deep learning approaches to classify Lambani vowel perceptual space. Results show that Fully Connected Dense Layer achieves better accuracy in classifying Lambani vowels.","As the importance of machine learning tools for decision support continues to grow, interpretability has emerged as a key factor. Rule-based classification algorithms, such as decision trees and rule induction, enable high local interpretability by providing transparent reasoning rules in an IF-THEN format. In this context, it is essential to provide concise and clear rules and conditions to achieve high local interpretability. This study proposes a novel Concise Algorithm, designed to effectively remove irrelevant conditions from classification rules. We present a framework incorporating the Concise Algorithm, which employs the One-Sided-Maximum decision tree algorithm for rule generation, followed by the application of the Concise Algorithm to remove irrelevant conditions. This proposed framework produces a rule-based classification model that exhibits an enhanced predictive performance-interpretability trade-off compared to benchmark methods (CART, Ripper, CN2, and modified One-Sided-Maximum), as demonstrated by empirical tests conducted on 19 UCI datasets. A case study focusing on the breast-cancer-wisconsin dataset provides a comprehensive analysis of the rule and condition generation processes.","Aspect-based sentiment analysis (ABSA) is a subtask of sentiment classification, and the difficulty is how to capture the sentiment aspect and sentiment polarity pairs in a sentence. Early studies applied serialization models with attention mechanisms to mine sentiment information. These models are simple and effective, but cannot accurately capture sentiment pairs when encountering complex sentences. Recently, scholars have applied dependency information to construct various graph neural networks for the ABSA task. Compared with serialized models, these structured models demonstrate the graph neural network is powerful in capturing information, and further illustrates the syntactic information is effective for sentiment analysis. However, these syntactic models are usually influenced by syntactic parsers, especially for complex sentences. Hence, this paper builds a Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis (LSOIT). Specifically, inducing knowledge-aware opinion induction trees for each aspect word applied by reinforcement learning and attention mechanisms that integrate the lexicon knowledge (i.e. sememe knowledge) and syntax knowledge (i.e. phrase structures, and dependency relationships). Finally, we establish graph neural networks on knowledge-aware opinion induction tree for ABSA. Experimental results on four benchmarking datasets (i.e., Rest14, Laptop14, Twitter and MAMS) demonstrate that LSOIT significantly improves 2.21%, 0.47%, and 0.18% on Rest14, Laptop14, and MAMS comparing with state-of-the-art models, respectively. Ablation Study and Case Study manifest that external knowledge is useful, especially for datasets with standardized grammar rules.\nHighlights\n\u2022\nLexicon and Syntax Enhanced Opinion Induction Tree is proposed.\n\u2022\nUsing reinforcement learning and attention mechanism builds opinion induction trees.\n\u2022\nKnowledge enhanced opinion induction tree is presented.\n\u2022\nGCNs is constructed based on knowledge opinion induction tree for ABSA.","Leveraging unlabeled examples is a crucial issue for boosting performances in semi-supervised learning. In this work, we introduce the SAMOSA framework based on semantic augmentation for mixing semantic components from labeled examples and non semantic characteristics from unlabeled data. Our approach is based on a novel reconstruction module that can be grafted onto most state of the art networks. The proposed approach leans on two main aspects: an architectural component optimized to disentangle semantic and auxiliary non semantic representations using an unsupervised loss, and a semantic augmentation scheme that leverages this disentangling module to generate artificially labeled examples preserving known class information while controlling auxiliary variations. We demonstrate the ability of our method to improve the performance of models trained according to standard semi-supervised procedures Mean Teacher (Tarvainen and Valpola, 2017) MixMatch (Berthelot et al., 2019) and FixMatch (Sohn et al., 2020).\nHighlights\n\u2022\nSAMOSA regularizes classifiers through reconstruction in semi-supervised learning.\n\u2022\nOur Auto-encoder separates semantic and non-semantic information.\n\u2022\nNon-semantic information is isolated thanks to an asymmetrical decoder architecture.\n\u2022\nThe asymmetrical decoder allows for a novel semantic reconstruction regularizer.\n\u2022\nMixing samples\u2019 semantic and non-semantic contents yields a novel data augmentation.","Canonical Correlation Analysis (CCA) has been widely used in Steady-State Visually Evoked Potential (SSVEP) analysis, but there are still challenges in this research area, specifically regarding data quality and insufficiency. In contrast to most previous studies that primarily concentrate on the development of spatial or spectral templates for SSVEP data, this paper proposes a novel temporal filtering method based on a reinforcement learning (RL) algorithm for CCA on SSVEP data. The proposed method leverages RL to automatically and precisely detect and filter low-quality segments in the SSVEP data, thereby improving the accuracy of CCA. Additionally, the proposed RL-based Temporal Filtering is algorithm-independent and compatible with various CCA algorithms. The RL-based Temporal Filtering is evaluated using a wearable dataset consisting of 102 subjects. The experimental results demonstrate significant advancements in CCA accuracy, particularly when combined with the extended CCA (ECCA) algorithm. In addition to performance enhancement, the RL-based Temporal Filtering method provides visualizable filters, which can ensure the transparency of the filtering process and the reliability of the obtained results. By addressing data quality and insufficiency concerns, this novel RL-based Temporal Filtering approach demonstrates promise in advancing SSVEP analysis for various applications.","In this paper, a novel knowledge distillation (KD)-based pedestrian attribute recognition (PAR) model is developed, where a multi-label mixed feature learning network (MMFL-Net) is designed and adopted as the student model. In particular, by applying the grouped depth-wise separable convolution, re-parameterization and coordinate attention mechanism, not only the multi-scale receptive field information is sufficiently fused and spatially dependent robust features are extracted, the model complexity is also effectively kept acceptable. To alleviate the imbalance of category samples, an attribute weight parameter is proposed and considered when calculating the multi-label loss. Moreover, the Jensen\u2013Shannon (JS) divergence-based KD scheme can facilitate the learning of MMFL-Net from the teacher model, which benefits strong fitting ability of the deep feature correlations so as to realize a highly generalized model. The proposed KD-PAR is comprehensively evaluated through many of experiments, and experimental results show the effectiveness and superiority of the proposed model as compared with other advanced MLL-based methods and state-of-the-art PAR models, which efficiently achieves the balance between accuracy and complexity. When facing the complex scenes such as blurry background, similar object interference, and target occlusion, the proposed KD-PAR can even present satisfactory recognition results with strong robustness, thereby providing a feasible and practical solution to the PAR tasks.\nHighlights\n\u2022\nThe proposed KD-PAR can achieve multi-label mixed feature learning for PAR tasks.\n\u2022\nThe JS-based divergence KD scheme is beneficial for learning generalized features.\n\u2022\nAttribute weight can alleviate performance degradation caused by imbalanced samples.\n\u2022\nStructural re-parameterization refines feature presentation with less complexity.","The prevalence of skin cancer, specifically melanoma, constitutes a significant global health concern, thus giving rise to intricate detection challenges that demand immediate attention and comprehensive solutions. In this study, we investigate the application of deep learning models for melanoma detection. Five pre-trained models, including VGG-16, ResNet50, InceptionV3, DenseNet-121, and Xception, are evaluated through a series of experiments. The models undergo the same training process with transfer learning, freezing all layers and modifying the classification layer. The experiments reveal that ResNet50 consistently outperforms the other models, demonstrating superior accuracy, precision, recall, and F1 score. Notably, ResNet50 exhibits exceptional accuracy and F1 score, achieving around 93% in both. This study sheds light on the potential use of deep learning in enhancing melanoma diagnosis and underscores the need for robust and accurate classification systems for early detection and effective treatment of skin cancer.","In microseismic monitoring, various types of vibration events are often collected. Realizing the automatic identification of microseismic events in many suspected events is the basis of monitoring timeliness. However, due to the different sampling methods of microseismic data provided by different products, the data often contains different waveform sizes and sampling frequencies. This makes it difficult for existing approaches to be widely used in different projects without data preprocessing. In this paper, we propose the Universal Automatic Classification Network (UACNet), a deep learning approach that automatically identifies microseismic data in engineering without preprocessing. The UACNet model includes multiple convolution layers, adaptive average pooling layers, fully connected layers, and UAC blocks. UAC block is a residual structure with multiple convolutional layers and reset and update gates. The adaptive average pooling layer unifies the input size, and the UAC block functions as a feature extraction network to mine sufficient features from data. We test the proposed UACNet on engineering data and compare it with existing common and advanced methods. As a result, UACNet passed the ablation study, and the classification accuracy of UACNet is 95.62%, which is higher than 89.14% of CNN, 91.24% of ResNet, 91.04% of CapsNet, and 86.16% of RTFN, respectively. Moreover, the influence of waveform size, sampling rate, signal-to-noise ratios, and amplitude on the accuracy of UACNet is analyzed. The results show that UACNet can overcome the influence of these factors and truly realize automatic real-time classification of microseismic signals without preprocessing.","The heart, as the main organ of our human body, plays an important role in pumping blood through our body. Early prevention and prediction of cardiovascular disease (CVD) can save more lives, especially for ordinary people. Hence, this study proposes a voting ensemble-based prediction model for the risk of CVD in ordinary people. We first integrate 2 years of data from the Korea National Health and Nutrition Examination Survey (KNHANES) and then extract the experimental data. Thereafter, the extracted data is preprocessed with missing value imputation and data normalization. A filter-based feature selection approach is also applied to select the efficient attributes for the experiment, then split the data into training (80%) data and test (20%) data. Thenceforth, we use two kinds of hybrid data sampling techniques such as synthetic minority oversampling techniques (SMOTE) plus Tomek Links (SMOTETomek) and SMOTE plus Edited Nearest Neighbors (SMOTEENN) to solve the imbalance issue in the training data. Next, the voting ensemble-based prediction model is designed based on different machine learning algorithms such as logistic regression, support vector machine, and AdaBoost on the balanced training data with selected features and complete features. Lastly, the proposed model is evaluated on the test data and compared with other popularly used machine learning-based models. In the experimental results, the proposed voting ensemble-based prediction model with the SMOTEENN technique on selected features by using the filter-based feature selection approach achieved the best performance with the accuracy of 0.8102, recall 0.8102, g-mean 0.8102, and AUC 0.8102, respectively for the risk of CVD in ordinary people and outperformed other machine learning-based prediction models.","The K-nearest neighbor interpolation method was used to fill in missing data of five indicators of coronary heart disease, diabetes, total cholesterol, triglycerides, and albumin;, and the SMOTE algorithm was used to balance the number of variable indicators. The Relief-F algorithm was used to remove 18 variable indicators and retain 42 variable indicators. LASSO and ridge regression algorithms were used to remove eight variable indicators and retain 52 variable indicators; The prediction accuracy, recall, and AUC values of the linear kernel support vector machine model filtered using Relief-F and LASSO features are high, and the prediction results are optimal; The test result of random forest screened by Relief-F and LASSO features is better than that of the support vector machine model. It is concluded that the random forest model screened by Relief-F features is better as a prediction of lung cancer typing. The research results provide theoretical data support for predicting lung cancer classification using machine learning methods.","State-of-the-art weakly supervised text classification methods, while significantly reduced the required human supervision, still requires the supervision to cover all the classes of interest. This is never easy to meet in practice when human explore new, large corpora without complete pictures. In this paper, we work on a novel yet important problem of weakly supervised open-world text classification, where supervision is only needed for a few examples from a few known classes and the machine should handle both known and unknown classes in test time. General open-world classification has been studied mostly using image classification; however, existing methods typically assume the availability of sufficient known-class supervision and strong unknown-class prior knowledge (e.g., the number and/or data distribution). We propose a novel framework \u00f8ur that lifts those strong assumptions. Specifically, it follows an iterative process of (a) clustering text to new classes, (b) mining and ranking indicative words for each class, and (c) merging redundant classes by using the overlapped indicative words as a bridge. Extensive experiments on 7 popular text classification datasets demonstrate that \u00f8ur outperforms strong baselines consistently with a large margin, attaining 23.33% greater average absolute macro-F1 over existing approaches across all datasets. Such competent accuracy illuminates the practical potential of further reducing human effort for text classification.","Planktons are the building blocks of marine food webs and key indicators of ocean health. Monitoring of plankton populations help study the biological diversity of microbial eukaryotes. Recent years have witnessed the wide usage of digital holographic microscopes (DHM) for in situ detection of underwater microplanktons. Holography has an edge over other imaging techniques due to its unique ability to provide a 3D hologram of the microplankton without disturbing its orientations. In this paper, a novel network architecture with 5.29 GFLOPs is developed for the classification of microplanktons in digital holographic images. The proposed method achieved a class-wise F1-scores above\n80\n%\nat a lower computational cost. The proposal provided competitive performance with respect to six baseline network architectures. This technique has the potential to be appealing for future applications of in situ classification of microplanktons.","Railway switches are critical components in the rail system. Operation and maintenance tasks are essential to ensure proper functioning and avoid any failure that can cause delays, reducing operational safety. Data from condition monitoring systems requires advanced analysis tools. This paper presents the analysis of power output data of railway switches. A novel approach is proposed based on statistical analysis techniques combined with Machine Learning techniques to classify power curves by analyzing different sections of the power curves. These curves are studied statistically to classify them into normal and non-normal curves. Then, a dataset is generated with normal and non-normal labelled curves. Shapelets and k-Nearest Neighbour classification algorithms are applied to these data with good results (accuracy, sensitivity and specificity above 88% in each case). As a further analysis, a second dataset with the sectioned curves is done to detect non-normal curves without analyzing the complete curve. For this case study, k-Nearest Neighbour algorithm is able to classify with higher accuracy on the last section of the curve.","Few-Shot Class-Incremental Learning (FSCIL) is to learn novel classes with few data points incrementally, without forgetting old classes. It is very hard to capture the underlying patterns and traits of the few-shot classes. To meet the challenges, we propose a Self-supervised Contrastive Feature Refinement (SCFR) framework which tackles the FSCIL issue from three aspects. Firstly, we employ a self-supervised learning framework to make the network to learn richer representations and promote feature refinement. Meanwhile, we design virtual classes to improve the models robustness and generalization during training process. To prevent catastrophic forgetting, we attach Gaussian Noise to encountered prototypes to recall the distribution of known classes and maintain stability in the embedding space. SCFR offers a systematic solution which can effectively mitigate the issues of catastrophic forgetting and over-fitting. Experiments on widely recognized datasets, including CUB200, miniImageNet and CIFAR100, show remarkable performance than other mainstream works.","The findings on open-set recognition (OSR) show that models trained on classification datasets are capable of detecting unknown classes not encountered during the training process. Specifically, after trainig, the learned representations of known classes dissociate from the representations of the unknown class, facilitating OSR. In this paper, we investigate this emergent phenomenon by examining the relationship between the Jacobian norm of representations and the inter/intra-class learning dynamics. We provide a theoretical analysis, demonstrating that intra-class learning reduces the Jacobian norm for known class samples, while inter-class learning increases the Jacobian norm for unknown samples, even in the absence of direct exposure to any unknown sample. Overall, the discrepancy in the Jacobian norm between the known and unknown classes enables OSR. Based on this insight, which highlights the pivotal role of inter-class learning, we devise a marginal one-vs-rest (m-OvR) loss function that promotes strong inter-class separation. To further improve OSR performance, we integrate the m-OvR loss with additional strategies that maximize the Jacobian norm disparity. We present comprehensive experimental results that support our theoretical observations and demonstrate the efficacy of our proposed OSR approach.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThe underlying principle of OSR is demystified by the Jacobian norm of representation.\n\u2022\nA marginal one-vs-rest loss function is devised for effective OSR.","Meta-learning excels in few-shot learning by extracting shared knowledge from the observed tasks. However, it needs the tasks to adhere to the i.i.d. constraint, which is challenging to achieve due to complex task relationships between data content. Current methods that create tasks in a one-dimensional structure and use meta-learning to learn all tasks flatly struggle with extracting shared knowledge from tasks with overlapping concepts. To address this issue, we propose further constructing tasks from the same environment into hyper-tasks. Since the distributions of hyper-tasks and tasks in a hyper-task can both be approximated as i.i.d. due to further summarization, the meta-learning algorithm can capture shared knowledge more efficiently. Based on the hyper-task, we propose a hierarchical meta-learning paradigm to meta-learn the meta-learning algorithm. The paradigm builds a customized meta-learner for each hyper-task, which makes meta-learners more flexible and expressive. We apply the paradigm to three classic meta-learning algorithms and conduct extensive experiments on public datasets, which confirm the superiority of hierarchical meta-learning in the few-shot learning setting. The code is released at https://github.com/tuantuange/H-meta-learning.","To lessen damages from landslides, the key challenge is to predict the events precisely and accurately. The objective of this study is to assess landslide susceptibility in the study area. To achieve this objective, a detailed landslide inventory has been prepared based on imagery data and frequent field visits of 153 rock slides and 44 debris slides. Nine landslide factors were prepared initially and their relationships with each other and with the type of landslide was analysed. Information gain ratio measure is used to eliminate triggering factors with least score. Train_test_split method was used to classify the dataset into training and testing groups. Decision tree classification model of machine learning was applied for landslide susceptibility model (LSM). The performance was evaluated using classification report and receiver operating characteristic (ROC) curve. Results obtained have proven that the decision tree classification model performed well with good accuracy in forecasting landslide susceptibility.","The metric-based learning framework has been widely used in data-scarce few-shot visual classification. However, the current loss function limits the effectiveness of metric learning. One issue is that the nearest neighbor classification technique used greatly narrows the value range of similarity between the query and class prototypes, which limits the guiding ability of the loss function. The other issue is that the episode-based training setting randomizes the class combination in each iteration, which reduces the perception of the traditional softmax losses for effective learning from episodes with various data distributions.To solve these problems, we first review some variants of the softmax loss from a unified perspective, and then propose a novel Dynamically-Scaled Softmax Loss (DSSL). By adding a probability regulator (for scaling probabilities) and a loss regulator (for scaling losses), the loss function can adaptively adjust the prediction distribution and the training weights of the samples, which forces the model to focus on more informative samples. Finally, we found the proposed DSSL strategy for few-shot classifiers can achieve competitive results on four generic benchmarks and a fine-grained benchmark, demonstrating the effectiveness of improving the distinguishability (for base classes) and generalizability (for novel classes) of the learned feature space.\nHighlights\n\u2022\nThe deep connections between some known losses were established and revealed.\n\u2022\nThe new framework are suitable for small sample scenarios with intuitive motivation.\n\u2022\nDetailed implementation was conducted on sufficient datasets with good result.","\u201cUnknown unknowns\u201d are instances predicted models assign incorrect labels with high confidence, greatly reducing the generalization ability of models. In practical applications, unknown unknowns may lead to significant decision-making mistakes and reduce the application value of models. As unknown unknowns are agnostic to models, it is extremely difficult to figure out why models would make highly confident but incorrect predictions. In this paper, based on identification of unknown unknowns, we investigate the interpretability of unknown unknowns arising from convolutional neural network models in image classification tasks by interpretable methods. We employ visualization methods to interpret prediction results on unknown unknowns, further understand predictive models and analyze the predictive basis of unknown unknowns. We focus the application scenario of interpretability of unknown unknowns on a clothes category recognition task (dress vs shorts) in e-commerce platforms, and observe some patterns of models making wrong classifications that lead to unknown unknowns, which indicates that a CNN model that lacks of common sense can make mistakes even for a large dataset. Besides, we observe some interesting phenomena: certain correct predictions of instances are unreliable due to wrongly identified features by CNNs.","Uncertainty measures exhibit algebraic and informational perspectives, and the two-view measure integration facilitates feature selections in classification learning. According to neighborhood decision systems (NDSs), two basic algorithms of feature selections (called JE-FS and DE-FS) already exist by using joint and decisional entropies, respectively, but they have advancement space for informationally fusing algebraic measures. In this paper on NDSs, three-way fusion measures are systematically constructed by combining three-way algebraic and informational measures, and thus three-level feature selections are hierarchically investigated by using corresponding monotonic and nonmonotonic measures and strategies. At first, the accuracy, granularity, and composite granularity-accuracy constitute three-way algebraic measures, while the joint, conditional, and decisional entropies (JE, CE, DE) formulate three-way informational measures. Then, three-way algebraic and informational measures are combined via normalization and multiplication, so three-way fusion measures based on JE, CE, DE are established. These new measures acquire granulation monotonicity and nonmonotonicity. Furthermore by relevant measures and monotonicity/nonmonotonicity, three-level feature selections (with null, single, and double fusion levels) related to JE, CE, DE are proposed, and corresponding heuristic algorithms are designed by monotonic and nonmonotonic principles. 4 \u00d7 3 = 12 selection algorithms comprehensively emerge, and they extend and improve current JE-FS and DE-FS. Finally by data experiments, related uncertainty measures and granulation properties are validated, and all 12 selection algorithms are compared in classification learning. As a result, new algorithms outperform JE-FS and DE-FS for classification performance, and the algorithmic improvements accord with the fusion-hierarchical deepening and entropy-systematic development of uncertainty measures.\nHighlights\n\u2022\nThree-way algebraic and informational measures induce three-way fusion measures.\n\u2022\nThree-way fusion measures acquire granulation monotonicity and nonmonotonicity.\n\u2022\nThree-level feature selections offer 4 \u00d7 3 = 12 monotonic/nonmonotonic algorithms.\n\u2022\nExtended heuristic algorithms improve 2 current algorithms on classification effects.","Accurate classification of Acute Myeloid Leukemia (AML) subtypes is crucial for clinical decision-making and patient care. In this study, we investigate the potential presence of age and sex bias in AML subtype classification using Multiple Instance Learning (MIL) architectures. To that end, we train multiple MIL models using different levels of sex imbalance in the training set and excluding certain age groups. To assess the sex bias, we evaluate the performance of the models on male and female test sets. For age bias, models are tested against underrepresented age groups in the training data. We find a significant effect of sex and age bias on the performance of the model for AML subtype classification. Specifically, we observe that females are more likely to be affected by sex imbalance dataset and certain age groups, such as patients with 72 to 86 years of age with the RUNX1::RUNX1T1 genetic subtype, are significantly affected by an age bias present in the training data. Ensuring inclusivity in the training data is thus essential for generating reliable and equitable outcomes in AML genetic subtype classification, ultimately benefiting diverse patient populations.","Data classification is the most common task in machine learning, and feature selection is the key step in the classification task. Common feature selection methods mainly analyze the maximum correlation and minimum redundancy between feature factors and tags while ignoring the impact of the number of key features, which will inevitably lead to waste in subsequent classification training. To solve this problem, a feature selection algorithm (SSMI) based on the combination of sinusoidal sequences and mutual information is proposed. First, the mutual information between each feature and tag is calculated, and the interference information in high-dimensional data is removed according to the mutual information value. Second, a sine function is constructed, and sine ordering is carried out according to the mutual information value and feature mean value between different categories of the same feature. By adjusting the period and phase value of the sequence, the feature set with the largest difference is found, and the subset of key features is obtained. Finally, three machine learning classifiers (KNN, RF, SVM) are used to classify key feature subsets, and several feature selection algorithms (JMI, mRMR, CMIM, SFS, etc.) are compared to verify the advantages and disadvantages of different algorithms. Compared with other feature selection methods, the SSMI algorithm obtains the least number of key features, with an average reduction of 15 features. The average classification accuracy has been improved by 3% on the KNN classifier. On the HBV and SDHR datasets, the SSMI algorithm achieved classification accuracy of 81.26% and 83.12%, with sensitivity and specificity results of 76.28%, 87.39% and 68.14%, 86.11%, respectively. This shows that the SSMI algorithm can achieve higher classification accuracy with a smaller feature subset.","To improve the classification accuracy of hand movements from sEMG signals, this paper puts forward a unified hand gesture classification framework which exploits the potentials of variational mode decomposition (VMD) and multi-class support vector machine (SVM). Acquiring the sEMG signals from 25 intact subjects for ten functional activities in real-time, we implement a non-recursive adaptive decomposition technique to sEMG signals and perform power spectral analysis to identify the dominant narrow-band intrinsic mode functions (IMFs) that contain prominent biomarkers. Subsequently, to compute the optimal feature vectors from a set of entropy measures, this work investigates the performance of two techniques namely minimum redundancy and maximum relevance (MRMR) technique and kernel principal component analysis (kPCA). After extracting the optimal set of entropy features, the proposed approach implements a multi-class SVM based on one-vs-one (OVO) strategy to classify the hand gestures. The performance of the multi-class SVM compared with those of the K-nearest neighbor (KNN) and na\u00efve bayes (NB) classifiers highlight that multi-class SVM offers superior performance with an average classification accuracy of 99.98%. Moreover, for statistical analysis of the experimental results, this work performs Friedman test to analyze the significance of the SVM, KNN and NB classifier performances. Finally, the performance comparison of the proposed approach with those of the state-of-the-art techniques highlights the superiority of the proposed framework to improve the hand gesture classification accuracy.\nHighlights\n\u2022\nVMD augmented multi-class SVM framework is presented for gesture recognition.\n\u2022\nOptimal entropy measures from decomposed IMFs are extracted through kPCA technique.\n\u2022\nA maximum classification accuracy of 99.98% is achieved using multi-class SVM.\n\u2022\nStatistical analysis of ML classifier models is performed using Friedman test.","Evaluating speaker emotion in conversations is crucial for various applications requiring human-computer interaction. However, co-occurrences of multiple emotional states (e.g. 'anger' and 'frustration' may occur together or one may influence the occurrence of the other) and their dynamic evolution may vary dramatically due to the speaker's internal (e.g., influence of their personalized socio-cultural-educational and demographic backgrounds) and external contexts. Thus far, the previous focus has been on evaluating only the dominant emotion observed in a speaker at a given time, which is susceptible to producing misleading classification decisions for difficult multi-labels during testing. In this work, we present Self-supervised Multi- Label Peer Collaborative Distillation (SeMuL-PCD) Learning via an efficient Multimodal Transformer Network, in which complementary feedback from multiple mode-specific peer networks (e.g.transcript, audio, visual) are distilled into a single mode-ensembled fusion network for estimating multiple emotions simultaneously. The proposed Multimodal Distillation Loss calibrates the fusion network by minimizing the Kullback-Leibler divergence with the peer networks. Additionally, each peer network is conditioned using a self-supervised contrastive objective to improve the generalization across diverse socio-demographic speaker backgrounds. By enabling peer collaborative learning that allows each network to independently learn their mode-specific discriminative patterns,SeMUL-PCD is effective across different conversation environments. In particular, the model not only outperforms the current state-of-the-art models on several large-scale public datasets (e.g., MOSEI, EmoReact and ElderReact), but with around 17% improved weighted F1-score in the cross-dataset experimental settings. The model also demonstrates an impressive generalization ability across age and demography-diverse populations.","In this paper the first results of the process of extracting survival patterns in diagnosed women with invasive cervical cancer with classification techniques from data reported in population-based cancer registry of the municipality of Pasto (Colombia) for a time period of 10 years are presented. The generated knowledge will allow to understand the different socioeconomic and clinical factors affecting the survival of this population group. This knowledge will support effective decision making of government agencies and private health sector in relation to the approach of public policies and prevention programs designed to detect new cases of women with this disease early.","Haze classification plays a crucial role in air quality and visibility assessment. In contrast to traditional image classification, haze classification requires the classifier to capture the characteristics of different levels of haze. However, existing methods primarily focus on feature extraction while neglecting the interference of background information. To address this issue, this paper proposes a hard attention infused network (HAINet) for haze classification, consisting of an unsupervised segmentation module (USM) and a hybrid information fusion module (HIF). The USM is used to extract haze area information in an unsupervised manner, generating various forms of haze images. The HIA selects different various forms of haze images, as a hard attention mechanism, to reduce the impact of background and improve classification performance. We conduct experiments on two datasets, Hazel-level and Haze-Wild, in terms of performance comparison, ablation study, and case studies. The results show that our method effectively reduces the impact of background noise in haze images and consistently improves the classification performance.","Hierarchical text classification aims to assign text to multiple labels in a label set stored in a tree structure. The current algorithms mainly introduce the priori information of the label hierarchy, but the implicit correlation between labels in the hierarchy is rarely applied. At the same time, we also found that the inherent class imbalance of chain labels will also lead to poor classification effects of lower-level labels through a large number of studies. Therefore, a label structure enhanced hierarchy aware global model (LSE-HiAGM) is proposed. Firstly, the common density coefficient of labels is defined to measure the importance of a pair of labels in the hierarchical structure. Secondly, the common density coefficient is used as the weight of the label to update the topological structure features, so that the label can be linked with all labels globally. Finally, the topological structure feature, text features, and label hierarchical features are fused to make full use of all features to improve the embedding quality of low-level labels. In addition, to alleviate the class imbalance problem, a new loss function is used to constrain the model training. The probability of the label being sampled relative to all the labels of the sample is taken as the weight of the loss function. Therefore, a small penalty is imposed on the upper label and a large penalty on the lower label. A large number of experiments on datasets such as RCV1, WOS and NYT show that LSE-HiAGM performs better than the baseline models in hierarchical text classification.","MERS-CoV, which belongs to the beta-coronaviruses together with SARS-CoV-2, although it has received relatively less attention by the COVID-19 pandemic, there is a sufficient possibility of new MERS-CoV lineages and variants. Previous studies have discussed the possibility of frequent recombination of MERS-CoV. We thus present a highly accurate method for the phylogenetic analysis and classification of MERS-CoV including recombinant sequences. We collected the sequences of S protein from MERS-CoV and divided them into five phylogenetic groups, of which recombinant sequences were divided into seven types. Physicochemical properties of amino acids were then calculated from the S protein sequences, and the results were used for the random forest model, Na\u00efve Bayes classification, and k-nearest neighbor method. We also constructed several feature subsets based on the ranked amino acid properties and applied them to the random forest model. In each dataset, the amino acid physicochemical properties were ranked differently. Using this information, classification of MERS-CoV based on machine learning algorithms showed that the random forest model had the best accuracy and area under the curve compared with the k-nearest neighbor and Na\u00efve Bayes classification methods. Several feature subsets were constructed using the correlation feature selection algorithm and applied to the random forest model. Overall, the performance of the classifier was improved compared to that when using all features. Coronaviruses including MERS-CoV continue to evolve into new forms through recombination or mutation. We thus present a method to increase the accuracy of their classification using additional information of the viral protein sequence, and confirm that a subunit consisting of optimal prominent features can improve the performance of the classifier by removing the unnecessary characteristic information.","Cautious classifiers are designed to make indeterminate decisions when the uncertainty on the input data or the model output is too high, so as to reduce the risk of making wrong decisions. In this paper, we propose two cautious decision-making procedures, by aggregating trees providing probability intervals constructed via the imprecise Dirichlet model. The trees are aggregated in the belief functions framework, by maximizing the lower expected discounted utility, so as to achieve a good compromise between model accuracy and determinacy. They can be regarded as generalizations of the two classical aggregation strategies for tree ensembles, i.e., averaging and voting. The efficiency and performance of the proposed procedures are tested on random forests and illustrated on three UCI datasets.","One of the difficult problems in agriculture is predicting the crop production. At the international, regional, and crop level, it is crucial to make decisions on this. In Most of the cases, agricultural, land, climatic, atmospheric, and other characteristics are used to forecast crop production. ML is a crucial decision-support model for estimating agricultural yields, enabling choices about which crops to cultivate and what to do while they are in the growing season. Numerous ML and DL algorithms have been applied to support studies on agricultural yield prediction. In this paper, a new crop yield prediction model is proposed which includes preprocessing, feature extraction and yield prediction phase. In preprocessing, data cleaning will takes place. Higher order statistical feature, information gain and improved entropy based features are extracted in feature extraction phase. The prediction is done by the hybrid model that combines Bi-GRU model and Maxout classifiers. To enhance the performance of this hybrid classifier, a new Self Adaptive Archimedes Optimization Algorithm (SAAOA) is introduced for training the weight parameters optimally. Finally the overall performance is evaluated and the better result is determined.","In the realm of ChatGPT's language capabilities, exploring Arabic Sentiment Analysis emerges as a crucial research focus. This study centers on ChatGPT, a popular machine learning model engaging in dialogues with users, garnering attention for its exceptional performance and widespread impact, particularly in the Arab world. The objective is to assess people's opinions about ChatGPT, categorizing them as positive or negative. Despite abundant research in English, there is a notable gap in Arabic studies. We assembled a dataset from Twitter, comprising 2,247 tweets, classified by Arabic language specialists. Employing various machine learning algorithms, including Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), and Naive Bayes (NB), we implemented hyperparameter optimization techniques such as Bayesian optimization, Grid Search, and random search to select the best hyperparameters which contribute to achieve the best performance. Through training and testing, performance enhancements were observed with optimization algorithms. SVM exhibited superior performance, achieving 90% accuracy, 88% precision, 95% recall, and 91% F1 score with Grid Search. These findings contribute valuable insights into ChatGPT's impact in the Arab world, offering a comprehensive understanding of sentiment analysis through machine learning methodologies.","In this study, we propose a new method called 'multi-label mapping' (MLM) for solving multi-class classification problems by mapping them into multi-label problems. The MLM method frequently selects different combinations of base classes, merges the classes, and assigns a new label to each class. Six standard datasets are selected from the UCI machine learning repository to evaluate the proposed method. Experimental results demonstrate that the MLM method reduces 50% to 96.66% of the number of required SVM classifiers and 25.76% to 72.27% of the training-testing time in comparison with the OVA and OVO methods. It also yields a better performance in terms of accuracy, precision, recall, and overfitting. Due to the need for a very low number of the SVM binary classifiers, a low training-testing time, and an acceptable prediction error, the presented method is a potential candidate for use in pattern recognition applications and multi-class classification problems.","Breast cancer characterization remains a significant and challenging issue in contemporary medicine. Accurately distinguishing between malignant and benign breast lesions is crucial for effective diagnosis and treatment. The anatomical structure of malignant breast ultrasound images is more chaotic than that of benign images due to disease pathologies. However, texture-based analysis alone often fails to identify the extent of chaoticness in malignant breast ultrasound images due to their vague appearance with normal echo patterns, leading to missed diagnoses and increased mortality rates. To address this issue, we proposed an angular feature-based multilevel breast cancer classification framework mBCCf that aims to improve the accuracy and efficiency of classification. The proposed framework mimics the radiologist interpretation procedure by identifying the chaoticness on the periphery of the breast lesion in a breast ultrasound image (level-1). If the lesion contains an acute angle in any part of the periphery, it can be characterized as malignant or otherwise benign. However, solely relying on level-1 analysis may result in misclassification, especially when benign lesions exhibit echo patterns that resemble malignant ones. To overcome this limitation and to make the proposed system highly sensitive, advanced texture-based analysis (using combined shape, texture, and angular features) is performed (level-2). Finally, the performance of the proposed system is evaluated using a cross-dataset (consisting of 1293 breast ultrasound images) and compared with the different individual feature extraction techniques. Encouragingly, our system demonstrated an accuracy of 96.99% for classifying malignant and benign tumors, which is also validated using statistical analysis. The implications of our research lie in its potential to significantly improve breast cancer diagnosis by providing a reliable, efficient, and sensitive tool for radiologists.","Homicide involving multiple victims has a significant negative effect on society. Criminal profiling consists of determining the traits of an unknown offender based on those of the crime and the victims, with a view to their identification. To provide the most likely profile of the perpetrator of a multi-victim homicide, we propose a predictive model of supervised machine learning based on a Bayesian Network. Conventional classifiers can generate the perpetrator\u2019s profile according to the traits of each of the victims of the same homicide, but the profiles may differ from one another. To address this issue, we consider the Multi-Instance (MI) learning framework, in which the victims of the same incident form a bag, and each bag is associated with a unique label for each of the perpetrator\u2019s features. We introduce the unanimity MI assumption in this domain, and accordingly allocate a label to the bag based on the labels and probabilities the Bayesian Network has assigned its instances, using a combination rule from those of the ensemble of classifiers. We apply this methodology to the Federal Bureau of Investigation (FBI) homicide database to compare three combination rules empirically in the validation process, as well as theoretically, using the one that ultimately proves to be the best to build the final model, which is then applied in some illustrative examples to achieve the criminal profile.\nHighlights\n\u2022\nPredictive model of Machine Learning based on Bayesian Networks.\n\u2022\nUseful for criminal profiling of multi-victim homicides.\n\u2022\nMulti-Instance learning using combination rules of the ensembles of classifiers.\n\u2022\nApplication to the FBI homicide dataset.","In scenarios with long-tailed distributions, the model's ability to identify tail classes is limited due to the under-representation of tail samples. Class rebalancing, information augmentation, and other techniques have been proposed to facilitate models to learn the potential distribution of tail classes. The disadvantage is that these methods generally pursue models with balanced class accuracy on the data manifold, while ignoring the ability of the model to resist interference. By constructing noisy data manifold, we found that the robustness of models trained on unbalanced data has a long-tail phenomenon. That is, even if the class accuracy is balanced on the data domain, it still has bias on the noisy data manifold. However, existing methods cannot effectively mitigate the above phenomenon, which makes the model vulnerable in long-tailed scenarios. In this work, we propose an Orthogonal Uncertainty Representation (hOUR) of feature embedding and an end-to-end training strategy to improve the long-tail phenomenon of model robustness. As a general enhancement tool, OUR has excellent compatibility with other methods and does not require additional data generation, ensuring fast and efficient training. Comprehensive evaluations on long-tailed datasets show that our method significantly improves the long-tail phenomenon of robustness, bringing consistent performance gains to other long-tailed learning methods.","The original K-nearest neighbour (KNN) algorithm was meant to classify homogeneous complete data, that is, data with only numerical features whose values exist completely. Thus, it faces problems when used with heterogeneous incomplete (HI) data, which has also categorical features and is plagued with missing values. Many solutions have been proposed over the years but most have pitfalls. For example, some solve heterogeneity by converting categorical features into numerical ones, inflicting structural damage. Others solve incompleteness by imputation or elimination, causing semantic disturbance. Almost all use the same K for all query objects, leading to misclassification. In the present work, we introduce KNNHI, a KNN-based algorithm for HI data classification that avoids all these pitfalls. Leveraging rough set theory, KNNHI preserves both categorical and numerical features, leaves missing values untouched and uses a different K for each query. The end result is an accurate classifier, as demonstrated by extensive experimentation on nine datasets mostly from the University of California Irvine repository, using a 10-fold cross-validation technique. We show that KNNHI outperforms six recently published KNN-based algorithms, in terms of precision, recall, accuracy and F-Score. In addition to its function as a mighty classifier, KNNHI can also serve as a K calculator, helping KNN-based algorithms that use a single K value for all queries that find the best such value. Sure enough, we show how four such algorithms improve their performance using the K obtained by KNNHI. Finally, KNNHI exhibits impressive resilience to the degree of incompleteness, degree of heterogeneity and the metric used to measure distance.","Accurate liver cancer classification is essential, as it substantially influences the selection of effective treatment strategies and impacts patient prognosis. Convolutional neural network (CNN) classifiers typically require extensive labeled datasets for training to attain decent performance. However, the process of obtaining labeled data through manual labeling is time-consuming, potentially biased, and costly when applied to large datasets. This study utilizes the Simple Siamese (SimSiam) contrastive self-supervised learning approach to enhance the classification of liver tumours, especially considering the limited availability of labeled computed tomography (CT) scans of liver cancer. We integrate SimSiam with three baseline CNN-based classifiers - Inception, Xception, and ResNet152 - and pretrain them with two loss functions: mean squared error (MSE) and cosine similarity (COS). Our findings show consistent improvements for three classifiers compared to the baseline models. Specifically, the ResNet152 model exhibits the highest performance among the evaluated networks. With MSE and COS losses, the classification accuracy for ResNet152 improves by 1.27% and 2.53%, respectively. The classification accuracy of the Inception model improves by 3.95% and 5.26%. Similarly, Xception\u2019s validation accuracy demonstrates an increase of 2.60% with both loss functions, compared to the baseline models. We validate our pipeline via our multi-resolution in-house abdominal CT scans of primary and secondary liver cancers, including 155 patients with hepatocellular carcinoma, 198 patients with colorectal liver metastases, and 107 patients with intrahepatic cholangiocarcinoma. Source code available at: https://github.com/Ramtin-Mojtahedi/SimSiam-LiverCancer-CL.","The predict-then-optimize framework is fundamental in many practical settings: predict the unknown parameters of an optimization problem and then solve the problem using the predicted values of the parameters. A natural loss function in this environment is to consider the cost of the decisions induced by the predicted parameters in contrast to the prediction error of the parameters. This loss function is referred to as the smart predict-then-optimize (SPO) loss. In this work, we seek to provide bounds on how well the performance of a prediction model fit on training data generalizes out of sample in the context of the SPO loss. Because the SPO loss is nonconvex and non-Lipschitz, standard results for deriving generalization bounds do not apply. We first derive bounds based on the Natarajan dimension that, in the case of a polyhedral feasible region, scale at most logarithmically in the number of extreme points but, in the case of a general convex feasible region, have linear dependence on the decision dimension. By exploiting the structure of the SPO loss function and a key property of the feasible region, which we denote as the strength property, we can dramatically improve the dependence on the decision and feature dimensions. Our approach and analysis rely on placing a margin around problematic predictions that do not yield unique optimal solutions and then providing generalization bounds in the context of a modified margin SPO loss function that is Lipschitz continuous. Finally, we characterize the strength property and show that the modified SPO loss can be computed efficiently for both strongly convex bodies and polytopes with an explicit extreme point representation.\nFunding: O. El Balghiti thanks Rayens Capital for their support. A. N. Elmachtoub acknowledges the support of the National Science Foundation (NSF) [Grant CMMI-1763000]. P. Grigas acknowledges the support of NSF [Grants CCF-1755705 and CMMI-1762744]. A. Tewari acknowledges the support of the NSF [CAREER grant IIS-1452099] and a Sloan Research Fellowship.","The application of hyperspectral imaging with computer-aided technology has promising prospects, and achieving real-time, efficient, and non-destructive detection, especially for food and agricultural products, undoubtedly poses a great challenge. Hyperspectral data processing has many complications, such as large volume, high redundancy, and difficulty extracting useful features. Therefore, this study develops a lightweight end-to-end unified framework for deep neural networks with excellent generalization to conserve memory space and computation. To improve the classification accuracy and performance of the core model LSAC-net, we combine an attention mechanism based on the temporal convolution method with a complementary model-scaling technique. Experimental results on our own datasets for the production year of citri reticulate pericarpium, production origin of Pu\u2019er tea, and process mode of coffee beans show that our model outperforms several other state-of-the-art models.\nHighlights\n\u2022\nA valid approach for the assessment of agri-food products by hyperspectral images is proposed.\n\u2022\nThe network is an integration of convolution and self-attention.\n\u2022\nRobustness of the accuracy by efficient use of hyperspectral image data.\n\u2022\nAn equilibrium model performance achieved by the compound scaling strategy.","Ship classification based on machine learning (ML) has proven to be a significant underwater acoustic research direction. One of the critical challenges rests with how to embed domain signal knowledge into ML models to obtain suitable features that highly correlate with the classification and create better predictors. In this paper, a novel ML-based ship classification model, Hierarchical Underwater Acoustic Transformer (HUAT), is proposed to improve the classification performance. Firstly, the Detection of Envelope Modulation on Noise (DEMON) spectra of ship-radiated noise signals are estimated by cyclostationary analysis. The motivation for using a DEMON-based preprocessing scheme is that valuable propeller information can be revealed by exploiting the second-order cyclostationarity of ship-radiated noise signals. Secondly, the useful features of DEMON spectra are enhanced using a multi-head self-attention module, and the potential features of the Mel spectrograms are extracted employing a Convolutional Neural Network (CNN) module. The two kinds of features are fused to provide ship classification patterns. The challenge of feature learning in the deep classification model is reduced by leveraging domain-related classification knowledge. Finally, the Swin Transformer, based on shifted window self-attention mechanism, is used to learn high-level feature representations and conduct ship classification. Experimental results show that the HUAT model achieves excellent classification performance on ship-radiated noise datasets, ShipsEar and DeepShip. And its classification efficiency is better than the model based on traditional Transformer architecture. In addition, the proposed method provides technical support for the underwater intelligent system capable of automatically sensing sailing vessels and recognizing vessel types.\nHighlights\n\u2022\nThe Detection of Envelope Modulation on Noise (DEMON) spectra of ship-radiated noise signals are estimated by cyclostationary analysis.\n\u2022\nA novel feature fusion strategy is proposed for embedding domain signal knowledge into ML models to obtain suitable features highly correlated with the classification.\n\u2022\nThe valuable features of DEMON spectra and the Mel spectrogram of ship signals are extracted using two different feature extractors.\n\u2022\nThe Swin Transformer is used to learn high-level feature representations and conduct ship classification.","Long-tailed learning is attracting increasing attention due to the unbalanced distributions of real-world data. The aim is to train well-performing depth models. Traditional knowledge transfer methods for long-tailed learning are classified into feature-based horizontal knowledge transfer (HKT) and class-based vertical knowledge transfer (VKT). HKT transfers head-to-tail feature knowledge from different classes to improve classification performance when there are few tail classes. However, HKT easily leads to invalid transfer due to the deviation caused by the difference between the knowledge of head and tail classes. Fortunately, the class space has a multi-grained relationship and can form a multi-granularity knowledge graph (MGKG), which can be recast as coarse-grained and fine-grained losses to guide VKT. In this paper, we propose a hierarchical long-tailed classification method based on multi-granularity knowledge transfer (MGKT), which vertically transfers knowledge from coarse- to fine-grained classes. First, we exploit the semantic information of classes to construct an MGKG, which forms an affiliation of fine- and coarse-grained classes. Fine-grained knowledge can inherit coarse-grained knowledge to reduce transfer bias with the help of MGKG. We then propose a multi-scale feature fusion network, which aims to fully mine the rich information of the features to drive MGKT. Experiments show that the proposed model outperforms several state-of-the-art models in classifying long-tailed data. For example, our model performed 4.46% better than the next-best model on the SUN-LT dataset.\nHighlights\n\u2022\nWe propose a multi-scale feature fusion network about channel and spatial features.\n\u2022\nWe investigate a multi-granularity relationship of class space.\n\u2022\nWe explore a vertical transfer of coarse- to fine-grained knowledge.","According to the characteristics of complex feature information garbage classification application, a garbage classification method based on multi-source information fusion based on Bayesian network is proposed.In this method, the training sample data is preprocessed by La Pullaras smoothing method to solve the problem of zero prior probability in traditional Bayesian method and eliminate the influence of zero value prior probability on fusion results.Then, according to the decision information of the image sensor, combined with the multi-source heterogeneous characteristic information of other sensors of different types, the multi-source information fusion model is established by using the improved Bayesian parameter estimation algorithm.Bayesian networks are established and Bayesian classifiers are constructed to simplify the fusion results. Finally, the discriminant results are obtained by calculating the maximum posterior probability estimate.Through comparative experiments, the average discrimination accuracy of the improved data fusion method for complex feature information garbage samples is increased from 89.5% to 98.5%, which proves that the method can fully integrate multi-source heterogeneous feature information, reduce the high fuzziness of the discrimination process of hazardous waste and recyclable waste, so as to obtain more accurate classification results.This has important theoretical significance and practical value for the classification of complex garbage in daily life.","As the latest representative of GNSS positioning technology, the PPP-RTK method, which is able to achieve centimeter-level positioning using a single receiver, has been recognized as a preferred alternative for emerging applications such as self-drive cars and unmanned ariel vehicles. Nevertheless, the performance of PPP-RTK faces serious challenges in urban environments due to the severe impact of multipath and non-line-of-sight (NLOS) reception. Presently, machine learning-based signal classification methods are increasingly prevalent, which have great potential to serve for detecting NLOS signals by leveraging a wide range of features and parameters. In this contribution, a novel NLOS signal detection method based on the machine learning algorithm is developed, aiming to improve the kinematic positioning performance of PPP-RTK in urban areas. A multilayer perceptron (MLP)-based signal classifier is proposed where the signal strength, satellite elevation and pseudorange consistency are considered as input and then mapped to the signal type labeled by the fish-eye camera. Furthermore, a new stochastic model derived from both the classification results and the prediction confidence is also developed and employed in PPP-RTK processing. Several vehicular experiments are conducted in diverse urban areas to verify the effectiveness of the proposed method. Results indicate that the proposed method outperforms the traditional PPP-RTK with the 3D positioning accuracy improved by 36.7\u201342.3%. Besides, the horizontal positioning availability within 0.1 m and 1 m is improved from 34.9% to 76.3% and 69.5% to 92.1%, respectively. In partly blocked areas, the proposed method is capable of providing continuous centimeter-level positions in both horizontal and vertical directions. Particularly, in urban canyon, the vertical positioning accuracy is dramatically improved by 80.3% with NLOS signals effectively mitigated.","Consumer preference prediction aims to predict consumers\u2019 future purchases based on their historical behavior-level data. Using machine learning algorithms, the prediction results provide evidence to conduct commercial activities and further improve consumer experiences. However, missing values and imbalanced class problems of consumer behavioral data always make machine learning algorithms ineffective. While several methods have been proposed to address missing data or imbalanced class problems, few works have considered the relationships among missing mechanisms, imputation algorithms, imbalanced class methods, and the effectiveness of classification algorithms that use impute data. In this study, we aim to propose an adaptive process for selecting the optimal combination of amputation, imputation, imbalance treatment, and classification based on classification performance. Our research extends the literature by showing significant interaction effects between 1) the amputation mechanism and imputation algorithms, 2) imputation and imbalance treatments, and 3) imbalance treatments and classification algorithms. Using three consumer behavioral datasets from the UCI Machine Learning Repository, we empirically show that, among different classification methods, the overall performance of Random Forest is better than that of Logit, SVM, or Decision Tree. Moreover, Logit, as the most widely used classification method, suffers most from imbalance issues in real-world datasets. Furthermore, Metacost is always the best imbalance treatment for different imputation techniques or missing value mechanisms.","We present a novel algorithm for learning a union of convex separators (UCS) to separate a class from another using decision boundaries, each of which is a convex separator. A convex separator is defined by a collection of hyperplanes that separate one class from another class using an intersection of half-spaces. A union of convex separators can be thought of as an ensemble of such convex separators that collectively separate all points of one class from the other. In this work, we put forth the notion of separability using a UCS previously known in earlier works as min-max separability, provide a gradient-based algorithm for learning UCS, and assess it against popular classifiers using recent datasets of interest.","Handwritten Chinese character recognition has achieved high accuracy using deep neural networks (DNNs), but the structural recognition (which offers structural interpretation, e.g., stroke and radical composition) is still a challenge. Existing DNNs treat character image as a whole and perform classification end-to-end without perception of the structure. They need a large amount of training samples to guarantee high generalization accuracy. In this paper, we propose a method for structural recognition of handwritten Chinese characters based on a modified part capsule auto-encoder (PCAE), which explicitly considers the hierarchical part-whole relationship of characters, and leverages extracted structural information for character recognition. Our PCAE is improved based on stacked capsule auto-encoder (SCAE) so as to better extract strokes and perform classification. By the modified PCAE, the character image is firstly decomposed into primitives (stroke segments), with their shape and pose information decoupled. The transformed primitives are aggregated into higher-level parts (strokes) guided by prior knowledge extracted from writing rules. This process enhances interpretability and improves the discrimination ability of features. Experimental results on a large dataset demonstrate the effectiveness of our method in both Chinese character recognition and stroke extraction tasks.","Deep forest models offer a promising alternative to traditional deep neural networks by demanding fewer training samples and hyperparameters. However, existing deep forest fault diagnosis models encounter persistent challenges such as insufficient representation of multi-grained spatial information and redundancy of cascaded forest features. To address the above challenges, an enhanced deep forest method called random multi-grained fusion cascade forest (rgfc-Forest) is presented for fault diagnosis of electromechanical systems with limited training samples. First, a random multi-grained scanning module is designed to improve feature information learning. Subsequently, a feature fusion cascade forest module is constructed to improve the representativeness of features in multi-grained scanning and cascade forest delivery while ensuring data diversity. Finally, a decision tree self-growth strategy is combined to refine the classification capability of the high-level forest. To evaluate the effectiveness of our proposed method, we applied it to experimental data related to motor system and gearbox faults. Our results demonstrate significant improvements over existing methods: With just 20 samples per class, our method achieved an average accuracy of 84.41% for motor System Diagnosis. Similarly, for the gearbox system, we attained an impressive accuracy of up to 92.72% with the same limited dataset. These outcomes underscore the superior feature representation and fault classification capabilities of our approach compared to both benchmark deep forest models and mainstream deep learning methods when confronted with small training datasets.","Once a crisis arises, people use social media platforms (such as Twitter) to communicate real-time updates. This data is incredibly helpful to disaster relief and response organisations and may offer rapid notifications for prioritising requests. Text mining and machine learning algorithms can scan enormous amounts of unstructured data created by social media outlets like Twitter to recognise disaster-related content based on keywords and phrases. One of the difficulties that algorithms may confront is determining whether the tweet content discusses actual disasters or uses these keywords as metaphors. As a result, this research aims to apply natural language processing (NLP) and classification models to discriminate between authentic and bogus disaster tweets. This dataset from the Kaggle website includes tweets about genuine disasters and fictional disasters. Four machine learning classifier methods were used: KNN, SVM, XGBoostand, and Naive Bayes. KNN offers the highest accuracy.","The family orientation process in Cuban Schools for children with Affective \u2013 Behavioral Maladies (SABM) involves clustering and classification of mixed type data with non-symmetric similarity functions. To improve this process, this paper includes some novel characteristics in clustering and prototype selection. The proposed approach uses a hierarchical clustering based on compact sets, making it suitable for dealing with non-symmetric similarity functions, as well as with mixed and incomplete data. The proposal obtains very good results on the SABM data, and over repository databases. In addition, the proposed clustering method is able to detect the true partitions of data and it was significantly better with respect to others according to external validity indexes. In prototype selection, the proposal obtains a highly reduced prototype set, while maintains the original classifier accuracy.","Highlights\n\u2022\nNine supervised machine-learning models were trained and compared.\n\u2022\nA hyperspectral data collection platform was developed for field data collection.\n\u2022\nEffectiveness of MCC and F1 scores were compared for imbalanced dataset.\n\u2022\nQuadratic discriminant classifier with F1 score 0.95 &amp; MCC 0.85 was chosen.\nAbstract\nWeed infestation and their management are a critical production challenge in agricultural fields. Palmer amaranth has created management challenges because it has multiple emergence pattern and has evolved resistant to nine unique herbicide sites of action. Effective Palmer amaranth detection and positive identification in field conditions will help to improve Palmer amaranth control. A field-based hyperspectral imaging system was developed to record Palmer amaranth in soybean fields. The data were pre-processed applying Savitzky-Golay 2nd derivative, Multiplicative Scatter Correction, and Standard Normal Variate in a forward feed manner. Recursive feature elimination, SelectFromModel, sequential forward selection, and backward elimination were used to select significant wavebands from the available 224 bands. Later, supervised machine-learning models were generated to classify soybean and Palmer amaranth using the selected wavebands. Matthew\u2019s correlation coefficient (MCC), F1 score, precision, and recall were considered as the most significant parameters to evaluate the models\u2019 performance. The highest result was obtained by quadratic discriminant analysis with a prediction accuracy of 93.95%, a precision of 90.30%, a recall of 90.29%, an F1 score of 0.95, and an MCC score of 0.85. The findings of this study showed that the combination of hyperspectral imaging and machine-learning is a potential technique for real-time weed detection in the open field condition.","For the machine learning-based prediction of the conversion from mild cognitive impairment to Alzheimer\u2019s disease, the collection of sufficient data to train a model is required, which involves a lot of time and expense. When data is not enough, combining public and in-house data may be appropriate by applying domain adaptation that alleviates inter-site heterogeneity. Existing methods simultaneously transform in-house and public data to represent them into a common feature space, and then train a classifier using labels in public data. However, this procedure causes the time- and cost-consuming re-training of classifier whenever in-house data changes, and also inheres the risk of information loss in public data. Motivated by this, we propose a method that only transforms in-house data while preserving public data, namely one-way domain adaptation. The proposed method represents in-house data similar with public data by matching the data distribution and the connectivity between brain regions with mean vectors and covariance matrices, respectively. Then, the pre-trained classifier in public data is applied to predict AD conversion for in-house data. The experiments, which use the Australian Imaging Biomarkers and Lifestyle Study of Aging and the Open Access Series of Imaging Studies as the in-house data and the Alzheimer's Disease Neuroimaging Initiative as the public data, show the effectiveness and efficiency of the proposed method, improving prediction performance about 34.8% on average without labels in the in-house datasets.","Classifying architectural structures is an important and challenging task that requires expertise. Convolutional Neural Networks (CNN), which are a type of deep learning (DL) approach, have shown successful results in computer vision applications when combined with transfer learning. In this study, we utilized CNN based models to classify regional houses from Anatolia and Balkans based on their architectural styles with various pretrained models using transfer learning. We prepared a dataset using various sources and employed data augmentation and mixup techniques to solve the limited data availability problem for certain regional houses to improve the classification performance. Our study resulted in a classifier that successfully distinguishes 15 architectural classes from Anatolia and Balkans. We explain our predictions using grad-cam methodology.","Over the past two decades, matrix-based or bilinear discriminant analysis (BLDA) methods have received much attention. However, it has been reported that the traditional vector-based regularized LDA (RLDA) is still quite competitive and could outperform BLDA on some benchmark datasets. A central question is whether the superiority of the vector-based RLDA would always hold for general matrix data, or is there any type of matrix data on which BLDA would perform better than RLDA? Actually, the reported comparisons are found to suffer from two limitations: (i) the comparisons are only limited to image data, and (ii) regularized RLDA is compared with non-regularized BLDA. In this paper, we break the two limitations and investigate the central question on another type of matrix data, namely multivariate time series (MTS) data. We propose a new two-parameter regularized BLDA (RBLDA) for MTS data classification. To choose the two parameters, we develop an efficient model selection algorithm. The newly proposed RBLDA enables us to perform a fair comparison between vector-based RLDA and matrix-based RBLDA. Experiments on a number of real MTS data sets are conducted to compare RBLDA with RLDA and evaluate the proposed algorithm. The results reveal that the superiority of the vector-based RLDA does not always hold for general matrix data, and RBLDA outperforms RLDA on MTS data. Moreover, the proposed model selection algorithm is efficient, and RBLDA can produce better visualization of MTS data than RLDA.\nHighlights\n\u2022\nA new regularized BLDA (RBLDA) is proposed for multivariate time series (MTS) classification.\n\u2022\nAn efficient model selection algorithm is developed for the proposed RBLDA.\n\u2022\nEmpirical results show that the proposed RBLDA generally performs better than RLDA on MTS data.\n\u2022\nRBLDA can produce better visualization of MTS data than RLDA.","Skip Abstract Section\nAbstract\nNetwork slicing (Ns) is a key enabling technology to support the concurrent provisioning of better quality of service (QoS) in 5G networks. These services have become essential for a telecom service provider (SP) to offer better QoS and QoE (quality of experience). The QoS parameters are used to estimate the performance of the network, and QoE determines user satisfaction with the network services. The main challenges faced by the service provider are to select the appropriate slice for each service and accurately classify these services on a timely basis to satisfy the Service level agreement (SLA) while improving the QoS and QoE. To overcome this issue, machine learning (ML) is a good solution. In this paper, we have proposed a 5G-KPQI (5G-key performance and quality indicator) model that considers the 5G service-based dataset for the 5G services classification. Next, we used feature selection (FS) methods to rank and select the best feature subset, which increases the performance of ML models and also reduces the training time required by the models. We subsequently considered various ML models to classify the services. Results demonstrate that the 5G-KPQI model ranks the features using Relief-F and mrMR methods and also reduces the training time of the model, hence improving classification performance measured by precision, accuracy, F1-score, recall, MCC, and time. The evaluation of the key approach outperforms in high classification accuracy and less training time using decision tree (DT) and random forest (RF).","Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility. Our proposed model is rigorously tested in the context of the HuMob Challenge 2023---a competition designed to evaluate the performance of prediction models on standardized datasets to predict human mobility. The challenge leverages two datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a longitudinal period of 75 days. Geo-Former stands out as a top performer in the competition, securing a place in the top-3 ranking. Its success is underscored by performing well on both performance metrics chosen for the competition---the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of the GeoFormer on the HuMob Challenge 2023 underscores its potential to make substantial contributions to the field of human mobility prediction, with far-reaching implications for disaster preparedness, epidemic control, and beyond.","Mobile application (App) reviews which are provided by users through different App stores are considered as a rich information source for developers to inform about bugs, new feature requests, performance issues, etc. These feedbacks help developers improve the quality of their apps which in turn will significantly impact the user experience and the App\u2019s overall ratings. Popular Apps receive a high number of user reviews daily which makes their manual analysis a very tedious and time-consuming task. Automating the classification of user reviews will save developers time and help them better prioritize the issues that need to be handled. Since an App review is text data in which a user may report more than one issue, we propose a multi-label text classification model which uses neural language models. These models have shown high performance in various natural language processing problems. Experimental results confirm that neural language models outperform frequency-based methods in the context of App reviews classification. In fact, with RoBERTa, we could achieve a 0.87 average F1-score and a 0.16 hamming loss performances.","Recognizing plant species and disease is essential to practical applications, such as keeping biodiversity and obtaining a desired crop yield. This study aims to extend the recognition from known to unknown classes in the context of plants, termed Plant-relevant Open-Set Recognition (POSR). In this task, a trained model is required to either classify an input image into one of the known classes or an unknown class, even if the model is only trained with the images of known classes. To achieve this task, we propose a method to obtain a high-performance classifier with compact feature distributions for known classes. To have a high-performance classifier, a ViT model pre-trained in the PlantCLEF2022 dataset is transferred, following an observation that a plant-related source dataset is more beneficial to plant species and disease recognition than other commonly used datasets, such as ImageNet. To have compact feature distributions, we adopt additive margin Softmax loss (AM-Softmax) which brings the distance smaller between the features of the same known class and hence gives more spaces for the unknown class. Extensive experimental results suggest that our method outperforms current algorithms. To be more specific, our method obtains AUROC 93.685 and OSCR 93.256 on average on four public datasets, with an average accuracy of 99.295 on closed-set classification. We believe that our study will contribute to the community and, to fuel the field, our codes will be public https://github.com/xml94/POSR. .\nHighlights\n\u2022\nA plant-relevant versatile recognition, PVR, is explicitly proposed from a unified perspective for real-world applications.\n\u2022\nPVR is instantiated as POSR to perform known and unknown class recognition on plant species and disease.\n\u2022\nTo achieve POSR, a ViT model pre-trained in the PlantCLEF2022 dataset and AM-Softmax are leveraged.\n\u2022\nExtensive experiments are executed with non-trivial analysis, which suggests that the proposed method surpasses the current methods with clear margins.","This paper presents a LIghtweight Domain Adaptive Cell Segmentation (LIDACS) framework that achieves state-of-the-art results (0.9505 mIoU) in instance segmentation on the SegPC-21 challenge dataset featured in ISBI 2021, while being significantly parameter efficient than the existing methods. LIDACS is a hierarchical multi-stage approach that utilizes prior domain-specific information to perform statistical and empirical analysis. It also employs task-specific augmentations and improved transfer learning via shared representation to enable better data representation. LIDACS also applies a novel cell structure-based contrastive augmentation paired with cell cloning, increasing annotation density and promoting better stain color in-variance. Effectively, LIDACS is a lightweight architecture, efficient for practical deployment, that provides optimal generalization.","The sequential three-way decision (S3WD) model, which merges three-way decisions and granular computing, is increasingly crucial in classification. The risk attitude to the decision process and result costs affects the decisive actions in the S3WD model. Furthermore, decision conflict arises when there is a discrepancy between coarse-grained and fine-grained definite decision-making for the same object, which can potentially impact decision accuracy. However, current studies show incomplete risk preference research and a lack of decision correction strategies to address decision conflict. To address the limitation, four sequential three-way classifiers (S3WCs) are proposed. First, three prominent distance functions are employed to compute similarity classes for condition probability estimation. Second, optimistic, pessimistic, and weighted compromise sequential three-way classifiers are established to reflect the risk preference for the two types of costs. Third, four precision differences in the S3WCs are defined from local and global perspectives. An S3WC with decision correction is presented to improve precision by judging precision differences in adjacent granularity levels and the entire granular structure. Finally, a series of experiments are conducted to thoroughly analyze the characteristics and applications of these S3WCs. The superior classification performance of the proposed models on diverse datasets is demonstrated.\nHighlights\n\u2022\nThree prominent distance functions are adopted to construct similarity classes for condition probability estimation.\n\u2022\nThree kinds of sequential three-way classifiers considering risk preference are proposed.\n\u2022\nLocal and global classification precision differences are defined to detect the classification precision changing status.\n\u2022\nThe sequential three-way classifier with a decision correction strategy is presented to improve the classification precision.","In this paper, we propose a generalization of classical Rough Sets, the Nearest Neighborhood Rough Sets, by modifying the indiscernible relation without using any similarity threshold. We also combine these Rough Sets with Compact Sets, to obtain a prototype selection algorithm for Nearest Prototype Classification of mixed and incomplete data as well as arbitrarily dissimilarity functions. We introduce a set of rules to a priori predict the performance of the proposed prototype selection algorithm. Numerical experiments over repository databases show the high quality performance of the method proposed in this paper according to classifier accuracy and object reduction.","Using convolutional neural networks for 360\u00b0 images can induce sub-optimal performance due to distortions entailed by a planar projection. The distortion gets deteriorated when a rotation is applied to the 360\u00b0 image. Thus, many researches based on convolutions attempt to reduce the distortions to learn accurate representation. In contrast, we leverage the transformer architecture to solve image classification problems for 360\u00b0 images. Using the proposed transformer for 360\u00b0 images has two advantages. First, our method does not require the erroneous planar projection process by sampling pixels from the sphere surface. Second, our sampling method based on regular polyhedrons makes low rotation equivariance errors, because specific rotations can be reduced to permutations of faces. In experiments, we validate our network on two aspects, as follows. First, we show that using a transformer with highly uniform sampling methods can help reduce the distortion. Second, we demonstrate that the transformer architecture can achieve rotation equivariance on specific rotations. We compare our method to other state-of-the-art algorithms using the SPH-MNIST, SPH-CIFAR, and SUN360 datasets and show that our method is competitive with other methods.","With the exponential increase of interdisciplinary research, identifying accurate disciplines of scientific documents has become increasingly important in various research management tasks. Interdisciplinary classification, which classifies documents into multiple disciplines, is essential for multidisciplinary research development. Due to the scarcity of labeled multidiscipline data, existing scientific document classification methods can't solve the interdisciplinary issue. Most of them also have the problem of explainability with curtly providing classification results. This study proposes an explainable transfer-learning-based classification method for interdisciplinary documents. First, we trained a single-discipline classification model using existing labeled single-discipline documents. Then, we transfer the knowledge learned from single-discipline classification to interdisciplinary classification to address the scarcity of labeled interdisciplinary data. We also added discipline co-occurrence information into our proposed model. Finally, we obtained our final model by training the transferred model with interdisciplinary data. In addition, keyword-based explanations for classifying texts are provided by employing layer-wise relevance propagation. Experiments on real-life NSFC data show the effectiveness of the proposed method, which can promote interdisciplinary development by constructing an efficient and fair classification for interdisciplinary review systems.","We presented the Pyramid Swin Transformer, a versatile and efficient architecture tailored for object detection and image classification. This time we applied it to a wider range of tasks, such as object detection, image classification, semantic segmentation, and video recognition tasks. Our architecture adeptly captures local and global contextual information by employing more shift window operations and integrating diverse window sizes. The Pyramid Swin Transformer for Multi-task is structured in four stages, each consisting of layers with varying window sizes, facilitating a robust hierarchical representation. Different numbers of layers with distinct windows and window sizes are utilized at the same scale. Our architecture has been extensively evaluated on multiple benchmarks, including achieving 85.4% top-1 accuracy on ImageNet for image classification, 51.6\nA\nP\nbox\nwith Mask R-CNN and 54.3\nA\nP\nbox\nwith Cascade Mask R-CNN on COCO for object detection, 49.0 mIoU on ADE20K for semantic segmentation, and 83.4% top-1 accuracy on Kinetics-400 for video recognition. The Pyramid Swin Transformer for Multi-task outperforms state-of-the-art models in all tasks, demonstrating its effectiveness, adaptability, and scalability across various vision tasks. This breakthrough in multi-task learning architecture opens the door to new research and applications in the field.","Clothing classification serves as a fundamental task for clothing retrieval, clothing recommendation, etc. In this task, there are two inherent challenges: suppressing complex backgrounds outside the clothing region and disentangling the feature entanglement of shape-similar clothing samples. These challenges arise from insufficient attention to key distinctions of clothing, which hinders the accuracy of clothing classification. Also, the high computational resource requirement of some complex and large-scale models also decreases the inference efficiency. To tackle these challenges, we propose a new COntext-driven Clothing ClassIfication network (COCCI), which improves inference accuracy while reducing model complexity. First, we design a self-adaptive attention fusion (SAAF) module to enhance category-exclusive clothing features and prevent misclassification by suppressing ineffective features with confused image contexts. Second, we propose a novel multi-scale feature aggregation (MSFA) module to establish spatial context correlations by using multi-scale clothing features. This helps disentangle feature entanglement among shape-similar clothing samples. Finally, we introduce knowledge distillation to extract reliable teacher knowledge from complex datasets, which helps student models learn clothing features with rich representation information, thereby improving generalization while reducing model complexity. In comparison to state-of-the-art networks trained with one single model, our method achieves SOTA performance on the widely-used clothing classification benchmark.","This paper introduces a binary classification network that utilizes the Informer Encoder to classify ping pong actions as either correct or incorrect. The dataset used in this study comprises 949 action videos capturing two fundamental ping pong stroke actions performed by athletes, including both correct and incorrect actions. The average frame count for each action is 38.62. Temporal skeletal data is extracted from the videos using a 2D pose estimation model, and a fully connected layer is employed to perform binary classification on the temporal skeletal data. During training and testing, the extracted skeletal data is segmented into temporal sequences of 39 frames for training and evaluation. On the test set, the Informer Encoder-based model achieves 100% accuracy, while the MLP-based model reaches 94%.","Decision tree algorithm, because of its strong interpretability and high algorithm efficiency, is widely used in the field of pattern recognition and classification. When the number of data samples is small and there is uncertainty in the data, it is difficult for the traditional decision tree algorithm to fully mine the effective information in the data. In this paper, we use the Dempster\u2013Shafer framework to model data uncertainty and propose a hierarchical interval estimation method to improve decision tree algorithms. The proposed method constructs intervals through two methods of attribute boundary and mean square error estimation, which not only utilizes the characteristics of intervals to model the inaccuracy of data, but also constrains intervals from two aspects, narrowing the representation range of available information. By comparing with the classic decision tree algorithm and the decision tree algorithm based on single interval estimation, the proposed method can perform classification tasks robustly and accurately in different types of data under seven data sets.\nHighlights\n\u2022\nWe propose an evidential decision tree based on a reliability-based BPA generation method and hierarchical interval estimation.\n\u2022\nThe proposed method greatly reduces the influence of the labels of uncertain data on the classification accuracy of the decision tree and strengthens the robustness of the algorithm.\n\u2022\nComparison with fifteen different decision trees, the accuracy of our proposed method on seven datasets is higher than other methods especially in the face of with uncertain attributes and labels.","Ensemble methods are advanced learning algorithm proposed for generating base classifiers and accumulating them all together to derive a new classifier which is expected to perform better than the constituent classifier. This study proposes a novel ensemble technique where a base learning classifier is trained repeatedly by using different weightings over the training samples or examples, and the process is governed by the conceptualization of evolutionary processes and the aggregation operators. We utilize the evolutionary technique that can efficiently search a large weighing space for enriching suitable weights (chromosome) to the training samples. For finding an appropriate weighting, the crossover and mutation processes are applied on the weighting space to get the optimized set of weights which is accomplished through different generations. The considered base learning classifier is trained over the training examples along with their respective weightings by utilizing a learning algorithm, and for the finite number of generations, the weights are evolved and optimized through the evolutionary process. All the classifiers obtained in different generations of the evolutionary process are utilized for efficiently building the final ensemble. The set of classifiers obtained in different generations are combined together by utilizing the concept of priority-based averaging aggregation operator by availing priority to different generations. The classifier ensemble is done with two forms of operators: one without priority degree and the other with the priority degree. The proposed classifier ensemble algorithm is tested over the UCI benchmark dataset. The results obtained through the experimental process are more accurate, consistent, and reliable while comparing to other state-of-the-art methods, which ensures the efficacy of the proposed algorithm.","This paper presents an empirical analysis of theperformance of popular convolutional neural networks (CNNs) for identifying objects in real time video feeds. The most popular convolution neural networks for object detection and object category classification from images are Alex Nets, GoogLeNet, and ResNet50. A variety of image data sets are available to test the performance of different types of CNN\u2019s. The commonly found benchmark datasets for evaluating the performance of a convolutional neural network are anImageNet dataset, and CIFAR10, CIFAR100, and MNIST image data sets. This study focuses on analyzing the performance of three popular networks: Alex Net, GoogLeNet, and ResNet50. We have taken three most popular data sets ImageNet, CIFAR10, and CIFAR100 for our study, since, testing the performance of a network on a single data set does not reveal its true capability and limitations. It must be noted that videos are not used as a training dataset, they are used as testing datasets. Our analysis shows that GoogLeNet and ResNet50 are able to recognize objects with better precision compared to Alex Net. Moreover, theperformance of trained CNN\u2019s vary substantially across different categories of objects and we, therefore, will discuss the possible reasons for this.","Spectrogram zeros, originated by the destructive interference between the components of a signal in the time\u2013frequency plane, have proven to be a relevant feature to describe the time-varying frequency structure of a signal. In this work, we first introduce a classification of the spectrogram zeros in three classes that depend on the nature of the components that interfere to produce them. Then, we describe an algorithm to classify these points in an unsupervised way, based on the analysis of the stability of their location with respect to additive noise. Finally, potential uses of the classification of zeros of the spectrogram for signal detection and denoising are investigated, and compared with other methods on both synthetic and real-world signals.\nHighlights\n\u2022\nSpectrogram zeros can be classified in three kinds.\n\u2022\nAn unsupervised, noise-assisted method to classify spectrogram zeros is introduced.\n\u2022\nThe classification helped to overcome limitations of previous zero-based methods.\n\u2022\nOur approaches for signal detection and denoising are effective in low SNR cases.","Breast cancer became the major source of mortality between women. The accessibility of healthcare datasets and data analysis promote the researchers to apply study in extracting unknown pattern from healthcare datasets. The intention of this study is to design a prediction system that can predict the incidence of the breast cancer at early stage by analyzing smallest set of attributes that has been selected from the clinical dataset. Wisconsin breast cancer dataset (WBCD) have been used to conduct the proposed experiment. The potential of the proposed method is obtained using classification accuracy which was obtained by comparing actual to predicted values. The outcome confirms that the maximum classification accuracy (99.28%) is achieved for this study.","Data-driven bearing fault diagnosis methods have become increasingly crucial for the health management of rotating machinery equipment. However, in actual industrial scenarios, the scarcity of labeled data presents a challenge. To alleviate this problem, many transfer learning methods have been proposed. Some domain adaptation methods use models trained on source domain to generate pseudo labels for target domain data, which are further employed to refine models. Domain shift issues may cause noise in the pseudo labels, thereby compromising the stability of the model. To address this issue, we propose a Hierarchical Pseudo Label Domain Adversarial Network. In this method, we divide pseudo labels into three levels and use different training approach for diverse levels of samples. Compared with the traditional threshold filtering methods that focus on high-confidence samples, our method can effectively exploit the positive information of a great quantity of medium-confidence samples and mitigate the negative impact of mislabeling. Our proposed method achieves higher prediction accuracy compared with the-state-of-the-art domain adaptation methods in harsh environments.","The deep forest model, a random forest (RF) ensemble approach and an alternative to Deep Neural Network (DNN), has performance highly competitive to DNN in many classification tasks. However, deep forest model may encounter overfitting and characteristic dispersion issues as processing small-scale, class-imbalance or high-dimension data. Therefore, this paper proposes a Weighted Cascade Deep Forest framework, called WCDForest. In WCDForest, an equal multi-grained scanning module is used to scan each feature equally. Meanwhile, this framework adopts a class vector weighting module to emphasis the performance of each forest and each sliding window by weight. Furthermore, this study proposes a feature enhancement module to reduce the information loss in the first few cascade layers to improve the classification accuracy. Subsequently, systematic comparison experiments on 18 widely used public datasets demonstrate that the proposed model outperforms the state-of-the-art model. In particular, WCDForest improves the accuracy, precision, recall and F1-score by an average of 5.47%,7.04%,8.23% and 8.94%,respectively.","This study addresses challenges in land use and cover identification using remote sensing (RS) imagery, focusing on the Uppal region. By leveraging deep learning models, particularly an optimized ResNext-50 architecture, we aim to enhance efficiency and accuracy in classifying land features. Our approach integrates Landsat-8 and hyper-spectral satellite data, utilizing preprocessing techniques like dark subtraction, stacking, merging, and spectral enhancement. Principal Component Analysis (PCA) is applied to streamline high-dimensional feature sets obtained from pre-processed spectral data. We further employ hybrid NSCT-FDCT fusion for integrating Landsat-8 and hyperspectral images. The resulting fused image is fed into our classification process, utilizing the modified ResNext50 (Deep Learning Architecture) model with Reptile Search Optimization for weight link optimization. Notably, our proposed method achieves impressive outcomes: 97% accuracy, 96% sensitivity, 99% specificity, 3% error, 97% precision, and a 95% Matthew Correlation Coefficient. This demonstrates the efficacy of our approach in predicting diverse land covers within the Uppal region, showcasing the potential of Landsat-8 and Hyper-spectral data for accurate land use and cover identification.","Existing class incremental learning methods typically employ knowledge distillation to minimize discrepancies in model outputs. However, these methods are restricted by the mismatch between quondam knowledge and new data. To alleviate these issues, we introduce semantic alignment decouples the classification and distillation in different semantic spaces. The unmatched new data is regarded as out-of-distribution data on the old class distribution, and the corresponding pseudo-labels are attached to the new data using the original network. Intuitively, the pseudo-labels could be consistently preserved in the old semantic space. Moreover, we develop auxiliary self-supervised classifiers to learn more generalized representation, enabling a better stability-plastic trade-off. Furthermore, self-distillation is employed to refine self-supervised knowledge from auxiliary classifiers. Extensive experiments demonstrate that our method achieves the best performance on CIFAR100, ImageNet100, ImageNet, CUB200, and Stanford-Dogs120 datasets. Notably, our method outperforms existing methods by a substantial margin when only one old exemplar is stored per class, i.e., 11.34% and 21.46% improvement on CIFAR100 of 5 phases and 10 phases, respectively.","Bees play an important role as pollinating agents, contributing to the reproduction of many plant species around the world. Brazil is the home for different species of stingless bees, with around 200 registered species out of the more than 500 species classified worldwide. Each species constructs the entrance to its colony in an unique but similar way among colonies of the same species. In this work, we proposed a new dataset created in collaboration with stingless beekeepers from Brazil for the exploration of stingless bee species classification. The dataset consists of 158 samples distributed unequally among the 13 species: Boca de Sapo, Bor\u00e1, Bugia, Ira\u00ed, Japur\u00e1, Jata\u00ed, Lambe Olhos, Mandaguari, Mirim Droryana, Mirim Pregui\u00e7a, Mo\u00e7a Branca, Manda\u00e7aia, and Tubuna. The results presented in this work were obtained using deep learning models (i.e. CNN architectures) such as VGG and DenseNet, which are commonly used for image classification task in different application domains. Pre-trained models from ImageNet were used, along with transfer learning techniques, and due to the small size of the dataset, data augmentation techniques were applied, resulting in an expanded dataset of 1,106 samples. The experimental results demonstrated that the DenseNet model achieved the best results, reaching an accuracy of\n95\n%\n. The dataset created will be also made available as a contribution of these work. As far as we know, the stingless bee species identification task based on the colony entrance is addressed for the first time in this work.","The QRS complex is the significant wave of electrocardiogram (ECG) and occurs during ventricular depolarization. If the synchronization problem (i.e., depolarization) occurs between endocardial cardiomyocytes and outer layers, then abnormal morphological changes in QRS complex take place which is possible in case of arrhythmia and ischemia. The proposed approach describes time domain measures of such alterations (i.e., the ratio of average rise &amp; fall amplitude and interval) of QRS complex along with the frequency domain feature i.e., peak frequency and power of mean QRS complexes. An improvised Difference Operation Method (DOM) (Yeh Yun-Chi et al., 2008) is implemented with added features like preprocessing techniques (e.g., baseline drifts and noise cancellation). The proposed methodology is evaluated with the standard databases, i.e., FANTASIA (healthy subjects), MIT-BIH Arrhythmia database (MITDB), and European ST-T database (EDB) respectively. Linear Discriminant Analysis (LDA) and decision tree are carried out for classification healthy, arrhythmic and ischemic subjects incorporating the time-frequency domain characteristics. The Naive Bayes\u2019 Classifiers also implemented where these two classes, i.e., ischemia and arrhythmia are visually distinguished by convergently spreading in different areas. Real-time hardware validation of this approach has also executed. The future scope of this approach is to be validated with ischemia-induced arrhythmia subjects for precise identification and classification.","Machine Learning (ML) and feature extraction techniques have shown a great potential in medical imaging field. This work presents an effective approach for the identification and classification of thyroid nodules. In the proposed model, various features are extracted using Grey Level Co-occurrence Matrix (GLCM), Local Binary Pattern (LBP) and intensity-based matrix. These features are fed to various ML classifiers like K-Nearest Neighbour (KNN), Decision-Tree (DT), Artificial Neural Network (ANN), Na\u00efve Bayes, Extreme Gradient Boosting (XGBoost), Random Forest (RF), Linear Regression (LR) and Support Vector Machine (SVM). From the result analysis, it can be observed that proposed Model-4 has performed better in comparison with the rest of seven proposed models with the reported literature. An improvement of 4% to 5% is seen in performance evaluation of model in comparison with reported literature.","Multi-instance learning (MIL), as a special version of classification, focuses on labeled sets (bags) consisting of unlabeled instances and has drawn accumulative attention due to its significant importance in practical applications. However, most existing MIL methods just utilize partial information (bags or instances) of MIL data to construct the kernel function, resulting in deteriorated classification performance of MIL. In this paper, we propose a Double Similarities weighted Multi-Instance Learning (DSMIL) kernel framework, which utilizes the similarities of Bag-to-Bag (B2B) and Instance-to-Bag (I2B). In the proposed kernel framework, the similarities of B2B and I2B could be derived from the prototypes distance of inter-bag and similarity matrix of intra-bag, respectively, based on the affinity propagation (AP) clustering of the bag. Meanwhile, we give theoretical proof of the validity of the designed kernel function. Experimental results on benchmark and semi-synthetic datasets show that our proposed method obtains competitive classification performance and achieves robustness to parameters and noise.\nHighlights\n\u2022\nA double similarities weighted MIL kernel is proposed and proved as a valid kernel.\n\u2022\nThe DSMIL integrates the similarities of B2B and I2B into the kernel function.\n\u2022\nThe DSMIL obtains competitive results on benchmark datasets and newsgroups dataset.","Detection of diseases in plants at an early stage is crucial to achieving high yields, preserving crop quality, and effective disease management. Existing research focuses mostly on leaf disease detection, despite the fact that disease may develop everywhere on the plant. We developed a new dataset using the PlantVillage dataset and other online sources. We used Convolutional Neural Network (CNN) architectures, Alexnet and MobileNet to analyze and evaluate the performance of the models on the new dataset (i.e., consists of over 50,000 images). The models were trained on the new dataset for 100 epochs. MobileNet outperformed the other two models, attaining 99.69% training accuracy, 94.37% validation accuracy, 96% average precision, 96% recall, and an F1-score. The MobileNet model predicted diseases that affect portions of the plant other than the leaf better. This work demonstrates detecting plant disease and provides a feasible technique for enhancing crop management.","Cervical cancer (CC) is one of the most prevalent malignancies affecting women globally, with a particularly notable impact and high mortality in regions with limited economic resources. This underscores the imperative for the expeditious development of techniques that facilitate timely and precise detection, thereby augmenting treatment efficacy, enhancing survival rates, and mitigating the burden of healthcare expenditure. The intricacies of cervical cancer detection are inherently aligned with the challenges of fine-grained visual classification. This study focuses on the integration of bilinear pooling within convolutional neural networks (CNNs) and addresses the problem of the computational complexity of bilinear features with the fortification of the bilinear CNN with a random projection paradigm (RP-BCNN). The aim is the simultaneous achievement of improved classification precision and streamlined processing temporalities. The proposed methodology entails the introduction of a dyadic feature extraction protocol in which the input cellular image is subjected to twin feature extraction modalities. The feature maps obtained from this process undergo element-wise multiplication via an outer-product operation, thereby engendering composite feature representations. Subsequently, a judiciously designed random projection procedure is invoked to reduce dimensionality, yielding a more succinct yet informative image descriptor. Empirical evaluations of the introduced model predicted on the RP-BCNN framework yielded commendable outcomes. Notably, an accuracy of 0.9983 was achieved for the dual-label classification scenarios, and an accuracy of 0.9530 was realized in the context of multiclass classification encompassing seven distinct labels. The proposed model achieves an optimal equilibrium between classification accuracy and processing efficiency, thus constituting a potent instrument for the classification of cervical cancer. Further, it holds promise for the refinement of diagnostic accuracy, thereby providing a vantage point for embracing sophisticated techniques in the realm of medical image analysis.","Classification of Indonesian crops is a critical task in developing farming and getting more understanding of agriculture. However, there is no clear task in classifying types of crops in Indonesia. Transfer learning has been used successfully in a variety of image classification applications. Thus, in this paper, we collected images of Indonesian crops from the internet randomly and proposed a classification by using transfer learning of deep learning with four pre-trained models: EffficientNet- B0, ResNet18, VGG19, and AlexNet. In the experiment, augmentation techniques such as random horizontal flip, random vertical flip, and random affine were utilized to prevent the network from overfitting. The result found that EfficientNet-B0 outperformed other models with an accuracy of 82.55. Then, the model struggled to distinguish between crops in the same family. According to the results, although transfer learning can work well to classify images of Indonesian agricultural crops, some improvements are still required to address existing issues.","Hyperspectral image(HSI) classification is a crucial topic within remote sensing. Recently, deep self-supervised learning methods have gained widespread use in HSI classification, effectively addressing the scarcity of labeled samples issue. In particular, masked image modeling and contrastive learning have achieved commendable performance in the field of self-supervised learning. Therefore, to better investigate the association and synergy between the two self-supervised learning methods, we propose a novel hybrid self-supervised learning framework (HSL) for HSI classification that conforms to the properties of hyperspectral data. The HSL exploits the efficacy of masked image modeling and contrastive learning, and combines masked image reconstruction and instance contrastive learning to improve performance. The HSL specifically employs an asymmetric encoder-decoder two-branch structure. The structure adopts the Vision Transformer as the backbone network to efficiently extract spatial spectral information. Experiments on two commonly used HSI datasets demonstrate that this pre-training task results in better modeling of the feature relationships between shallow and deep layers and achieves superior performance.","The most malignant tumors of the central nervous system are adult-type diffuse gliomas. Historically, glioma subtype classification has been based on morphological features. However, since 2016, WHO recognizes that molecular evaluation is critical for subtyping. Among molecular markers, the mutation status of IDH1 and the codeletion of 1p/19q are crucial for the precise diagnosis of these malignancies. In pathology laboratories, however, manual screening for those markers is time-consuming and susceptible to error. To overcome these limitations, we propose a novel multimodal biomarker classification method that integrates image features derived from brain magnetic resonance imaging and histopathological exams. The proposed model consists of two branches, the first branch takes as input a multi-scale Hematoxylin and Eosin whole slide image, and the second branch uses the pre-segmented region of interest from the magnetic resonance imaging. Both branches are based on convolutional neural networks. After passing the exams by the two embedding branches, the output feature vectors are concatenated, and a multi-layer perceptron is used to classify the glioma biomarkers as a multi-class problem. In this work, several fusion strategies were studied, including a cascade model with mid-fusion; a mid-fusion model, a late fusion model, and a mid-context fusion model. The models were tested using a publicly available data set from The Cancer Genome Atlas. Our cross-validated classification models achieved an area under the curve of 0.874, 0.863, and 0.815 for the proposed multimodal, magnetic resonance imaging, and Hematoxylin and Eosin stain slide images respectively, indicating our multimodal model outperforms its unimodal counterparts and the state-of-the-art glioma biomarker classification methods.","Real-world industrial scenarios pose a challenging task known as few-shot class-incremental learning (FSCIL), which aims to recognize new classes using a few samples while not forgetting the old classes. Despite the recent advance of FSCIL, most existing methods rely on a single metric for making incremental relation predictions, which is unilateral and lacks stability. In this paper, we remedy this issue from two aspects. Specifically, to make convincing relation predictions, we first propose a relation complementation strategy that aggregates different metric models to investigate the comprehensive relation of classifier weights and test features. Then, to make the proposed strategy well fit the incremental scenarios, we design a pseudo incremental relation complementation learning scheme that constructs the learning tasks by mimicking the data setting in real incremental sessions. Taken together, our proposed method dubbed Relation Complementation Network (RCN) achieves the state-of-the-art performance on miniImageNet, CIFAR100 and CUB200. Our code is available at https://github.com/YeZiLaiXi/KT-RCN.git.","Belief rule-based classification system (BRBCS) is a useful model to handle classification problems. In our previous work, a novel data-driven BRBCS with batch-by-batch observation, online learning and multi-weights (BRBCS-BOM) is proposed. It can powerfully obtain knowledge from data. However, in some applications of industrial engineering, it can be hard to obtain enough training samples. The knowledge contained in data is not enough to deal with the problem well. It is necessary to adopt expert-driven BRBCS as an important supplement (hybrid-driven). In this paper, a hybrid-driven BRBCS-BOM with expert intervention (HBRBCS-BOM/E2) is proposed. It adopts a modified inheriting-and-learning hybrid-driven mode. Generally, it inherits the belief rules generated from training samples and make a secondary optimization for these inherited belief rules based on learning from expert-driven BRBCS. Moreover, a novel mode of expert intervention is proposed, based on the reliability evaluation. It can diversely-and-precisely obtain some important online new training samples for enhancement of data-knowledge, making hybrid-driven model better. The related experiments on an industrial engineering classification problem, called abnormity recognition of synthetical balance of material and energy, have demonstrated that the proposed HBRBCS-BOM/E2 not only makes an effective improvement for data-driven BRBCS-BOM from above two ways, but also has a more advanced performance compared with other existing high-performance BRBCS.\nHighlights\n\u2022\nA hybrid-driven mode is proposed based on swapping the inheriting-and-learning.\n\u2022\nA mode of expert intervention is proposed based on the reliability evaluation.\n\u2022\nProposed model can handle the abnormity recognition in electrolytic cell well.","Credit risk assessment is a crucial element in credit risk management. With the extensive research on consumer credit risk assessment in recent decades, the abundance of literature on this topic can be overwhelming for researchers. Therefore, this article aims to provide a more systematic and comprehensive analysis from three perspectives: classification algorithms, data traits, and learning methods. Firstly, the state-of-the-art classification algorithms are categorized into traditional single classifiers, intelligent single classifiers, hybrid and ensemble multiple classifiers. Secondly, considering the diversity of data traits in the credit dataset, data traits are divided into external structure information traits, data quality traits, data quantity traits, and internal information traits. Data traits-driven modeling framework based on multiple classifiers is proposed for solving credit risk assessment. Thirdly, considering the differences in data modeling methods, learning methods are classified into data status, label status, and structure form. Furthermore, model interpretability, model bias, model multi-pattern, and model fairness are discussed. Finally, the limitations and future research directions are presented. This review article serves as a helpful guide for researchers and practitioners in the field of credit risk modeling and analysis.","A classification system for hazardous materials in air traffic control was investigated using the Human Factors Analysis and Classification System (HFACS) framework and natural language processing to prevent hazardous situations in air traffic control. Based on the development of the HFACS standard, an air traffic control hazard classification system will be created. The dangerous data of the aviation safety management system is selected by dead bodies, classified and marked in 5 levels. TFIDF TextRank text classification method based on key content extraction and text classification model based on CNN and BERT model were used in the experiment to solve the problem of small samples, many labels and random samples in hazardous environment of air pollution control. The results show that the total cost of model training time and classification accuracy is the highest when the keywords are around 8. As the number of points increases, the time spent in dimensioning decreases and affects accuracy. When the number of points reaches about 93, the time spent in determining the size increases, but the accuracy of the allocation remains close to 0.7, but the increase in the value of time leads to a decrease in the total cost. It has been proven that extracting key content can solve text classification problems for small companies and contribute to further research in the development of security systems.","Accurate and timely crop classification results play a crucial role in providing data support for agricultural policy-making and crop yield estimation. However, the current development of crop classification faces a bottleneck in improving classification performance due to limited labeled samples and saturated classification algorithms. In this study, we propose a novel method to improve crop classification performance by leveraging unlabeled remote sensing data (URSD). Importantly, our method does not necessitate a large number of labeled samples or significant modifications to the classification algorithm. Instead, it relies on a unique self-supervised training approach and a substantial amount of URSD. Specifically, we develop a self-supervised classification framework based on a Multilayer Perceptron (MLP) and introduce a self-supervised training approach that takes into account both temporal and spectral factors. Additionally, we construct a historical sample classification model based on crop growth knowledge, emphasizing the correlation of local time series. We evaluate the proposed method using four study areas in China. The analysis of pre-training data types reveals that our method not only improves the classification performance of current year samples but also demonstrates noticeable improvement in classifying historical samples. The classification method analysis demonstrates the ability of our proposed self-supervised learning training approach to accumulate more prior knowledge. Overall, these results highlight the advantages of our method in terms of classification efficiency and performance improvement.","Each year, millions of pilgrims come to Saudi Arabia to perform Hajj and Umrah. To help pilgrims with their difficulties and make plans to enhance the Hajj and Umrah services, this article offers a deep learning-based framework to categorize and analyze pilgrims\u2019 posts on social media networks X (formerly Twitter), Facebook and Instagram. We extracted Arabic posts related to Hajj/Umrah then tokenized and pre-processed the dataset to remove unnecessary parts such as punctuation. Posts are manually labeled into five classes: Health, Organization, Security, Services, and Worship. Labeled posts are collected to build a Long Short-Term Memory (LSTM) network classifier for deep learning. To increase the prediction accuracy, we customized the LSTM classification layer and used the sum of squares error (SSE) loss function instead of the default cross-entropy loss function. A rigorous simulation is run to assess the system\u2019s effectiveness. Every time a simulation round occurs, the trained network is tasked with identifying the classes of unlabeled posts (testing data). Similar tests are performed using the K-Nearest Neighbors (KNN) and Linear Discriminant Analysis (LDA) algorithms for comparative analysis. Accuracy, confusion matrix, precision, sensitivity, specificity, and F 1 score are used to quantify the system performance. The maximum mean accuracy of the proposed framework, KNN and LDA are 85.65%, 68.47%, and 59.06% respectively. The proposed framework needs to be integrated into a larger system called the Intelligent Pilgrim Service System (IPSS). We described the IPSS architecture, which comprises modules for data generation, data storage (on the cloud), and a control center. We described a hashtag mechanism as a part of the IPSS. This hashtag mechanism will provide both general and focused advice to millions of pilgrims related to their social media posts. We discussed scenarios of how the IPSS can enhance the Hajj and Umrah services.\nHighlights\n\u2022\nA tagged dataset of social media posts from X (formerly Twitter), Facebook, and Instagram related to Hajj and Umrah.\n\u2022\nA customized edge deep learning-based framework to classify social media posts.\n\u2022\nNine parameters to measure the performance of the system.\n\u2022\nAn architecture of the Intelligent Pilgrim Service System (IPSS) is provided.\n\u2022\nA novel hashtag mechanism is presented that provides on-time advice to pilgrims.","Highlights\n\u2022\nCalculating the KNN for each instance and leveraging instance correlation to expand the original feature space.\n\u2022\nUsing mutual information to measure feature redundancy and extracting high-quality feature subsets with low dimensions.\n\u2022\nDeveloping a multi-label learning approach that considers label correlation, instance correlation, and feature redundancy.\nAbstract\nMulti-label classification is a machine-learning task that simultaneously processes instances associated with multiple labels. Label-specific feature learning selects each label's most discriminative feature subset, effectively reducing the feature dimension and improving the classification performance. However, most methods only consider label correlation, ignoring the correlation between instances and feature redundancy. To solve this problem, a multi-label classification method based on instance correlation and feature redundancy is proposed. The proposed method merges instance correlation by updating the data set and removes redundant features by calculating mutual information. By jointly considering label correlation, instance correlation, and feature redundancy, our method promotes effective multi-label feature selection. The experimental results on ten data sets demonstrate the effectiveness of the proposed method.","Interpreting regulatory documents or building codes into computer-processable formats is essential for the intelligent design and construction of buildings and infrastructures. Although automated rule interpretation (ARI) methods have been investigated for years, most of them are highly dependent on the early and manual filtering of interpretable clauses from a building code. While few of them considered machine interpretability, which represents the potential to be transformed into a computer-processable format, from both clause- and document-level. Therefore, this research aims to propose a novel approach to automatically evaluate and enhance the machine interpretability of single clauses and building codes. First, a few categories are introduced to classify each clause in a building code considering the requirements for rule interpretation, and a dataset is developed for model training. Then, an efficient text classification model is developed based on a pretrained domain-specific language model and transfer learning techniques. Finally, a quantitative evaluation method is proposed to assess the overall interpretability of building codes. Experiments show that the proposed text classification algorithm outperforms the existing CNN- or RNN-based methods, by improving the F1-score from 72.16% to 93.60%. It is also illustrated that the proposed classification method can enhance downstream ARI methods with an improvement of 4%. Furthermore, analysis of more than 150 building codes in China showed that their average interpretability is only 34.40%, which implies that it is still difficult to fully transform an entire regulatory document into computer-processable formats. It is also argued that the interpretability of building codes should be further improved both from the human side (considering certain constraints when writing building codes) and the machine side (developing more powerful algorithms, tools, etc.).","This paper proposes a novel hybrid approach that combines a mixture of non-central Wishart distribution (MoNCW) model and a feed forward neural network (FFNN) to accurately estimate both the number and orientations of white matter fibers in biological tissues in brain. While the MoNCW model performs well in determining fiber orientations when the separation angle is greater than 50\u00b0, accurately clustering these orientations is still a significant challenge. To tackle this issue, the authors introduce a machine learning (ML) model that can precisely identify the number of fibers per voxel. The ML model is then integrated with the MoNCW model to improve the accuracy of fiber orientation estimation. The FFNN is trained using simulated datasets, which contain signal vectors for single, as well as two and three crossing fiber voxels, using a sequential model. The FFNN is particularly effective in solving classification problems, as it can process input data through multiple layers to produce output values that correspond to class labels. In this study, three classes are labelled as 1, 2, and 3, representing the number of fibers. By utilizing this hybrid approach, the accuracy of fiber number and orientation estimation in biological tissues is significantly improved, outperforming existing mixture models.","Electroencephalogram (EEG) is a non-invasive technology with high temporal resolution, widely used in Brain-Computer Interfaces (BCIs) for mental workload (MWL) classification. However, numerous EEG channels in current devices can make them bulky, uncomfortable, and time-consuming to operate in real-life scenarios. A Riemannian geometry approach has gained attention for channel selection to address this issue. In particular, Riemannian geometry employs covariance matrices of EEG signals to identify the optimal set of EEG channels, given a specific covariance estimator and desired channel number. However, previous studies have not thoroughly assessed the limitations of various covariance estimators, which may influence the analysis results. In this study, we aim to investigate the impact of different covariance estimators, namely Empirical Covariance (EC), Shrunk Covariance (SC), Ledoit-Wolf (LW), and Oracle Approximating Shrinkage (OAS), along with the influence of channel numbers on the process of EEG channel selection. We also examine the performance of selected channels using diverse deep learning models, namely Stacked Gated Recurrent Unit (GRU), Bidirectional Gated Recurrent Unit (BGRU), and BGRU-GRU models, using a publicly available MWL EEG dataset. Our findings show that although no universally optimal channel number exists, employing as few as four channels can achieve an accuracy of 0.940 (\u00b10.036), enhancing practicality for real-world applications. In addition, we discover that the BGRU model, when combined with OAS covariance estimators and a 32-channel configuration, demonstrates superior performance in MWL classification tasks compared to other estimator combinations. Indeed, this study provides insights into the effectiveness of various covariance estimators and the optimal channel subsets for highly accurate MWL classification. These findings can potentially advance the development of EEG-based BCI applications.","Blood Pattern Analysis is a technique in forensic science that focuses on leftover bloodstains from the crime to recreate the event. However, the fluctuation in air resistance and drop deformity causes the calculations to deviate from the exact values. Therefore, machine learning models were constructed to overcome this limitation of calculations. A series of experiments was conducted by dropping porcine blood on paper across nine distinct heights: 20, 40, 60, 80, 100, 120, 140, 160, and 180 cm with four different drop volumes: 13, 16, 25, and 30 \u03bcL resulting in 36 classes. A simple simulation of a free-fall spherical object was also created to convert any drop height into impact velocity. Regarding both the empirical data and simulation, the correlation between the spreading factor and modified Reynold number, along with the number of spines and modified Weber number, were expressed as equations that can be used to determine drop height and drop volume. Concurrently, the same dataset used in physics calculations was used to train machine learning models that implement VGG-19 and XGBoost. For VGG-19, the inputs are images of bloodstains, while for XGBoost, the inputs are stain area, stain perimeter, and the number of spines. As a result, the accuracy for physics equations VGG-19 and XGBoost were 0.26, 0.56, and 0.49, respectively.","Efficiently classifying sheep breeds through image analysis is pivotal in modern animal husbandry, influencing critical management and breeding decisions. This study delves into automating this process by harnessing Convolutional Neural Networks (CNNs), with a particular focus on optimizing key hyperparameters\u2014the learning rate and dropout rate\u2014essential for refining model performance. Manual hyperparameter tuning is often time-consuming and demands expertise. To overcome this challenge, we introduce an innovative approach that utilises the Bat algorithm, a bio-inspired optimization technique. This algorithm mimics bat echolocation behaviors, skillfully navigating the complex hyperparameter search space to determine optimal values. By dynamically adjusting CNN hyperparameters, our research aims to boost classification accuracy while simplifying the tuning process. Empirical results highlight significant gains in classification accuracy and emphasizes the Bat algorithm's efficacy. The optimized CNN model, empowered by fine-tuned hyperparameters, demonstrates superior performance, promising practical applicability in real-world sheep breed classification scenarios. This study meticulously adjusts pulse rate and loudness, revealing an optimal combination of [0.001, 0.24404868], which substantially improves model performance. The findings emphasize the Bat algorithm's role in streamlining hyperparameter tuning and its potential impact on automated sheep breed classification.","Automated classification of skin lesions in dermoscopy images has the potential to significantly improve survival rates and reduce the risk of death for skin cancer patients. However, existing supervised learning models heavily depend on well-annotated dermoscopy training data, which is expensive and labor-intensive to obtain. This paper addresses this issue by proposing a semi-supervised framework called Noisy Consistent Pseudo Labeling (NCPL), which only utilizes less annotated images with many unlabeled raw data. The NCPL framework consists of two components: the Noisy-Consistent Sample Learning(NCSL) module to remove low-confidence images, and the Attentive Clustered Feature Integration (ACFI) module, incorporating an uncertainty-aware attention mechanism. Specifically, the NCSL module is introduced to filter and generate reliable pseudo-labels for unlabeled skin images, with excellent capability of removing noisy samples. Additionally, the ACFI module integrates high-dimensional representations of original lesion images in an attentive manner, assisted with the annotated data. By focusing the representative samples and removing noisy images, the NCPL approach performs outstanding experimental results, demonstrating the superiority of the NCPL framework in semi-supervised skin lesion classification task.","Highlights\n\u2022\nHyperspectral images of 10,000 maize seeds from 20 varieties are collected.\n\u2022\nA self-supervised learning method for seed classification is proposed.\n\u2022\nThe proposed method performs well on the raw spectral data.\n\u2022\nSelf-supervised pre-trained model improves seed classification performance.\nAbstract\nRapid and non-destructive variety identification is essential for screening maize seeds for different end-uses such as food, feed, and breeding. Hyperspectral imaging (HSI) is one of the most commonly used techniques in such seed classification. Typically, after acquiring hyperspectral images of seeds, the spectral domain signals need to be preprocessed and a classifier need to be designed. The traditional method is to find a appropriate spectral preprocessing method through trial-and-error experiment, which is time-consuming, laborious and has high risk of misuse preprocessing. In view of this, this paper proposes a self-supervised learning method that includes pre-training and fine-tuning phases. In the pre-training phase, a model was trained on the unlabeled raw spectral data in an unsupervised manner to obtain general representations. In the fine-tuning phase, the pre-trained model was fine-tuned with the goal of the seed classification task and trained in a supervised manner on labeled spectral data. Experimental results showed that the proposed method did not rely on spectral preprocessing, and its performance was superior to other existing seed classification methods. In addition, the self-supervised pre-trained model significantly outperformed the non-pre-trained model in the downstream seed classification task, and obtained good generalization ability. Overall, this method combined with HSI for seed quality evaluation has broad application prospects.","Vehicle classification holds significant importance in various domains such as infrastructure design and freight analysis. This study presents an innovative composite deep-learning framework for accurate vehicle classification. The framework exploits two distinct types of features extracted from vehicle images: (1) high-level encodings from state-of-the-art vision transformers (ViTs), and (2) localized vehicle wheel position features obtained through real-time object detection models. The former encapsulates global and semantic characteristics, while the latter focuses on specific wheel (axle) positions. Within this composite model paradigm, we evaluate and compare the efficacy of four ViT models: the original ViT, Cross ViT, Transformer-in-Transformer, and Swin Transformer. Similarly, we assess four object detection models for extracting wheel position features: two Faster R-CNN models (with ResNet-50 and MobileNetv3 backbones) and two YOLO models (YOLOv4 and YOLOR). The ViT encodings and wheel position features are then combined and channeled into a multi-layer perceptron classifier for precise vehicle classification. To enhance the ViT model's effectiveness, we employ a wheel masking strategy during its training, which acts as a regularizer, promoting robust and complementary encodings. Our experimental results reveal that introducing randomness by masking a single wheel significantly enhances the inference performance across all composite models. However, masking more wheels introduces excessive noise and causes performance degradation. Furthermore, initializing ViT encoders with pretrained weights through self-supervised methods leads to additional performance improvements. Notably, our best model achieves an impressive Top-1 classification accuracy of 96.7% when categorizing 13 vehicle classes as defined by the Federal Highway Administration. The results underscore the efficacy of the proposed composite architecture in achieving high precision in vehicle classification tasks.","Improper sorting of construction and demolition waste (CDW) leads to significant environmental and economic implications, including inefficient resource use and missed recycling opportunities. To address this, we developed a machine-learning-assisted procedure for recognizing CDW fragments using an RGB camera. Our approach uniquely leverages selected feature extraction, enhancing classification speed and accuracy. We employed three classifiers: convolutional neural network (CNN), gradient boosting (GB) decision trees, and multi-layer perception (MLP). Notably, our method\u2019s extraction of selected features for GB and MLP outperformed the traditional CNN in terms of speed and accuracy, especially for challenging samples with similar textures. Specifically, while convolution resulted in an overall accuracy of 85.9%, our innovative feature extraction approach yielded accuracies up to 92.3%. This study\u2019s findings have significant implications for the future of CDW management, offering a pathway for efficient and accurate waste sorting, fostering sustainable resource use, and reducing the environmental impact of CDW disposal. Supplementary materials, including datasets, codes, and models, are provided, promoting transparency and reproducibility.\nHighlights\n\u2022\nClassifiers were trained to recognize construction and demolition waste (CDW).\n\u2022\nCDW fragments were recognized from RGB images.\n\u2022\nFeatures were extracted for GB and MLP models; CNN employed convolution.\n\u2022\nGB and MLP outperformed CNN in terms of speed and accuracy.\n\u2022\nGB: 92.3% overall accuracy, MLP: 91.3%, and CNN: 85.9%.","Background: Breast cancer is one of the greatest health threats to women worldwide. Mammography is an effective and inexpensive tool for breast cancer early detection. Mammography-based breast cancer screening requires a lot of manpower from professional experts. Thus, computer-aided diagnosis tools, especially accurate classifiers which can distinguish the breast masses from the background tissues, are needed. However, since the sample size of publicly available mammography data sets is relatively small, the performance of the published breast mass identification models was not great, and the models were not well-embraced by clinical practice due to their low interpretability. Methods: In this work, using two independent and well-known mammography data sets, the CBIS-DDSM and the INbreast, we proposed a novel patch generation method for data augmentation and negative case generation. We implemented two successful deep learning models, the ResNet and the ViT, to classify the generated mass and non-mass patches. We also proposed to apply the patch-level model to the full-view mammogram screening in a sliding window manner and visualize/interpret the prediction results using a heatmap so that the clinic practice could potentially benefit from the well-trained model. Result: For the CBIS-DDSM dataset, we compared the performance of the ResNet and the ViT with and without data augmentation. The F1 score is 0.91, 0.86, 0.85, and 0.70, respectively. We also evaluated our models using other metrices such as accuracy, precision, recall, and ROC curve. The results show that the ResNet model outperforms the ViT model. And the data augmentation improves the overall performance of the models. The similar conclusions are further supported using the independent INbreast data. Furthermore, we also explored to use probability-based heatmaps to visualize the potential mass regions in mammogram images. Conclusion: The study shows that our patch-level data augmentation is effective in improving the classification performance of the deep learning models. The comparable performance on the CBIS-DDSM data and the independent INbreast data demonstrates the generalizability of our methods. The proposed heatmap visualization tool increases the interpretability of our results and could be a potential approach for clinic utilization.","Artificial intelligence (AI) technology has significant potential in Earth sciences, particularly in mineral identification for industrial exploration, geological mapping, and archaeological research. However, traditional methods are time-consuming, expensive, and complex. And existing mineral identification methods based on mineral photos face several critical challenges, including lack of consideration for natural image features captured in real environments, limitations of single-label classification which does not align with multi-mineral occurrences in nature, and growing computational complexity as the number of identifiable mineral labels increases. Therefore, this paper proposes an efficient mineral identification model based on multi-label image classification, focusing on natural environmental features. First, realistic feature datasets are created by simulating mineral photos in real environments. Then, the model uses the query-label (Query2Label) framework, with MaxViT-T (Multi-Axis Vision Transformer-Tiny) as the feature extraction network and the asymmetric loss function. Knowledge distillation is employed to improve identification accuracy while reducing computational complexity. The proposed model achieves an impressive average identification accuracy of 84.74% on a dataset of 495,756 mineral photos, surpassing existing models like ResNet-101, ML-GCN (Multi-Label Graph Convolutional Network), and SRN (Spatial Regularization Net). It maintains a lower parameter count and computational complexity. In the end, ablation experiments demonstrate the effectiveness of each optimization scheme.\nHighlights\n\u2022\nSelecting image noise and color shift methods for realistic mineral data simulation.\n\u2022\nProposing an enhanced two-stage image multi-Label identification model framework.\n\u2022\nApplying knowledge distillation for multi-label classification subtask decomposition.\n\u2022\nBeing with low computational complexity and high mineral identification accuracy.","Malware is a serious threat to the modern Internet, as it is used to, e.g., sending spam or stealing bank login credentials. Typically, to communicate with the attacker, it utilizes popular network protocols such as the HyperText Transfer Protocol (HTTP). The network traffic characteristics related to this protocol can be used to detect malware and identify its family. The latter is a standard multi-class classification problem for which machine learning algorithms are utilized. However, existing methods cannot identify a real-world situation of encountering a new malware family, which was not known during their training phase. To address this issue, an Open Set Recognition (OSR) approach can be used, capable of a multi-class classification and identification of unknown class occurrence. In this paper, we apply OSR to the malware classification using HTTP requests and compare it with the existing solutions. In more detail, we analyze the classification performance of three OSR and two standard algorithms and their computation time. Additionally, we utilize two request representations: one based on Hfinger tool and the other relying on trigrams. The obtained experimental results allowed to select an optimal set of algorithms and HTTP request representations suitable for OSR scenarios.","This paper proposes a texture-based domain-specific data augmentation technique applicable when training on small datasets for deep learning classification tasks. Our method focuses on label-preservation to improve generalization and optimization robustness over data-dependent augmentation methods using textures. We generate a small perturbation in an image based on a randomly sampled texture image. The textures we use are naturally occurring and domain-independent of the training dataset: regular, near regular, irregular, near stochastic and stochastic classes. Our method uses the textures to apply sparse, patterned occlusion to images and a penalty regularization term during training to help ensure label preservation. We evaluate our method against the competitive soft-label Mixup and RICAP data augmentation methods with the ResNet-50 architecture using the unambiguous \u201cBird or Bicyle\u201d and Oxford-IIT-Pet datasets, as well as a random sampling of the Open Images dataset. We experimentally validate the importance of label-preservation and improved generalization by using out-of-distribution examples and show that our method improves over competitive methods.","Highlights\n\u2022\nWe enhanced off-the-shelf ASR with classifiers to score verbal fluency tasks.\n\u2022\nMany novel scores utilizing timings of words can be calculated automatically.\n\u2022\nWe achieved high AUCs for the identification of valid words.\n\u2022\nMost automated scores correlate strongly with manual scores.\nAbstract\nSkip Objective Section\nObjective\nTo compare verbal fluency scores derived from manual transcriptions to those obtained using automatic speech recognition enhanced with machine learning classifiers.\nSkip Methods Section\nMethods\nUsing Amazon Web Services, we automatically transcribed verbal fluency recordings from 1400 individuals who performed both animal and letter F verbal fluency tasks. We manually adjusted timings and contents of the automatic transcriptions to obtain \u201cgold standard\u201d transcriptions. To make automatic scoring possible, we trained machine learning classifiers to discern between valid and invalid utterances. We then calculated and compared verbal fluency scores from the manual and automatic transcriptions.\nSkip Results Section\nResults\nFor both animal and letter fluency tasks, we achieved good separation of valid versus invalid utterances. Verbal fluency scores calculated based on automatic transcriptions showed high correlation with those calculated after manual correction.\nSkip Conclusion Section\nConclusion\nMany techniques for scoring verbal fluency word lists require accurate transcriptions with word timings. We show that machine learning methods can be applied to improve off-the-shelf ASR for this purpose. These automatically derived scores may be satisfactory for some applications. Low correlations among some of the scores indicate the need for improvement in automatic speech recognition before a fully automatic approach can be reliably implemented.","As for the characteristics of the objects in the airtight package in the X-ray image, some prohibited items of the airtight package are difficult to be detected from the X-ray images with complex and overlapped backgrounds. In this article, the cooperative knowledge distillation method is used to enhance the prohibited items detection model in the X-ray image. To efficiently implement hard example mining, this article designs an Multi-task Classification Head (MCH) for teachers to provide prior knowledge of image-level and instance-level predictions. Different from the distillation method in which the students imitate the teacher, the algorithm in this article is implemented by the cooperation between teacher and student. In order to verify the effectiveness of this algorithm, a series of related experiments are carried out on PIDray and SIXray respectively. Experiments show that the algorithm improves the AP of State-of-the-Art dense object detectors (e.g., RetinaNet, ATSS, GFL, and TOOD) in SIXray by 1% \u223c 2%. Especially for prohibited items that are difficult to be found in X-ray images, the algorithm is more effective, and the dense object detectors can achieve a performance improvement of about AP of 2% on the Hidden subset of PIDray. The experiments demonstrate that the cooperative knowledge distillation algorithm proposed in this article can effectively enhance the performance of prohibited items detection, particularly showing more pronounced improvements in detecting hard examples.","Graph neural networks (GNNs) are increasingly used in critical human applications for predicting node labels in attributed graphs. Their ability to aggregate features from nodes' neighbors for accurate classification also has the capacity to exacerbate existing biases in data or to introduce new ones towards members from protected demographic groups. Thus, it is imperative to quantify how GNNs may be biased and to what extent their harmful effects may be mitigated. To this end, we propose two new GNN-agnostic interventions namely, (i) PFR-AX which decreases the separability between nodes in protected and non-protected groups, and (ii) PostProcess which updates model predictions based on a blackbox policy to minimize differences between error rates across demographic groups. Through a large set of experiments on four datasets, we frame the efficacies of our approaches (and three variants) in terms of their algorithmic fairness-accuracy tradeoff and bench- mark our results against three strong baseline interventions on three state-of-the-art GNN models. Our results show that no single intervention offers a universally optimal tradeoff, but PFR-AX and PostProcess provide granular control and improve model confidence when correctly predicting positive outcomes for nodes in protected groups.","The field of image classification faces significant challenges due to the scarcity of target samples, leading to model overfitting and difficult training. To address these issues, few-shot learning has emerged as a promising approach. However, current methods do not fully utilize the correlations among samples and external semantic information, resulting in poor recognition accuracy. To overcome these limitations, we propose a new few-shot classification method that incorporates both attributes and attention guided approach. The method leverages the attention mechanism to extract discriminative features from the images. By exploring regional correlations among samples, it assists in generating visual representations by utilizing predicted attribute features. As a result, accurate prototypes are generated. Extensive experiments were conducted on two attribute-labeled datasets, namely Caltech-UCSD Birds-200\u20132011(CUB) and SUN Attribute Database (SUN) Attribute Dataset. With the Resnet12 backbone, the method achieves remarkable accuracies of 79.95% and 89.34% for 1-shot and 5-shot, respectively, on the CUB dataset. Similarly, with the Conv4 backbone, the method achieves notable accuracies of 67.21% and 80.87% for 1-shot and 5-shot, respectively, on the SUN Attribute dataset. The achieved accuracies highlight the robustness and generalizability of our method, and show the capability of our method to accurately classify samples with limited training data, which is a significant advantage in real-world scenarios where labeled data are often scarce.","Attention, one of the most important features of modern CNNs, has been shown to improve the performance of mammogram classification, but our understanding of why attention offers improvements is rather limited. In this paper, we present the first comprehensive comparison of different combinations of baseline models and attention methods at multiple resolutions for whole mammogram image classification of masses and calcifications. Our findings indicate that attention generally helps to improve the baseline model scores, but the benefits are variable depending on the resolution and abnormality type. Furthermore, we find that pooling and overall model architecture (i.e., combination of baseline and attention) significantly impact mammogram classification scores. Specifically, scores are generally improved by architectural features that allow the model to retain as much information as possible while still focusing on relevant features. We also find that attention improves the correlation between model performance and LayerCAM activation in the region of interest. Our work provides insightful information to help guide the future construction of attention-based models for mammogram classification.","Automated credit risk assessment plays an important role in agricultural lending. However, credit risk assessment in the agricultural domain has unique challenges due to the impact of weather, pest outbreaks, commodities market dynamics, and other volatile forces that drive risk. Training a model to account for these factors requires immense data assets that are challenging to obtain. Indeed, even the best credit risk assessment models in this domain are trained using data from single-institutions that often focus on dedicated geographical regions, or singular commodities. Hence, most agricultural credit risk models exhibit poor out-of-domain performance. In this paper, we use a novel dataset describing nearly 100 thousand historical loans, sourced from 9 large agricultural lenders to train a Bayesian network model for loan delinquency classification. The proposed model exhibited improved calibration (relative improvement in Expected Calibration Error) in out-of-domain performance tests when compared to three state-of-the-art credit risk scoring approaches: Logistic regression (81 \u00b1 15% improvement), XGBoost (80 \u00b1 14% improvement), and an Artificial Neural Networks (7 \u00b1 2% improvement). We conclude that Bayesian networks provide better modeling of agricultural credit risk by combining (limited) data assets with expert domain knowledge. Our approach is likely to generalize to any credit risk assessment task where small sample sizes is of concern.","Nowadays, Multi-Label Feature Selection (MLFS) attracts more and more attention to tackle the high-dimensional problem in multi-label data. A key characteristic of existing gradient-based MLFS methods is that they typically consider two-way variable correlations between features and labels, including feature-feature and label-label correlations. However, two-way correlations are not sufficient to steer feature selection since such correlations vary given different additional variables in practical scenarios, which leads to the selected features with relatively-poor classification performance. Motivated by this, we capture three-way variable interactions including feature-feature-label and feature-label-label interactions to further characterize the fluctuating correlations in the context of another variable, and propose a new gradient-based MLFS approach incorporating the above three-way variable interactions into a global optimization objective. Specifically, based on information theory, we develop second-order regularization penalty terms to regard three-way interactions while jointly combining with the main loss term in regard to feature relevance. Then the objective function can be efficiently optimized via a block-coordinate gradient descent schema. Meanwhile, we provide a theoretical analysis demonstrating the effectiveness of the regularization terms in exploiting three-way interaction. In addition, experiments conducted on a series of benchmark data sets also verify the validity of the proposed method on multiple evaluation metrics.\nHighlights\n\u2022\nFirst gradient-based multi-label feature selection method tackling three-way interactions.\n\u2022\nModel three-way interactions via two regularization terms, whose effectiveness is shown in theory.\n\u2022\nOptimize objective via iterative coordinate descent for feature importance blocks.","During the several years of production of an animated movie, review meetings take place daily, where supervisors and directors generate text notes about fixes needed for the movie. These notes are manually assigned to artistic departments for them to fixed. Being manual, many notes are not properly assigned and are never fixed, lowering the quality of the final movie. This paper presents a proposal for automating the distribution of these notes using multi-label text classification techniques. The comparison of the results obtained by fine-tuning several transformer-based language models is presented. A highest mean accuracy of 0.776 is achieved assigning several departments to each of the review notes in the test set with a BERT Multilingual model. A mean accuracy of 0.762 was reached in just 10 epochs and 10 min of training on an RTX-3090 with a DistilBERT transformer model.","With the rapid development of higher education in China, more and more archives are managed by the archives of colleges and universities. Therefore, many colleges and universities have equipped archives management software to manage archives by computer. However, at present, the mainstream archives management software for colleges and universities does not have the function of automatic classification of archives. In order to reduce the workload of college archives staff, this paper explores a text automatic classification method suitable for college archives. Classification tree algorithm is a method of organizing and storing information. The classification tree is used to classify data into various categories, such as customers and products. It also provides an effective way to search for data using keywords or phrases. Classification tree is very useful in document processing, because it can help us find documents with similar characteristics, such as customers with similar requirements, products with similar functions, etc. The working principle of classification tree algorithm is to decompose the problem into smaller subproblems, and then solve one subproblem at a time until all problems are completely solved.","Glaciers play a critical role in the Earth\u2019s climate system, and accurate estimates of their behaviours are essential for understanding the impacts of climate change and informing policy decisions. One of the most important parameters for such a task is ice distribution, which is difficult to measure and predict using traditional physics-based models. In this study, we propose a deep learning approach to predict glacier thickness by learning directly from ice velocity and topography. Our approach overcomes the limitations of traditional physics-based models, such as computational cost and the need for expert knowledge to calibrate the models. In addition, deep learning models are flexible enough to explore the relevance of multimodality and multitasking to address the physical problem. Our results demonstrate the feasibility of quickly training a neural network model with sufficient training data and producing stable, high-quality ice thickness estimates. We highlight the importance of some specific input features suggested by geophysicists that have a positive impact on model stability.","Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don\u2019t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn\u2019t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame\u2019s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI are becoming an imperative.","This paper presents an automatic dialect identification in Ao using modulation-based approach. Ao is a low-resource, Tibeto-Burman tonal language spoken in Nagaland, a North-East state of India. This work aims to investigate dialect-specific characteristics to build a more robust DID system for classifying the three Ao dialects. In this direction, modulation-based representation is explored. Considering Ao is a tone language, the experiments were evaluated for 3 sec segment duration in order to capture the temporal information of the modulation spectrogram. In addition, the log Mel spectrogram is used as the feature for the baseline DID system. The proposed modulation spectrogram shows a significant performance of\n\u2248\n8\n%\nimprovement in accuracy over the baseline Ao DID system. Hence, the result indicates the effectiveness of modulation-based representation in automatically identifying the three dialects of Ao.","Semi-supervised domain adaptation (SSDA) aims to bridge source and target domain distributions, with a small number of target labels available, achieving better classification performance than unsupervised domain adaptation (UDA). However, existing SSDA work fails to make full use of label information from both source and target domains for feature alignment across domains, resulting in label mismatch in the label space during model testing. This paper presents a novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE), to tackle this issue. Firstly, we introduce a cross-domain feature alignment strategy, Inter-domain Mixup, that incorporates label information into model adaptation. Specifically, we employ sample-level and manifold-level data mixing to generate compatible training samples. These newly established samples, combined with reliable and actual label information, display diversity and compatibility across domains, while such extra supervision thus facilitates cross-domain feature alignment and mitigates label mismatch. Additionally, we utilize Neighborhood Expansion to leverage high-confidence pseudo-labeled samples in the target domain, diversifying the label information of the target domain and thereby further increasing the performance of the adaptation model. Accordingly, the proposed approach outperforms existing state-of-the-art methods, achieving significant accuracy improvements on popular SSDA benchmarks, including DomainNet, Office-Home, and Office-31.\nHighlights\n\u2022\nA novel algorithm called IDMNE is proposed for semi-supervised domain adaptation.\n\u2022\nInter-Domain Mixup mitigates label mismatch during feature alignment in adaptation.\n\u2022\nNeighborhood Expansion diversifies target label information, curbs prediction uncertainty.\n\u2022\nIntegrated framework surpasses state-of-the-art on three SSDA benchmark datasets.","Leveraging the enormous amounts of real-world data collected through Internet of Things (IoT) technologies, human activity recognition (HAR) has become a crucial component of numerous human-centric applications, with the aim of enhancing the quality of human life. While the recent advancements in deep learning have significantly improved HAR, the process of labeling data continues to remain a significant challenge due to the substantial costs associated with human annotation for supervised model training. Active learning (AL) addresses this issue by strategically selecting informative samples for labeling during model training, thereby enhancing model performance. Although numerous approaches have been proposed for sample selection, which consider aspects of uncertainty and representation, the difficulties in estimating uncertainty and exploiting distribution of high-dimensional data still pose a major issue. Our proposed deep learning-based active learning algorithm, called Multiclass Autoencoder-based Active Learning (MAAL), learns latent representation leveraging the capacity of Deep Support Vector Data Description (Deep SVDD). With the multiclass autoencoder which learns the normal characteristics of each activity class in the latent space, MAAL provides an informative sample selection for model training by establishing a link between the HAR model and the selection model. We evaluate our proposed MAAL using two publicly available datasets. The performance results demonstrate the improvements across the overall active learning rounds, achieving enhancements up to 3.23% accuracy and 3.67% in the F 1 score. Furthermore, numerical results and analysis of sample selection are presented to validate the effectiveness of the proposed MAAL compared to the alternative comparison methods.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nWe present a deep learning-based active learning for an efficiently labeled dataset.\n\u2022\nThe proposed method extends the autoencoder with SVDD in a multiclass scheme.\n\u2022\nWe evaluate the proposed active learning method in the scenario of HAR applications.\n\u2022\nExperimental results show improvements in the performance of HAR with a smaller dataset.\n\u2022\nSelection of informative samples which is difficult for model to predict is validated.","Unmanned Aerial Systems (UAS), commonly known as drones, have revolutionized various industries with their diverse applications. As the demand for seamless and intuitive drone control grows, researchers are exploring innovative approaches to improve human-swarm interaction. This paper presents a novel method for operating a swarm of drones in real time using wearable technology and machine learning. Through the integration of motion capture data and classification algorithms, we strive to achieve an intuitive level of control that is accessible to users with varying skill levels. While the full realization of this approach remains a work in progress, our research lays the groundwork for future endeavors in this domain. In this paper, we discuss the limitations of existing control methods and present our methodology for data preprocessing, model training and testing, and result analysis. Our findings indicate the potential of this approach and open avenues for refining the interaction between humans and drone swarms.","This study introduces a novel model designed to classify macrocauses of violent crimes. The model\u2019s practical application is demonstrated through its integration into the framework of the Natal Smart City Initiative in Brazil. Utilizing the Design Science methodology, the study details the model\u2019s development, its subsequent implementation through a machine learning pipeline, and its assessment employing four prominent classification techniques: Decision Trees, Logistic Regression, Random Forest, and XGBoost. XGBoost performed exceptionally well, achieving an average accuracy of 0.961791, an F1-Score of 0.961410, and an AUC of ROC curve of 0.994732. Accurate classification of criminal macrocauses is crucial for developing effective public safety policies. The proposed model can provide public safety institutions and criminal analysts with a valuable tool for better understanding aspects related to violent crime analysis in their cities. This can streamline the analysis and management process and provide more accurate information for decision-making. This study also has important implications for the emerging field of smart cities. By providing a tool to assist in decision-making and planning public safety strategies, this work contributes to the development of innovative, data-based, and theory-based solutions to address urban challenges.\nHighlights\n\u2022\nWe propose a model for classifying criminal macrocauses to help criminal analysts.\n\u2022\nWe compared Decision Trees, Random Forest, Logistic Regression, and XGBoost.\n\u2022\nXGBoost obtained the best results (0.96 accuracies) after statistical analysis.\n\u2022\nUsing feature engineering techniques and the SMOTE-NC to handle unbalanced data.","Precise prediction of cancer survival is of paramount importance in aiding clinicians in formulating tailored treatment strategies. Such strategies have the potential to enhance the quality of life for individuals with cancer and lower the mortality rates associated with this disease. Recent research has underscored the significance of integrating data from various sources, including genomics and histopathologic images, as a pivotal step towards enhancing the accuracy of cancer survival prediction. Although these studies have achieved promising results, utilizing the consensus and complementarity of multimodal data for efficient learning of comprehensive multimodal representations poses an enormous challenge. In response to this challenge, we propose a Multimodal Disentangled Representation Learning (MMDR) method, aimed at acquiring modality-specific and shared representations, thus affording a comprehensive perspective of multimodal data. Empirical findings confirm that this approach yields notable enhancements in performance when compared to alternative methodologies.","The cultivation of desired grain varieties holds immense significance as about 67% of the world\u2019s population is associated with the agriculture sector. Unknowingly sowing the wrong variety of seeds may lead to a colossal waste of effort and money. Furthermore, the growing issue of rice grain adulteration in high-quality rice poses a threat to the trust of rice importers and exporters. While traditional methods are expensive, laborious, and error-prone, Computer Vision provides a good alternative that constitutes a current, advanced technology for image processing and data evaluation that holds tremendous promise and potential. In this research study, five varieties of rice grains including Jehlum Sr-1, Mushkibudji, Sr-2, and Sr-4 were collected from local grain and were used for research analysis. A computer vision system \u201cRiceNet\u201d contingent upon Deep Convolutional Neural Network (DCNN) framework has been designed for ameliorating the accuracy of identifying five unique groups of rice grain varieties. Deep Learning (DL) based pre-trained architectures including InceptionV3 and InceptionResNetV2 models were also adopted for classifying five specific groups of rice species. To optimize model parameters and alleviate back-propagation error during training, the Adam optimizer with a learning rate (lr) of 0.00003 has been employed to fine-tune the pre-trained InceptionV3 and ResNetInceptionV2 models. The proposed RiceNet architecture and pre-trained models were also compared with traditional ML approaches of HOG-SVM, SIFT-SVM, HOG-Logistic Regression(HOG-LR), SIFT-Logistic Regression(SIFT-LR), HOG-KNN, and SIFT-KNN for rice grain classification. With these experimentations at hand, it was observed that our proposed model \u201cRiceNet\u201d outperformed other approaches in similar computer vision tasks. The prediction accuracy outcome for the test dataset by HOG-SVM, SIFT-SVM, HOG-LR, SIFT-LR, HOG-KNN, and SIFT-KNN models were 66.0%, 65.33%, 62.67%, 65.0%, 54.0%, and 52.0% respectively. RiceNet, InceptionV3 and ResNetInceptionV2 have the best prediction accuracy of 94%, 84% and 81.333%. The remarkably high success rate of DCNN models makes them highly valuable and can be extended to endorse an integrated grain identification system that can operate in real-world situations.\nHighlights\n\u2022\nRice grain classification is crucial to ensure quality in the agricultural sector.\n\u2022\nDeep Convolutional Neural Network based RiceNet model achieved high accuracy of 94%.\n\u2022\nRiceNet outperforms ML traditional methods for rice grain identification.\n\u2022\nInceptionV3 and ResNetInceptionV2 achieved 84% and 81.333% prediction rates.","Highlights\n\u2022\nA pretrained model on augmented data and fine-tuned by using AI and 3D contour features for assessing facial attractiveness is proposed.\n\u2022\nThe proposed model overcomes the subjective inconsistency and unreliability common to all traditional rating methods.\n\u2022\nThis model provides an accurate 3D information of full facial that is unavailable in previous studies using either 2D or 3D measurement.\n\u2022\n3D facial images and deep transfer learning have been firstly combined for evaluating the facial attractiveness in patients undergoing OGS.\n\u2022\nThe developed web browser\u2013based user interface contributes to effective doctor\u2013patient communication and decision-making.\nAbstract\nIn this paper, we investigate a new approach based on a combination of three-dimensional (3D) facial images and deep transfer learning (TL) with fine-grained image classification (FGIC) for quantitative evaluation of facial attractiveness. The 3D facial surface images of patients with and without filtering and the publicly available SCUT-FBP5500 dataset was used for transfer training and model pre-training, respectively. Experimental results show that a bilinear CNN model with a Gaussian filter freezing 80 % of the weights exhibit the strongest performance and lowest average error as a deep learning prediction model; the model was subsequently adopted for automatic assessment of facial attractiveness in clinical application. This is the first TL model with FGIC using 3D facial images for automatic quantitative evaluation of facial attractiveness in patients undergoing Orthognathic surgery (OGS). The developed web browser\u2013based user interface enables effective and rapid assessment, thus contributing to effective patient\u2013clinician communication and decision-making.","Interior style classification is an interesting problem which has potential applications both commercial and academic communities. This task aims to devise interior design styles automatically. Thus, interior designers will explore customers\u2019 tastes and then precisely provide suggestions for decor inspiration based on their preferences. Recently, Convolutional Neural Networks (CNNs) have been considered the de-facto standard in computer vision tasks. Therefore, several current works have tended to address interior style classification using CNN-based architectures. Moreover, transformer-based architectures and attention-based encoder\u2013decoder models have been proven successfully in computer vision and natural language processing tasks. Sequentially, more studies have been arguing the efficiency of combining CNN-based architectures and transformer-based architectures for normal image classification problems. In this project, we focus on finding an architecture network that is suitable for the interior style classification problem. We propose a robustness method to address interior style design classification, named ISC-DeIT. The proposed method is based on Data-efficient image transformer architectures and knowledge distillation, which can be trained on small datasets effectively. Especially, a proposed additional module is plugged to leverage learning feature representations for improving predictive accuracy. Experiments were carried out on a new curated dataset with five interior styles including Art-Decor, Hitech, Indochina, Industrial, and Scandinavian. Empirical results of ISC- DeiT indicated that the ability of prediction for interior style classification of the proposed method has been increased significantly, compared with other state-of-the-art methods.","Identifying client needs to provide optimal services is crucial in tourist destination management. The events held in tourist destinations may help to meet those needs and thus contribute to tourist satisfaction. As with product management, the creation of hierarchical catalogs to classify those events can aid event management. The events that can be found on the internet are listed in dispersed, heterogeneous sources, which makes direct classification a difficult, time-consuming task. The main aim of this work is to create a novel process for automatically classifying an eclectic variety of tourist events using a hierarchical taxonomy, which can be applied to support tourist destination management. Leveraging data science methods such as CRISP-DM, supervised machine learning, and natural language processing techniques, the automatic classification process proposed here allows the creation of a normalized catalog across very different geographical regions. Therefore, we can build catalogs with consistent filters, allowing users to find events regardless of the event categories assigned at source, if any. This is very valuable for companies that offer this kind of information across multiple regions, such as airlines, travel agencies or hotel chains. Ultimately, this tool has the potential to revolutionize the way companies and end users interact with tourist events information.\nGraphical Abstract\nDisplay Omitted\nHighlights\n\u2022\nComputational techniques are used to classify tourism destination events.\n\u2022\nA Large Language Model (BERT) is used to get vectorial representations of events.\n\u2022\nA method to automatically classify events is proposed to easy the adoption of standards.\n\u2022\nThere is great scope for extending this methodology to other applications.","Objective: The objective is to develop a predictive model utilizing Support Vector Machines (SVM) for the purpose of classifying the clinical stage of breast cancer.\nMaterials and Methods: Accurate determination of the clinical stage of breast cancer patients holds significant importance in selecting suitable treatment options and minimizing avoidable complications. In this study, we present the application of radiomics and SVM for breast cancer computed tomography (CT) to anticipate the preoperative clinical stage in breast cancer patients. The training dataset encompasses 166 cases obtained from the Affiliated Hospital of Xiangnan University, while the test dataset comprises 91 cases from Chenzhou Third People's Hospital. The integration of clinical parameters with radiomics exhibits the most superior diagnostic efficacy in forecasting the clinical stage of breast cancer. As part of the evaluation, various metrics were calculated, including the area under the curve (AUC), the accuracy (ACC), sensitivity (Sen), specificity (Spe), positive predictive value (PPV) and negative predictive value (NPV). To differentiate between the radiomics model, clinical data model, and fusion model, the Delong test was utilized. The precision of the prediction model was evaluated by generating a calibration curve using 1,000 bootstrap weight samples. Furthermore, the decision curve analysis (DCA) was conducted to assess the model's practicality.\nResults: The fusion model exhibits superior predictive performance compared to both the single radiomics model and clinical model. The fusion model's test sets of AUC, ACC, Sen, Spe, PPV, and NPV are 0.824, 0.780, 0.932, 0.652, 0.707, and 0.909, respectively.\nConclusion: The fusion model exhibits greater efficacy than both the single radiomics model and clinical model, and thus holds significant potential for facilitating the diagnosis of breast cancer stage and the development of individualized treatment plans.CCS","Surface electromyography (sEMG) signal is essential for accurately controlling prosthetic devices with numerous degrees of freedom in human-machine interfaces for robotics and assistive technologies. The controlling method of the upper-limb prosthesis device depends on electromyogram (EMG) pattern recognition, which requires the efficient blending of conventional signal processing and machine learning. This paper focuses on stacked ensemble models, one of the popular methods for reducing generalization error. The proposed work uses a dataset of sEMG signals from different upper-limb positions in subjects. The raw signals are transformed into correlated time-domain descriptors (cTDD) for feature extraction, which are then used to train the stacked ensemble framework. The framework includes four base classifiers (support vector machine (SVM), K-nearest neighbours (KNN), logistic regression (LR), and decision tree (DT)) and two meta-classifiers (random forest (RF) and multi-layer perceptrons (MLP). The performance of the meta-classifiers is evaluated on two test sets, showing superior classification accuracy compared to the basic classifiers. The proposed approach demonstrates the capability to accurately classify limb position invariant EMG signal classification for prosthetic device control.","Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose Crash-Former, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8% in F1-score on average when using \"sparse\" input data.","Automatic classifier accuracy evaluation (ACAEval) on unlabeled test sets is critical for unseen real-world environments. The use of dataset-level regression on synthesized meta-datasets (comprised of many sample sets) has shown promising results for ACAEval. However, the existing meta-dataset for ACAEval is created using simple image transformations such as rotation and background substitution, which can make it difficult to ensure a reasonable distribution shift between the sample set and the test set. When the distribution shift is large, it becomes challenging to estimate the classifier accuracy on the test set using those sample sets. To ensure more robust ACAEval, this paper attempts to customize a meta-dataset in which each sample set has a reasonable distribution shift to the test set. An intra-class cycle-consistent adversarial learning (ICAL) method is introduced to transfer the style of a labeled training set to the style of the test set, by jointly considering the domain shift issue, the label flipping issue (the semantic information may be changed after style transformation), and the diversity of multiple sample sets in the meta-dataset. Experiments validate that under the same experimental setup, our method outperforms the existing ACAEval methods by a good margin, and achieves state-of-the-art performance on several standard benchmark datasets, including digit classification and natural image classification.\nHighlights\n\u2022\nTwo authors named Yan Huang in pinyin, one PostDoc (1st author), the other an Associate Prof (3rd author).\n\u2022\nPaper on ACAEval for classifier accuracy. Uses meta-dataset technique for unlabeled real-world data.\n\u2022\nCustomized meta-dataset for ACAEval to address distribution shift between samples and test set.\n\u2022\nOur sample set considers label flip issue. Introduces random indicator and FD margin loss.\n\u2022\nExperiments demonstrate our ACAEval matches existing methods and surpasses dataset-level regression.","Brain tumors can be generated anywhere in the brain, with an extensive size range and morphology that makes it challenging to identify and classify. Classifying brain tumors is essential for developing personalized treatment plans. Different types of brain tumors have different responses to treatment, and an accurate classification can help medical professionals develop treatment plans tailored to each patient\u2019s needs. Therefore, this case study aimed to classify T1-weighted contrast-enhanced images of three types of tumors through various approaches, from shallow neural networks to fine-tuning deep neural networks trained. Comparing shallow and deep neural network approaches could help to understand the trade-offs between their performance, interoperability, interpretability, benefits, limitations, scopes, and overall, choosing the best method for a given problem.","One of the major difficulties in face recognition while comparing photographs of individuals of different ages is the influence of age progression on their facial features. As a person ages, the face undergoes many changes, such as geometrical changes, changes in facial hair, and the presence of glasses, among others. Although biometric markers like computed face feature vectors should ideally remain unchanged by such factors, face recognition becomes less reliable as the age range increases. Therefore, this investigation was carried out to examine how the use of Embedded Prototype Subspace Classifiers could improve face recognition accuracy when dealing with age-related variations using face feature vectors only.","In many practical binary classification applications, such as financial fraud detection or medical diagnosis, it is crucial to optimize a model's performance on high-confidence samples whose scores are higher than a specific threshold, which is calculated by a given false positive rate according to practical requirements. However, the proportion of high-confidence samples is typically extremely small, especially in long-tailed datasets, which can lead to poor recall results and an alignment bias between realistic goals and loss. To address this challenge, we propose a novel loss reweighting framework called Momentum Threshold-Oriented Loss (MTOL) for binary classification tasks and propose two instantiated losses of it. Given a limited FPR range, MTOL aims to improve the recall of binary classification models at that FPR range by incorporating a batch memory queue and momentum estimation mechanisms. The MTOL adaptively estimates thresholds of FPR during the model training iterations and up-weights the loss of samples in the threshold range, with little consumption of storage and computation. Our experimental results on various datasets, including CIFAR-10, CIFAR-100, Tiny-ImageNet, demonstrate the significant effect of MTOL in improving the recall at low FPR especially in class imbalance settings. These results suggest that MTOL is a promising approach in scenarios where the model's performance in the low FPR range is of utmost importance.","In the era of digital information, ensuring the accuracy and reliability of information is crucial, making fact-checking a vital process. Currently, English fact-checking has thrived due to various language processing tools and ample datasets. However, the same cannot be said for Vietnamese fact-checking, which faces significant challenges due to the lack of such resources. To address these challenges, we propose a model for checking Vietnamese facts by synthesizing three popular technologies: Knowledge Graph (KG), Datalog, and KG-BERT. The KG serves as the foundation for the fact-checking process, containing a dataset of Vietnamese information. Datalog, a logical programming language, is used with inference rules to complete the knowledge within the Vietnamese KG. KG-BERT, a Deep Learning (DL) model, is then trained on this KG to rapidly and accurately classify information that needs fact-checking. Furthermore, to put Vietnamese complex sentences into the fact-checking model, we present a solution for extracting triples from these sentences. This approach also contributes significantly to the ease of constructing foundational datasets for the Vietnamese KG. To evaluate the model's performance, we create a Vietnamese dataset comprising 130,190 samples to populate the KG. Using Datalog, we enrich this graph with additional knowledge. The KG is then utilized to train the KG-BERT model, achieving an impressive accuracy of 95%. Our proposed solution shows great promise for fact-checking Vietnamese information and has the potential to contribute to the development of fact-checking tools and techniques for other languages. Overall, this research makes a significant contribution to the field of data science by providing an accurate solution for fact-checking information in Vietnamese language contexts.","As a fast and inexpensive machining method applicable for creating a wide range of shapes and producing large batches, sheet metal punching is widely used e.g., in automotive, aerospace, electronics, and construction industries. A significant downside of sheet metal punching is the punching tool wear in use. A worn punch tool may impact the quality of the end product by causing imperfections and reduce the efficiency of the manufacturing process through increased scrap and by slowing down the production. Effective monitoring of punching tool wear is therefore essential for an efficient and cost-effective production of high-quality parts. The monitoring can be based on acceleration measurement which produces large amounts of raw data, making edge processing ideal as only the indication of the tool condition needs to be sent forward for decision support. Classification models for tool wear identification were built and compared in this study. The models are based on measured acceleration data. Two different open-source methods for time series feature extraction, namely TSFEL and MiniRocket, were tested and the classification results based on them compared. All methods used for building the models are computationally light and therefore applicable for real-time data processing at the edge. According to the results the MiniRocket algorithm is suitable for the task and superior compared to the TSFEL method. The classification accuracies based on the MiniRocket features are at best over 96.5 % and at worst around 84 %, whereas the corresponding accuracies are between 35 and 56 % for TSFEL feature based models. The use of the MiniRocket algorithm in building a model for punch tool monitoring shows very promising results. However, the dataset used was very limited. Therefore, further investigation is required based on an ampler dataset.","The Healthcare Analytics(HcA) is a process in which clinical data is analyzed and patient\u2019s treatment is performed. The treatment depends on the analysis of clinical data accumulated from Electronic Health Records (EHRs), pharmaceutical and research and development cost and claims of patient. Lung cancer is the most common among cancer disease and the foremost reason for deaths in both men and women. In this research work EHRs are analyzed and the survivability rate is predicted for lung cancer. Researchers apply Machine Learning Techniques (MLT)for predicting the survivability rate so that chemotherapy can be provided for cancer affected people. MLTare well accepted by doctors and work well in diagnosing and predicting cancer. An ensemble of Support Vector Machine (SVM), Naive Bayes (NBs)and classification trees (C4.5) can be used to evaluate patterns that are risk factors for lung cancer study. The North Central Cancer Treatment Group (NCCTG) lung cancer data set along with new patient data is used for evaluating the performance of support SVM, NBs and C4.5. The comparison isbased on accuracy, Area Under the Curve(AUC), Receiver Operating Characteristic (ROC) and the resultshows that C4.5 performs better in predicting lung cancer with the increase in training data set.","Deciding the signal length is an important challenge for one-class time-series classification (OCTSC). This paper aims to develop an OCTSC algorithm that does not require model retraining for different signal lengths. For this purpose, a distance-based one-class time-series classification approach using local cluster balance (OCLCB) is proposed. OCLCB extracts feature vectors, namely, local cluster balance (LCB), from the clustering results of sliding windows. K-means clustering is applied to the sliding windows extracted from the training signal. Then, the local prototype (LP) is calculated as the average of the local cluster balance (LCB) in the training data. Unseen scores are computed as the distance metrics between LP and LCBs in the testing data. Since the sliding window size is independent of the entire signal size, OCLCB does not need to retrain the model. This aspect gives the benefit of reducing the parameter tuning costs. The source code is uploaded at https://github.com/ToshiHayashi/OCLCB.","Data classification is an important and challenging issue encountered in many practical applications. The classifier based on Evidential Reasoning Rule (ER Rule) can well handle the uncertainty in classification and obtain competitive accuracy. However, there are many parameters to be optimized, and the computation cost of the usually adopted optimization strategy is relatively high. This fact weakens the application advantage of ER Rule classifier. To address this challenge, an asynchronous optimization approach is proposed. In the original ER Rule classifier, feature referential values and evidence weights are optimized synchronously; while in the proposed method, these two types of parameters are optimized separately based on their essential impacts on the classification results. For the optimization of feature referential values, the objective function measures the quality of belief matrix, which is the critical strategy to improve the computational efficiency. Three types of feasible objective functions are constructed. After obtaining optimal referential values, evidence weights are optimized based on the actual classification effect, and the required iterations decrease. Various experiments on 14 publicly available datasets verify the computational efficiency and classification performance of the proposed method.\nHighlights\n\u2022\nThe low computational efficiency of ER Rule-based classifier is addressed by optimizing its parameters asynchronously.\n\u2022\nThe objective function of feature referential values optimization measures the quality of belief matrix.\n\u2022\nThe effectiveness of the proposed method is validated by theoretical analysis and various experiments.","In industrial settings, it is often necessary to achieve language-level accuracy targets. For example, Amazon business teams need to build multilingual product classifiers that operate accurately in all European languages. It is unacceptable for the accuracy of product classification to meet the target in one language (e.g, English), while falling below the target in other languages (e.g, Portuguese). To fix such issues, we propose Language Aware Active Learning for Multilingual Models (LAMM), an active learning strategy that enables a classifier to learn from a small amount of labeled data in a targeted manner to improve the accuracy of Low-resource languages (LRLs) with limited amounts of data for model training. Our empirical results on two open-source datasets and two proprietary product classification datasets demonstrate that LAMM is able to improve the LRL performance by 4%--11% when compared to strong baselines.","The trade-off between privacy and accuracy presents a challenge for current federated learning (FL) frameworks, hindering their progress from theory to application. The main issues with existing FL frameworks stem from a lack of interpretability and targeted privacy protections. To cope with these, we proposed Disentangled Federated Learning for Privacy (DFLP) which employes disentanglement, one of interpretability techniques, in private FL frameworks. Since sensitive properties are client-specific in nature, our main idea is to turn this feature into a tool that strikes the balance between data privacy and FL model performance, enabling the sensitive attributes to be private. DFLP disentangles the client-specific and class-invariant attributes to mask the sensitive attributes precisely. To our knowledge, this is the first work that successfully integrates disentanglement and the nature of sensitive attributes to achieve privacy protection while ensuring high FL model performance. Extensive experiments validate that disentanglement is an effective method for accuracy-aware privacy protection in FL frameworks.","Drug repurposing, which involves using already approved drugs for new clinical targets, represents a cost-effective alternative to the development of new drugs. In this study, we introduce an innovative computational strategy, which uses Non-negative Matrix Tri-Factorization (NMTF) to generate vector embeddings of given sizes for drugs and drug targets; vector embeddings are then employed to generate predictions for drug repurposing using conventional classifiers, like random forest, logistic regression, and multi-layer perceptron.\nOur approach leverages the NMTF method within a new approach to classification, named two-tower architecture, which is effective in solving complex tasks, such as the optimal prediction of targets for already approved drugs. This approach produces robust models, with AUROC reaching 0.90, which outperform traditional NMTF. We evaluate our method in the context of Parkinson\u2019s Disease; within the newly revealed drug-target predictions, we highlight compounds that exhibit potential in mitigating neurodegeneration, thereby revealing a potentially useful drug in relationships with a well-identified target.","This paper proposes a multi-domain sample classification method based on Baidu API's general object recognition function. we used three datasets in the experiment,including CIFAR-10, CIFAR-100, and Mini-ImageNet. For an unknown sample belonging to these three datasets, we first predict which domain it may belong to by using the output results of Baidu API, and then obtain the label of the sample by training a model on that domain. Compared with existing methods, our method reduces the number of high-performance models that need to be trained and reduces the computational difficulty. Experimental results show that our method is more convenient and accurate.","The fields of energy storage, photocatalysis, and sensors have undergone substantial technological advancements, which have led to the generation of vast amounts of data on electrochemical impedance (EIS). The interpretation of large amounts of EIS data is a challenging task since the analysis of EIS data requires multiple steps to get a suitable equivalent circuit. Recently, some progress has been made in the machine learning (ML) model for EIS classification. However, most of the ML models are performed as a \u201cblack box\u201d model, which provides only the classification result and lacks physical descriptor representation. Here, we apply variational autoencoders (VAE) to EIS data analysis, which includes classification, parameter prediction, and the visualization of physical descriptors. The VAE model performed well in the classification task, with an accuracy of 82.0%\u201392.4%. In the prediction task, VAE shows a high R-squared value on the Randles circuit. Additionally, the VAE model can map physical descriptors to the latent space, allowing the latent space to transform into a property space, which plays an important role in the optimization and exploration of novel materials research.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nAutomatically analyze the EIS spectrum.\n\u2022\nVAE model design for classification and regression.\n\u2022\nThe high accuracy classifier of the EIS circuit model with accuracy of 82.0%\u201392.4%.\n\u2022\nThe use of VAE model for the exploration and visualization of EIS dataset.","Network modeling has proven to be an efficient tool for many interdisciplinary areas, including social, biological, transportation, and various other complex real-world systems. In addition, cellular automata (CA) are a formalism that has received significant attention in recent decades as a model for investigating patterns in the dynamic spatio-temporal behavior of these systems, based on local rules. Some studies investigate the use of cellular automata to analyze the dynamic behavior of networks and refer to them as network automata (NA). Recently, it has been demonstrated that NA is effective for network classification, as it employs a Time-Evolution Pattern (TEP) for feature extraction. However, the TEPs investigated in previous studies consist of binary values (states) that do not capture the intrinsic details of the analyzed network. Therefore, in this work, we propose alternative sources of information that can be used as descriptors for the classification task, which we refer as Density Time-Evolution Pattern (D-TEP) and State Density Time-Evolution Pattern (SD-TEP). We examine the density of alive neighbors of each node, which is a continuous value, and compute feature vectors based on histograms of TEPs. Our results demonstrate significant improvement over previous studies on five synthetic network datasets, as well as seven real datasets. Our proposed method is not only a promising approach for pattern recognition in networks, but also shows considerable potential for other types of data that can be transformed into network.\nHighlights\n\u2022\nA Network Classification Method based on network automata is proposed.\n\u2022\nConway\u2019s life cellular automata are used as Network Automata model.\n\u2022\nTime Evolution Patterns Extracted from Network Automata represents the networks.\n\u2022\nResults on real-world and synthetic networks outperforms previous methods.","Abstract. In the past decade, deep learning based methods have taken a dominant position in natural language processing (NLP). For almost all NLP tasks, deep learning based methods far surpassed traditional methods. Especially in the past five years, the development of deep learning methods has been particularly rapid. For example, the pre-training and fine-tuning paradigms represented by BERT have dominated the NLP field, while also driving the development of other fields such as computer vision. Nowadays pre-trained large language models (LLMs) such as GPT-3/ChatGPT further demonstrate the advantages of Transformer based deep learning methods, which can achieve good results across various problems without any specialized training. In spite of the remarkable success, their performances still underperform fine-tuned models in the task of text classification in some scenarios. Nevertheless, the LLMs are good generalist models. The goal we pursue is the deep learning methods with good generalization ability. In the case of limited computing resources and high performance requirements, the fine-tuned models remain the first choice. So how is the generalization ability of the fine-tuned models? In this paper, we explore the generalization of representative Chinese text classification methods based on deep learning. The experimental results indicate that Transformer based methods present good ability of generalization on two significant different Chinese datasets. In the current era of LLMs, this work can assist us in choosing more appropriate solutions for natural language processing tasks.","One important aspect of human behavior understanding is the recognition and monitoring of daily activities. An accurate activity recognition system can improve the quality of life in many key areas. The multi-metric feature extraction and DeepForest classifier designed in this paper effectively had solved the problems of incomprehensive feature extraction and insufficient classifier accuracy.\nFirst, this paper extracts a total of 450 dimensional feature vectors using mean, variance, maximum, skewness, minimum, kurtosis, regression of independent variables and sample entropy as feature indicators, so that the features of the original vectors can be presented comprehensively. The dimensionality of the feature set is too large, so PCA is used to reduce the dimensionality of the high-dimensional feature vector. After studying the relationship between the dimensionality reduction and the cumulative contribution rate, it is concluded that the cumulative contribution rate reaches 90% when the dimensionality is 15, which can retain the original features better. Then DeepForest was used as the classifier, and the reduced-dimensional feature set was used as the sample set to divide the training set and test set by 3:1. The model was tested on the test set after training, and the classification accuracy of the test set was 98.202%. Six classifiers, GaussianNB, SVM, K-NN, XGBoost, RandomForest and DecisionTree, were selected as the control experimental group, of which only the RandomForest model reached 97%, while the rest of the control models did not achieve 95% effect, indicating that DeepForest was more accurate in classifying human activities.\nNext, the generalisation ability of the DeepForest classifier was assessed using Monte Carlo Cross Validation (MCCV), K-fold and its confusion matrix. The MCCV validation used 50% of the data as the training set and 30% of the data as the test set, and set the number of splits to 10, resulting in a mean accuracy of 98.227%. The size of K in the K-fold validation was determined to be 8 based on the number of people conducting the human activity experiment, and the final mean accuracy value obtained was 97.790%. The combined confusion matrix from the K-fold validation (which aggregates the confusion matrix for each classification result) was calculated, and the results showed that the highest accuracy reached 100% for A9 and A14 classifications, where A5 and A10, A15 and A10, A12 and A5 were more likely to be confused, with the highest error rate for A5 classification, which was 4.167%, and the rest of the activity classifications were better.","Advancements in the rapidly evolving specialization of deep learning have aided in improving several natural language understanding tasks. Sentiment and emotion classification models have improved, but when it comes to fine-grained sentiment analysis, these models can perform better. Human sentiment in natural language is generally an intricate combination of emotions, which can sometimes be indeterminate, neutral, or ambiguous. In the case of fine-grained sentiment analysis, the sentiments can be very similar to each other and interconnected, e.g., anger and fear. Most deep learning systems try to solve the problem of fine-grained sentiment analysis as a classification problem. However, fine-grained sentiments might combine similar emotions with one primary emotion. Trying to solve the problem as a classification task can result in better performance on benchmarks but does not ensure a better understanding and representation of language. The proposed work explores applying neutrosophy for fine-grained sentiment analysis using large language models. Neutrosophy identifies neutralities and employs membership functions (neutral, positive, negative) to quantify an instance into Single Valued Neutrosophic Sets (SVNS). This paper introduces Refined Emotion Neutrosophic Sets (RENS) for emotions (with four emotions) and Refined Ekman\u2019s Emotion Neutrosophic Sets (REENS) with seven emotions. In this paper, refined neutrosophic sets with membership functions are employed for each sentiment across a given taxonomy and assigned their values using the Neutrosophic Iterative Neural Clustering (NINC) algorithm proposed in this paper. It facilitates not only classifying sentiments but also quantifying the presence of each sentiment present in a given sample. It aids in better understanding and representation of samples across multiple sentiments, as in fine-grained sentiment analysis, experiments are performed on the GoEmotions dataset. The proposed approach performs on par with cross-entropy deep learning classifiers and is reproducible across different pre-trained language models.\nHighlights\n\u2022\nRefined neutrosophic sets for fine-grained sentiment analysis.\n\u2022\nUsing classification models as powerful feature learners.\n\u2022\nNeutrosophic iterative neural clustering for feature segregation.\n\u2022\nExperimental analysis using BERT, MPNet, RoBERTa, ELECTRA and XLNet.\n\u2022\nNeutrosophic logic for sentiment representation and quantification.","Accurate classification of magnetic resonance imaging (MRI) images of brain tumors is crucial for early diagnosis and effective treatment in clinical studies. In these studies, many models supported by artificial intelligence (AI) have been proposed as assistant systems for experts. In particular, state-of-the-art deep learning (DL) models that have proven themselves in different fields have been effectively used in the classification of brain MRI images. However, the low accuracy of multiple classification of these images still leads researchers to conduct different studies in this field. Especially there is a need to develop models that achieve high accuracy on original images, and it is believed that this need can be met not only by DL models but also by classical machine learning (ML) algorithms. However, it is critical to choose the hyperparameters correctly for the hybrid use of ML algorithms with DL models. This study proposes a powerful new hybrid method to perform multiple classifications of brain tumors with high accuracy. This method also uses a novel convolutional neural network (CNN) model for feature extraction, and ML algorithms are used for feature classification. In addition, nine state-of-the-art CNN models are used for CNN performance comparison. The Bayesian optimization algorithm is used to obtain the optimal hyperparameter values of ML algorithms. The results obtained from the experimental studies show that the proposed hybrid model achieved 97.15% mean classification accuracy and 97% recall, precision, and F1-score values. Other hybrid models, including DarkNet19-SVM, DarkNet53-SVM, DenseNet201-SVM, EfficientNetB0-SVM, InceptionV3-SVM, NasNetMobile-SVM, ResNet50-SVM, ResNet101-SVM, and Xception-SVM, achieved mean classification accuracies of 95.01%, 95.58%, 96.87%, 97.01%, 95.3%, 95.01%, 96.3%, 95.87%, and 96.23%, respectively. Additionally, the proposed hybrid model exhibited remarkable time efficiency, accomplishing the classification process in a mere 67 min. Conversely, the model that exhibited the lowest time efficiency was the InceptionV3, with a processing time of 370 min. In terms of computational complexity, the EfficientNetB0 model is the most efficient. Despite the higher computational complexity of the proposed CNN model compared to some other models, it achieves the second-best classification accuracy. These results show that the proposed method performs better than previous studies on the same dataset. Especially in the classification problem, the optimized ML algorithms were superior to CNN classifiers. Finally, except for one, the proposed CNN model achieved better classification accuracies than the state-of-the-art CNN models.","Artificial Intelligence (AI) classifier models based on Deep Neural Networks (DNN) have demonstrated superior performance in medical diagnostics. However, DNN models are regarded as \u201cblack boxes\u201d as they are not intrinsically interpretable and, thus, are reluctantly considered for deployment in healthcare and other safety-critical domains. In such domains explainability is considered a fundamental requisite to foster trust and acceptability of automatic decision-making processes based on data-driven machine learning models. To overcome this limitation, DNN models require additional and careful post-processing analysis and evaluation to generate suitable explainability of their predictions. This paper analyses a DNN model developed for predicting Alzheimer\u2019s Disease to generate and assess explainability analysis of the predictions based on feature importance scores computed using sensitivity analysis techniques. In this study, a high dimensional dataset was obtained from Magnetic Resonance Imaging of the brain for healthy subjects and for Alzheimer\u2019s Disease patients. The dataset was annotated with two labels, Alzheimer\u2019s Disease (AD) and Cognitively Normal (CN), which were used to build and test a DNN model for binary classification. Three Global Sensitivity Analysis (G-SA) methodologies (Sobol, Morris, and FAST) as well as the SHapley Additive exPlanations (SHAP) were used to compute feature importance scores. The results from these methods were evaluated for their usefulness to explain the classification behaviour of the DNN model. The feature importance scores from sensitivity analysis methods were assessed and combined based on similarity for robustness. The results indicated that features related to specific brain regions (e.g., the hippocampal sub-regions, the temporal horn of the lateral ventricle) can be considered very important in predicting Alzheimer\u2019s Disease. The findings are consistent with earlier results from the relevant specialised literature on Alzheimer\u2019s Disease. The proposed explainability approach can facilitate the adoption of black-box classifiers, such as DNN, in medical and other application domains.","Current person re-identification (ReID) methods heavily rely on well-annotated training data, and their performance suffers from significant degradation in the presence of noisy labels that are ubiquitous in real-life scenes. The reason is that noisy labels not only affect the prediction results of the classifier, but also impede feature refinement, making it difficult to distinguish between different person features. To address these issues, we propose an Adaptive Self-correction Classification (ASC) loss and an Adaptive Margin Self-correction Triplet (AMSTri) loss. Specifically, ASC loss helps the network to produce better predictions by balancing annotations and prediction labels, and pays more attention to the minority samples with the help of a focusing factor. On the other hand, the AMSTri loss introduces an adaptive margin that varies with sample features to accommodate complex data variations, and utilizes predicted labels to generate reliable triples for feature refinement. We then present an end-to-end adaptive self-correction joint training framework incorporating ASC loss and AMSTri loss to achieve a robust ReID model. Our comprehensive experiments demonstrate that the proposed framework outperforms most existing counterparts.","Aspect category sentiment analysis (ACSA) excels at identifying the aspect categories and corresponding sentiments involved in a sentence, regardless of whether the aspect terms are explicitly mentioned or not. However, current methods tend to overinflate the original data, resulting in the introduction of unnecessary information, and fail to capture the inter-task relationship sufficiently. This paper presents a new method termed the prompt-based joint model (PBJM) to address these complications. PBJM treats the sentiment polarity prediction as binary classification and leverages a natural language prompt template, a concise sentence that guides the model to perform aspect category identification subtask and curtails the need for data augmentation. The two subtasks are jointly trained in pre-trained language models (PLMs) to capture their correlation. Further, the attention mechanism for aspect categories enables the model to concentrate selectively on significant features such as phrases and words during the predictions. In addition, the verbalizer employs a set of parameters to balance the weight of each label word while projecting between the label space and the label words space. Through experiments on four datasets, our model demonstrated remarkable performance in detecting category-sentiment pairs.","Forecasting retail sales often requires various number of products from different stores. Existing deep or machine learning techniques fall short of producing accurate classification results because of overfitting and two-class problem that affects the performance of evaluation parameters like precision, recall, accuracy and F-measure. Hence there is a need for an efficient prediction framework that addresses the existing problems. This work proposes an efficient framework for predicting retail sales using an ensemble DNN-BiLSTM framework. We suggest creating a base forecaster pool that includes both individual and pooled forecasting techniques for developing this ensemble approach to forecasting retail sales. Instead of focusing on finding the best individual technique, we suggest finding the optimal combination of forecasts. Classification Accuracy, Precision, Recall, and F-measure performance metrics of the experiment utilizing the proposed ensemble approach DNN\u2009+\u2009BiLSTM surpass the current DNN, CNN, and LSTM classifiers by 98.3%, 98.1%, 97.8%, and 97.94%, respectively.","In recent years, the increasing use of online surveys for course evaluation in schools has led to an outpouring of evaluation texts. These texts, with their emotional polarity, can give schools the most direct feedback. Emotional analysis on course evaluation, therefore, has great implications. However, the not-so-rigid text grammar and rich text content pose a challenge for sentiment analysis in Chinese course evaluation. To solve this problem, this paper proposes a sentiment classification model BiLSTM-GCN-Att (BGAN). Here, BiLSTM is used to extract the features of the text and output the hidden state vector. Then, the deep biaffine attention mechanism is used to analyze the dependence of the text and generate a dependency matrix. Next, input the hidden state vector to the GCN. Finally, the softmax function is used as the output layer of the model to perform sentiment classification. The model proves effective and experimental results, showing that the BGAN achieved a maximum improvement of 11.02% and 14.47% in precision and F1-score respectively compared with the classical models.","While there have been extensive studies in the health assessment of the bearings using the vibration signal, most have focused on the constant operating conditions. The field, however, operates often under time-varying conditions as is the case of the automotive wheel bearing. In this study, a novel health indicator (HI) is proposed to address this problem based on the Isolation Forest algorithm, which was originally developed for anomaly detection. The method is advantageous in two aspects: the HI is not influenced by the type of operating conditions whether it is constant or time-varying. Only the data under normal condition are used to construct the HI without the need of run-to-failure data. The method is demonstrated by the three cases with different types of bearing and operating conditions ranging from constant to the highly variable conditions. As a result, monotonic trends are obtained for the HI in all cases, which may be useful for the prognostic monitoring. Furthermore, in comparison with the HI constructed by the run-to-failure data in the previous literature, it is found that the trends of HI agree reasonably well with each other, which supports the validity of the method.","A sequential learning framework for text categorization based on Meta-cognitive Neural Network (McNN) is presented in this paper. Initially text documents are pre-processed and represented in the form of Term Document Matrix (TDM). Since the TDM is of high dimension, to reduce it to lower dimension Regularized Locality Preserving Indexing (RLPI) is used. Further, to categorize the text document, Meta-cognitive Neural Network (McNN) classifier is employed. To measure the effectiveness of the proposed framework, various experiments are conducted on standard benchmark Reuters-21578 dataset and used leave one out cross validation technique to assess the performance. The proposed framework performance is investigated against two well known neural network based classifiers: MLP (Multi Layer Perceptron) and RBF-NN (Radial Basis Function-Neural Network). The experimental results reveals that the McNN classifier uses less number of training documents for learning and it has less true error rate than other two neural network classifiers.","Classifying ancient manuscripts based on their writing surfaces often becomes essential for palaeographic research, including writer identification, manuscript localization, date estimation, and, occasionally, forgery detection. Researchers continually perform corroborative tests to classify manuscripts based on physical materials. However, these tests, often performed on-site, require actual access to the manuscript objects. These procedures involve specific expertise in manuscript handling, a considerable amount of time, and cost. Additionally, any physical inspection can accidentally damage ancient manuscripts that already suffer degradation due to aging, natural corrosion, and damaging chemical treatments. Developing a technique to classify such documents using noninvasive techniques with only digital images can be extremely valuable and efficient. This study uses images from a famous historical collection, the Dead Sea Scrolls, to propose a novel method to classify the materials of the manuscripts. The proposed classifier uses the two-dimensional Fourier transform to identify patterns within the manuscript surfaces. Combining a binary classification system employing the transform with a majority voting process is adequate for this classification task. This initial study shows a classification percentage of up to 97% for a confined amount of manuscripts produced from either parchment or papyrus material. In the extended work, this study proposes a hierarchical k-means clustering method to group image fragments that are highly likely to originate from a similar source using color and texture features calculated on the image patches, achieving 77% and 68% for color and texture clustering with 100% accuracy on primary material classification. Finally, this study explores a convolutional neural network model in a self-supervised Siamese setup with a large number of images that obtains an accuracy of 85% on the pretext task and an accuracy of 66% on the goal task to classify the materials of the Dead Sea Scrolls images.","A startup is a recently established business venture led by entrepreneurs, to create and offer new products or services. The discovery of promising startups is a challenging task for creditors, policymakers, and investors. Therefore, the startup survival rate prediction is required to be developed for the success/failure of startup companies. In this paper, the feature selection using the Convex Least Angle Regression Least Absolute Shrinkage and Selection Operator (CLAR-LASSO) is proposed to improve the classification of startup survival rate prediction. The Swish Activation Function based Long Short-Term Memory (SAFLSTM) is developed for classifying the survival rate of startups. Further, the Local Interpretable Model-agnostic Explanations (LIME) model interprets the predicted classification to the user. Existing research such as Hyper Parameter Tuning (HPT)-Logistic regression, HPT-Support Vector Machine (SVM), HPT-XGBoost, and SAFLSTM are used to compare the CLAR-LASSO. The accuracy of the CLAR-LASSO is 95.67% which is high when compared to the HPT-Logistic regression, HPT-SVM, HPT-XGBoost, and SAFLSTM.","Semi-supervised learning (SSL) is a successful paradigm that can use unlabelled data to alleviate the labelling cost problem in supervised learning. However, the excellent performance brought by SSL does not transfer well to the task of class imbalance. The reason is that the class bias of pseudo-labelling further misleads the decision boundary. To solve this problem, we propose a new plug-and-play approach to handle the class imbalance problem based on a theoretical extension and analysis of distribution alignment. The method, called Basis Transformation Based Distribution Alignment (BTDA), efficiently aligns class distributions while taking into account inter-class relationships.BTDA implements the basis transformation through a learnable transfer matrix, thereby reducing the performance loss caused by pseudo-labelling biases. Extensive experiments show that our proposed BTDA approach can significantly improve performance in class imbalance tasks in terms of both accuracy and recall metrics when integrated with advanced SSL algorithms. Although the idea of BTDA is not complex, it can show advanced performance on datasets such as CIFAR and SVHN.","In recent years, the interpretive this looks like that structure has gained significant attention. It refers to the human tendency to break down images into key parts and make classification decisions by comparing them to pre-existing concepts in their minds. However, most existing prototypical-based models assign prototypes directly to each category without considering that key parts with the same meaning may appear in images from different categories. To address this issue, we propose dividing prototypes with the same meaning into the same latent space (referred to as Basic Feature Domain) since different category parts only slightly affect the corresponding prototype vectors. This process of integrating prototypes based on the feature domain is referred to as prototype alignment. Additionally, we introduce the concept of part-aware optimization, which prioritizes prototypical parts of images over simple category labels during optimizing prototypes. Moreover, we present two feature aggregation methods, by row and by cluster, for the basic feature domain. We demonstrate competitive results compared to other state-of-the-art prototypical part methods on the CUB-2011-200 dataset and Stanford Cars dataset using our proposed self-explanatory part-aware proto-aligned network (PaProtoPNet).","We introduce Robust Training with Trust Scores (RT2S), a framework to train machine learning classifiers with potentially noisy labels. RT2S calculates a trust score for each training sample, which indicates the quality of its corresponding label. These trust scores are employed as sample weights during training and optionally during threshold optimization. The trust scores are generated from two sources: (i) the model's confidence in the observed label, leveraging out-of-fold prediction scores to detect anomalous labels in the training data, and (ii) the probability of the correct label, ascertained by a Large Language Model with the ability to identify biased label noise. We evaluate RT2S by training machine learning models on 6 product classification datasets that utilize low-quality labels generated by a rule-based classification engine acting as a surrogate labeler. Our experimental findings indicate that RT2S outperforms all baselines, and achieves an average accuracy improvement of 4.38% (max 7.18%) over rule-based classifiers in particular.","Highlights\n\u2022\nPropose an improved random forest based on the improvement of decision trees.\n\u2022\nImprove the evaluation mechanism for the classification effect of decision trees.\n\u2022\nPropose a method for quantifying the diversity between decision trees.\n\u2022\nMultiple tests verify the superiority of the proposed improved random forest.\nAbstract\nRandom forest is one of the most widely used machine learning algorithms. Decision trees used to construct the random forest may have low classification accuracies or high correlations, which affects the comprehensive performance of the random forest. Aiming at these problems, the authors proposed an improved random forest based on the classification accuracy and correlation measurement of decision trees in this paper. Its main idea includes two parts, one is retaining the classification and regression trees (CARTs) with better classification effects, the other is reducing the correlations between the CARTs. Specifically, in the classification effect evaluation part, each CART was applied to make predictions on three reserved data sets, then the average classification accuracies were achieved, respectively. Thus, all the CARTs were sorted in descending order according to their achieved average classification accuracies. In the correlation measurement part, the improved dot product method was proposed to calculate the cosine similarity, i.e., the correlation, between CARTs in the feature space. By using the achieved average classification accuracy as reference, the grid search method was used to find the inner product threshold. On this basis, the CARTs with low average classification accuracy among CART pairs whose inner product values are higher than the inner product threshold were marked as deletable. The achieved average classification accuracies and correlations of CARTs were comprehensively considered, those with high correlation and weak classification effect were deleted, and those with better quality were retained to construct the random forest. Multiple experiments show that, the proposed improved random forest achieved higher average classification accuracy than the five random forests used for comparison, and the lead was stable. The G-means and out-of-bag data (OBD) score obtained by the proposed improved random forest were also higher than the five random forests, and the lead was more obvious. In addition, the test results of three non-parametric tests show that, there were significant diversities between the proposed improved random forest and the other five random forests. This effectively proves the superiority and practicability of the proposed improved random forest.","Existing intelligent classification methods could be inefficient to deal with the hybrid environments including hesitant fuzzy information and real numbers. With respect to this real issue, in this study, we propose some new intelligent methods to achieve deep learning and intelligent classification under this hybrid environment. To do this, we construct the hesitant fusion bidirectional recurrent neural network (HF-BiRNN) based on the hesitant fusion mechanism. Then, the twice-cycle mechanism is designed, which includes the extension mechanism and the decomposition-reorganization mechanism, to fully utilize the original data and optimize the classification results. Meanwhile, the overlap degree algorithm is constructed to filter the optimal outputs. After that, we further propose the hesitant expansion BiRNN (HE-BiRNN) by combining with the twice-cycle mechanism, overlap degree algorithm, and BiRNN. Lastly, these new methods are used to the problems of driving route classification and red wine quality assessment. The derived optimal results and comparison analysis fully show the effectiveness and feasibility of the new proposed mechanisms and developed models.","Pest control is essential for crop planting as crops are highly susceptible to pest damage. In general, pest recognition is a fundamental element of pest control. Previous works have used computer vision to achieve automatic pest recognition. However, only a few of them have focused on the open-world pest recognition problem. That is, most methods cannot process new pest categories without expensive network retraining. To fill the gap, this paper proposes an open-world pest image classifier based on two observations: (1) convolutional features learned from previous pest classes are generally applicable to new pest categories, and (2) removing fully-connected neural layers allows a deep network to be exempted from model fine-tuning in case of a new class. First, an optimized lightweight ResNet8-based matching network is developed as the image feature extractor, which saves computational resources. To prevent model collapse, the proposed ResNet8-based matching network is trained with the normalized temperature-scaled cross-entropy loss function instead of the triplet loss function. The trained ResNet8-based matching network is then used to compute similarities between support class prototypes and query image representations for the pest classification. Compared with the state-of-the-arts, the proposed method has achieved the highest 40-way 5-shot classification accuracy of 84 . 29 \u00b1 0 . 23 % with 14.18 frames per second on the D0 dataset. It is significantly superior to the ResNet12-based baseline. These suggest that the proposed method is a technically feasible solution to the open-world pest recognition problem. The Python code can be accessed at https://github.com/scau-gqw1993.\nHighlights\n\u2022\nThis work is, to our best knowledge, the first one on open-world pest classification.\n\u2022\nA lightweight matching network was obtained using ResNet8 and NT-Xent loss function.\n\u2022\nThe method achieved the best 40-way 5-shot accuracy of 84.29% on the D0 dataset.","Highlights\n\u2022\nGrading modeling and decision-making framework were proposed for yield estimation.\n\u2022\nNormalized weight decision-making strategy improved the estimation precision.\n\u2022\nDeep learning network ConvNeXt was compared for modeling performance.\n\u2022\nProposed framework performs precisely and robustly using UAV RGB images.\nAbstract\nRice yield estimation is of great significance for ensuring food security and breeding new varieties with high yield and good stress resistance. The popular yield estimation method is to combine unmanned aerial vehicle (UAV) images to extract vegetation index (VI) for multi-variable regression, whose application is always limited by expensive equipment and complex data processing. In this study, based on the deep learning network, ConvNeXt, a robust framework developed by grading modeling and normalized weight decision-making strategy was innovatively proposed to estimate the rice yield, only using RGB images collected by UAVs. The main results are: (1) the yield estimation performance of yield grading model was better than that of regression model, and R2, mean absolute error (MAE), and mean absolute percentage error (MAPE) on the test dataset using the grading model were 0.97, 410.94 kg/ha, and 3.96 % respectively; (2) the confidence scores of the grading model were adopted as the weights, which could correct the estimated yield of the misclassified samples and further reduce the estimated error. The normalized weight decision-making after optimization had obvious advantages, the performance of 2-weight strategy was the best, whose R2, MAE, and MAPE reached 0.98, 386.08 kg/ha, and 3.79 %, respectively; (3) the MAPE results of generalization assessment showed that the generalization of the grading (12.98 %) and regression (10.88 %) models was inferior to the proposed framework (8.71 %), which could reduce the MAPE on the generalization evaluation dataset to less than 10 %. Furthermore, the framework exhibited good adaptability when applied to the rice yield estimation of the new data in 2022, with an MAPE of 4.54 %. Considering both application potential and adaptability, this framework constructs a novel strategy and method for rice yield estimation using grading modeling and normalized weight decision-making strategy, which provides a reference for future real-time and precise yield estimation using UAV remote sensing.","Classification of brain haemorrhage is a challenging task that needs to be solved to help advance medical treatment. Recently, it has been observed that efficient deep learning architectures have been developed to detect such bleeding accurately. The proposed system includes two different transfer learning strategies to train and fine-tune ImageNet pre-trained state-of-the-art architecture such as that VGG 16, Inception V3 and DenseNet121. The evaluation metrics have been calculated based on the performance analysis of the employed networks. Experimental results show that the modified fine-tuned Inception V3 performed well and achieved the highest test accuracy.","The homophily assumption in graph theory posits that nodes with similar characteristics have a higher tendency to form connections. This principle has rendered Graph Neural Networks (GNNs) as vital tools for graph representation learning. However, many real-world graphs may exhibit a phenomenon often termed as neighbor class imbalance, which is characterized by frequent connections between dissimilar nodes, a scenario reflecting low homophily. Classical GNNs tend to overlook this issue, leading to a significant decline in performance. Prior research has attempted to address this challenge by employing high-order neighborhoods and filtering out dissimilar neighbors, yet they have paid little attention to homophily degree estimation and label utilization. In this work, we initially explore the performance of classical GNNs on a synthetic graph with varying homophily degrees, designated as SynG-N. Following this, we introduce a novel method, HLA-GNN, which integrates homophily degree estimation and label utilization to enhance classical GNNs. The degrees of homophily between node pairs are estimated using a limited set of ground-truth labels, which can be integrated into classic GNNs to guide the message aggregation process. Drawing on the label propagation algorithm, we combine the partially observed class labels to enhance the original feature space. Here, the observed class labels are randomly masked as a feature augmentation and training signal. Our experimental results on eight datasets with varying degrees of homophily underscore the effectiveness of our method. HLA-GNN achieves a 12.69%\u223c34.19% improvement on low-homophily graphs, while maintaining competitive results in homophilous settings.\nHighlights\n\u2022\nHLA-GNN assigns weights by homophily in latent space.\n\u2022\nHLA-GNN enhances feature space with label propagation algorithm.\n\u2022\nOur method Boosts low-homophily performance by 12.69% to 34.19%.","Recently, Convolution Neural Networks (CNN) have achieved excellent performance in some areas of computer vision, including face recognition, character recognition, and autonomous driving. However, there are still many CNN-based models that cannot be deployed in real-world scenarios due to poor robustness. In this paper, focusing on the classification task, we attempt to evaluate and optimize the robustness of CNN-based models from a new perspective: the convolution kernel. Inspired by the discovery that the root cause of the model decision error lies in the wrong response of the convolution kernel, we propose a convolution kernel robustness evaluation metric based on the distribution of convolution kernel responses. Then, we devise the Convolution Kernel Robustness Calibrator, termed as CKR-Calibrator, to optimize key but not robust convolution kernels. Extensive experiments demonstrate that CKR-Calibrator improves the accuracy of existing CNN classifiers by 1%\u20134% in clean datasets and 1%\u20135% in corrupt datasets, and improves the accuracy by about 2% over SOTA methods. The evaluation and calibration source code is open-sourced at https://github.com/cym-heu/CKR-Calibrator.","In the semiconductor manufacturing process, analyzing the defect patterns on a wafer map is crucial for identifying the causes of the defects. The advent of convolutional neural networks (CNNs) has significantly increased the accuracy of automated wafer map pattern classification. Generally, the use of a larger training dataset results in higher classification accuracy. However, collecting a large number of wafer maps and labeling them with their defect categories is expensive and time-consuming. In this paper, we present an improved training method under data insufficiency for wafer map pattern classification. We apply supervised contrastive learning to train a CNN by exploiting the rotational-invariant characteristic of wafer map labeling. The CNN is trained by simultaneously minimizing two loss functions: classification loss and contrastive loss. The first loss function is to classify the rotational variants of wafer maps accurately. The second loss function is to align the representation vectors for the rotational variants of wafer maps with similar labels to be close to each other. Using two benchmark datasets, WM-811K and MixedWM38, we demonstrate that the proposed method enhances classification accuracy compared with existing methods, particularly when the training dataset is small.","Semi-supervised learning (SSL) addresses the lack of labeled data by exploiting large unlabeled data through pseudolabeling. However, in the extremely low-label regime, pseudo labels could be incorrect, a.k.a. the confirmation bias, and the pseudo labels will in turn harm the network training. Recent studies combined finetuning (FT) from pretrained weights with SSL to mitigate the challenges and claimed superior results in the low-label regime. In this work, we first show that the better pretrained weights brought in by FT account for the state-of-the-art performance, and importantly that they are universally helpful to off-the-shelf semi-supervised learners. We further argue that direct finetuning from pretrained weights is suboptimal due to covariate shift and propose a contrastive target pretraining step to adapt model weights towards target dataset. We carried out extensive experiments on both classification and segmentation tasks by doing target pretraining then followed by semi-supervised finetuning. The promising results validate the efficacy of target pretraining for SSL, in particular in the low-label regime.","Severe limitations in data and technological availability have vastly affected NLP research into African languages. With Africa having over 2000 languages, the lack of NLP research is a massive flaw within the NLP field. African languages can hold the key to the next significant advancement in NLP research because some researchers suggest that 30% of current-day languages are derived from African languages. With Sentiment Analysis being a foundational part of NLP research, the release of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th International Workshop on Semantic Evaluation, has provided 14 new annotated datasets for Sentiment Analysis on African languages. We utilize these datasets to evaluate our approach: Delta TF-IDF features with conventional machine learning models. Delta TF-IDF results showed that our approach could provide promising results with the low resource task of sentiment analysis on African Languages. Since it utilized a significantly less data than its transformer counter parts.","In recent years, class-imbalanced learning has become an important branch of machine learning. Synthetic Minority Oversampling Technique (SMOTE) is known as a benchmark method to address imbalanced learning. Although SMOTE performs well on many data, it also has the drawback of generating noisy samples. There are many SMOTE variants to solve this problem. Specifically, these methods are hybrid sampling methods, that is, carrying out an undersampling stage after SMOTE to remove noisy samples. It requires a method that can accurately identify noise to provide reliable performance. In this paper, a hybrid re-sampling method based on SMOTE and a two-layer nearest neighbor classifier (SMOTE-kTLNN) is proposed. SMOTE-kTLNN recognition noise is realized by an Iterative-Partitioning Filter (IPF). Specifically, SMOTE is performed on the original data to balance the data, then the data is divided into n equal parts, establishing kTLNN on each part to predict the whole data. And noisy samples are removed according to the majority voting rule. In the last, the balanced data sets are used to train kNN, AdaBoost, and SVM to verify whether SMOTE-kTLNN is irrelevant to the classifier. The experiment results demonstrate that SMOTE-kTLNN performs better than the comparisons in 25 binary data sets, including Recall, AUC, F1-measure, and G-mean.","This study develops an end\u2010to\u2010end deep learning framework to learn and analyze ground motions (GMs) through their latent features, and achieve reliable GM classification, selection, and generation of simulated motions. The framework is composed of an analysis workflow that transforms and reconstructs GMs through short\u2010time Fourier transform (STFT), encodes and decodes their latent features through convolutional variational autoencoder (CVAE), and classifies and generates GMs by grouping and interpolating latent variables. A benchmark study is established to confirm the minor difference between original GMs and the corresponding reconstructed accelerograms. The encoded latent space reveals that certain latent variables are directly linked to the dominant physical features of GMs. Resultantly, clustering latent variables using the k\u2010means algorithm successfully classifies GMs into different groups that vary in earthquake magnitude, soil type, field distance, and fault mechanism. By linearly interpolating two parent latent variables, simulated GMs are generated with consistent class information and matching response spectra. Furthermore, seismic fragility models are developed for a steel frame building and a concrete bridge using different sets of GMs. Using five classified, top\u2010ranked motions, regardless of recorded or simulated accelerograms, can achieve reasonable and efficient fragility estimates compared to the case that adopts 230 GMs. The proposed deep learning framework addresses two compelling questions regarding seismic fragility assessment: How many GMs are sufficient and what types of motions should be selected.","Skip Abstract Section\nAbstract\nAir quality prediction is considered one of complex problems. This is due to volatility, dynamic nature, and high variability in space and time of particulates and pollutants. Meanwhile, designing an automated model for monitoring and predicting air quality becomes more and more relevant, particularly in urban regions. Air pollution can significantly affect the environment and eventually citizens\u2019 health. In this paper, one of the popular machine learning algorithms, the neural network algorithm, is employed to classify different species of air pollutants. To boost the performance of the traditional neural network, the war strategy optimization algorithm tunes the neural network\u2019s parameters. The experimental results demonstrate that the proposed optimized neural network based on the war strategy algorithm can accurately classify air pollutant species.","In image classification task, imbalanced dataset is a problem that often occurs. Batik pattern data also suffers this problem, mainly because of the poor quality of available images and rarity of certain patterns. In this research, we employed a novel ad- vanced augmentation and oversampling techniques on the imbalanced dataset to address this issue. This approach enhanced the diversity of the images, encompassing variations in color, contrast, wrinkles, and warps that may be present in batik garments. We employed two CNN models, DenseNet169 and VGG-16, along with three different training methods for our study. These methods included training without oversampling and advanced augmentation, training with oversampling, and training with both oversampling and advanced augmentation. The results showed that the best accuracy was achieved with DenseNet169 with our oversampled and augmented dataset, with an accuracy of 84.62%. Additionally, VGG-16 also performed well on said dataset, achieving an accuracy of 82.56%.Our results suggested that by using our oversampling &amp; advanced augmentation on the dataset,the model performance improved compared to plain data and oversampled data.","For a long time, images have proved perfect at both storing and conveying rich semantics, especially human emotions. A lot of research has been conducted to provide machines with the ability to recognize emotions in photos of people. Previous methods mostly focus on facial expressions but fail to consider the scene context, meanwhile scene context plays an important role in predicting emotions, leading to more accurate results. In addition, Valence-Arousal-Dominance (VAD) values offer a more precise quantitative understanding of continuous emotions, yet there has been less emphasis on predicting them compared to discrete emotional categories. In this paper, we present a novel Multi-Branch Network (MBN), which utilizes various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image. Experimental results on EMOTIC dataset, which contains large-scale images of people in unconstrained situations labeled with 26 discrete categories of emotions and VAD values, show that our proposed method significantly outperforms state-of-the-art methods with 28.4% in mAP and 0.93 in MAE. The results highlight the importance of utilizing multiple contextual information in emotion prediction and illustrate the potential of our proposed method in a wide range of applications, such as effective computing, human-computer interaction, and social robotics.","This paper features convolutional neural network (CNN) models on Clifford algebras applied to a medical image classification task, namely the diagnosis of acute lymphoblastic leukemia (ALL). ALL is a type of cancer identified by malformed lymphocytes, known as lymphoblasts, in the bloodstream. The image classification task aims to discriminate healthy cells from lymphoblasts. This work shows that CNNs featuring parameters in Clifford algebras significantly outperform real-valued networks of equivalent size in this application. Indeed, the real-valued and a Clifford CNN achieved an average accuracy of 94.60% and 97.02%, respectively, in the ALL-IDB dataset with a 50% train-test split. Moreover, we present smaller versions of Clifford CNNs with roughly 75% fewer parameters that yielded a 96.50% average accuracy. The results reported in this work are comparable to high-end models in the literature despite having several orders of magnitude fewer parameters.","This work constitutes the first approach for automatically classifying the surface that the voiding flow impacts in non-invasive sound uroflowmetry tests using machine learning. Often, the voiding flow impacts the toilet walls (traditionally made of ceramic) instead of the water in the toilet. This may cause a reduction in the strength of the recorded audio signal, leading to a decrease in the amplitude of the extracted envelope. As a result, just from analysing the envelope, it is impossible to tell if that reduction in the envelope amplitude is due to a reduction in the voiding flow or an impact on the toilet wall. In this work, we study the classification of sound uroflowmetry data in male subjects depending on the surface that the urine impacts within the toilet: the three classes are water, ceramic and silence (where silence refers to an interruption of the voiding flow). We explore three frequency bands to study the feasibility of removing the human-speech band (below 8 kHz) to preserve user privacy. Regarding the classification task, three machine learning algorithms were evaluated: the support vector machine, random forest and k-nearest neighbours. These algorithms obtained accuracies of 96%, 99.46% and 99.05%, respectively. The algorithms were trained on a novel dataset consisting of audio signals recorded in four standard Spanish toilets. The dataset consists of 6481 1-s audio signals labelled as silence, voiding on ceramics and voiding on water. The obtained results represent a step forward in evaluating sound uroflowmetry tests without requiring patients to always aim the voiding flow at the water. We open the door for future studies that attempt to estimate the flow parameters and reconstruct the signal envelope based on the surface that the urine hits in the toilet.","Face attribute classification (FAC) is a high-profile problem in biometric verification and face retrieval. Although recent research has been devoted to extracting more delicate image attribute features and exploiting the inter-attribute correlations, significant challenges still remain. Wavelet scattering transform (WST) is a promising non-learned feature extractor. It has been shown to yield more discriminative representations and outperforms the learned representations in certain tasks. Applied to the image classification task, WST can enhance subtle image texture information and create local deformation stability. This paper designs a scattering-based hybrid block, to incorporate frequency-domain (WST) and image-domain features in a channel attention manner (Squeeze-and-Excitation, SE), termed WS-SE block. Compared with CNN, WS-SE achieves a more efficient FAC performance and compensates for the model sensitivity of the small-scale affine transform. In addition, to further exploit the relationships among the attribute labels, we propose a learning strategy from a causal view. The cause attributes defined using the causality-related information can be utilized to infer the effect attributes with a high confidence level. Ablative analysis experiments demonstrate the effectiveness of our model, and our hybrid model obtains state-of-the-art results in two public datasets.","Diabetic retinopathy, a condition characterized by retinal damage and vision loss, is a prevalent complication of diabetes arising from elevated blood sugar levels. With a growing number of individuals affected, efficient and accurate diagnosis is crucial. This study aims to implement and compare the Local Binary Pattern (LBP) and Gray Level Co-occurrence Matrix (GLCM) feature extraction techniques, which have demonstrated success in prior research. The comparison will provide a comprehensive under- standing of the image features, extract relevant data, and improve the performance of the image analysis pipeline for diabetic retinopathy classification. The result showed that from three scenarios the best accuracy provided by Support Vector Machine with the accuracy score between 73% until 74%, however, other algorithm have little difference which the result on 73%.","The recognition and classification of wire melted marks is crucial in modern fire investigation. The existing technology mainly uses physical or chemical methods to deal with wire melted marks and draws conclusions through manual observation, or manually extracts the features and train classification model, both of which consume excessive manpower and resources. The research on automatic feature extraction and recognition of wire weld marks by artificial intelligence technology is still blank. Based on the data set of wire melted mark metallographic images provided by a city fire research institute, we proposed an algorithm to recognize the type of wire melted mark metallographic images based on artificial intelligence which can help fire fighters efficiently speculate the cause of fire. In the algorithm, the TransUnet network is used to segment the melted zone by semantic segmentation to extract the melted zone containing the main features, and the mIOU reaches 92.2%. Then, the features of wire melted mark are extracted based on the melted zone image. Finally, XGBoost is used for feature modeling for classification. The F1 Score of model is 82.9%.","Skewed class proportions in real-world datasets present a challenge for machine learning algorithms, as they have a tendency to correctly categorize the majority class while incorrectly classifying the minority class. Such classification disparities hold significant implications, particularly in predictive scenarios involving minority groups, where misclassifying minority instances could lead to adverse outcomes. To tackle this, class imbalance learning has gained attention, with the Synthetic Minority Oversampling Technique (SMOTE) being a notable approach that addresses class imbalance by generating synthetic instances for the minority class based on their feature space neighbors. Despite its effectiveness and simplicity, SMOTE is known to suffer from a noise propagation issue where noisy and uninformative samples are introduced. While various SMOTE variants, including hybrids with undersampling, have been developed to tackle this problem, identifying noisy samples in complex real-world datasets remains a challenge. To address this, our study introduces a new SMOTE-based hybrid approach called SMOTE-centroid displacement-based k-NN (SMOTE-CDNN). SMOTE-CDNN employs centroid displacement for class prediction, which is more robust against noisy data. After SMOTE is applied, noise instances are detected and removed for clearer decision boundaries if their labels predicted by our centroid displacement-based k-NN algorithm are different from the real ones. While our experiments on 24 imbalance datasets demonstrate the resilience and efficiency of our proposed algorithm, which outperforms state-of-art resampling algorithms with various classification models, we acknowledge the need for further investigation into specific dataset characteristics and classification scenarios to determine the generalizability of our approach.\nHighlights\n\u2022\nSkewed class proportions pose a challenge for machine learning.\n\u2022\nSMOTE is widely used but has a noise propagation issue.\n\u2022\nA novel hybrid variant, SMOTE-CDNN, uses k-NN with centroid displacement.\n\u2022\nIt detects and removes noise instances after SMOTE is applied.\n\u2022\nExperiments show its efficiency and outperformance of other algorithms.","With the exponential growth of various data interactions on network systems, network intrusions are also increasing. The emergence of edge computing technology brings a new solution to network security. However, due to the difficulty of processing massive and unbalanced data at the edge, higher accuracy requirements are necessary for deployed detection models. This paper proposes a multi-classification model for network intrusion detection based on reconstruction and feature matching. This model can be deployed on small-scale edge nodes, effectively identifying various attack behaviors through the utilization of reconstruction errors and adaptive scaling. Furthermore, we proposed a model transfer method based on feature matching to enhance the training and detection efficiency of multi-classification models under different data distribution conditions. The proposed model has been evaluated on the CICIDS2017 dataset in terms of accuracy, recall, precision and F1 score. The model demonstrates high accuracy for normal flows in the network, majority class attacks, and minority class attacks, achieving an overall multi-class accuracy of 99.81%, outperforming similar models. Furthermore, this model demonstrates faster convergence and training speed after feature matching, exhibiting better robustness and outstanding performance at the edge.","Ordinal classification of imbalanced datasets is a challenging problem that occurs in many real-world applications. The main challenge is to simultaneously consider the classes ordering and imbalanced distribution. Although the classic synthetic instances oversampling techniques can improve the identification of minority classes, they easily incur the damage of the classes ordering when the synthetic instances fall in non-adjacent classes regions. In this paper, we propose a powerful method for handling the imbalanced problem embedded in the ordinal classification, namely Iterative Minority oversampling technique for imbalanced Ordinal Classification (IMOC). Concretely, we first develop an iterative identification procedure to select the minority instance that is hardest to learn. Then, a weighted oversampling probability distribution that respects the ordinal nature is used to generate synthetic minority instances to balance the skewed distribution. Furthermore, two novel ensemble versions are developed to boost the capability of our proposed IMOC. In order to verify the effectiveness and robustness of our proposed methods, an extensive experimental study is carried out on a large number of datasets from real-world applications. The experimental results supported by proper statistical tests indicate that our proposed methods outperform state-of-the-art algorithms in terms of the most frequently used performance measures.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201cco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","The article provides a description of the most frequent bigrams and trigrams obtained using the n-gram analysis technique on a representative sample of Russian spoken language. N-gram analysis allows identifying frequent lists of sequences consisting of n graphical words, which is important for describing corpus material in various theoretical and applied aspects. The source data for applying this technique was a sample of 388 episodes of everyday speech communication from the ORD corpus (about 110 hours of audio). The results of the n-gram analysis in the form of frequency lists of word sequences allow constructing a typology of the most common bigrams and trigrams in Russian oral communication and lead the study equally to the levels of grammar, pragmatics, lexicon, and phraseology. The list of the most frequent bigrams and trigrams contains grammatical structures (U TEBYA, YA NE PONIMAYU, MNE KAZHETSYA), idioms (in a broad sense of the term) (VSYO RAVNO, TO ZHE SAMOE), introductory units (TAK SKAZAT\u2019, S DRUGOY STORONY), as well as a number of sequences typical only for oral speech, such as one-word pragmatic markers (NU VOT, KAK BY, NU V OBSHCEM), amplifications (DA-DA, TAK-TAK-TAK), and hesitations-vocalizations (E-E, M-M-M). The obtained frequency lists can be useful for solving many modern applied natural language processing tasks.","The Gene Ontology (GO) project is a major bioinformatics initiative with the aim of standardizing the representation of gene and gene product attributes across species and databases. The classes in GO are hierarchically structured in the form of a directed acyclic graph (DAG), what makes its prediction more complex. This work proposes an adapted Learning Classifier Systems (LCS) in order to predict protein functions described in the GO format. Hence, the proposed approach, called HLCS (Hierarchical Learning Classifier System) builds a global classifier to predict all classes in the application domain and its is expressed as a set of IF-THEN classification rules, which have the advantage of representing more comprehensible knowledge. The HLCS is evaluated in four different ion-channel data sets structured in GO terms and compared with a Ant Colony Optimisation algorithm, named hAnt-Miner. In the tests realized the HLCS outperformed the hAnt-Miner in two out of four data sets.","Highlights\n\u2022\nOrigin and variety identification of Chrysanthemum were studied by NIR-HSI.\n\u2022\nAdvanced deep learning and visualization methods were utilized for classification.\n\u2022\nFew-shot Class-Incremental learning using the Replay training strategy was studied.\n\u2022\nGood performances were obtained by Few-shot Class-Incremental learning approach.\nAbstract\nChrysanthemum, a traditional Chinese medicine, possesses diverse pharmacological effects with a myriad of origins and varieties. Due to the difficulty of acquiring and modeling all Chrysanthemum varieties comprehensively, it becomes imperative to establish models based on the available samples in order to swiftly identify newly emerging Chrysanthemum categories from a limited dataset. In this study, hyperspectral imaging combined with deep learning was exploited for the classification of fourteen Chrysanthemum categories by origin and variety. Leveraging the convolutional neural network, the few-shot class-incremental learning (class-IL) method was applied to the detection of few-shot Chrysanthemum categories. By employing a Replay training strategy, the challenges associated with severely sample-limited and unbalanced classes can be effectively addressed. When incrementally expanding from four to fourteen categories, with each new category consisting of only 30 samples, the achieved accuracy on the test dataset reached 80.13 %. This remarkable performance exhibited a narrow margin of 15.75 % compared to conventional supervised learning, which utilized an incremental training sample size nearly 100 times larger. This approach consistently outperforms conventional supervised learning methods, thereby showcasing its remarkable scalability. It facilitates the practical implementation of few-shot learning and deep learning models, providing a substantiated framework to tackle real-world scenarios in various domains using hyperspectral imaging and related techniques.","Recently, transfer learning has generated promising performance in few-shot classification by pre-training a backbone network on base classes and then applying it to novel classes. Nevertheless, there lacks a theoretical analysis on how to reduce the generalization error during the learning process. To fill this gap, we prove that the classification error bound on novel classes is mainly determined by the base-class generalization error, given the base-novel domain divergence and the novel-class generalization error produced by an incremental learner using novel samples. The novel-class generalization error is further decided by the base-class empirical error and the VC-dimension of the hypothesis space. Based on this theoretical analysis, we propose a Born-Again Networks under Self-supervised Label Augmentation (BANs-SLA) method to improve the generalization capability of classifiers. In this method, cross-entropy and supervised contrastive losses are simultaneously used to minimize the base-class empirical error in the expanded space with SLA. Afterward, BANs are adopted to transfer the knowledge sequentially across generations, which acts as an effective regularizer to trade-off the VC-dimension. Extensive experimental results have verified the effectiveness of our method, which establishes the new state-of-the-art performance on popular few-shot classification benchmark datasets.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThis is the first theoretical study on FSC in the context of the transfer learning paradigm.\n\u2022\nWe propose a Born-Again Networks under Self-supervised Label Augmentation method.\n\u2022\nWe conduct experiments on multiple benchmarks to demonstrate the effectiveness.","To increase classification accuracy, a variety of feature extraction techniques have been presented. A pre-processing method called superpixel segmentation divides an image into meaningful sub-regions, which simplifies the image. This substantially reduces single-pixel misclassification. In this work, a texture-based superpixel segmentation technique is developed for the accurate classification of hyperspectral images (HSI). Initially, the local binary pattern and Gabor filters are employed to extract local and global image texture information. The extracted texture features are then provided as input to the simple linear iterative clustering (SLIC) algorithm for segmentation map generation. The final classification map is constructed by utilising a majority vote strategy between the superpixel segmentation map and the pixel-wise classification map. The proposed method was validated on standard HSI datasets. In terms of classification performance, it outperformed other state-of-the-art algorithms. Furthermore, the algorithm may be incorporated into the UAV's onboard camera to automatically classify HSI.","To address the problem of low classification accuracy of liquid dangerous goods in daily security screening technology, we propose a two-layer feature extraction classification algorithm based on Ultra-Wideband centimeter wave detection, which is composed of shallow Wavelet Transform-Autoencoder (WT-AE) and deep Attention-Gated Recurrent Unit (Attention-GRU) network. In order to abstract the best description feature, the shallow autoencoder adds a classification constraint. In the classification stage, the deep algorithm Attention-GRU algorithm can further abstract the sequence composed of shallow features into deep features to improve the accuracy of classification. The experimental results show that the WT-AE algorithm with shallow constraint is more suitable for feature extraction of UWB centimeter-wave signals in this experimental scene than PCA and ICA feature extraction algorithms. Compared with KNN, Linear kernel SVM, Gaussian kernel SVM and decision tree algorithms for sequence processing, Attention-GRU has better processing effect and higher accuracy of classification. By comparing the test accuracy of other algorithms, the double-layer feature classification algorithm performs better in this experimental scene. The final test accuracy can reach 95.8%.","Social media text can be classified in different ways, viz sentiment analysis, humour detection, hate speech detection and hope speech detection. Multitask learning (MTL) models built on Large Language Models (LLMs) eliminate the need to build separate models for each of these tasks. However, building MTL models by fully fine-tuning the LLM has limitations such as catastrophic forgetting and requiring complete retraining to add a new task. AdapterFusion was introduced to address these limitations. However, existing AdapterFusion techniques have not been experimented with code-mixed or code-switched text. Moreover, they only considered task-based AdapterFusion on monolingual LLMs. However, using monolingual LLMs is sub-optimal in classifying code-mixed or code-switched text. A better alternative is multilingual LLMs. In this paper, we present an MTL model that combines task AdapterFusion with language adapters on top of a multilingual LLM. We combine language adapters sequentially, in parallel, and as a fusion with task adapters to capture cross-lingual knowledge in code-mixed and code-switched text. We believe that this is the first research to introduce language-based AdapterFusion.","Convolutional neural network (CNN) and its variants have been widely applied to hyperspectral classification for their excellent ability to extract local features. However, as research on hyperspectral imaging (HSI) has progressed, CNNs have been proven to struggle in extracting and representing the sequential properties of spectral characteristics. Recently, some researchers have demonstrated the feasibility of transformer architecture in HSI classification due to its powerful ability to characterize spectral information. The lack of suitable pre-processing and optimization methods which are used for the transformer's application in HSI becomes a major limitation to model's performance. Therefore, to enhance model's performance and practicality, we propose an efficient transformer backbone for HSI classification, named Efficient-Spectralformer. In the proposed framework, we rethink the input form and design the Split Grouping Embedding (SGE) module that requires much less computational resources. Additionally, to maximize the use of attentional feature information from different layers, we have used the Multi-layer Feature Fusion (MFF) module is used to learn multi-layer spectral attention information. The experiments conducted on five HSI datasets demonstrate that the proposed method achieves better performance under much less memory usage (about 30% of the original on average) by comparing with the original Spectralformer.","Support vector machine (SVM) is widely recognized as an effective classification tool and has demonstrated superior performance in diverse applications. However, for large-scale pattern classification problems, it may require much memory and incur prohibitive computational costs. Motivated by this, we propose a new SVM model with novel generalized ramp loss (L R-SVM). The first-order optimality conditions for the non-convex and non-smooth L R-SVM are developed by the newly developed P-stationary point, based on which, the L R support vectors and working set of L R-SVM are defined, interestingly, which shows that all of the L R support vectors are on the two support hyperplanes under mild conditions. A fast proximal alternating direction method of multipliers with working set (L R-ADMM) is developed to handle L R-SVM and L R-ADMM has been demonstrated to achieve global convergence while maintaining a significantly low computational complexity. Numerical comparisons with nine leading solvers show that L R-ADMM demonstrates outstanding performance, particularly when applied to large-scale pattern classification problems with fewer support vectors, higher prediction accuracy and shorter computational time.\nHighlights\n\u2022\nThe new sparse and robust SVM model. We construct a new sparse and robust generalized ramp loss SVM.\n\u2022\nThe novel support vectors. To reduce the scale of the training set, we define the support vectors of generalized ramp loss SVM.\n\u2022\nThe efficient new algorithm. To solve the generalized ramp loss SVM, we design a new alternating direction method of multipliers with working set.\n\u2022\nHigh numerical performance. Numerical experiments show that the proposed algorithm has excellent performance.","License Plate Recognition (LPR) plays a critical role in various applications, such as toll collection, parking management, and traffic law enforcement. Although LPR has witnessed significant advancements through the development of deep learning, there has been a noticeable lack of studies exploring the potential improvements in results by fusing the outputs from multiple recognition models. This research aims to fill this gap by investigating the combination of up to 12 different models using straightforward approaches, such as selecting the most confident prediction or employing majority vote-based strategies. Our experiments encompass a wide range of datasets, revealing substantial benefits of fusion approaches in both intra- and cross-dataset setups. Essentially, fusing multiple models reduces considerably the likelihood of obtaining subpar performance on a particular dataset/scenario. We also found that combining models based on their speed is an appealing approach. Specifically, for applications where the recognition task can tolerate some additional time, though not excessively, an effective strategy is to combine 4\u20136 models. These models may not be the most accurate individually, but their fusion strikes an optimal balance between accuracy and speed.","In this paper, an analysis of convolutional neural network (CNN) models to classify the quality of dried chili pepper is described. The classifier models can determine the categories of a set of images that could be encountered in a sorting machine, such as \u201cExtra\u201d, \u201cFirst class\u201d, and \u201cSecond class\u201d which correspond to different qualities of dried chili peppers. Additionally, two more classes were added as \u201cTrash\u201d and \u201cEmpty\u201d which corresponds to cases that could occur in a sorting machine. To determine the best model for image classification, a set of state-of-the-art architectures were compared from the Torchvision library, including ResNet, ResNeXt, Wide ResNet, EfficientNet, and RegNet. The models were trained using feature extraction on the transfer learning approach, and were evaluated using cross-validation method and various advanced metrics such as Precision, Recall, Specificity, F1-score, Geometric mean, and Index of Balanced Accuracy. The results of the cross-validation process indicate that ResNet-152 is the best CNN model for implementation in a sorting machine, with a mean validation accuracy of 95.04%. By using this model, agricultural producers can ensure that their products are sorted according to international standards.","In this research, a method was developed for utilizing voice commands with programmable logic controllers (PLCs) and supervisory control and data acquisition (SCADA) systems, which are commonly utilized in industrial automation. This approach incorporates artificial intelligence to enable human\u2013machine interaction, aligning with the trends of Industry 4.0. A deep neural network was specifically designed for speech recognition, eliminating the need for reliance on any pre-existing speech-to-text engines. The objective was to create a model that is accurate and compact in size, making it suitable for embedded systems within industrial systems. To train the deep learning network, 21,600 sound files were generated. These files combined real factory noise with a synthetic dataset of human speech, forming a dataset comprising 60 different classes of voice commands. These commands encompassed actions like starting, stopping, and operating at various speeds for 10 motors controlled by the automation system. After applying the Mel-frequency cepstral coefficient (MFCC) to the voice commands, the resulting data was directly fed into the proposed network. The network achieved an impressive accuracy rate of 99.73%. Notably, the proposed network outperformed even networks several times its size.","Neighborhood rough set theories are commonly used in global feature selection to achieve high performance in continuous data classification. However, selecting a single feature subset to represent the entire dataset may degrade the performance when there are intra-class dissimilarities among objects. Therefore, this paper proposes a novel feature-selection method, Granule-specific Feature Selection (GFS) to select local feature subsets for continuous data classification. The feature selection approach constitutes a novel feature selection algorithm and a novel feature evaluation function and uses existing approaches for granule identification and classification with some adjustments. The neighborhood rough set theories are used in granule (subclass) identification within each class when there are no subclass label information available in the training data, while an improved k-Nearest Neighbors approach is used in classification with granule-specific feature subsets. Experimental results show GFS outperforms most of the global, class-specific, and local feature selection baselines in terms of classification performance.\nHighlights\n\u2022\nGranule-specific feature selection using neighborhood rough set theories.\n\u2022\nFeature selection while managing intra-class dissimilarities of objects.\n\u2022\nHandle data uncertainty of continuous data when selecting features.\n\u2022\nImprove classification performance using granule-specific feature subsets.","Pathological complete response (pCR) after neoadjuvant che-motherapy (NAC) in patients with breast cancer was found to improve survival, and it has a great prognostic value in the aggressive tumor subtype. This study aims to predict pCR before NAC treatment with a radiomic feature-based ensemble learning model using both positron emission tomography/computed tomography (PET/CT) images taken from the online QIN-Breast dataset. It studies the problem of constructing an end-to-end classification pipeline that includes a large-scale radiomic feature extraction, a hybrid iterative feature selection and a heterogeneous weighted ensemble classification. The proposed hybrid feature selection procedure can identify significant radiomic predictors out of 2153 features extracted from delineated tumour regions. The proposed weighted ensemble approach aggregates the outcomes of four weak classifiers (Decision tree, Naive Bayes, K-nearest neighbour, and Logistics regression) based on their importance. The empirical study demonstrates that the proposed feature selection-cum-ensemble classification method has achieved 92% and 88.4% balanced accuracy in PET and CT, respectively. The PET/CT aggregated model performed better and achieved 98% balanced accuracy and 94.74% F1-score. Furthermore, this study is the first classification work on the online QIN-Breast dataset.","This paper presents a novel framework that enables the generation of unbiased estimates for test loss using fewer labeled samples, effectively evaluating the predictive performance of classification models in data-limited applications. The framework\u2019s key innovation lies in developing an adaptive sampling distribution that iteratively identifies influential testing samples based on interactions between learner and evaluator agents. Notably, the adaptive distribution dynamically adjusts the evaluator agent\u2019s supervisory role by prioritizing inputs with discrepancies between the agents and considering the evaluator\u2019s uncertainty. Comprehensive experimental analyses on synthetic data and two sparse data sets from material extrusion additive manufacturing problems validate the framework\u2019s superiority over uniform and fixed sampling distributions. First, the proposed framework provides unbiased estimates of the test loss across various data sets, sampling ratios, and evaluator models. Second, the introduced adaptive sampling distribution significantly reduces the standard deviation of the test loss estimator compared to uniform sampling, achieving a 50% reduction for a 10% sampling ratio in the filament selection benchmark. Third, the framework demonstrates its efficacy in model selection to determine the optimal number of hidden units with a reduced number of test samples. Overall, this work offers a promising framework for evaluating classification models in applications where acquiring labeled data is time-consuming and resource-intensive, including materials science and engineering.","Internet traffic classification plays a key role in network visibility, Quality of Services (QoS), intrusion detection, Quality of Experience (QoE) and traffic-trend analyses. In order to improve privacy, integrity, confidentiality, and protocol obfuscation, the current traffic is based on encryption protocols, e.g., SSL/TLS. With the increased use of Machine-Learning (ML) and Deep-Learning (DL) models in the literature, comparison between different models and methods has become cumbersome and difficult due to a lack of a standardized framework. In this paper, we propose an open-source framework, named OSF-EIMTC, which can provide the full pipeline of the learning process and simulation reproducibility. From well-known datasets to extracting new and well-known features, it provides implementations of well-known ML and DL models (from the traffic classification literature) as well as experimental test-beds and their evaluation. By providing a standardized platform, OSF-EIMTC enables repeatable, reproducible, and accurate comparisons of both established and novel features and models. As part of our framework evaluation, we demonstrate the reproducibility of a variety of cases where the framework can be of use, utilizing multiple datasets, models, and feature sets. We show analyses of publicly available datasets and invite the community to participate in our open challenges using OSF-EIMTC, fostering collaborative advancements in encrypted traffic classification.","Handwriting is widely investigated to mark emotional states and personality. However, the majority of the studies are based on graphology, and do not utilise personality factor models. We use the well-known five-factor model which says that people possess five basic traits, together known as big-five. Hence the problem of personality prediction from handwriting is essentially a multi-label problem. In addition to that, the predicted values should be non-binary decimal numbers since the model says people possess the traits in various degrees. Multi-label classifiers have not been explored for personality assessment using handwriting features. The current work aims to bridge the gap. Multi-label classifiers are trained by trait scores obtained by big-five inventory as well as handwriting features. A number of classifiers including classifier chain, binary relevance and label power-set are employed in the work. Best accuracies of 95.9% with non-binary label values and 97.9% with binary label values are achieved.","Active learning has achieved remarkable success in minimizing labeling costs for classification tasks with all data samples drawn from known classes. However, in real scenarios, most active learning methods fail when encountering open-set annotation (OSA) problem, i.e., numerous samples from unknown classes. The main reason for such failure comes from existing query strategies that are unavoidable to select unknown class samples. To tackle such problem and select the most informative samples, we propose a novel active learning framework named OSA-CQ, which simplifies the detection work of samples from known classes and enhances the classification performance with an effective contrastive query strategy. Specifically, OSA-CQ firstly adopts an auxiliary network to distinguish samples using confidence scores, which can dynamically select samples with the highest probability from known classes in the unlabeled set. Secondly, by comparing the predictions between auxiliary network, classification, and feature similarity, OSA-CQ designs a contrastive query strategy to select these most informative samples from unlabeled and known classes set. Experimental results on CIFAR10, CIFAR100 and Tiny-ImageNet show the proposed OSA-CQ can select samples from known classes with high information, and achieve higher classification performance with lower annotation cost than state-of-the-art active learning algorithms.","Deep neural networks (DNNs) achieve top performance through costly training on large datasets. Such resources may not be available in some scenarios, like IoT or healthcare. Extreme learning machines (ELMs) aim to alleviate this problem using single-layered networks, requiring fewer training resources. Current investigations have found that DNNs are prone to security and privacy threats, where malfunction of the network or training data extraction can be performed.\nDue to the increasing attention to ELMs and their lack of security investigations, we research the security implications of this type of network. Precisely, we investigate backdoor attacks in ELMs. We created a comprehensive experimental setup to evaluate their security in various datasets and scenarios. We conclude that ELMs are vulnerable to backdoor attacks with up to 97% attack success rate. Additionally, we adapt and evaluate the usage fine-pruning to ELMs.","Cancer is a complicated illness that is caused by numerous gene mutations or deregulation of gene interactions. This study, on the other hand, proposes a unique method for cancer categorization. Cancer is the major reason of death in this era. Appropriate methods are required to diagnose it as early as possible so that accurate treatment should be started to save human lives. Heuristic Class Topper Optimization describes a vital role in the detection of cancer for classification. A large dataset of tumors has been taken and Naive Bayes classifier exported to categorize them. The Heuristic Class Topper Optimization method (HCTO) is planted to extract the features. The optimization technique is based on the intelligent learning of pupils in a classroom. Weak students are learning from the class topper. There are various class toppers based upon the number of sections. Thus, the characteristics are refined with the aid of HCTO. The HCTO algorithm is a novel artificial intelligence technology that is rapidly converging. The HCTO-NB technique is simple, less complex, accurate, and has a low error rate, all of which are important characteristics in cancer categorization. The recommended method\u2019s achieved parameters are accuracy of 97.6%, precision of 98.4, error rate decreased by 3% on 1000 iterations, and classification efficacy are all demonstrated. The results are also compared to the KNN classifier, which has been used to classify cancer by a number of studies in the past. Experiments on a range of datasets demonstrated that this novel method was more accurate and dependable by\u2009~\u200914% compared to KNN. The findings shows that the suggested approach is both rapid and accurate, making it a great alternative for cancer diagnosis in the real world. In this paper 4 types of cancers datasets with relevant features like age, Gender, Tumor size, Tumor area and smoker or non-smoker etc. have been used for real time validation.","Recently, introducing nonconvex loss functions in support vector machine (SVM) to improve the robustness against varies noises has been drawing much attention. In this paper, we first construct a new robust capped asymmetric elastic net (CaEN) loss function. Second, we describe a novel robust Huberized kernel-based (HK) loss function and theoretically demonstrate several important properties, such as smoothness, boundness and the trade-off between the standard least squares and the truncated least squares. Finally, we apply the CaEN loss and the HK loss into elastic net nonparallel hyperplane SVM (ENNHSVM) to develop a fused robust geometric nonparallel SVM (FRGNHSVM). The proposed FRGNHSVM not only inherits the advantages of ENNHSVM but also improves the robustness of classification problems. An efficient Pegasos-based DC (difference of convex functions) algorithm is implemented to solve the FRGNHSVM optimization problem. In comparison with four famous SVMs, including Lagrangian SVM, twin SVM, pinball SVM and C-loss twin SVM, experimental results on simulations and twelve UCI datasets show that the proposed FRGNHSVM can often improve more than 5% average prediction accuracy. Moreover, the performance of the high prediction accuracy of FRGHNSVM is more significant along with the ratio of label noise increasing, indicating its superiority in dealing with label-contaminated datasets.\nHighlights\n\u2022\nA novel FRGNHSVM is proposed for robust binary learning problems.\n\u2022\nFRGNHSVM is stable for re-sampling and robust to outliers.\n\u2022\nThe designed Pegasos-based DC algorithm is scalable and applicable to large data.\n\u2022\nExperimental results demonstrate the effectiveness of FRGNHSVM.","Electronic nose (e-nose) is composed of a set of gas sensors combined with a series of algorithmic models. The practical application of the electronic nose system can prove that the electronic nose is more widely used in the classification problems, and always has a good performance. Moreover, it can be inferred that classification methods significantly influence e-nose. So far, the classification models proposed in e-nose can generally be divided into two categories. One is the linear classifier, representing the model of the Bayesian classifier, principal component analysis (PCA), and K-nearest neighbour (KNN), etc. The other is the nonlinear classifier, including support vector machine (SVM), random forest (RF), and extreme learning machine (ELM), etc. This review aims to supply a summary of the various classification methods used in e-nose, and provides a reference for the choice of an appropriate classification model used in e-nose in the specific application.","With rapid development of single-cell multi-modal sequencing technologies, more and more multi-omics data come into being and provide a unique opportunity for the identification of distinct cell types at the single-cell level. Therefore, it is important to integrate different modalities which are with high-dimensional features for boosting final multi-omics data classification performance. However, existing multi-omics data classification methods mainly focus on exploiting the complementary information of different modalities, while ignoring the learning confidence and cross-modal sample relationship during information fusion. In this paper, we propose a multi-omics data classification network via global and cross-modal feature aggregation, referred to as GCFANet. On one hand, considering that a large number of feature dimensions in different modalities could not contribute to final classification performance but disturb the discriminability of different samples, we propose a feature confidence learning mechanism to suppress some redundant features, as well as enhancing the expression of discriminative feature dimensions in each modality. On the other hand, in order to capture the inherent sample structure information implied in each modality, we design a graph convolutional network branch to learn the corresponding structure preserved feature representation. Then the modal-specific feature representations are concatenated and input to a transformer induced global and cross-modal feature aggregation module for learning consensus feature representation from different modalities. In addition, the consensus feature representation used for final classification is enhanced via a view-specific consistency preserved contrastive learning strategy. Extensive experiments on four multi-omics datasets are conducted to demonstrate the efficacy of the proposed GCFANet.\nHighlights\n\u2022\nA feature aggregation network is proposed for multi-omics classification.\n\u2022\nA contrastive learning strategy is designed for feature representation alignment.\n\u2022\nBoth complementary information and sample structure are used for consensus learning.\n\u2022\nThe proposed network is successfully used for drug response prediction.","Skin cancer is regarded as the hazardous as well as widespread disease. Worldwide, there is been a 53% increment in present melanoma cases annually, and the mortality rate is also expected to be increasing in the coming decade. Hence, it is an urgent requirement to design a new early-detection model so that skin cancer can be more treatable without many complications. This work focuses on recognising skin cancer. The model includes the median filter (MF)-based pre-processing. The pre-processed image is subjected to a modified fuzzy C means (FCM)-based segmentation process. Finally, the recognition is done by employing a hybrid model with bi-LSTM and ANN. The proposed model's error rate was 0.091694, whereas the greatest error values for the other approaches were 0.20377 for BOA, 0.62192 for BRO, 0.170028 for ALO, 0.17168 for AOA, and 0.187915 for FIREFLY.","Pose-based approaches for sign language recognition provide light-weight and fast models that can be adopted in real-time applications. This article presents a framework for isolated Arabic sign language recognition using hand and face keypoints. We employed MediaPipe pose estimator for extracting the keypoints of sign gestures in the video stream. Using the extracted keypoints, three models were proposed for sign language recognition: Long-Term Short Memory, Temporal Convolution Networks, and Transformer-based models. Moreover, we investigated the importance of non-manual features for sign language recognition systems and the obtained results showed that combining hand and face keypoints boosted the recognition accuracy by around 4% compared with only hand keypoints. The proposed models were evaluated on Arabic and Argentinian sign languages. Using the KArSL-100 dataset, the proposed pose-based Transformer achieved the highest accuracy of 99.74% and 68.2% in signer-dependent and -independent modes, respectively. Additionally, the Transformer was evaluated on the LSA64 dataset and obtained an accuracy of 98.25% and 91.09% in signer-dependent and -independent modes, respectively. Consequently, the pose-based Transformer outperformed the state-of-the-art techniques on both datasets using keypoints from the signer\u2019s hands and face.","Ensemble learning consists of combining the prediction of different learners to obtain a final output. One key step for their success is the diversity among the learners. In this paper, we propose to reach the diversity in terms of the classification complexity by guiding the sampling of instances in the Bagging algorithm with complexity measures. The proposed Complexity-driven Bagging algorithm complements the classic Bagging algorithm by considering training samples of different complexity to cover the complexity space. Besides, the algorithm admits any complexity measure to guide the sampling. The proposal is tested in 28 real datasets and for a total of 9 complexity measures, providing satisfactory and promising results and revealing that training with samples of different complexity, ranging from easy to hard samples, is the best strategy when sampling based on complexity.","Skip BACKGROUND: Section\nBACKGROUND:\nAlzheimer\u2019s disease (AD) endangers the physical and mental health of the elderly, constituting one of the most crucial social challenges. Due to lack of effective AD intervention drugs, it is very important to diagnose AD in the early stage, especially in the Mild Cognitive Impairment (MCI) phase.\nSkip OBJECTIVE: Section\nOBJECTIVE:\nAt present, an automatic classification technology is urgently needed to assist doctors in analyzing the status of the candidate patient. The artificial intelligence enhanced Alzheimer\u2019s disease detection can reduce costs to detect Alzheimer\u2019s disease.\nSkip METHODS: Section\nMETHODS:\nIn this paper, a novel pre-trained ensemble-based AD detection (PEADD) framework with three base learners (i.e., ResNet, VGG, and EfficientNet) for both the audio-based and PET (Positron Emission Tomography)-based AD detection is proposed under a unified image modality. Specifically, the effectiveness of context-enriched image modalities instead of the traditional speech modality (i.e., context-free audio matrix) for the audio-based AD detection, along with simple and efficient image denoising strategy has been inspected comprehensively. Meanwhile, the PET-based AD detection based on the denoised PET image has been described. Furthermore, different voting methods for applying an ensemble strategy (i.e., hard voting and soft voting) has been investigated in detail.\nSkip RESULTS: Section\nRESULTS:\nThe results showed that the classification accuracy was 92% and 99% on the audio-based and PET-based AD datasets, respectively. Our extensive experimental results demonstrate that our PEADD outperforms the state-of-the-art methods on both audio-based and PET-based AD datasets simultaneously.\nSkip CONCLUSIONS: Section\nCONCLUSIONS:\nThe network model can provide an objective basis for doctors to detect Alzheimer\u2019s Disease.","The core objective of this research is to develop a methodology for selecting a supervised machine learning classification technique based on the specific categories of objects that need to be classified. The study focuses on product categories extracted from Amazon's Product Reviews database, which are utilized to evaluate the subjectivity of post-purchase feedback. The primary supervised machine learning methods are utilized to efficiently perform the classification task. The resulting insights will enable the prioritization and choice of the best approach based on the selected categories. In the context of accelerated technological adoption due to the COVID-19 pandemic, this research contributes by showcasing how AI/ML can play a pivotal role in enhancing decision-making processes across various sectors and highlighting the significance of adapting to emerging technologies for sustainable growth.","The liver is a key organ in the human body that aids in the digestion of food, the elimination of toxins, and the storage of energy. Patients with liver disorders are on the rise all over the world. However, because the disorder's symptoms are unclear, it is difficult to diagnose it, which raises the disease's death rate. The study introduces novel fuzzy twin models for liver disease classification. In the first model, the membership is calculated based on the quadratic function called fuzzy twin kernel ridge regression-quadratic (FTKRR-Q). In the second model, we have calculated the fuzzy membership based on the centroid and named the model as fuzzy twin kernel ridge regression-centroid (FTKRR-C). For our research, the BUPA or liver disease dataset has been used from the UCI machine learning repository. Experimental results are compared with the twin support vector machine, kernel ridge regression classifier and twin kernel ridge regression classifier. The accuracy, sensitivity, F1-score, and Mathew's correlation coefficient are used to evaluate the suggested model's performance. Experiments are also carried out on some real-world benchmark datasets. The results reveal the applicability of the proposed models.","Deep learning has been increasingly incorporated into various computational pathology applications to improve its efficiency, accuracy, and robustness. Although successful, most previous approaches for image classification have crucial drawbacks. There exist numerous tasks in pathology, but one needs to build a model per task, i.e., a task-specific model, thereby increasing the number of models, training resources, and cost. Moreover, transferring arbitrary task-specific model to another task is still a challenging problem. Herein, we propose a task-agnostic generative and general pathology image classifier, so called GPC, that aims at learning from diverse kinds of pathology images and conducting numerous classification tasks in a unified model. GPC, equipped with a convolutional neural network and a Transformer-based language model, maps pathology images into a high-dimensional feature space and generates pertinent class labels as texts via the image-to-text classification mechanism. We evaluate GPC on six datasets for four different pathology image classification tasks. Experimental results show that GPC holds considerable potential for developing an effective and efficient universal model for pathology image analysis.","Skin cancer is the most prevalent type of cancer worldwide. Early detection is essential as it could be fatal at later stages. The classification of skin lesions is challenging since there are many variations, including changes in color, shape, size, high intra-class variation, and high inter-class similarity. In this paper, a unique class-wise attention method is proposed that considers each class equally while extracting additional discriminative information of skin lesions. The proposed attention mechanism is employed in a progressive manner to incorporate discriminative feature information from multiple scales. The proposed approach obtained competitive performance against more than 15 state-of-the-art methods including HAM1000 and ISIC 2019 leaderboard winners. The proposed method achieved 97.40% accuracy on the HAM10000 and 94.9% accuracy on the ISIC 2019 dataset.\nHighlights\n\u2022\nA novel attention based mechanism is proposed for skin lesions classification.\n\u2022\nThe problem of significant intra-class variance, high inter-class similarity, and class imbalance is addressed by a class-wise attention mechanism.\n\u2022\nThe important features for the classification are extracted without the burden of additional parameters using a progressive class-wise attention mechanism.\n\u2022\nThe final three layers of the baseline model are discarded and the global average pooling (GAP) and classification output layers are added to reduce the number of parameters, while maintaining performance.\n\u2022\nThe proposed network is robust, end-to-end trainable and has good generalization on unseen data.","Previously, single classification models were mainly studied to classify human protein cell images, i.e., to identify a certain protein based on a set of different cells. However, a classifier can identify only one protein, in fact, a single cell usually consists of multiple proteins, and the proteins are not completely independent of each other. In this paper, we build a human protein cell classification model by multi-label learning. The logical relationship and distribution characteristics among the labels are analyzed to determine the different proteins contained in a set of different cells (i.e., containing multiple elements in the output space). In this paper, using human protein image data, we conducted comparison experiments on pre-trained Xception and InceptionResnet V2 to optimize the two models in terms of data augmentation, channel settings, and model structure. The results show that the Optimized InceptionResnet V2 model achieves high performance in the classification task. The final accuracy of the Optimized InceptionResnet V2 model we obtained reached 96.1%, which is a 2.82% improvement relative to that before the optimized model.","Intelligent Transportation Systems (ITS) have experienced significant growth over the past decade thanks to advances in control, communication, and information technology applied to vehicles, roads, and traffic control systems. Vehicle type classification plays a vital role in implementing ITS because of its ability to collect useful traffic information, enable future development of transport infrastructures, and increase human comfort. As a branch of machine learning, deep learning represents a frontier for artificial intelligence, which seeks to be closer to its primary goal. Deep learning is a powerful tool for classifying vehicle types because it can capture complex traffic data characteristics and learn from large amounts of data. This means that it can be used to accurately classify traffic data and generate valuable insights that can be used to improve traffic management. Researchers have successfully adopted these algorithms as a solution to propose optimal vehicle-type classification strategies. This paper highlights the role of deep learning algorithms in solving the vehicle type classification problem, reviewing the state-of-the-art approaches in this field.","Occupant presence and their behaviour in the built environment significantly impact energy consumption in buildings. Currently, building systems are often operated based on assumed occupancy and fixed schedules, or occupants manually adjust them for their comfort, which sometimes leads to energy wastage. Also, the inherent complexity and unpredictability of occupancy patterns can contribute to disparities between simulated and actual energy consumption, underscoring the importance of selecting suitable methods for occupancy prediction. Various methods, such as occupancy cameras, thermal imagers, Passive Infrared Sensors, and Radio-Frequency Identification, can collect occupancy information. However, they often come with limitations including cost, complexity, and invasiveness. Hence, there is a growing interest in creating occupancy prediction models using an indirect approach based on indoor air quality (IAQ) data. However, this indirect approach must be further explored within the building simulation field. In this study, we apply an approach based on the novel QLattice algorithm for occupancy detection, utilizing a minimal sensing strategy with a comprehensive set of IAQ data. Furthermore, we compare the QLattice algorithm\u2019s performance with that of traditional machine learning (ML) algorithms such as Support Vector Machines (SVM), Decision Trees (DT), and XGBoost using metrics including accuracy, precision, recall, F1 score, AUC-ROC values, and computational time. The QLattice algorithm outperforms traditional ML algorithms in all evaluation metrics, achieving over 90% accuracy on the test dataset. Additionally, compared to traditional black-box ML algorithms, QLattice stands out for its explainability and interpretability, providing insights useful in decision-making.","This paper introduces a novel approach to address the challenges of transfer learning, which aims to efficiently train a classifier for a new domain using supervised information from similar domains. Traditional transfer learning methods may fail to maintain the discriminative features of the target domain due to the scarcity of labelled data and the use of irrelevant source domain data distribution subspace, resulting in poor metrics. To overcome these challenges, the proposed approach, called KDADP, transforms the data distribution of both the source and target domains into a lower-dimensional subspace while preserving their discriminatory information. The KDADP model maximizes between-class variance and minimizes within-class variance with L1 penalization, enabling the recovery of the most useful characteristics and reducing the model\u2019s complexity. Experimental results on three real-world domain adaptation datasets demonstrate that the proposed KDADP model significantly improves classification performance and outperforms state-of-the-art primitive, shallow, and deeper domain adaptation methods.","Convolutional Neural Network (CNN) is a widely used neural network in deep learning, and Graph Convolutional Network (GCN) is one of the most effective semi -supervised methods. It spread node information in a conversion way. In this article, we have studied the differences between CNN and GCN in the classification of high -spectrum image. Because the traditional GCN algorithm needs to build an adjacent matrix on all data, the calculation cost is very high, especially in large -scale remote sensing problems. MinigCNS uses a small -batch learning method to solve the problem of CCN calculation costs, and then it has not solved the problem of low efficiency of single model classification. This article studies the advantages of minigcns and CNN, and proposes a weighted fusion network FU-W, which weighs the minigcns and CNN weighted integration to break the bottleneck of single model performance. We experimented with the fusion algorithm on the two high -spectrum data sets, and its overall accuracy can reach 88.8%in Indian Pines. The experiment proves the superiority of the fusion strategy for a single CNN or GCN model.","Graph neural networks (GNNs) have emerged as a powerful tool for analyzing graph data, where data are represented by nodes and edges. However, the conventional methods have limitations in analyzing graphs with diverse attributes and preserving crucial information during the graph embedding. As a result, there is a possibility of losing crucial information during the integration of individual nodes. To address this problem, we propose an attention-based readout with subgraphs for graph embedding that partitions the graph according to unique node attributes. This method ensures that important attributes are retained and prevents dilution of distinctive node features. The adjacency matrices and node feature matrices for the partitioned graphs go into a graph isomorphism network (GIN) to aggregate the features, where the attention mechanism merges the partitioned graphs to construct the whole graph embedding vector. Extensive experiments on six graph datasets demonstrate that the proposed method captures various local patterns and produces superior performance against the state-of-the-art methods for graph classification. Especially, on the challenging IMDB-MULTI dataset, our method achieves a significant performance gain of 27.87%p over the best method called MA-GCNN.","Abstract\u2014The implementation of computational approaches for protein glycosylation site prediction is becoming popular since the experimental-validated glycosylation data became more abundant. Some of the data were found to be wrong after the experiment was again carried out with more sophisticated technology. To solve this issue, the latest state-of-the-art model trained the model based on a positive-unlabelled algorithm. The aim of this research is to explore the possibility of an approach applying a simple neural network algorithm and still achieve high classification performance. The model proposed in this research gave competitive results with fewer preprocessing steps. Increasing the accuracy of glycosylation site prediction can complement laboratory-based methods and is very useful for understanding the role of glycosylation.","Time series classification exists in widespread domains such as EEG/ECG classification, device anomaly detection, and speaker authentication. Although many methods have been proposed, efficient selection of intuitive temporal features to accurately classify time series remains challenging. Therefore, this paper presents TSC-RTF, a new time series classification method using random temporal features. First, to ensure the intuitiveness of the features, TSC-RTF selects subsequences containing important data points as candidates for intuitive temporal features. Then, TSC-RTF uses random sampling to reduce the number of candidates significantly. Next, TSC-RTF selects the final temporal features using a random forest to ensure the validity of the final temporal features. Finally, a deep learning classifier is trained by TSC-RTF to achieve high accuracy. The experimental results show that the proposed method can compete with the state-of-the-art methods.","With the emerging of new data collection ways, the features are incremental and accumulated gradually. Due to the expansion of feature spaces, it is more common that there are unknown biases between the distribution of training and testing datasets. It is known as the unknown data selection bias, which belongs to the learning scenario with non-i.i.d samples. The performance of traditional approaches, which need the i.i.d. assumption, will be aggravated seriously. How to design an algorithm to address the problem of data selection bias in this feature incremental scenario is crucial but rarely studied. In this paper, we propose a feature incremental classification algorithm with causality. Firstly, we embed the confounding variable balance algorithm in causal learning into the prediction modeling and utilize the logical regression algorithm with balancing regular terms as a baseline. Then, to satisfy the special requirement of feature increment, we design a new regularizer, which maintains the consistency of the regression coefficients between the data in the current and previous stages. It retains the correlation between the old features and labels. Finally, we propose the Multiple Balancing Logistic Regression model (MBRLR) to jointly optimize the balancing regularizer and weighted logistic regression model with multiple feature sets. We also present theoretical results to show that our proposed algorithm can make precise and stable predictions. Besides, the numerical results also demonstrate that our MBRLR algorithm is superior to other methods.\nHighlights\n\u2022\nWe have pioneered the use of causal inference and proposed a novel method approach, i.e., MBRLR, for achieving stable and accurate classification in the feature increase scenario.\n\u2022\nWe have improved the sample reweighting method by redesigning the loss function and regularizer which could be formulated as a convex optimization problem and could be easily solved.\n\u2022\nWe have proved that the MBRLR algorithm can make a stable classification for feature incremental data in the non-i.i.d case.","In the classification task, many improved algorithms have been developed based on Support Vector Machines (SVM). Since the recently proposed Fast Support Vector Classifier (FSVC) can handle large scale datasets, this paper improves FSVC by quantile, called QSVC, which uses quantile rather than average value of samples to represent all samples. The advantages of QSVC are as follows: 1) QSVC performs better on the skewed distribution; 2) and the robustness of quantile is better. Experiments show that our QSVC performs better in accuracy and speed than FSVC. For example,Table 2 shows that the average accuracy of QSVC is higher than that of FSVC and Liblinear, and it takes less time.","This article presents a solution for Speech Emotion Recognition (SER) in multilingual setting using a hierarchical approach. The approach involves two levels, the first level identifies the gender of the speaker, while the second level predicts their emotional state. We evaluate the performance of three classifiers of increasing complexity: k-NN, transfer learning based on YAMNet, and Bidirectional Long Short-Term Memory neural networks. The models were trained, validated, and tested on a dataset that includes the big-six emotions and was collected from well-known SER datasets representing six different languages. Our results indicate that there are differences in classification accuracy when considering all data versus only female or male data, across all classifiers. Interestingly, prior knowledge of the speaker\u2019s gender can improve the overall classification performance.","Often pieces of information are received sequentially over time. When did one collect enough such pieces to classify? Trading wait time for decision certainty leads to early classification problems that have recently gained attention as a means of adapting classification to more dynamic environments. However, so far results have been limited to unimodal sequences. In this pilot study, we expand into early classifying multimodal sequences by combining existing methods. Spatial-temporal transformers trained in the supervised framework of Classifier-Induced Stopping outperform exploration-based methods. We show our new method yields experimental AUC advantages of up to 8.7%.","While utilizing machine learning models, one of the most crucial aspects is how bias and fairness affect model outcomes for diverse demographics. This becomes especially relevant in the context of machine learning for medical imaging applications as these models are increasingly being used for diagnosis and treatment planning.\nIn this paper, we study biases related to sex when developing a machine learning model based on brain magnetic resonance images (MRI). We investigate the effects of sex by performing brain age prediction considering different experimental designs: model trained using only female subjects, only male subjects and a balanced dataset. We also perform evaluation on multiple MRI datasets (Calgary-Campinas(CC359) and CamCAN) to assess the generalization capability of the proposed models.\nWe found disparities in the performance of brain age prediction models when trained on distinct sex subgroups and datasets, in both final predictions and decision making (assessed using interpretability models). Our results demonstrated variations in model generalizability across sex-specific subgroups, suggesting potential biases in models trained on unbalanced datasets. This underlines the critical role of careful experimental design in generating fair and reliable outcomes.","Emitter classification plays a crucial role in electronic support measurement systems. A data-driven model named Gaussian dynamic recurrent unit is proposed to accomplish the end-to-end emitter classification tasks, which is simplified based on the long short-term memory unit by using a Gaussian function to characterize the relationship between the input and the network state, and a learnable exponentially weighted average to update the states. The Gaussian function and the dynamic exponentially weighted average amplify the difference between the input signals from different classes. The parameter size and computational time of many emitter classification methods are measured. The results show that the model proposed in this paper has the highest parameter efficiency, and low computational and storage costs. The results on a real-world dataset show that the proposed model has the highest accuracy and stability. These advantages have important significance for deploying the model in practical applications.","Cross-domain sentiment analysis (CDSA) aims to learn transferable knowledge from the source domain to facilitate the sentiment polarity classification on the target domain of lacking labeled data. Currently, two types of unsupervised domain adaptation (UDA) methods are widely used in CDSA tasks. One employs the domain adversarial strategy to extract domain-invariant features, and the other utilizes the distance metric strategy to reduce domain distribution discrepancy. However, the fine-grained domain-specific information related to categories aligned between domains is not preserved, which suppresses the performance of target-domain classification. To overcome the mentioned problem, a unified Domain Adversarial Category-wise Alignment Network (DACAN) was proposed in this paper. An integrated network was constructed with progressive multi-level feature learning. Specifically, a feature extraction module was constructed with parameter sharing between two domains at low-level text feature extraction layers. The domain adversarial module was added to enable shared knowledge transfer by extracting domain-invariant information and by updating the shared parameters at the feature extraction layers. A category-wise alignment module was built to achieve local distribution alignment at the high dimension-level semantic layers guided by fine-grained category structure information. Meanwhile, joint constraint was established with domain-invariant constraint based on domain adversarial, and domain-consistency constraint based on category-wise alignment. Comprehensive experiments were conducted on two standard Amazon review datasets. The results show that DACAN outperforms other state-of-the-art UDA methods by 0.7% and 1.1% on the two- and three-category CDSA tasks, respectively. Also, better performance results are achieved with a synergistic UDA scheme compared with a single UDA scheme.","Abstract: The electromyogram (EMG), also known as an EMG, is used to assess nerve impulses in motor nerves, sensory nerves, and muscles. EMS is a versatile tool used in various biomedical applications. It is commonly employed to determine physical health, but it also finds utility in evaluating emotional well-being, such as through facial electromyography. Classification of EMG signals has attracted the interest of scientists since it is crucial for identifying neuromuscular disorders (NMDs). Recent advances in the miniaturization of biomedical sensors enable the development of medical monitoring systems. This paper presents a portable and scalable architecture for machine learning modules designed for medical diagnostics. In particular, we provide a hybrid classification model for NMDs. The proposed method combines two supervised machine learning classifiers with the discrete wavelet transform (DWT). During the online testing phase, the class label of an EMG signal is predicted using the classifiers\u2019 optimal models, which can be identified at this stage. The simulation results demonstrate that both classifiers have an accuracy of over 98%. Finally, the proposed method was implemented using an embedded CompactRIO-9035 real-time controller.","Plagiarism detection (PD) in natural language processing involves locating similar words in two distinct sources. The paper introduces a new approach to plagiarism detection utilizing bidirectional encoder representations from transformers (BERT)-generated embedding, an enhanced artificial bee colony (ABC) optimization algorithm for pre-training, and a training process based on reinforcement learning (RL). The BERT model can be incorporated into a subsequent task and meticulously refined to function as a model, enabling it to apprehend a variety of linguistic characteristics. Imbalanced classification is one of the fundamental obstacles to PD. To handle this predicament, we present a novel methodology utilizing RL, in which the problem is framed as a series of sequential decisions in which an agent receives a reward at each level for classifying a received instance. To address the disparity between classes, it is determined that the majority class will receive a lower reward than the minority class. We also focus on the training stage, which often utilizes gradient-based learning techniques like backpropagation (BP), leading to certain drawbacks such as sensitivity to initialization. In our proposed model, we utilize a mutual learning-based ABC (ML-ABC) approach that adjusts the food source with the most beneficial results for the candidate by considering a mutual learning factor that incorporates the initial weight. We evaluated the efficacy of our novel approach by contrasting its results with those of population-based techniques using three standard datasets, namely Stanford Natural Language Inference (SNLI), Microsoft Research Paraphrase Corpus (MSRP), and Semantic Evaluation Database (SemEval2014). Our model attained excellent results that outperformed state-of-the-art models. Optimal values for important parameters, including reward function are identified for the model based on experiments on the study dataset. Ablation studies that exclude the proposed ML-ABC and reinforcement learning from the model confirm the independent positive incremental impact of these components on model performance.\nHighlights\n\u2022\nBERT-based plagiarism detection with RL and ML-ABC.\n\u2022\nReward function in RL improves detection of minority plagiarism class.\n\u2022\nModel outperforms state-of-the-art on SNLI, MSRP, SemEval2014 datasets.\n\u2022\nAblation studies highlight the impact of ML-ABC and RL on performance.","Performance of the pseudo-label (PL)-based self-supervised training depends greatly on the quality of estimated PLs. Recent studies have shown that label noise can remarkably impact downstream performance. Recently, research has demonstrated that mixup regularization is effective against noise memorization. In this work, we extend this previous study by exploring several recent forms of mixup, namely 2-step interpolation double mixup to enhance model robustness, mixup over speech frames for better recognition at the frame-level, moment exchange mixup to encourage utilization of moment information of speaker speech as they can reveal speaker style, and virtual mixup training to regularize the areas in-between training points to be locally-Lipschitz and enforce consistent predictions. We analyze their effect on the generalization of some state-of-the-art speaker verification (SV) systems and explore their combination via different multi-task learning-based approaches. Our results show that the proposed mixup formulations are aligned with the SV task and that our proposed multi-task learning-based approach can be beneficial to improve the performance and robustness of SV systems.","Occupancy sensing and estimation in large commercial buildings has become a significant problem to be solved, with applications ranging from occupancy-based HVAC control to space planning, and security, etc. Thermal sensing is a promising technology to solve this problem, being easy to deploy in practice and allowing an actual occupancy count in a particular room without violating the data and privacy concerns. While initial strides have been made to solve this problem with thermal arrays, there are many problems that remain unsolved, including accuracy performance, overlapping of sensing areas that lead to under/over-counting, and data training requirements for different zones.\nIn this paper, we introduce TODOS 1, a novel system for estimating occupancy in intelligent buildings. TODOS uses a low-cost, low-power thermal sensor array along with a passive infrared sensor. We introduce a novel data processing pipeline that allows us to automatically extract features from the thermal images using an artificial neural network. Through an extensive experimental evaluation2, we show that TODOS provides occupancy detection accuracy of 98% to 100% under different scenarios. In addition, it solves the issue of occupancy over/under-counting by overlapping sensing areas when using multiple thermal sensors in large rooms. This is done by treating the entire area as a single input thermal image instead of partitioning the area into multiple thermal images individually processed. Furthermore, TODOS introduces a data augmentation technique that allows the generation of training data for rooms of different sizes and shapes, without requiring specific training data from each room. Using these data, TODOS can train specifically designed neural networks optimized for any room size and shape, and achieve almost the same level of occupancy detection accuracy in rooms where experimental labeled training data is available, making it a viable solution that generalizes to the different rooms in large buildings.","Fine-grained visual classification (FGVC) is a difficult task due to the challenges of discriminative feature learning. Most existing methods directly use the final output of the network which always contains the global feature with high-level semantic information. However, the differences between fine-grained images are reflected in subtle local regions which often appear in the front of the network. When the texture of the background and object are similar or the proportion of the background is too large, the prediction will be greatly affected. In order to solve the above problems, this paper proposes multi-granularity feature fusion module (MGFF) and two-stage classification based on Vision-Transformer (ViT). The former comprehensively represents images by fusing features of different granularities, thus avoiding the limitations of single-scale features. The latter leverages the ViT model to separate the object from the background at a very small cost, thereby improving the accuracy of the prediction. We conduct comprehensive experiments and achieves the best performance in two fine-grained tasks on CUB-200-2011 and NA-Birds.\nHighlights\n\u2022\nA multi-granularity feature fusion module is proposed to solve the limitations of single-scale features.\n\u2022\nA two-stage classification based on Vision-Transformer is proposed to reduce background interference on predictions. By leveraging the ViT model, the object can be separated from the background and the details can be enlarged.\n\u2022\nExtensive experiments prove the superiority of our model. The visualization results illustrate that our two-stage classification can accurately localize objects and facilitate correct predictions.","Aspect-Level Sentiment Classification (ALSC) aims to assign specific sentiments to a sentence toward different aspects, which is one of the crucial challenges in the field of Natural Language Processing (NLP). Despite numerous approaches being proposed and obtaining prominent results, the majority of them focus on leveraging the relationships between the aspect and opinion words in a single instance while ignoring correlations with other instances, which will make models inevitably become trapped in local optima due to the absence of a global viewpoint. Instance representation derived from a single instance, on the one hand, the contained information is insufficient due to the lack of descriptions from other perspectives; on the other hand, its stored knowledge is redundant since the inability to filter extraneous content. To obtain a polished instance representation, we developed a Retrieval Contrastive Learning (RCL) framework to subtly extract intrinsic knowledge across instances. RCL consists of two modules: (a) obtaining retrieval instances by sparse retriever and dense retriever, and (b) extracting and learning the knowledge of the retrieval instances by using Contrastive Learning (CL). To demonstrate the superiority of RCL, five ALSC models are employed to conduct comprehensive experiments on three widely-known benchmarks. Compared with the baselines, ALSC models achieve substantial improvements when trained with RCL. Especially, ABSA-DeBERTa with RCL obtains new state-of-the-art results, which outperform the advanced methods by 0.92%, 0.23%, and 0.47% in terms of Macro F1 gains on Laptops, Restaurants, and Twitter, respectively.\nHighlights\n\u2022\nWe proposed RCL to enable ALSC models to generate polished representations.\n\u2022\nRCL has two modules: obtain retrieval instances and learn common features by CL.\n\u2022\nThe sparse and dense retrievers are used to obtain high-quality retrieval instances.\n\u2022\nThe ALSC model can be enhanced greatly by training with RCL.\n\u2022\nABSA-DeBERTa obtains new state-of-the-art results by being trained with RCL.","Early classification of longitudinal data remains an active area of research today. The complexity of these datasets and the high rates of missing data caused by irregular sampling present data-level challenges for the Early Longitudinal Data Classification (ELDC) problem. Coupled with the algorithmic challenge of optimising the opposing objectives of early classification (i.e., earliness and accuracy), ELDC becomes a non-trivial task. Inspired by the generative power and utility of the Generative Adversarial Network (GAN), we propose a novel context-conditional, longitudinal early classifier GAN (LEC-GAN). This model utilises informative missingness, static features, and earlier observations to improve the ELDC objective. It achieves this by incorporating ELDC as an auxiliary task within an imputation optimization process. Our experiments on several datasets demonstrate that LEC-GAN outperforms all relevant baselines in terms of F1 scores while increasing the earliness of prediction.","The histopathological analysis of a suspected region is critical for cancer diagnosis, treatment, and management. Histopathological diagnosis consists in analyzing the characteristics of the lesions using tissue sections stained with hematoxylin and eosin. Classification of digital tumor pathology images, called whole slide images (WSIs), is a great challenge since WSIs usually have huge resolutions while lacking localized annotations. Multiple instance learning (MIL) is a commonly used method applied to pathological image analysis. However, most MIL methods often focus only on the global representation of WSIs, ignoring whether the category labels play other roles in the model training besides being a supervision signal. In addition, feature confusion is also a problem that should be avoided for the analysis of WSIs with weakly supervised methods. To address these problems, we propose a novel algorithm of classifying WSI for cancer diagnosis. The proposed model, ProMIL, uses only slide-level labels rather than localized annotations for analysis. There are three innovations in this work. Firstly, we present the concept of class proxy which is the representation of the intrinsic feature of each category, and plays a key role in guiding the training of the model. Secondly, we design a novel WSI representation learning module that utilizes a multi-scale feature extraction strategy to represent each patch in a WSI and then aggregates these representations using an attention mechanism to encode the WSI. Thirdly, we design a metric-learning-based weakly supervised multiclass-classifier by measuring the similarity between each WSI embedding and class proxies. The proposed ProMIL can effectively alleviate the side effect of feature confusion, and carry intuitive interpretability and scalability. To evaluate the performance of ProMIL, we conduct a series of experiments on several datasets of WSIs with different types of cancer from open data sources. It can be observed from the experimental results that ProMIL outperforms most of the compared methods and achieves better performance on a various type of cancer image data for classification, thus suggesting the proposed method is suitable for classifying different categories of cancer rather than a specific kind of cancer. Therefore, it is expected to act as a general framework to be extended to more cancer diagnoses.\nHighlights\n\u2022\nThe class proxy is the representation of the intrinsic feature of each category.\n\u2022\nA multi-scale feature extraction strategy is proposed to represent each patch.\n\u2022\nEncoding the whole slide image by aggregating and gated-attention mechanism.\n\u2022\nWSI classification performs by metric-learning-based weakly supervised MIL.","Various ensemble machine learning techniques have been widely studied and implemented to construct the predictive models in different sciences, including bagging, boosting, and stacking. However, bagging and boosting concentrate on minimizing variance or bias, stacking techniques aimed at reducing both by identifying the optimal integration of base learners. Moreover, while most ensemble methods simply combine identical machine learning models, stacking utilizes a meta-machine learning model to combine different base learning models, aiming to enhance the overall accuracy of generalization. Therefore, this research showed the utilization of stacking, an ensemble approach, to develop mineral prospectivity models for Pb-Zn mineralization in the Varcheh District, west Iran. To end this, various exploration evidence layers, including geochemical data, remote sensing data, geological and tectonic controls were used to construct the stacking structure. In the following, a set of five base learners were applied, containing support vector regression (SVR) using RBF, linear and polynomial kernels, the K-nearest neighbor (KNN), and linear regression. Ridge, SVR-RBF and XGBoost were used as a meta-learner to integrate the outputs of basic learners. To measure how well each model performed, ROC, F1-score and Precision metrics was carried out. Moreover, compared to the separate algorithms, the stacking-based ensemble model showed a better prediction accuracy. The findings of this study demonstrated that the ensemble model based on stacking achieved a 95% prediction rate for Pb-Zn deposits, covering only 9% of the study area. As a result, this model holds promise as an effective tool for predicting mineral prospectivity in other study areas, regardless of whether they exhibit similar or different types of mineralization.","Highlights\n\u2022\nExploring the effect of locally weighted learning with machine learning model.\n\u2022\nGain ratio are used to select the most important environmental factor.\n\u2022\nLWL-RS-ADT appears as an accurate model in assessing landslide susceptibility.\nAbstract\nAssessing landslide susceptibility and predicting the possibility of landslide event is the foundation and prerequisite for emergency response and management of landslide disaster. The target of current paper is to propose five integration models based on integrating locally weighted learning (LWL) with a radial basis function classifier (RBF), Fisher's linear discriminant (FLDA), quadratic discriminant analysis (QDA), a Credal decision tree (CDT), an alternating decision tree (ADT) and random subspace (RS) and the performance of five integration models were compared for modeling landslide susceptibility. Yongxin County from China was employed as a study area, 364 landslide locations and fifteen environmental factors were applied. The results demonstrate that the proposed LWL-RS-ADT model is more reliable and stable than the other models. Among the fifteen environmental factors, NDVI, lithology, and altitude are the very significant factors in the six models. It is concluded that the proposed integration models provide an effective way to predict the susceptibility of landslides.","Alzheimer's disease (AD) represents a prevalent, progressive neurodegenerative ailment marked by the gradual deterioration of memory and cognitive faculties. Resting-state functional magnetic resonance imaging (rs-fMRI) offers good specificity in AD by reflecting the early changes in the brain network. As a result, combining the popular deep learning methods with rs-fMRI brain network features has attracted a wide attention. In our experiment, A cohort comprising 325 participants, sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, was stratified into three distinct groups: Alzheimer's Disease (AD, 53), mild cognitive impairment (MCI, 140) and normal control (NC, 152). With the preprocessed rs-fMRI data, the functional brain networks were constructed. Though the obtained features of rs-fMRI network and clinical scales, one improved BrainNet-graph convolutional network (GCN) was proposed for AD classification. In the realm of performance assessment, we conducted a comparative analysis between our BrainNet-GCN model and the GCN model. Our proposed BrainNet-GCN demonstrated better capability than those of GCN with high accuracies (ACCs) of AD vs.MCI of 91.89%, MCI vs.NC of 91.38%, and AD vs.NC of 92.50% for binary classification, and with an improved ACC of 83.58% for multi-class classification. The proposed BrainNet-GCN using the combined features of rs-fMRI network and clincal scales demonstrated robust capability in AD classification owing to its high sensitivity and specificity.","\u2014Graph convolutional network (GCN) has attracted much attention in the field of hyperspectral image classification for its excellent feature representation and convolution on arbitrarily structured non-Euclidean data. However, most state-of-the-art methods build a graph utilize the distance measure, which makes it challenging to fully characterize the complex relationship of hyperspectral remote sensing data. Moreover, the hyperspectral image usually has uncertainty introduced by the problems of the spectral variability and noise interference. This article uses fuzzy theory to optimize the GCN and thus solve the uncertainty problem in hyperspectral images, and presents a novel fuzzy graph convolutional network (F-GCN) for hyperspectral image classification. By calculating the fuzzy similarity of samples, a robust graph is first built rather than using the traditional Euclidean distance method, which allows a better representation of the complex relationship between hyperspectral remote sensing data. Furthermore, the proposed network introduces fuzzy layers into the model to cope with the ambiguity of the hyperspectral image. Finally, the classification results for three real-world hyperspectral data sets to show its feasibility and effectiveness in hyperspectral image classification.","In texture classification, local binary pattern (LBP) is currently one of the most widely-concerned feature encoding models. Most existing LBP-based texture classification methods are usually limited to single-kind texture features. In fact, an across-domain fusion of LBP features with other features, such as image contours, could be another potential path to promote texture classification. To enhance the feature modeling ability of LBP-based methods, this paper firstly designs a Cellular Neural Network (CellNN) with recurrent convolutions, initially trained by a simplified simulated-annealing algorithm, to extract informative image contours. For better reliability, a new three-channel contour extractor of deep CellNNs (i . e ., dCellNNs) is proposed. This extractor contains the initially-trained CellNNs of more than three layers, and it is further optimized by fine-tuning parameters. Moreover, a new weighted-base algorithm is designed to fulfill the fusion of the multi-scale texture features by LBPs and the contour features by dCellNNs to enhance feature representation. Finally, these enhanced features are concatenated together to generate the final multi-scale features of given texture image. On texture datasets KTH, Brodatz, OTC12 and UIUC, experiment results verify that the across-domain fusion of multi-scale LBPs and dCellNNs is efficient in capturing &amp; enhancing texture features. With moderate feature dimensionality and computational costs, it could improve texture classification, acquiring an obvious accuracy increase on previous state-of-the-art ones, e.g., a rise of 2.58% on KTH-TIPS2b, a rise of 3.11% on Brodatz, a rise of 0.71% on OTC12 and a rise of 0.42% on UIUC.\nHighlights\n\u2022\nA multi-scale across-domain feature fusion of textures and contours is proposed.\n\u2022\nThe first deep model of CellNN (dCellNNs) with two-stage training is proposed.\n\u2022\nThe three-channel texture contour extractor of dCellNNs is designed.\n\u2022\nA weighted-base fusing is designed for the across-domain fusion of features.","One of the significant challenges in Brain\u2013Computer Interface (BCI) is to develop a classifier that can decode users\u2019 mental states based on electroencephalogram (EEG) data collected from independent subjects. The focus of such subject-independent (SI) classification is justified because it can lead to BCIs that do not require a user-specific calibration process. In recent years, the emergence of deep neural networks (DNNs) has significantly improved the performance of EEG classification. Among various deep learning techniques, the training efficiency and the performance of Convolutional Neural Networks (CNNs), in particular, have led to several state-of-the-art architectures for accurate classification of EEG. Not surprisingly, the efforts to improve the performance of these architectures for EEG classification have been ramped up in recent years. In this regard, a trivial approach is to train and tune a large number of architectures and hyperparameters and hope to improve upon the existing results. In contrast with this ad hoc approach, here we put forward a systematic method inspired by the jackknife estimation to improve the performance of existing CNN architectures. Using EEGNet and ShallowConvNet as archetypical, our empirical results show that the proposed \u201cDelete-a-Subject Jackknife\u201d (DASJ) technique can potentially improve the performance of existing CNN architectures for SI classification of EEG.\nHighlights\n\u2022\nProposes DASJ-CNN which is a jackknife-inspired approach with Convolutional Neural Network (CNN) base classifiers.\n\u2022\nPresents an analytical motivation of the DASJ ensemble classification.\n\u2022\nEvaluates the effectiveness of the method using two state-of-the-art CNN architectures for EEG classification.\n\u2022\nDemonstrates the capability of the method to improve the performance of existing CNN architectures.","Deep Learning (DL) has enabled considerable increases in the accuracy of classification tasks in several domains, including Human Activity Recognition (HAR). It is well-known that when data distribution changes between the training and test datasets, the accuracy can drop, sometimes significantly. However, some variability sources in HAR, such as sensor orientation, are only sometimes considered when evaluating these models. Therefore, we must understand how much such changes could impact current DL architectures. In this paper, under an orientation variability scenario, we evaluate three common DL architectures, DeepConvLSTM, TinyHAR, and Attend-and-Discriminate, to quantify the performance drop attributed to this shift. Our results show that all architectures show performance drops on average, as expected, but participants are affected differently from them, so they would fall short for some in classification accuracy in real-life settings where orientation can change across the wearing sessions of one participant or across participants. The performance change is related to the difference in distribution distance.","Hyperspectral image (HSI) classification has attracted significant interest among researchers owing to its diverse practical applications. Convolutional neural networks (CNNs) have been extensively utilized for HSI classification. However, the effectiveness of CNN-based approaches is constrained by the fixed size and structure of the convolutional kernels, as well as their incapacity to capture global features. Moreover, these networks are inadequate in modeling the sequential characteristics of data. Recently, a promising approach, window-based multi-head self-attention has emerged to address the limitations of CNNs and incorporate efficient sequence modeling capabilities. This paper introduces a novel method, multiscale 3D atrous convolution with a lightweight swin transformer (MACLST), that effectively combines the strengths of two networks to capture both local and global features at different scales in HSI classification. The MACLST is designed to process HSI cubes as input and employs a spectral\u2013spatial features extraction module based on multiscale 3D atrous convolution. This module involves parallel branches of 3D layers with varying atrous rates, enabling the extraction of features at multiple scales and resolutions. The extracted spectral\u2013spatial features are fused and passed to the lightweight Swin transformer module as linear embeddings. This module captures long-range dependencies and learns effective feature representations of HSI. To reduce computational complexity, the swin transformer module is simplified and consists of only two stages, offering a more efficient version of the original swin transformer. The proposed MACLST model is extensively evaluated on five widely used benchmark HSI datasets, and the experimental results validate its superiority over state-of-the-art approaches with an overall accuracy of 99.00%, 99.59%, 99.95%, 98.71%, and 94.98% on the Indian Pines, University of Pavia, Salinas Valley, Houston University 2013, and Houston University 2018 datasets, respectively.","Utilizing classical convolutional networks results in lackluster performance in certain classification tasks. To address this problem, recent solutions add extra layers or sub-networks to increase the classification performance of existing networks. More recent methods employ multiple networks coupled with varying learning strategies. However, these approaches demand larger memory and computational requirement due to additional layers, prohibiting usage in devices with limited computing power. In this paper, we propose an efficient convolutional block which minimizes the computational requirements of a network while maintaining information flow through concatenation and element-wise addition. We design a classification architecture, called Half-Append Half-Add Network (HAHANet), built using our efficient convolutional block. Our approach achieves state-of-the-art accuracy on several challenging fine-grained classification tasks. More importantly, HAHANet outperforms top networks while reducing parameter count by at most 54 times. Our code and trained models are publicly available at https://github.com/dlsucivi/HAHANet-PyTorch.","The problem of biometric person identification on the basis of component-based face recognition is considered. It is shown that the face recognition system can be represented as a hierarchically organized multilevel system, in which an ensemble of local classifiers forms \u201csoft\u201d decisions about the images of individual components of a face belonging to given classes. Then, based on the integration of these decisions, the final decision on whether the recognized face belongs to one of the given classes is formed. The problems of constructing a local classifier model, as well as choosing an integrator of intermediate solutions of local classifiers, are formulated and solved.","Imbalanced datasets are commonly observed in various real-world applications, presenting significant challenges in training classifiers. When working with large datasets, the imbalanced issue can be further exacerbated, making it exceptionally difficult to train classifiers effectively. To address the problem, over-sampling techniques have been developed to linearly interpolating data instances between minorities and their neighbors. However, in many real-world scenarios such as anomaly detection, minority instances are often dispersed diversely in the feature space rather than clustered together. Inspired by domain-agnostic data mix-up, we propose generating synthetic samples iteratively by mixing data samples from both minority and majority classes. It is non-trivial to develop such a framework, the challenges include source sample selection, mix-up strategy selection, and the coordination between the underlying model and mix-up strategies. To tackle these challenges, we formulate the problem of iterative data mix-up as a Markov decision process (MDP) that maps data attributes onto an augmentation strategy. To solve the MDP, we employ an actor-critic framework to adapt the discrete-continuous decision space. This framework is utilized to train a data augmentation policy and design a reward signal that explores classifier uncertainty and encourages performance improvement, irrespective of the classifier's convergence. We demonstrate the effectiveness of our proposed framework through extensive experiments conducted on seven publicly available benchmark datasets using three different types of classifiers. The results of these experiments showcase the potential and promise of our framework in addressing imbalanced datasets with diverse minorities.","This work proposes a novel approach to object recognition, particularly for human faces, based on the principle of human cognition. The suggested approach can handle a dataset or problem with a large number of classes for classification more effectively. The model for the facial recognition-based object detection system was constructed using a combination of decision tree clustering based multi-level Backpropagation neural network classifier-TFMLBPNN-DTC and hybrid texture feature (ILMFD+GLCM) and applied on NS and ORL databases. This model produced the classification accuracy (\u00b1standard deviation) of 95.37 \u00b10.951877% and 90.83 \u00b1 1.374369% for single input and 96.58 \u00b10.5604582% and 91.50 \u00b1 2.850439% for group-based decision for NS and ORL database respectively. The better classification results encourage its application to other object recognition and classification issues. This work's basic idea also makes it easier to improve classification management for a wide range of classes.","Graph Neural Networks (GNNs) have emerged as one of the most prominent research areas in accomplishing machine learning tasks over graphical networks. GNNs are prominently used in performing tasks like semi-supervised node classification, link prediction, and community detection. GraphSAGE is one of the most recent GNN models which is being used to accomplish these tasks. A floor plan is an architectural design of a building that represents various floor compartments. In this paper, we represent floor plan(s) as graph(s). We characterize floor room (compartment) classification as a node classification problem. We propose a variation of the traditional GraphSAGE (sample and aggregation) algorithm: Centrality based GraphSAGE (CB-SAGE), which captures the structural properties of the network. We use the average clustering coefficient and average betweenness centrality to capture structure properties. We compute CB scores for all the floor plan graphs. Top 70% nodes (based on CB scores) are selected for the training. During the training, we append the betweenness centrality score of each node as an additional feature in the feature matrix for the embedding process. We conduct experiments on the House-GAN dataset, which contains 1,43,184 vectorized floor plan images. The proposed method outperforms the current state-of-art models in accomplishing the task of floor plan classification. We compare our results with the traditional machine learning approach (MLP) and other GNN-based methods. Our approach achieves an accuracy of 96.70%, which is significantly (approximately 16%) higher than other state-of-the-art methods.\nHighlights\n\u2022\nCB-SAGE: Achieves 96 . 70 % accuracy, outperforming state of the art methods.\n\u2022\nOur innovative GraphSAGE training method relies on CB scores, not random training.\n\u2022\nUtilized three different centrality measures for diverse floor plan insights.\n\u2022\nWe show the statistical significance of our CB-SAGE model compared to other methods.\n\u2022\nOur versatile framework is applicable to various domains\u2019 problem-solving.","Sentiment analysis is an essential task in understanding human-generated textual documents. While most research into sentiment analysis focuses on monolingual sentences, in multilingual communities, a significant proportion of social media text contains a mixture of languages or code-switching. Thus, it has become vital to research and build models that handle code-switched data. However, despite significant research and custom expert neural architectures proposed, the current literature is mainly limited to modeling single language pairs. To expand on existing work and baseline performance for this particular task, we perform multiple experiments: fine-tuning pre-trained multilingual models and fine-tuning monolingual BERT models on sentence and word-level translations. The experiments are performed across five datasets where English is code-switched with Spanish, Tamil, Telugu, Hindi, and Malayalam. Our best model outperforms the current best single model that works with multiple code-switched language pairs on standard classification metrics on a binary sentiment classification task. We further expand our experiment with a ternary sentiment classification task and produce results comparable to single language-pair-specific models.","With the development of internet technology, cloud computing is becoming increasingly popular, and it has a wide range of applications in various fields, such as mobile payments and the Internet of Things. The big data model is a very important and valuable set of useful and unique information. This article mainly introduces the establishment of an object-oriented architecture-based machine learning system classification model using big data analysis methods, as well as the use of neural network algorithms to construct machine learning system classification patterns. Through examples, a comparative experiment is conducted to verify the effectiveness of traditional manual annotation modeling methods combined with parallel processing. Its experimental results show that the model has high accuracy, with an accuracy rate above 92% and a recall rate above 94%, and its F1 value is infinitely close to 1, indicating that the average accuracy and precision of the model is very high.","Diabetes is considered as one of the deadliest and chronic diseases which causes an increase in blood sugar. Many complications occur if diabetes remains untreated and unidentified. The tedious identifying process results in visiting of a patient to a diagnostic center and consulting doctor. But the rise in machine learning approaches solves this critical problem. The motive of this study is to design a model which can prognosticate the likelihood of diabetes in patients with maximum accuracy. Therefore three machine learning classification algorithms namely Decision Tree, SVM and Naive Bayes are used in this experiment to detect diabetes at an early stage. Experiments are performed on Pima Indians Diabetes Database (PIDD) which is sourced from UCI machine learning repository. The performances of all the three algorithms are evaluated on various measures like Precision, Accuracy, F-Measure, and Recall. Accuracy is measured over correctly and incorrectly classified instances. Results obtained show Naive Bayes outperforms with the highest accuracy of 76.30% comparatively other algorithms. These results are verified using Receiver Operating Characteristic (ROC) curves in a proper and systematic manner.","For imbalanced data, classification efficiency degrades significantly due to the missing information for the positive class, and existing sampling schemes do not consider the distributions of samples. Additionally, the global parameters of fuzzy neighborhoods are set manually. These defects affect the effectiveness of classifier. To address these problems, we offer an adaptive fuzzy multi-neighborhood feature selection methodology with intercluster distance-based hybrid sampling for class-imbalanced data. First, the number of clusters can be defined in terms of the number of samples in the negative or positive class. The initial centers of the clusters are determined according to the number of clusters, and the dissimilarity and similarity measures are calculated by using the intercluster distances between samples. Then, the cluster center, fuzzy membership matrix, and intercluster distance are studied, and then the optimization objective function is designed. The hybrid sampling scheme can be used to combine the generated positive class samples and negative class samples and obtain a class-balanced system. Second, according to the sample distribution, the standard deviation and a set of adaptive fuzzy multi-neighborhood radii are designed. A fuzzy multi-neighborhood similarity relation is defined by introducing a Gaussian kernel model to obtain a fuzzy multi-neighborhood granule, and an improved fuzzy multi-neighborhood rough set model is provided. Uncertain measures of fuzzy neighborhood systems are evaluated by the positive region and dependency. Third, by integrating fuzzy dependence with fuzzy complementary condition entropy, fuzzy multi-neighborhood complementary mutual information is provided on two viewpoints of algebra and information. Finally, a heuristic feature subset selection methodology for imbalanced classification with hybrid sampling using fuzzy c-means clustering is studied to obtain this excellent set of features. Experiments on 26 imbalanced datasets show the effectiveness of our designed algorithm.\nHighlights\n\u25cf\nThe optimization objective function of hybrid sampling via intercluster distance is designed to get a class-balanced system.\n\u25cf\nA set of adaptive fuzzy multi-neighborhood radii is designed to study the fuzzy multi-neighborhood similarity relation.\n\u25cf\nAn adaptive fuzzy multi-neighborhood rough set model is provided to assess uncertain measures of fuzzy neighborhood systems.\n\u25cf\nFuzzy multi-neighborhood complementary mutual information is constructed from the two viewpoints of algebra and information.","Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply the methodology to analyze six label noise correction methods according to several fairness metrics on standard OpenML datasets. Our results suggest that the Hybrid Label Noise Correction [20] method achieves the best trade-off between predictive performance and fairness. Clustering-Based Correction [14] can reduce discrimination the most, however, at the cost of lower predictive performance.","Meta-learning is one of the important methods to solve the challenging few-shot learning setting by using previous knowledge and experience to guide the learning of new tasks. Model-agnostic meta-learning (MAML) is one of the most popular meta-learning algorithms, and many variants of MAML have appeared in recent years. However, the performance of this algorithm for few-shot classification falls behind some other algorithms working on this problem. Therefore, its generalization performance needs to be further explored and improved. In view of the generalization problem, we found that MAML always shares an initialization in the process of parameter update, ignoring the bias between different tasks, resulting in limited generalization performance. On the other hand, the sample diversity of meta-learning model is low, and shallow network training is generally used, so it is difficult to obtain good performance based on deep neural network models. Based on these problems, we propose a hybrid optimization meta-learning method based on data augmentation, initialization attenuation, and resolution increase, called Mix-MAML. Experimental results show that our method reaches 76.93% classification accuracy on mini-ImageNet with 100 \u00d7 100 resolution, and 83.62% classification accuracy on CIFAR-FS with 80 \u00d7 80 resolution in the 5-way 5-shot settings under ResNet12, which achieves comparable or even better performance than other algorithms in some standard few-shot learning benchmarks without changing MAML simplicity and model-agnostic.","Recent advance in linear support vector machine with the 0-1 soft-margin loss (L 0 / 1-SVM) shows the ability to solve the 0-1 loss problem directly. However, its theoretical and algorithmic requirements restrict us from directly extending the linear solving framework to its nonlinear kernel form. The lack of an explicit expression of the Lagrangian dual function of L 0 / 1-SVM is a major shortcoming among them. By applying the nonparametric Representation Theorem, we propose a nonlinear model for support vector machine with 0-1 soft-margin loss, called L 0 / 1-KSVM, which skillfully incorporates the kernel technique, and more importantly, follows the success in systematically solving its linear problem. The optimal condition is theoretically explored and a working set selection alternating direction method of multipliers (ADMM) algorithm is introduced to obtain its numerical solution. Furthermore, we first introduce a closed-form definition to the support vector (SV) of L 0 / 1-KSVM. Theoretically, we prove that all SVs of L 0 / 1-KSVM are only located on the parallel decision surfaces. The experimental results show that L 0 / 1-KSVM has much fewer SVs compared to its linear counterpart and the other six nonlinear benchmark SVM classifiers, while maintaining good prediction accuracy.","Data stream classification is of great significance to numerous real-world scenarios. Nevertheless, the prevalent data stream classification techniques are influenced by concept drift and demonstrate unreliability in non-stationary environments. Ensemble models are typically successful when they increase diversity among their members. Several ensembles that enhance diversity have been proposed in literatures. Regrettably, there is no established method to verify that cooperativity indeed improves performance. In response to this knowledge gap, we have developed an innovative ensemble learning framework driven by diversity and cooperativity, termed EDDC, to address the issue. EDDC first dynamically maintains multiple groups of classifiers, with primary classifier in each group chosen to enhance diversity. Next, cooperativity is employed to update groups and replace outdated members. Finally, when environment changes, EDDC adaptively selects either diversity or cooperativity as the strategy for predicting labeling of new instances, while also establishing an excellent performance guarantee. Through simulation experiments, we assessed the performance of EDDC and the benefits of cooperativity for enhancing prediction. The results demonstrated that EDDC is efficient and robust in most scenarios, particularly when dealing with gradual drift. Furthermore, EDDC maintains a competitive edge in terms of classification accuracy and other metrics.\nHighlights\n\u2022\nThis paper proposes an online ensemble model driven by diversity and cooperativity for data stream classification called EDDC.\n\u2022\nAn adaptive voting-strategy is proposed in this paper, which selects diversity or cooperativity as voting methods in ever-changing environment.\n\u2022\nAccording to simulation results, EDDC works superior to the-state-of-art ensembles, especially on gradual drifting stream.","The increasing availability of quantitative data in archaeological studies has prompted the research of Machine Learning methods to support archaeologists in their analysis. This paper considers in particular the problem of automatic classification of 3D surface patches of \u201crubble stones\u201d and \u201cwedges\u201d obtained from Prehistorical and Protohistorical walls in Crete. These data come from the W.A.L.(L) Project aimed to query 3D photogrammetric models of ancient architectonical structures in order to extract archaeologically significant features. The principal aim of this paper is to address the issue of a clear semantically correspondence between data analysis concepts and archaeology. Classification of stone patches has been performed with several Machine Learning methods, and then feature relevance has been computed for all the classifiers. The results show a good correspondence between the most relevant features of the classification and the qualitative features that human experts adopt typically to classify the wall facing stones.","With the game market growing year by year, game developers find themselves in an extremely competitive scenario. To draw players attention towards their game and to engage them even more during gameplay, one alternative is to apply a Dynamic Difficulty Adjustment algorithm. But the problem of the DDA approach is usually not the algorithm itself, but the player classification step. Therefore, we created a generic Unity Plugin that, allied with a Python API, will be able to classify players, using unsupervised and supervised Machine Learning techniques, based on game telemetry. We also implemented our own simple DDA algorithm, to test how it would work allied with the online classification process. The results show that the DDA version outperforms the standard one in the Video-Game category (CEGE Framework). The resultant classification was 63% completely accurate and 100% partially accurate. Moreover, no other work was able to create a generic plugin that simplified the use of ML in the game development context, allowing to test 28 different algorithm combinations.","Brain computer interface (BCI), has been one of the most popular domains in computing in the recent years. BCI is a pathway which allows communication between computers and the human brain. We acquire real time EEG data with the device, Neurosky Mindwave Mobile, which uses a single dry electrode. Experiment for acquisition of data is carried on 40 subjects (33 male and 7 female). Feature extraction of EEG signals are done by statistical measures such as mean, standard deviation, maximum and minimum amplitudes. In this paper we explore the approach of ensemble learning with classifiers such as random forest classifier to build a BCI model to predict mental states as concentration and meditation. Analysis and results of our proposed model shows an accuracy of 75% using the above methodologies. This model is further implemented in the field of Internet of Things (IoT), for the application of home automation.","Large-scale natural soundscapes are remarkably complex and offer invaluable insights into the biodiversity and health of ecosystems. Recent advances have shown promising results in automatically classifying the sounds captured using passive acoustic monitoring. However, the accuracy performance and lack of transferability across diverse environments remains a challenge. To rectify this, we propose a robust and flexible ecoacoustics sound classification grid search-based framework using optimised machine learning algorithms for the analysis of large-scale natural soundscapes. It consists of four steps: pre-processing including the application of spectral subtraction denoising to two distinct datasets extracted from the Australian Acoustic Observatory, feature extraction using Mel Frequency Cepstral Coefficients, feature reduction, and classification using a grid search approach for hyperparameter tuning across classifiers including Support Vector Machine, k-Nearest Neighbour, and Artificial Neural Networks. With 10-fold cross validation, our experimental results revealed that the best models obtained a classification accuracy of 96% and above in both datasets across the four major categories of sound (biophony, geophony, anthrophony, and silence). Furthermore, cross-dataset validation experiments using a pooled dataset highlight that our framework is rigorous and adaptable, despite the high variance in possible sounds at each site.","Crop disease is a major threat to agricultural production. Reduced yield due to crop diseases can lead to immeasurable economic losses. Therefore, the detection and classification of crop diseases are of great significance. Based on AlexNet, VggNet, ResNet, and DenseNet, this paper presents an Ensemble Network improve the recognition accuracy. In this study, firstly training four CNN models by randomly sampling the dataset. Before that, these CNN were improved by batch normalization and global average pooling to accelerate convergence, designed a dynamic concatenated ReLU, an improved activation function on ReLU, to improved detection performance. We use focal loss to solve data imbalance. Then weighted voting is used to fuse the four CNN models. Finally, we verify that the EnsembleNet can effectively improve the recognition performance compared with a single network. Verified improvement in recognition performance on our datasets, obtained from PlantVillag.org, containing 4577 citrus leaf images of three categories. The maximum test accuracy in identifying citrus leaf diseases was as high as 93.58\n%\n. Compared with single network, our EnsembleNet can significantly performance. The experimental results showed that this method can be practically applied to the identification of citrus leaf diseases and provides a basis for the identification of other plant leaf diseases.","Deep learning-based incipient fault diagnostic techniques have achieved surprisingly well in wind turbines. Due to component failures, wind turbines must undergo active maintenance, substantially influencing revenue and power generation. Unfortunately, there are consistently uneven data distributions between samples with faults and those without faults, resulting in incorrect fault classification. Wind turbine fault classification has a significant data imbalance problem, compromising learning attention for majority and minority classes. Machine learning methodologies based on Generative Adversarial Networks (GAN), over-sampling, and under-sampling techniques for generating synthetic data have been widely employed to address the imbalance data problem. However, the traditional synthetic minority oversampling technique (SMOTE) accomplishes oversampling using linear interpolation between close minority class samples, which could be confusing, subpar, and indistinguishable from the majority class. This study suggests combining over and under-sampling using adaptive SMOTE and edited nearest neighbors (ASMOTE-ENN) that incorporate over-sampling with adaptive SMOTE and under-sampling with ENN to improve the quality of the generated samples. With this resampling technique, noise in an imbalanced dataset is reduced on three levels by using an adaptive nearest neighbor selection algorithm to find the nearest neighbors that are visible. Then use SMOTE to create samples that precisely fall into the minority class, and later use the ENN technique to eliminate instances that contribute to noise afterwards. Resampling data created by combining over- and under-sampling approaches to match the data distribution over all classes is the foundation of the suggested method\u2019s efficacy. A hybrid ensemble method is used for effective classification, including boosting, bagging, and stacking techniques. The original unbalanced and balanced data using the ASMOTE-ENN algorithm were classified using the proposed hybrid ensemble method. The classification results show that the proposed strategy is more accurate than a few imbalanced fault diagnosis techniques.\nHighlights\n\u2022\nTo gain complete knowledge, characteristics of SCADA data are obtained using data analysis.\n\u2022\nWe present the adaptive SMOTE-ENN algorithm-based data resampling technique to deal with imbalanced data.\n\u2022\nCreate a hybrid ensemble classification technique to identify faulty and no-fault events effectively.\n\u2022\nThe results demonstrate that the suggested method outperforms the most popular ML techniques.","Speech emotion recognition (SER) is a crucial aspect of affective computing and human-computer interaction, yet effectively identifying emotions in different speakers and languages remains challenging. This paper introduces SER-Fuse, a multi-modal SER application that is designed to address the complexities of multiple speakers and languages. Our approach leverages diverse audio/speech embeddings and text embeddings to extract optimal features for multi-modal SER. We subsequently employ multi-feature fusion to integrate embedding features across modalities and languages. Experimental results archived on the English-Chinese emotional speech (ECES) dataset reveal that SER-Fuse attains competitive performance in the multi-lingual approach compared to the single-lingual approaches. Furthermore, we provide the implementation of SER-Fuse for download at https://github.com/nhattruongpham/SER-Fuse to support reproducibility and local deployment.","To better understand how accurate opaque black box models work, it is necessary to explain their internal workings in terms of human-interpretable image sub-regions known as concepts. This explanation will provide insights into how these models perceive the sharedness of concepts across related classes, as frequently observed in the real world. With this objective in mind, the proposed work aims to leverage an incremental Non-negative Matrix Factorization technique to extract shared concepts in a memory-efficient manner, thereby reflecting the sharedness of concepts across classes. The relevance of the extracted concepts towards prediction, as well as the encoding of primitive image aspects such as color, texture, and shape by the concept, will be estimated after training the concept extractor. This approach reduces training overhead and simplifies the explanation pipeline, enabling the elucidation of various concepts - some genuine, some spurious - on which different black box architectures trained on the Imagenet dataset group and distinguish related classes.","Artificial neural networks are being used in many fields for different purposes. Medical diagnosis is one of the major purposes. In the field of medical, classification plays an important role as the main aim of the doctor is to classify whether a person is suffering from the disease or not. The objective of this paper is to evaluate neural network for the detection of alopecia in human beings and to find the accuracy. With the help of proposed model, the clinical experts will be able to get a second opinion that will help them to take proper decisions for diagnosing the presence of this disease in patients. This second opinion is crucial due to many factors while doing disease identification. These factors include increased population, environmental pollution, growing demands for proper medication, and less availability of medical experts to cope up with this increasing demand. Also, the dynamic nature of disease symptoms plays an important role in correct diagnosis of a certain disease. The proposed system uses a feedforward artificial neural network and backpropagation algorithm to classify patients with alopecia and without alopecia. The evaluation of the proposed system is done with the help of performance plot as well as regression plot. Experimental results show that the accuracy of proposed system is 91% which is reliable enough for a clinical expert to make his decisions.","Skip Abstract Section\nAbstract\nThe earth\u2019s ecology is well balanced and protected by forests. On the other hand, forest fires affect forest resources, thus causing both economical and ecological losses. Hence, preserving forest resources from fires is very essential to reduce environmental disasters. Controlling forest fire at an early stage is necessary to control their spread. This requirement enforces the necessity of fast and reliable fire detection algorithms. In this paper, a color models aware dynamic feature extraction for forest fire detection using machine learning classifiers is proposed to achieve early detection of fire and reduced false alarm rate. The proposed algorithm extracts fire detection index, wavelet energy, and gray level co-occurrence matrix features from RGB, L*a*b*, and YCbCr color models respectively to train the machine learning classifiers. The performance of the proposed model is analysed using various machine learning algorithms and the standard classification metrics. The proposed color-aware feature extraction gives precision, recall, F1-score, and accuracy of 99, 95, 94, and 97% respectively for the K-nearest neighbourhood model. The support vector machine model delivers 98, 95, 93, and 96.5% respectively. The accuracy of the proposed model is improved by a minimum of 3%, and a maximum of 11% than other color models. Similarly, the false rate reduction is a minimum of 5% and a maximum of 17% than other models.","Normal blood supply to the human brain may be marred by the presence of a clot inside the blood vessels. This clot structure called emboli inhibits normal blood flow to the brain. It is considered as one of the main sources of stroke. Presence of emboli in human\u2019s can be determined by the analysis of transcranial Doppler signal. Different signal processing and machine learning algorithms have been used for classifying the detected signal as an emboli, Doppler speckle, and an artifact. In this paper, we sought to make use of the wavelet transform based algorithm called Wavelet Scattering Transform, which is translation invariant and stable to deformations for classifying different Doppler signals. With its architectural resemblance to Convolutional Neural Network, Wavelet Scattering Transform works well on small datasets and subsequently was trained on a dataset consisting of 300 Doppler signals.\nTo check the effectiveness of extracted Scattering transform based features for Doppler signal classification, learning algorithms that included multi-class Support vector machine, k-nearest neighbor and Naive Bayes algorithms were trained. Comparative analysis was done with respect to the handcrafted Continuous wavelet transform features extracted from samples and Wavelet scattering with Support vector machine achieved an accuracy of 98.89%. Also, with set of extracted scattering coefficients, Gaussian process regression was performed and a regression model was trained on three different sets of scattering coefficients with zero order scattering coefficients providing least prediction loss of 34.95%.\nHighlights\n\u2022\nA white-box network Wavelet scattering transform is used for Doppler signal classification.\n\u2022\nWith architecture similarity to convolutional neural network, Wavelet scattering transform is well suited for small datasets.\n\u2022\nContinuous wavelet transform based handcrafted features are extracted for comparison with Wavelet scattering transform.\n\u2022\nRegression and classification results are presented for Doppler signal dataset.","Multi-label feature selection, which addresses the challenge of high dimensionality in multi-label learning, has wide applicability in pattern recognition, machine learning, and related domains. Most existing studies on multi-label feature selection assume that all labels have the same importance with respect to features, however, they overlook the differences between labels and candidate features relative to selected features and the internal influence of the label space. To address this issue, we propose a novel method for multi-label feature selection that accounts for both the strongly relevant label gain and the label mutual aid. Firstly, we advance two new potential relationships between labels and candidate features relative to selected features, and the label discriminant function is introduced. Secondly, the mutual aid information between labels is presented to describe the internal correlation of the label space. Thirdly, the concept of strongly relevant label gain is defined based on the label discriminant function, which allows better exploration of positive correlation between features. Finally, the experimental results on sixteen multi-label benchmark datasets indicate that the proposed method outperforms other compared representative multi-label feature selection methods.\nHighlights\n\u2022\nTwo relationships are proposed from the perspective of fuzzy information measures.\n\u2022\nA label discriminant function is defined according to two proposed relationships.\n\u2022\nStrongly relevant label gain is proposed based on the label discriminant function.\n\u2022\nThe label mutual aid is defined based on fuzzy conditional mutual information.\n\u2022\nA novel multi-label feature selection algorithm is proposed.","Psychological changes in humans are the result of emotions which occur due to activities in daily life. To understand these changes in behavioral pattern, research on a ective computing has emerged. Emotions are an integral part of our daily lives, based on which in this paper an investigation have been made to analyze the impact of positive and negative emotions using Electroencephalogram (EEG). Three classes of emotions namely calm, anger and happiness have been studied. The EEG signals are recorded in real time from 10 subjects while watching di erent emotions video clips of 2 minutes each. Next, the fractal dimension feature has been extracted from raw EEG. To further detect emotional states, the extracted features have been classified using Support Vector Machine (SVM) with radial basis function (RBF) kernel with an average accuracy of 60%. The proposed methodology shows that emotions recognition is possible from EEG signals.","Amidst the critical role that high-quality labeled data plays in advancing machine learning, the persistence of noise within widely-used datasets remains a challenge. While noise learning has gained traction within machine learning, particularly in computer vision, its exploration in text and multimodal classification domains has lagged. Furthermore, a comprehensive comparison of noise learning techniques in text and multimodal classification has been lacking, partly due to variations in experimental noise settings across prior studies. Addressing these gaps, this research introduces a pioneering Multimodal Infusion Joint Training (MinJoT) framework featuring a novel co-regularized loss function that seamlessly integrates multimodal information during joint training. This framework notably excels in maintaining model robustness amidst noisy data environments. Adapting established noise learning methods from computer vision to text classification, the study conducts extensive experiments across five English and Chinese textual and multimodal datasets, involving four methods, five noise modes, and seven noise rates. Critically, this work challenges the implicit assumption that widely-used datasets are devoid of noise, revealing that these datasets indeed encompass noise levels ranging from 0.61% to 15.77% which is defined as intrinsic noise in this study. For the first time, the study investigates the impact of intrinsic noise on model performance, categorizing it into distinct levels of ambiguity. To facilitate accurate method comparison, a new dataset, Golden-Chnsenticorp (G-Chnsenticorp), is introduced, carefully crafted to be free of intrinsic noise. This research establishes the inaugural noise learning benchmark for text classification, while simultaneously pioneering the first noise learning framework tailored for multimodal sentiment classification. Through these contributions, the study advances the understanding of noise learning in text and multimodal contexts, providing a novel framework, benchmarks, and insights to propel the field forward.\nHighlights\n\u2022\nIntroducing MinJoT, a novel noise learning framework for multimodal classification.\n\u2022\nStudying intrinsic noise in text classification and its impacts.\n\u2022\nCreating G-Chnsenticorp, a noise-free dataset, for reliable research in this area.","Protein sequence classification is a crucial research field in bioinformatics, playing a vital role in facilitating functional annotation, structure prediction, and gaining a deeper understanding of protein function and interactions. With the rapid development of high-throughput sequencing technologies, a vast amount of unknown protein sequence data is being generated and accumulated, leading to an increasing demand for protein classification and annotation. Existing machine learning methods still have limitations in protein sequence classification, such as low accuracy and precision of classification models, rendering them less valuable in practical applications. Additionally, these models often lack strong generalization capabilities and cannot be widely applied to various types of proteins. Therefore, accurately classifying and predicting proteins remains a challenging task. In this study, we propose a protein sequence classifier called Multi-Laplacian Regularized Random Vector Functional Link (MLapRVFL). By incorporating Multi-Laplacian and L 2,1 \u2212 norm regularization terms into the basic Random Vector Functional Link (RVFL) method, we effectively improve the model's generalization performance, enhance the robustness and accuracy of the classification model. The experimental results on two commonly used datasets demonstrate that MLapRVFL outperforms popular machine learning methods and achieves superior predictive performance compared to previous studies. In conclusion, the proposed MLapRVFL method makes significant contributions to protein sequence prediction.\nHighlights\n\u2022\nMLapRVFL improves protein sequence prediction.\n\u2022\nEnhanced generalization and accuracy with Multi-Laplacian and L 2,1 \u2212 norm regularization terms.\n\u2022\nMLapRVFL outperforms in protein sequence classification.","Eosinophilic Esophagitis (EoE) is an allergic condition increasing in prevalence. To diagnose EoE, pathologists must find 15 or more eosinophils within a single high-power field (400X magnification). Determining whether or not a patient has EoE can be an arduous process and any medical imaging approaches used to assist diagnosis must consider both efficiency and precision. We propose an improvement of Adorno et al\u2019s approach for quantifying eosinphils using deep image segmentation. Our new approach leverages Monte Carlo Dropout, a common approach in deep learning to reduce overfitting, to provide uncertainty quantification on current deep learning models. The uncertainty can be visualized in an output image to evaluate model performance, provide insight to how deep learning algorithms function, and assist pathologists in identifying eosinophils.","The ability to classify images is dependent on having access to large labeled datasets and testing on data from the same domain of which the model was trained on. Classification becomes more challenging when dealing with new data from a different domain, where gathering and especially labeling a larger image dataset for retraining a classification model requires a labor-intensive human effort. Cross-domain classification frameworks were developed to handle this data domain shift problem by utilizing unsupervised image-to-image translation models to translate an input image from the unlabeled domain to the labeled domain. The problem with these unsupervised models lies in their unsupervised nature. For lack of annotations, it is not possible to use the traditional supervised metrics to evaluate these translation models to pick the best-saved checkpoint model. This paper introduces a new method called Domain-knowledge Inspired Pseudo Supervision (DIPS) which utilizes Gaussian Mixture Models and domain knowledge to generate pseudo annotations to enable the use of traditional supervised metrics. This method was designed specifically to support cross-domain classification applications contrary to other typically used metrics such as the Fr\u00e9chet Inception Distance (FID) which were designed to evaluate the model in terms of the quality of the generated image from a human-eye perspective. DIPS outperforms state-of-the-art GAN evaluation metrics when selecting the optimal saved checkpoint. Furthermore, DIPS showcases its robustness and interpretability by demonstrating a strong correlation with truly supervised metrics, highlighting its superiority over existing state-of-the-art alternatives The boiling crisis problem has been approached as a case study. The code and data to replicate the results can be found on the official GitHub-repository https://github.com/Hindawi91/DIPS. .\nHighlights\n\u2022\nDIPS utilizes domain knowledge and a GMM model to provide pseudo supervision.\n\u2022\nDIPS introduces a metric for evaluating UI2I models in cross-domain classification.\n\u2022\nDIPS outperforms SOTA unsupervised metrics such as the FID, KID, IS and MMD.\n\u2022\nDIPS correlates highly with true supervision, making it robust and explainable.\n\u2022\nDIPS real-world applicability is demonstrated through the boiling crisis problem.","In this paper, we address an issue of finding explainable clusters of class-uniform data in labeled datasets. The issue falls into the domain of interpretable supervised clustering. Unlike traditional clustering, supervised clustering aims at forming clusters of labeled data with high probability densities. We are particularly interested in finding clusters of data of a given class and describing the clusters with the set of comprehensive rules. We propose an iterative method to extract high-density clusters with the help of decision-tree-based classifiers as the most intuitive learning method, and discuss the method of node selection to maximize quality of identified groups.","Nature inspired algorithms have become popular for discovering classification rules due to their ability to effectively handle large and complex search spaces. However, nature inspired algorithms have to compute the fitness of individuals (candidate classification rules) over successive generations repeatedly. Each fitness computation requires scanning the training data. Since the database scan is computationally expensive operation, the execution time for nature inspired algorithms for discovering classification rules grows unreasonably faster for bulky datasets. This paper proposes a novel fitness computation framework for nature inspire algorithms by using a list structure. The indices of instances, covered by every possible attribute-value pair with respect to each class in the training data, are stored in the suggested list structure. The list is prepared only once in advance and stores all information to compute the fitness of any rule that may come up in the life time of the nature inspired algorithm. The existence of the pre-maintained list eliminates the need of scanning training data again and again for fitness computation. We have conducted experiments on 12 datasets from UCI machine learning repository. The results show that the suggested fitness computational framework brings significant speed gain without compromising predictive accuracy. Although, a Genetic Algorithm is used for classification rule discovery as the nature inspired algorithm in this paper, the fitness computation framework is general and can be used with any other nature inspired algorithm.","Although the high number of bands in hyperspectral remote sensing images increases their usefulness, it also causes some processing difficulty. In supervised classification, one problem is decreasing classification accuracy due to the insufficient training samples against the bands. A way to deal with this problem is the selection of appropriate bands by the metaheuristic methods. Because of the stochastic search, the selected bands differ in any implementation of a metaheuristic method. So, the results obtained from the classification of these different band subsets will also have some differences. In this study, a fusion-based approach has been proposed to improve the classification of hyperspectral remote sensing images by multiple implementations of a metaheuristic method for band selection. We have tested the proposed method using ten metaheuristic methods with different objective functions on four well-known datasets. The results show the proposed fusion-based approach successfully improves the classification accuracy in all experiments. The accuracy improvement varies depending on the metaheuristic method, the objective function, and the dataset and ranges from 0.4% to 15.7%. The proposed method improves the classification of complex datasets more and affects weaker objective functions considerably. The results also show the proposed method brings the accuracy of different metaheuristic methods close to each other and reduces the sensitivity of selecting the proper ones. Thus, an automated classification system can be obtained using a parameter-less method.\nHighlights\n\u2022\nA new fusion-based classification is proposed for hyperspectral images based on stochastic nature of metaheuristic methods.\n\u2022\nA fully automated classification system is developed to classify hyperspectral remote sensing images.\n\u2022\nMany Traditional and new metaheuristic methods include PSO, CSO, GWO, GEO, JSA, \u2026 are examined in the proposed framework.\n\u2022\nThe experiments are done in both case of filter and wrapper band selection with different objective function.","As pests can cause heavy crop losses, integrated pest management is a vital aspect of agriculture. In general, pest recognition is essential to the integrated pest management. Many studies have explored how to achieve automatic pest recognition using computer vision and artificial intelligence techniques. However, most existing methods did not consider the class ambiguity problem. That is, a pest image may belong to multiple possibly true categories, but only one possible class label is assigned to the pest image. To close the above gap, this study converted the conventional one-label pest classification task into a multi-label one. In detail, the state-of-the-art deep network, Swin Transformer, was first modified to enable the predicted scores of possible classes to approximate one simultaneously by replacing the fully connected soft-max layer with a sigmoid activation layer. Then, a two-stage supervised learning algorithm using the binary cross entropy loss and the novel soft binary cross entropy loss was designed to train the Swin-Transformer-based multi-label classification model with single-label images. Experiments on the IP102 image dataset showed that the proposed method obtained the highest F 1-score value of 60.83%. It outperformed the second-best one by a margin of 7.52%. In conclusion, the proposed method can tackle the pest class ambiguity problem on IP102 better.\nHighlights\n\u2022\nExploit the multi-label classification to tackle the pest class ambiguity problem.\n\u2022\nDevelop a modified Swin-Transformer-based multi-label classification model.\n\u2022\nPropose the soft binary cross entropy loss to train the model with single-label images.","This study conducts a thorough evaluation of deep learning architectures, pretraining methods, and finetuning approaches for mammogram classification for tissue density. No architecture was distinctly superior. However, models pretrained on ImageNet consistently surpassed those trained on custom mammogram datasets. Finetuning strategies played a crucial role in model performance. In particular, finetuning the entire model yielded better results. Investigation of confusion matrices revealed that most misclassifications occurred within a one-grade difference, but severe misclassifications were observed in certain configurations. While some architectures offered comparable performance, trade-offs between model performance and computational efficiency were observed, with convolutional neural networks showing faster inference times on CPUs compared to vision transformers.","Multiple instance learning (MIL) is a classic weakly supervised learning approach, in which samples are grouped into bags that may contain varying numbers of instances. A bag is designated as positive if it contains at least one positive instance; otherwise, it is considered negative. Previous studies have consistently assumed that the bag labels are completely known. In fact, labeling every bag can be extremely challenging or even unfeasible due to the exorbitant expenses in terms of time and labor. Fortunately, it is much easier to obtain the similarity confidence, which represents the probability of two bags sharing the same label. How to employ it in MIL is worthy of study. Inspired by the above study, we present the first attempt to investigate MIL from similarity-confidence bags. Therefore, this paper proposes a new framework for training bag-level classifiers that adheres to the principle of empirical risk minimization. Moreover, we theoretically derive a generalization error bound to guarantee model convergence. Finally, we implement risk correction to mitigate potential over-fitting problem and provide theoretical consistency. Numerical experiments on eight datasets further validate the effectiveness of the proposed bag-level classifier.\nHighlights\n\u2022\nWe first explore MIL from similarity-confidence bags that makes sense in many scenes.\n\u2022\nWe propose an unbiased estimator at bag-level that does not rely on loss or optimizer.\n\u2022\nWe introduce a method for estimating unknown prior probability.\n\u2022\nWe derive a theoretical error bound and a optimal parameter convergence rate.\n\u2022\nWe employ risk correction methods to mitigate over-fitting and derive the consistency.","Smart buildings are generally equipped with thousands of heterogeneous sensors and control devices that impact the operation of their electrical systems. Analytical tools that aim to optimise the energy efficiency within such complex systems requires prior mapping or (classification) of diverse set of sensors according to a standard. Prior research primarily focuses on exploiting the similarities in sensor names (text metadata) to categorise them into identical classes (or groups). However, the sensors within and across buildings often follow distinct naming conventions by different vendors. In addition the definition of the classes or groups also varies significantly amongst researchers. This limits the usability and portability of prior techniques when applied across buildings. There are standard ontologies (Brick, Haystack etc.) that provide a set of standardized classes for the sensors in the buildings. The work herein follows a new avenue to address this challenging classification problem by (i) utilizing only time-series data of sensors and not text metadata, (ii) developing a simple, effective and hitherto unexplored Machine Learning (ML) model to classify the sensors into a set of standard Brick classes, and (iii) evaluating the model on a large proprietary dataset comprising of 129 buildings. Experimental results demonstrate promising performance of the presented data driven model, with average classification accuracy in terms of weighted F-score at 0.78 (\u00b10.14), and statistically significant improvements over prior methods.","Existing studies have recognized the effect of noise of granulated datasets on classification performance. Whether this effect continues an aid in generating decisional rules for the tree-based learning models needs to be disclosed. This study conducts an experiment that investigates the effect of noisy data on rule generation performance (RGP). The unsupervised (equal-width interval, EWI) and 28 supervised (minimum description length, MDL) techniques were used to granulate datasets. The decision-tree based classification model that either included or did not include 24 EWI and 28 MDL noisy granulated datasets were used, followed by testing and comparison on classification accuracy and RGP. Main results are as follows. Removal of noisy granulated datasets with EWI is advantageous to decision tree generation when original classification accuracy (OCA) of datasets is higher than 90% or less than 70%, but not obvious between 70% and 90%. Contrariwise, those with MDL is neither highly related to improvement of generation rate nor simplicity for scales of both higher than 90% and less than 70%, but slightly related to those with OCA between 70% and 90%.","Over the past two decades, an increasing number of large-scale structures have been built around the world. Constructing these structures has been a time consuming and highly expensive process. Thus, providing a structural health monitoring system to guarantee their proper functionality is important. In recent years, the advancement of technology and artificial intelligence methods based on signal processing and machine learning has attracted the attention of researchers. The challenges currently exist in the field of structural health monitoring to identify and classify damages to achieve high accuracy in a health-monitoring program. The presence of noise in measurement, various exciting load types, and varying environmental conditions cause difficulty in the practical identification and classification of damage in structures. Recent studies have employed finite element modeling to test the effectiveness of proposed methods for identifying damages in structures. However, detecting damage in real-world structures as mentioned above, presents unique difficulties, and the effectiveness of the proposed methods for damage detection in real-world structures remains uncertain. In order to improve the performance of damage detection methods and increase the accuracy of these methods as much as possible, the most important action is to identify damage sensitive data in the structure. The next challenge is to choose a high performance algorithm for damage identification and classification. One of the advanced algorithms, which has a very high ability to extract the desired features from the measured data, is the XGBoost algorithm. This algorithm has recently attracted the attention of researchers and has been used in different fields. So far, the ability of this algorithm has not been examined in the field of damage detection in order to extract desirable features. This article deals with the identification, classification, and severity of damages in the SMC benchmark bridge, which is an existing megastructure in the real world, as well as the IASC-ASCE benchmark structure, whose responses were taken under applied loads in the laboratory environment. First, using the XGBoost algorithm, the importance of the features extracted from the sensors' data is evaluated, and then the features, which are effective in the damage detection process, are selected. The results of this algorithm indicate that only by selecting 6 features from a large volume of data, the best performance can be achieved and selecting more does not help increase efficiency. In the next step, the Stacking method, which is a hybrid machine learning algorithm for damage classification, is evaluated and compared with some conventional machine learning algorithms that have been used in previous studies. The Stacking method stands out as the top performer with an average accuracy rate of 93.1%, leading to the conclusion that it is the most effective approach. Finally, by applying the presented algorithm to the two mentioned structures, its validation is appraised.","Ensemble learning is a technique of combining multiple base machine learning models and using the blended results as the final classification output. Such models provide a unique perspective on the classification results as it produces a more comprehensive and encompassing output. As such ensemble learning techniques are widely used for classification in today. Hence it is important that any ensemble learning model be robust and resilient to any type of data and not just applicable to one dataset. This research investigates and evaluates the robustness and the resilience of the proposed Legitimacy ensemble learning model. This ensemble learning model was previously proposed for Credibility Based Fake News Detection. This research evaluates Legitimacy\u2019s performance with a variety of datasets. In the first scenario, the Legitimacy ensemble learning model is evaluated with 3 different binary classification datasets for training and testing purposes, respectively. In the second scenario, the Legitimacy model is assessed where one dataset is used for training whilst another dataset is used for testing. In the final scenario the Legitimacy ensemble learning model is evaluated against a multiclass dataset for multiclass classification. The results of all the above tests are assimilated and evaluated. The results suggest that the Legitimacy ensemble learning model performs well in all three scenarios giving AUC values all equal to or greater than 0.500. As such it can be concluded that the Legitimacy model is a robust and resilient ensemble learning technique and can be employed for the task of classification with any dataset.","The Antinuclear Antibody (ANA) test is a valuable diagnostic tool for autoimmune disorders that uses Indirect Immunofluorescence (IIF) microscopy with HEp-2 cells as the substrate to identify antibodies and their distinct staining patterns. Machine learning-based approaches have shown promise in automating this diagnosis process, with Data Augmentation (DA) techniques playing a crucial role in improving performance. Even though traditional DA methods have yielded positive results, generative techniques like Variational AutoEncoders (VAEs) have shown potential in exploring the input distribution and generating new images. To address the limitations of traditional DA and explore the potential of generative approaches, this paper focuses on applying Conditional Variational AutoEncoders (CVAEs) to HEp-2 cell image classification. A customized CVAE architecture is proposed, considering multiple labels during generation to enhance versatility. Extensive experiments were conducted with the largest publicly available dataset of HEp-2 cell images, the I3A dataset. The performance of traditional and generative data augmentation techniques were compared while investigating potential synergies between them. The findings highlight the benefits of combining these techniques, especially in scenarios with class imbalance. Thorough statistical analysis provides valuable insights from the experimental results.","Neurodegenerative disorders like Alzheimer\u2019s disease (AD) are irreversible and show atrophies in the area of the cerebral cortex of brain. AD leads to loss of memory and other cognitive impairments. The AD subjects are evaluated based on magnetic resonance imaging scans. The data may have the problem of class imbalance, noise and outliers which is a great challenge for classification. Support vector machines and twin support vector machine-based classifiers may not effectively deal with these problems as both these models assume that all the samples are equally important for the separating hyperplane. To overcome these issues, we propose intuitionistic fuzzy least square twin support vector machine for class imbalance problems (IFLSTSVM) and class specific-IFLSTSVM (CS-IFLSTSVM). To minimize the effects of class imbalance, the samples are appropriately weighted to minimize their effect on the optimal hyperplane. Moreover, we use intuitionistic fuzzy scores to overcome the issues of noise and outliers. Intuitionistic fuzzy score values generate appropriate weights by considering both the distance of the samples from the class centroid as well as the heterogeneity of the samples. The proposed models IFLSTSVM and CS-IFLSTSVM are efficient as they need to solve a system of linear equations. In Alzheimer\u2019s disease diagnosis, the proposed IFLSTSVM and CS-IFLSTSVM models showed better performance in MCI_vs_AD and CN_vs_MCI cases, respectively. Moreover, the proposed models showed better performance in the diagnosis of breast cancer classification. The statistical analysis carried out over KEEL and UCI data leads to the superiority of the proposed models. The source code of the proposed model is available at https://github.com/mtanveer1/Diagnosis-of-Alzheimer-s-disease-via-Intuitionistic-fuzzy-least-squares-twin-SVM.\nHighlights\n\u2022\nTo handle the CIL issue, training data are assigned weights based on imbalance ratio.\n\u2022\nThe regularization term improves the generalization performance of proposed models.\n\u2022\nThe proposed models solve system of linear equations. Hence, it is very efficient.\n\u2022\nThe weights reduce the impact of noise/outliers in classifying imbalanced data.\n\u2022\nThe results on biomedical and UCI data show the superiority of proposed models.","This paper provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.","Classification of normal vs. pathological infant cry is a socially relevant and challenging problem. Many feature sets, such as Mel Frequency Cepstral Coefficients (MFCC), Linear Frequency Cepstral Coefficients (LFCC), and Constant Q Cepstral Coefficients (CQCC) have been used for this task. However, an effective representation of the spectral and pitch components of a spectrum together is not achieved leaving scope for improvement. Also, the infant cry can be considered a melodic sound implying that the fundamental frequency and timbre-based features also carry vital information. This work proposes Constant Q Harmonic Coefficients (CQHC), and Constant Q Pitch Coefficients (CQPC) extracted by the decomposition of the Constant Q Transform (CQT) spectrum for the infant cry classification. This work uses Convolutional Neural Network (CNN) as the classifier along with traditional classifiers, such as Gaussian Mixture Models (GMM) and Support Vector Machines (SVM). The results using the CNN classifier are compared by considering the MFCC, LFCC, and CQCC feature sets as the baseline features. The feature-level fusion of MFCC with log-CQHC and MFCC with log-CQPC achieved a 5-fold accuracy of 98.73% and 98.96% respectively, surpassing the baseline MFCC. Furthermore, the fusion of MFCC with log-CQHC and log-CQPC feature sets resulted in improved classification accuracy of 3%, 4.7%, and 5.85% when compared with the baseline MFCC, LFCC, and CQCC feature sets, respectively. Further, our intensive experiments using three classifiers structures, namely, GMM, SVM, and CNN indicate superior results using the proposed feature extraction techniques.","Recently, the prompt tuning technique, which incorporates prompts into the input of the pre-training language model (like BERT, GPT), has shown promise in improving the performance of language models when facing limited annotated data. However, the equivalence of template semantics in learning is not related to the effect of prompts and the prompt tuning often exhibits unstable performance, which is more severe in the domain of the scientific domain. To address this challenge, we propose to enhance prompt tuning using data augmentation with L2 regularization. Namely, pairing-wise training for the pair of the original and transformed data is performed. Our experiments on two scientific text datasets (ACL-ARC and SciCite) demonstrate that our proposed method significantly improves both accuracy and robustness. By using 1000 samples out of 1688 in the ACL-ARC training set, our method achieved an F1 score 3.33% higher than the same model trained on all 1688-sample data. In the SciCite dataset, our method surpassed the same model with labeled data reduced by over 93%. Our method is also proved to have high robustness, reaching F1 scores from 1% to 8% higher than those models without our method after the Probability Weighted Word Saliency attack.","This study introduces an ensemble methodology, namely, hybrid feature ranking and classifier aggregation (HyFraCa), to integrate ensemble feature selection and ensemble classification in a composite framework. The proposed HyFraCa is embedded in a multi-criteria decision-making (MCDM)-based scheme for feature ranking and classifier weighting, with an effective aggregation rule that yields a consensus feature ranking from ensembles of heterogeneous classifiers and feature selectors. Experimental evaluations on 20 public UCI datasets demonstrated the superiority of HyFraCa in producing a more accurate and generalizable classification compared with state-of-the-art benchmark ensemble methods. HyFraCa also provides robust and reliable consensus feature rankings, which are favorable for real-world classification problems in which feature interpretability is emphasized.","Recently meta-learning-based few-shot learning methods have been widely used for relation classification. Previous work reveals that meta-learning performs poorly in scenarios where the edge probability distribution of the target domain dataset appears to be significantly different from the source domain. In this paper, we enhance the meta-learning framework with high-dimensional semantic feature extraction and hyperplane projection metrics for meta-tasks. First, we enhance the focus of BERT on entity words by adding entity markers and vector pooling. After that, the high-dimensional semantic features of the support set are extracted and transformed into hyperplanes. Finally, we obtain the classification results by calculating the projection distance between the query sample and the hyperplane. In addition, we design a auxiliary function with a plane correction factor, which can better amplify the plane spacing and reduce the degree of category confusion, which is important for solving the problem of metric spatial loss. Experiments on two real-world few-shot datasets show that our model HPN is more effective in classifying few-shot relations in the same domain and domain-adapted scenarios. And HPN is more stable on NOTA tasks.\nHighlights\n\u2022\nA hyperplane projection network is proposed for few shot relation classification.\n\u2022\nPropose an effective entity encoder that extracts better features.\n\u2022\nFirst apply a novel hyperplane module to generate class-level feature.","In recent years, numerous machine learning-based systems have actively propagated discriminatory effects and harmed historically disadvantaged groups through their decision-making. This undesired behavior highlights the importance of research topics such as fairness in machine learning, whose primary goal is to include fairness notions into the training process to build fairer models. In parallel, Differential Item Functioning (DIF) is a mathematical tool often used to identify bias in test preparation for candidate selection; DIF detection assists in identifying test items that disproportionately favor or disadvantage candidates solely because they belong to a specific sociodemographic group. This paper argues that transposing DIF concepts into the machine learning domain can lead to promising approaches for developing fairer solutions. As such, we propose DIF-SR, the first DIF-based Sample Reweighting method for weighting samples so that the assigned values help build fairer classifiers. DIF-SR can be seen as a data preprocessor that imposes more importance on the most auspicious examples in achieving equity ideals. We experimentally evaluated our proposal against two baseline strategies by employing twelve datasets, five classification algorithms, four performance measures, one multicriteria measure, and one statistical significance test. Results indicate that the sample weight computed by DIF-SR can guide supervised machine learning methods to fit fairer models, simultaneously improving group fairness notions such as demographic parity, equal opportunity, and equalized odds.","With advances in sensing technology, multi-modal data collected from different sources are increasingly available. Multi-modal classification aims to integrate complementary information from multi-modal data to improve model classification performance. However, existing multi-modal classification methods are basically weak in integrating global structural information and providing trustworthy multi-modal fusion, especially in safety-sensitive practical applications (e.g., medical diagnosis). In this paper, we propose a novel Dynamic Poly-attention Network (DPNET) for trustworthy multi-modal classification. Specifically, DPNET has four merits: (i) To capture the intrinsic modality-specific structural information, we design a structure-aware feature aggregation module to learn the corresponding structure-preserved global compact feature representation. (ii) A transparent fusion strategy based on the modality confidence estimation strategy is induced to track information variation within different modalities for dynamical fusion. (iii) To facilitate more effective and efficient multi-modal fusion, we introduce a cross-modal low-rank fusion module to reduce the complexity of tensor-based fusion and activate the implication of different rank-wise features via a rank attention mechanism. (iv) A label confidence estimation module is devised to drive the network to generate more credible confidence. An intra-class attention loss is introduced to supervise the network training. Extensive experiments on four real-world multi-modal biomedical datasets demonstrate that the proposed method achieves competitive performance compared to other state-of-the-art ones.","The wide acceptance of decision tree classifiers lies with their fast performance and simple nature. The J48 group of decision tree classifiers are widely used for classification and decision-making process. In this paper, three popular J48 group classifiers, namely J48, J48Consolidated and J48Graft are evaluated using both binary and multi-class datasets across thirteen performance matrices, which is unique in its area. In order to come across a versatile classifier, the evaluated results of these classifiers are nourished to a prominent multi-criteria decision-making module called Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) for suitable rank allocation.","Face shape classification plays a crucial role in various applications, including facial recognition and personalized beauty rec- ommendations like hairstyles. In some cases, it is tricky to establish one's genuine facial shape, making it difficult to further process this information. This paper attempts to harness the advantages of the Swin Transformer to classify face shapes with higher accuracy. We also compared the test results with augmentation to evaluate the improvement. Our proposed method obtained 86.34% accuracy with augmentation, which is decent for further processing in various applications that require face shape recognition.","Heart disease is a major health issue, and accurate diagnosis of irregular heartbeats and heart failure is crucial. Current diagnostic processes can be time-consuming, requiring significant effort from clinicians. An effective classifier, ADCGNet: Attention-based Dual Channel Gabor Network is proposed to address this challenge by accurately classifying anomalies. ADCGNet involves pre-processing every ECG beat into two-dimensional images using Analytical Morlet transform and then applying thirty-two Gabor filters and Sobel edge detection to enhance features. ADCGNet comprises three blocks, with the first block using dual channels to extract essential features in the images efficiently. The second block includes a multi-head attention mechanism to focus on relevant features, and the third block uses a SoftMax activation function to perform classification tasks. Extensive experiments with public datasets from PhysioNet, and comparison with several state-of-the-art classifiers indicate ADCGNet is superior. Specifically, ADCGNet achieved an accuracy of 99.17%, 98.98% in precision, a recall of 98.87%, an F1-score of 98.82% and AUC, 98.75% with optimal hyperparameters. Further, a GRAD-CAM visualization of activated areas on the test samples gives graphical insight into the performance of ADCGNet. The proposed ADCGNet classifier has promising potential for enhancing the diagnosis of heart disease, and we believe it will be of much interest to the medical community.","Granular computing involves a comprehensive process that encompasses theories, methodologies, and techniques to solve complex problems, rather than being just an algorithm. As the volume of generated data continues to grow rapidly, data-driven problems have become increasingly complex. Although deep learning models have outperformed traditional machine learning models in solving complex problems, there is still room for enhancing their performance. In this paper, we propose a granular computing-based deep learning model, aimed at enhancing classifier accuracy in complex natural language-based problems. The proposed approach involves a new granulation method, which comprises a novel algorithm built on combinatorial concepts and ten rule-based numerical granules. By utilizing this granulation method, each granule adds a new representation and concept to the existing data. The proposed model consists of multiple models that perform learning separately in a granular view. In the final step, the model pays attention to the granulated matrices generated by various models. The proposed model is evaluated using datasets related to cyberbullying and two hate speech datasets, resulting in significant improvements in accuracy compared to state-of-the-art models.\nHighlights\n\u2022\nProposing a granular computing-based deep learning model for text classification.\n\u2022\nUsing granular computing for data augmentation from a new representation in the context of deep learning-based text classification.\n\u2022\nUtilizing different representations of the existing texts.\n\u2022\nProposing the first stacked-BILSTM-SVM model in granular computing.","Clinical text classification allows assigning labels to content-based data using machine learning algorithms. However, unlike other study domains, clinical texts present complex linguistic diversity, including abbreviations, typos, and numerical patterns that are difficult to represent by the most-used classification algorithms. In this sense, sequences of character strings and symbols, known as Regular Expressions (RegExs), offer an alternative to represent complex patterns from the texts and could be used jointly with the most commonly used classification algorithms for accurate text classification. Thus, a classification algorithm can label test texts when RegExs produce no matches. This work proposes a method that combines automatically-generated RegExs and supervised algorithms for classifying clinical texts. RegExs are automatically generated using alignment algorithms in a supervised manner, filtering out those that do not meet a minimum confidence threshold and do not contain specific keywords for the classification problem. At prediction time, our method assigns the class of the most confident RegEx that matches a test text. When no RegExs matches a test text, a supervised algorithm assigns a class. Three clinical datasets with textual information on obesity and smoking habits were used to assess the performance of four classifiers based on Random Forest (RF), Support Vector Machine (SVM), Naive Bayes (NB), and Bidirectional Encoder Representations from Transformers (BERT). Classification results indicate that our method, on average, improved the classifiers\u2019 performance by up to 12% in all performance metrics. These results show the ability of our method to generate confident RegExs that capture representative patterns from the texts for use with supervised algorithms.","The Internet is a crucial way to share information in both personal and professional areas. Sentiment analysis attracts great interest in marketing, research, and business today. The instability faced by imbalanced datasets on sentiment analysis is examined in this research. Balancing the datasets using techniques based on under-sampling and over-sampling is examined to achieve more efficient classification results as the effects of using BERT as word embedding and ensemble learning methods for classification. The effects of the resampling training set algorithms on different deep learning classifiers were investigated using BERT as a word embedding model and Cohen's kappa, accuracy, ROC-AUC curve, and MCC as evaluation metrics with k-fold validation on three sentiment analysis datasets containing English, Arabic, and Moroccan Arabic Dialect texts. Also, we did those performance metrics for all models when scaling the dataset for training and testing, and we calculated the memory and the execution time for each model. Finally, we analyzed the National Office of Railways of Morocco (ONCF) customers' Facebook comments in Modern Standard Arabic (MSA) and MD to determine customer satisfaction as positive, negative, and neutral comments.","Hyperspectral facial data presents creative information, taken with Hyperspectral camera, as compared to the traditional camera and images. This facial spectral dataset is a rich source of information extraction and analysis over traditional single band data with constant wavelength of Electromagnetic Spectrum (EMS). Herein study, Hyperspectral Image (HSI) classification and recognition have done in Visible to Near Infrared (NIR) region using supervised classifiers: Maximum Likelihood, Minimum Distance and SAM (Spectral Angle Mapper). The experiment is performed on CMU Hyperspectral Face Datasets (HFDS) within the spectral range of 610 to 1050 nm (VIR-NIR), having 45 spectral bands using ENVI 4.8 image processing tool. Supervised classification is performed using conventional supervised classifiers (MLH, MDA and SAM) on pre-processed HSI, further compressed dataset has classified by PCAMLH, PCAMD and PCASAM classifiers.","Protein acetylation refers to a process of adding acetyl groups (CH3CO-) to lysine residues on protein chains. As one of the most commonly used protein post-translational modifications, lysine acetylation plays an important role in different organisms. In our study, we developed a human-specific method which uses a cascade classifier of complex-valued polynomial model (CVPM), combined with sequence and structural feature descriptors to solve the problem of imbalance between positive and negative samples. Complex-valued gene expression programming and differential evolution are utilized to search the optimal CVPM model. We also made a systematic and comprehensive analysis of the acetylation data and the prediction results. The performances of our proposed method aie 79.15% in Sp, 78.17% in Sn, 78.66% in ACC 78.76% in F1, and 0.5733 in MCC, which performs better than other state-of-the-art methods.","With advancement in satellites and remote sensing technology, reflectance data are increasingly being used in agriculture. In this paper, the machine learning models have been explored with three distinct types of properties to classify the hydro-metrological rainfall parameter, Standardized Precipitation Index (SPI), and Vegetation Condition Index (VCI) to monitor the agriculture state of Rajasthan. These three distinct indexes are used to classify the geospatial Rainfall-SPI, Rainfall-VCI, and Rainfall-SPI-VCI models. The K-fold cross validation has been used to evaluate the robustness of the outperforming classification method. The outcome shows that DecisionTree and RandomForest classification model performs outstanding machine learning classification methods for vegetation with sensitivity of 0.798 and accuracy of 95.792% on test dataset with DecisionTree and of 0.796 and accuracy of 95.584% on testing dataset with RandomForest model.","Multi-view learning aims to leverage data acquired from multiple sources to achieve better performance compared to using a single view. However, the performance of multi-view learning can be negatively impacted by noisy or corrupted views in certain real-world situations. As a result, it is crucial to assess the confidence of predictions and obtain reliable learning outcomes. In this paper, we introduce CALM, an enhanced encoding and confidence evaluation framework for trustworthy multi-view classification. Our method comprises enhanced multi-view encoding, multi-view confidence-aware fusion, and multi-view classification regularization, enabling the simultaneous evaluation of prediction confidence and the yielding trustworthy classifications. Enhanced multi-view encoding takes advantage of cross-view consistency and class diversity to improve the efficacy of the learned latent representation, facilitating more reliable classification results. Multi-view confidence-aware fusion utilizes a confidence-aware estimator to evaluate the confidence scores of classification outcomes. The final multi-view classification results are then derived through confidence-aware fusion. To achieve reliable and accurate confidence scores, multivariate Gaussian distributions are employed to model the prediction distribution. The advantage of CALM lies in its ability to evaluate the quality of each view, reducing the influence of low-quality views on the multi-view fusion process and ultimately leading to improved classification performance and confidence evaluation. Comprehensive experimental results demonstrate that our method outperforms other trusted multi-view learning methods in terms of effectiveness, reliability, and robustness.","In machine learning, the term \u201dclass imbalanced\u201d is frequently used. This is a crucial part of the field of machine learning. It is quite important in the classification process and has a significant impact on performance. That is why researchers are concentrating on it to overcome this difficulty. Various researchers have devised numerous methods till now. The approaches to addressing this imbalance issue found so far can be broadly categorized into three categories, which are the data-level approach, algorithm-level approach, and hybrid-level approach. To evaluate the most recent developments in resolving the negative effects of class imbalance, this study provides a comparative analysis of research that has been published within the last 5 years with an emphasis on high-class imbalance. In this study, an attempt has been made to provide a concise overview of what imbalance classification is, how it is created, and what the inconveniences are due to it. We have tried to provide a summary of several studies that have been published in the last few years and along with that a comparative analysis of all these approaches has been done."],"author":["Sotero, Roberto C and Sanchez-Bornot, Jose M and Shaharabi-Farahani, Iman and Iturria-Medina, Yasser","Ankit and Saleena, Nabizath","El Hlouli, Fatima Zohra and Riffi, Jamal and Mahraz, Mohamed Adnane and Yahyaouy, Ali and El Fazazy, Khalid and Tairi, Hamid","Manivannan, Siyamalan","NaN","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","Senthil Kumar, Prathyusha","Kalb, Thorsten and Kushibar, Kaisar and Cintas, Celia and Lekadir, Karim and Diaz, Oliver and Osuala, Richard","Kim, Seonjun and Kim, Minjae and Lee, Youngki","Lv, Yan and Yin, Yu Jia and Guo, Wenwen and Bai, Lan","Sotero, Roberto Carlos and Sanchez-Bornot, Jose Miguel and Iturria-Medina, Yasser","NaN","Miftahushudur, Tajul and Sahin, Halil Mertkan and Grieve, Bruce and Yin, Hujun","Chen, Benwei and Zhang, Xianyong and Yang, Jilin","Verbiest, Nele and Ramentol, Enislay and Cornelis, Chris and Herrera, Francisco","NaN","Mohiuddin, Karishma and Alam, Mirza Ariful and Alam, Mirza Mohtashim and Welke, Pascal and Martin, Michael and Lehmann, Jens and Vahdati, Sahar","Ritesh and Bhagvati, Chakravarthy","Kamali Lassem, Nima and Gaafar, Obai Mohamed Hisham Abdelmohsen and Ali, Seyid Amjad","Chen, Jinqian and Zhu, Jihua and Zheng, Qinghai","NaN","Bhope, Rahul Atul and Jayaram, K. R. and Venkatasubramanian, Nalini and Verma, Ashish and Thomas, Gegi","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","NaN","Mishra, Aakriti and Ramanathan, A. and Batta, Vineet and Malathy, C. and Kundu, Soumya Snigdha and Gayathri, M. and Vathana, D. and Kamineni, Srinath","Dharwada, Sriram and Tembhurne, Jitendra and Diwan, Tausif","NaN","Liu, Dan and Zhong, Shisheng and Lin, Lin and Zhao, Minghang and Fu, Xuyun and Liu, Xueyun","Gupta, Rohan Kumar and Sinha, Rohit","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","Rajalakshmi, A. and Sridhar, S. S.","Chen, Zhikui and Lou, Kai and Liu, Zhenjiao and Li, Yue and Luo, Yiming and Zhao, Liang","Koottungal, Akash and Pandey, Shailesh and Nambiar, Athira","Airao, Jay and Gupta, Abhishek and Saraf, Gaurav and Nirala, Chandrakant K","Tripathi, Diwakar and Edla, Damodar Reddy and Kuppili, Venkatanareshbabu and Bablani, Annushree and Dharavath, Ramesh","Gyasi-Agyei, Amoakoh","Shen, Yuhao and Li, Bo and Xu, Xinlan and Luo, Bing and Zhang, Chao and Hao, Fei","Zhu, Jianjian and Su, Zhongqing and Wang, Qingqing and Lan, Zifeng and Siu-fai Chan, Frankie and Han, Zhibin and Wang, Zhaokun and Wing-fai Wong, Sidney and Chi-fung Ngan, Andy","NaN","Behera, Adarsh Prasad and Morabito, Roberto and Widmer, Joerg and Champati, Jaya Prakash","Firdous, Naira and Din, Nusrat Mohi Ud and Assad, Assif","Matorin, S. I. and Gul, S. V. and Shcherbinina, N. V.","Putzu, Lorenzo and Loddo, Andrea","Nouri, Zahra and Kiani, Vahid and Fadishei, Hamid","Xu, Zhongguo and Jha, Naresh and Mehadi, Syed and Mandal, Mrinal","Sharma, Arnav and Sharma, Subhanjali and Bhardwaj, Utkarsh and Mistry, Sajib and Deb, Novarun and Krishna, Aneesh","Chen, Jianting and Ding, Ling and Yang, Yunxiao and Xiang, Yang","Li, Li and Han, Qihong and Li, Jiayao and Cui, Zhanqi","Jaiswal, Dibyanshu and Chatterjee, Debatri and B s, Mithun and Ramakrishnan, Ramesh Kumar and Pal, Arpan","Jhee, Jong Ho and Yeon, Jeongheun and Kwak, Yoonshin and Shin, Hyunjung","Adel, Alti and Farid, Ayeche","Wu, Hanrui and Li, Nuosi and Zhang, Jia and Chen, Sentao and Ng, Michael K. and Long, Jinyi","Sithungu, Siphesihle Philezwini and Ehlers, Elizabeth Marie","Etemadi, Sepideh and Khashei, Mehdi and Tamizi, Saba","Liu, Jingyi and Li, Sheng","Wang, Huaduo and Gupta, Gopal","NaN","Yao, Jianping and Tran, Son N. and Sawyer, Samantha and Garg, Saurabh","Ali, Muhammad and Zhu, Peimin and Jiang, Ren and Huolin, Ma and Ehsan, Muhsan and Hussain, Wakeel and Zhang, Hao and Ashraf, Umar and Ullaah, Jared","Huang, Yingcheng and Xiao, Fuyuan","Mushava, Jonah and Murray, Michael","Zhang, Liu and Wei, Yaoguang and Liu, Jincun and Wu, Jianwei and An, Dong","Ozkaya, Suat Gokhan and Baygin, Mehmet and Barua, Prabal Datta and Tuncer, Turker and Dogan, Sengul and Chakraborty, Subrata and Acharya, U. Rajendra","Zeng, Jie and Xiao, Fuyuan","Zhang, Bo and Ming, Zuheng and Liu, Yaqian and Feng, Wei and He, Liang and Zhao, Kaixing","He, Jiahui and Zia, Haris Bin and Castro, Ignacio and Raman, Aravindh and Sastry, Nishanth and Tyson, Gareth","Shrivastava, Saurabh and Shukla, Sanyam and Khare, Nilay","NaN","Yamaguchi, Akihiro and Ueno, Ken and Kashima, Hisashi","Kuljeet Singh and Shastri, Sourabh and Kumar, Sachin and Mansotra, Vibhakar","Erceg, Mirjana and Palamas, Georgios","Li, Jianqiang and Cheng, Wenxiu and Xu, Xi and Zhao, Linna and Liu, Suqin and Gao, Zhengkai and Ye, Caihua and You, Huanling","Yuan, Yage and Wei, Jianan and Huang, Haisong and Jiao, Weidong and Wang, Jiaxin and Chen, Hualin","Oh, Se Won and Jeong, Hyuntae and Chung, Seungeun and Lim, Jeong Mook and Noh, Kyoung Ju","NaN","Sahu, Sushanta Kumar and Chowdhury, Ananda S.","Singh, Onkar and Kashyap, Kanchan Lata and Singh, Koushlendra Kumar","Mu, Tengxiao and Liang, Yaru and Liu, Lingzhi","Paul, Jackson H. and Digh, Andy D.","Tang, Jun and Chen, Wenhui and Wang, Ke and Zhang, Yan and Liang, Dong","Roy, Debaditya and Lekssays, Ahmed and Girdzijauskas, Sarunas and Carminati, Barbara and Ferrari, Elena","Wang, Rui and Huang, Weiguo and Zhang, Xiao and Wang, Jun and Ding, Chuancang and Shen, Changqing","Raza, Rehan and Zulfiqar, Fatima and Khan, Muhammad Owais and Arif, Muhammad and Alvi, Atif and Iftikhar, Muhammad Aksam and Alam, Tanvir","NaN","NaN","Yi, Liping and Wang, Gang and Liu, Xiaoguang and Shi, Zhuan and Yu, Han","Ashraf, Mudasir and Zaman, Majid and Ahmed, Muheet","Grina, Fares and Elouedi, Zied and Lefevre, Eric","Deng, Jiakang and Xing, De and Chen, Cheng and Han, Yongguo and Chen, Jianqiang","Dai, Lulu and Han, Mingyue","NaN","Ma, Xi-Ao and Jiang, Wentian and Ling, Yun and Yang, Bailin","Yin, Xiuye and Chen, Liyong","Sun, Pengbo and Zuo, Yi and Wang, Yudi","Ren, He and Wang, Jun and Huang, Weiguo and Jiang, Xingxing and Zhu, Zhongkui","NaN","NaN","Hechen, Zhenzhe and Huang, Wei and Yin, Le and Xie, Wenjing and Zhao, Yixin","Zhang, Zhuo and Wang, Hongfei and Jiang, Wen and Geng, Jie","Khatri, Sabita and Arora, Deepak and Kumar, Anil","Qian, Wenbin and Xiong, Yinsong and Ding, Weiping and Huang, Jintao and Vong, Chi-Man","Geng, Zengmin and Lin, Bijun and Yuan, Ye and Liu, Shiyu and Gao, Dandan and Du, Jianxia","Mu, Qiaoxu and Zhang, Meng","Christen, Peter and Hand, David J. and Kirielle, Nishadi","Li, Jingbo and Yang, Guijun and Yang, Hao and Xu, Weimeng and Feng, Haikuan and Xu, Bo and Chen, Riqiang and Zhang, Chengjian and Wang, Han","NaN","Zhao, Konghao and Bhandari, Sapan and Whitener, Nathan P and Grayson, Jason M and Khuri, Natalia","Wang, Lin and Gjoreski, Hristijan and Ciliberto, Mathias and Lago, Paula and Murao, Kazuya and Okita, Tsuyoshi and Roggen, Daniel","Chen, Xiangbo and Nishiyama, Masashi and Iwai, Yoshio","Liang, Chunhui and Ma, Wenqing","Jayanthi, B. and Kumar, Lakshmi Sutha","Kathuria, Charu and Mehrotra, Deepti and Misra, Navnit Kumar","Ke, Ting and Ge, Xuechun and Yin, Feifei and Zhang, Lidong and Zheng, Yaozong and Zhang, Chuanlei and Li, Jianrong and Wang, Bo and Wang, Wei","Xu, Bo and Bhatti, Uzair Aslam and Tang, Hao and Yan, Jialin and Wu, Shulei and Sarhan, Nadia and Awwad, Emad Mahrous and M. S., Syam and Ghadi, Yazeed Yasin","Debnath, Chandrima and Guha, Debashree and Hait, Swati Rani and Guria, Soumita and Chakraborty, Debjani","Jeune, Hayden and Pechan, Niklas and Reitsma, Sharn-Konet and Kempa-Liehr, Andreas W.","Lee, Eunji and Kim, Sihyeon and Kim, Sundong and Jung, Soyeon and Kim, Heeja and Cha, Meeyoung","Andersen, Lasse R. and Jacobsen, Lukas J. and Campos, David","Wasi, Nesar Ahmad and Abulaish, Muhammad","Yao, Rujing and Wu, Ou","Koga, Tsukasa and Maruyama, Osamu","Diep, Tuong-Nghiem and Tran, Thien-Phuc and Ho-Ngoc, Vinh-Phat and Yang, Tuan-Anh and Do, Trong-Le","Baroni, Giulia L. and Rasotto, Laura and Roitero, Kevin and Siraj, Ameer Hamza and Della Mea, V.","Bahri, Shivani and Bahri, Pranav and Lal, Sangeeta","Philips, James and Tabrizi, Nasseh","Besharati Moghaddam, Fatemeh and Lopez, Angel J. and Van Gheluwe, Casper and De Vuyst, Stijn and Gautama, Sidharta","Chen, Qiong and Huang, Tianlin and Liu, Qingfa","Liang, Xiayu and Gao, Ying and Xu, Shanrong","NaN","Hasan, Ali M. and Al-Waely, Noor K.N. and Aljobouri, Hadeel K. and Jalab, Hamid A. and Ibrahim, Rabha W. and Meziane, Farid","Ding, Biyun and Zhang, Tao and Wang, Chao and Liu, Ganjun and Liang, Jinhua and Hu, Ruimin and Wu, Yulin and Guo, Difei","Sun, Zhigang and Wang, Guotao and Zhai, Guofu and Li, Pengfei and Liang, Qi and Zhang, Min","Nariswari, Rinda and Pudjihastuti, Herena","Sharma, Rohit and Mahanti, Gautam Kumar and Chakraborty, Chinmay and Panda, Ganapati and Rath, Adyasha","Banoth, Ravi Kumar and Murthy, B. V. Ramana","Zheng, Jian and Hu, Xin","Spinnato, Francesco and Guidotti, Riccardo and Monreale, Anna and Nanni, Mirco and Pedreschi, Dino and Giannotti, Fosca","Damarla, Seshu Kumar","Tariq, Muhammad Arham and Sargano, Allah Bux and Iftikhar, Muhammad Aksam and Habib, Zulfiqar","Bond, Jacob and Gupta, Siddhartha and Elvitigala, Thanura","Teng, Zeyu and Cao, Peng and Huang, Min and Gao, Zheming and Wang, Xingwei","Chandana Mani, R.K. and Kamalakannan, J.","Blachnik, Marcin and undefinedciegienka, Piotr and Da\u0327browski, Daniel","Edla, Damodar Reddy and Ansari, Md Fahim and Chaudhary, Nikhil and Dodia, Shubham","Lung, Rodica Ioana and Suciu, Mihai-Alexandru","Bahala, Renante G. and Sagum, Ria A.","Xiang, Yu and Bai, Lei","NaN","Sun, Yanjie and Xu, Kele and Liu, Chaorun and Dou, Yong and Qian, Kun","NaN","Han, Fenggang and Zhang, Xiao and He, Linjie and Kong, Liru and Chen, Yumin","Ojo, Akinlolu Oluwabusayo and Bouguila, Nizar","NaN","Akash, Bathini Sai and Kumar, Lov and Singh, Vikram and Patel, Anoop Kumar and Krishna, Aneesh","Niranjan, Ranjani and Rao, Sachit","NaN","Site, Aditi and Nurmi, Jari and Lohan, Elena Simona","Azizi, Afshin and Zhang, Zhao and Rui, Zhaoyu and Li, Yunxi and Igathinathane, C. and Flores, Paulo and Mathew, Jithin and Pourreza, Alireza and Han, Xiongzhe and Zhang, Man","Negru, Vlad-Andrei and Lemnaru, Camelia and Potolea, Rodica","Saha, Sourajit and Saha, Nisha","NaN","Rozendo, Guilherme Botazzo and Roberto, Guilherme Freire and do Nascimento, Marcelo Zanchetta and Alves Neves, Leandro and Lumini, Alessandra","He, Xiaoxu","Zeng, Meng and Zhang, Zhonglin","NaN","Duan, Jicong and Gu, Yan and Yu, Hualong and Yang, Xibei and Gao, Shang","Tian, Yuchen and Wang, Jiacheng and Jin, Yueming and Wang, Liansheng","Yumang, Analyn N and Banguilan, Dave Emilson S and Veneracion, Clark Kent S","Che, Xiaoya and Chen, Degang and Deng, Jiang and Mi, Jusheng","Gu, Qiangqiang and Shaikh, Nazim and Lin, Ping-chang and Jayachandran, Srinath and Porwal, Prasanna and Li, Xiao and Nie, Yao","Fan, Caoyun and Chen, Wenqing and Tian, Jidong and Li, Yitian and He, Hao and Jin, Yaohui","Khater, Tarek and Tawfik, Hissam and Singh, Balbir","Manisha and Clifford, William and McLaughlin, Eugene and Stynes, Paul","Sun, Guoying and Cheng, Yanan and Zhang, Zhaoxin and Tong, Xiaojun and Chai, Tingting","Islam, MD. Sajjatul and Sang, Yongsheng and Mohammed, Adam A.Q. and Yuan, Lei and Lv, Jiancheng","Calzavara, Stefano and Cazzaro, Lorenzo and Pibiri, Giulio Ermanno and Prezza, Nicola","Alcacer, Aleix and Martinez-Garcia, Marina and Epifanio, Irene","Zhong, Mingwei and Yi, Siqi and Fan, Jingmin and Zhang, Yikang and He, Guanglin and Cao, Yunfei and Feng, Lutao and Tan, Zhichao and Mo, Wenjun","NaN","Mcdonald, Denisa Qori and Sariyanidi, Evangelos and Zampella, Casey J. and Dejardin, Ellis and Herrington, John D. and Schultz, Robert T. and Tunc, Birkan","Wei, Jianan and Wang, Jiaxin and Huang, Haisong and Jiao, Weidong and Yuan, Yage and Chen, Hualin and Wu, Rui and Yi, Junhui","Luo, Kaiwen and Wang, Xiaomin and Sun, Fan","Elaraby, Nagwa and Barakat, Sherif and Rezk, Amira","Huti, Mohamed and Lee, Tiarna and Sawyer, Elinor and King, Andrew P.","Gunaratna, Kalpa and Srinivasan, Vijay and Jin, Hongxia","NaN","NaN","Baci, Alkid and Heindorf, Stefan","Putro, Nur Achmad Sulistyo and Avian, Cries and Prakosa, Setya Widyawan and Leu, Jenq-Shiou","Dihingia, Leena and Bannulmath, Prashant and Chowdhury, Amartya Roy and Prasanna, S.R.M and Deepak, K.T and Sheikh, Tehreem","Hong, Jung-Sik and Lee, Jeongeon and Sim, Min K.","Wu, Haiyan and Zhou, Di and Sun, Chaoqun and Zhang, Zhiqiang and Ding, Yong and Chen, Yanhong","NaN","Ou, Liang and Do, Thomas and Tran, Xuan-The and Leong, Daniel and Chang, Yu-Cheng and Wang, Yu-Kai and Lin, Chin-Teng","Wu, Peishu and Wang, Zidong and Li, Han and Zeng, Nianyin","Mousa, Yehia and Taha, Radwa and Kaur, Ranpreet and Afifi, Shereen","He, Zhengxiang and Jia, Mingtao and Wang, Liguan","Zheng, Huilin and Sherazi, Syed Waseem Abbas and Arif, Saba and Lee, Myung Jin and Lee, Jong Yun","Li, Dantong and Li, Guixin and Li, Shuang and Bang, Ashley","Wang, Tianle and Wang, Zihan and Liu, Weitang and Shang, Jingbo","Shrihari, A. and Guha, Prithwijit and Kulkarni, Rishikesh Dilip","NaN","Ma, Shengjin and Yuan, Wang and Wang, Yiting and Tan, Xin and Zhang, Zhizhong and Ma, Lizhuang","Park, Jaewoo and Park, Hojin and Jeong, Eunju and Teoh, Andrew Beng Jin","Guan, Yunchuan and Liu, Yu and Zhou, Ke and Huang, Junyuan","Nirbhav and Malik, Anand and Maheshwar and Prasad, Mukesh","Zhang, Yu and Zuo, Xin and Zheng, Xuxu and Gao, Xiaoyong and Wang, Bo and Hu, Weiming","Li, Huan and Wang, Yue","Gou, Hongyuan and Zhang, Xianyong and Yang, Jilin and Lv, Zhiying","Sadafi, Ario and Hehr, Matthias and Navab, Nassir and Marr, Carsten","Yuan, Gaoteng and Lu, Lu and Zhou, Xiaofeng","T., Prabhavathy and Elumalai, Vinodh Kumar and E., Balaji","Anand, Sidharth and Devulapally, Naresh Kumar and Bhattacharjee, Sreyasee Das and Yuan, Junsong","NaN","Li, Jingyu and Ma, Haokai and Li, Xiangxian and Qi, Zhuang and Meng, Xiangxu and Meng, Lei","Liu, Hankai and Huang, Xianying and Liu, Xiaoyang","Kim, Hayeon and Cho, Myeongji and Son, Hyeon S.","NaN","Kolipaka, Venkata Rama Rao and Namburu, Anupama","Nasayreh, Ahmad and Al Mamlook, Rabia Emhamed and Samara, Ghassan and Gharaibeh, Hasan and Aljaidi, Mohammad and Alzu'Bi, Dalia and Al-Daoud, Essam and Abualigah, Laith","Saremi, Mohammad and Amirani, Mehdi Chehel","Panigrahi, Lipismita and Chandra, Tej Bahadur and Srivastava, Atul Kumar and Varshney, Neeraj and Singh, Kamred Udham and Mahato, Shambhu and Rajamohan, Vasudevan","NaN","Ma, Yanbiao and Jiao, Licheng and Liu, Fang and Yang, Shuyuan and Liu, Xu and Li, Lingling","Hamed, Ahmed and Tahoun, Mohamed and Nassar, Hamed","Mojtahedi, Ramtin and Hamghalam, Mohammad and Jarnagin, William R. and Do, Richard K. G. and Simpson, Amber L.","El Balghiti, Othman and Elmachtoub, Adam N. and Grigas, Paul and Tewari, Ambuj","Yu, Ziru and Cui, Wei","Chen, Lu and Luo, Xinwei and Zhou, Hanlu","Zhao, Wei and Zhao, Hong","Wang, Xu and Yang, Guangxiang and Xiao, Zhenqi and Yu, Guangling","Li, Xin and Xu, Qi and Li, Xingxing and Xin, Hao and Yuan, Yilong and Shen, Zhiheng and Zhou, Yuxuan","Liu, Yahui and Li, Bin and Yang, Shuai and Li, Zhen","Prasad, Amit and Garg, Rahul and Sabharwal, Yogish","Wu, Xin-Jian and Ao, Xiang and Zhang, Rui-Song and Liu, Cheng-Lin","Ming, Yuhang and Shao, Haidong and Cai, Baoping and Liu, Bin","Sudha, S. Baby and Dhanalakshmi, S.","NaN","Graham Ram, Billy and Zhang, Yu and Costa, Cristiano and Raju Ahmed, Mohammed and Peters, Thomas and Jhala, Amit and Howatt, Kirk and Sun, Xin","Park, Sunghong and Son, Sang Joon and Park, Kanghee and Nam, Yonghyun and Shin, Hyunjung","NaN","Zhao, Jianhua and Liang, Haiye and Li, Shulan and Yang, Zhiji and Wang, Zhen","Anjali Rajak and Rakesh Tripathi","Solatorio, Aivin V.","Khlifi, Ghaith and Jenhani, Ilyes and Messaoud, Montassar Ben and Mkaouer, Mohamed Wiem","Meng, Yao and Xu, Mingle and Kim, Hyongsuk and Yoon, Sook and Jeong, Yongchae and Park, Dong Sun","Rai, Prakhar and Gehlot, Shiv and Gupta, Ritu and Gupta, Anubha","Liang, Pei and Cao, Wanying and Hu, Junhua","NaN","Cho, Sungmin and Jung, Raehyuk and Kwon, Junseok","Huang, Xiaoming and Zhu, Peihu and Chen, Yuwen and Ma, Jian","Wang, Chenyu and Endo, Toshio and Hirofuchi, Takahiro and Ikegami, Tsutomu","Jiang, Minghua and Liu, Shuqing and Shi, Yankang and Du, Chenghu and Tang, Guangyu and Liu, Li and Peng, Tao and Hu, Xinrong and Yu, Feng","Luo, Jueling and Long, Hui and Xie, Si and Zhang, Yalu and Ma, Haodong and Meng, Guangyao","Gao, Bingjie and Zhou, Qianli and Deng, Yong","Debnath, Chandrima and Aishwaryaprajna and Hait, Swati Rani and Guha, Debashree and Chakraborty, Debjani","Sharma, Neha and Jain, Vibhor and Mishra, Anju","NaN","Kumari, Madhu and Singh, Vijendra","Ping, Mingtian and Pi, Dechang and Chen, Zhiwei and Wang, Junlong","Huang, Jiande and Chen, Ping and Lu, Lijuan and Deng, Yuhui and Zou, Qiang","Aruna Sri, P. and Santhi, V.","Fu, Zhiling and Wang, Zhe and Xu, Xinlei and Yang, Mengping and Chi, Ziqiu and Ding, Weichao","NaN","Bhoi, Akash Kumar and Sherpa, Karma Sonam and Khandelwal, Bidita","Srivastava, Rajshree and Kumar, Pardeep","Zhang, Jianan and Wu, Yongfei and Hao, Fang and Liu, Xueyu and Li, Ming and Zhou, Daoxiang and Zheng, Wen","Konduru, S. and Amiruzzaman, M. and Avina, V. and Islam, M. R.","Abd-Alhalem, Samia M. and Marie, Hanaa Salem and El-Shafai, Walid and Altameem, Torki and Rathore, Rajkumar Singh and Hassan, Tarek M.","Isnan, Mahmud and Hidayat, Alam Ahmad and Pardamean, Bens","Fang, Xiaoqi and Zhang, Guoyun and Zhang, Guifeng and Zhou, Xuhui and Wu, Jianhui and Zhao, Lin","NaN","Wang, Ye and Wang, Yaxiong and Zhao, Guoshuai and Qian, Xueming","Shi, Jue and Chen, Xiaofang and Xie, Yongfang and Zhang, Hongliang and Cen, Lihui and Sun, Yubo","Zhang, Xiaoming and Yu, Lean","Su, Yawen","Wang, Hengbin and Ye, Zijing and Wang, Yan and Liu, Xueyi and Zhang, Xindan and Zhao, Yuanyuan and Li, Shaoming and Liu, Zhe and Zhang, Xiaodong","Khan, Murtaza Ali and AlGhamdi, Mohammed","Zhang, Yong and Jiang, Yuqing and Zhang, Qi and Liu, Da","Zheng, Zhe and Zhou, Yu-Cheng and Chen, Ke-Yin and Lu, Xin-Zheng and She, Zhong-Tian and Lin, Jia-Rui","Puri, Ashishi and Kumar, Sanjeev","Kingphai, Kunjira and Moshfeghi, Yashar","Ukanchanakitti, Phatsakorn and Winaichatsak, Nattapong and Cho, Natthawin and Sumetpipat, Kanes","Ravikiran, H. K. and Jayanth, J. and Sathisha, M. S. and Bindu, K.","Zhu, Qi and Li, Sen and Li, Zhantao and Min, Xianjun and Li, Qian","Zhang, Liu and Zhang, Shubin and Liu, Jincun and Wei, Yaoguang and An, Dong and Wu, Jianwei","Ma, Shihan and Yang, Jidong J. and Chorzepa, Mi Geum and Morris, Clint and Kim, S. Sonny and Durham, Stephan A.","NaN","Xie, Wentao and Liu, Qian and Su, Yongye and Yan, Yi and Huang, Shujun and Kuang, Qin and Hu, Pingzhao","Gao, Qi and Long, Teng and Zhou, Zhangbing","NaN","Dash, Amanda and Albu, Alexandra Branzan","Bushnell, Justin and Unverzagt, Frederick and Wadley, Virginia G. and Kennedy, Richard and Gaizo, John Del and Clark, David Glenn","Wei, Yuanxi and liu, Yinan and Wang, Haibo","Merchant, Arpit and Castillo, Carlos","Wang, Ziquan and Li, Hui and Zhang, Zikai and Chen, Feng and Zhai, Jia","Berghouse, Marc and Bebis, George and Tavakkoli, Alireza","Teixeira, Ana Clara and Yazdanpanah, Hamed and Pezente, Aline and Ghassemi, Mohammad","Zou, Yizhang and Hu, Xuegang and Li, Peipei","NaN","Zhao, Ziye","Lopez Uroz, Lorenzo and Benoit, Alexandre and Yan, Yajing and Lin-Kwong-Chon, Christophe and Giffard-Roisin, Sophie and Rabatel, Antoine","Lalor, John P. and Abbasi, Ahmed and Oketch, Kezia and Yang, Yi and Forsgren, Nicole","Tzudir, Moakala and Sadashiv T.N., Rishith and Agarwal, Ayush and Prasanna, S. R. Mahadeva","Li, Jichang and Li, Guanbin and Yu, Yizhou","Park, Hyunseo and Lee, Gyeong Ho and Han, Jaeseob and Choi, Jun Kyun","NaN","NaN","Xu, Ying and Liu, Honglei and Shi, Yi and Li, Ao and Wang, Minghui","Din, Nusrat Mohi Ud and Assad, Assif and Dar, Rayees Ahmad and Rasool, Muzafar and Sabha, Saqib Ul and Majeed, Tabasum and Islam, Zahir Ul and Gulzar, Wahid and Yaseen, Aamir","Lo, Lun-Jou and Yang, Chao-Tung and Chiang, Wen-Chung and Lin, Hsiu-Hsia","Vo, Anh H. and Nguyen, Bao T.","NaN","Guo, Yeang and Tao, Tan and Ronglin, Ronglin and Xiao, Liangfen and Ding, Lijuan and Li, Qing and Xie, Hui","Samui, Suman and Garai, Soumen and Ghosh, Anindya and Mukhopadhyay, Anand Kumar","Karimi Monsefi, Amin and Shiri, Pouya and Mohammadshirazi, Ahmad and Karimi Monsefi, Nastaran and Davies, Ron and Moosavi, Sobhan and Ramnath, Rajiv","Huang, Yan and Zhang, Zhang and Huang, Yan and Wu, Qiang and Huang, Han and Zhong, Yi and Wang, Liang","NaN","Hast, Anders","Jiang, Chenzhi and Jin, Yin and Wang, Ningtao and Wu, Ruofan and Fu, Xing and Wang, Weiqiang","Duong, Huong T. and Ho, Van H. and Do, Phuc","Junttila, Jukka and Raunio, Kalle and Kokkonen, Petteri and Saarela, Olli","K R, Pradeep and N C, Naveen","NaN","Zhao, Ruirui and Sun, Jianbin and Tu, Li and Jiang, Jiang","Ye, Ze and Liu, Dantong and Pavani, Kaushik and Dasgupta, Sunny","Zhou, Wenjie and Li, Piji and Han, Zhaoyang and Lu, Xiaozhen and Li, Juan and Ren, Zhaochun and Liu, Zhe","Messa, Letizia and Testa, Carolina and Carelli, Stephana and Rey, Federica and Cereda, Cristina and Raimondi, Manuela Teresa and Ceri, Stefano and Pinoli, Pietro","Cui, Yuwei and Song, Qingzeng and Xue, Yongjiang and Yu, Jing","Doonyapisut, Dulyawat and Kim, Byeongkyu and Kim, Jung Kyu and Lee, Eunseok and Chung, Chan-Hwa","Zielinski, Kallil M.C. and Ribas, Lucas C. and Machicao, Jeaneth and Bruno, Odemir M.","Zhou, Jun Yu and Fei, Chun Qing and Zou, Bing Guo","Chen, Junze","Sharma, Mayukh and Kandasamy, Ilanthenral and Vasantha, W.B.","Celik, Muhammed and Inik, Ozkan","Atmakuru, Akhila and Di Fatta, Giuseppe and Nicosia, Giuseppe and Varzandian, Ali and Badii, Atta","Fu, Hui and Zhang, Ke and Wang, Jingyu","Ping, Zhichao and Sang, Guoming and Liu, Zhi and Zhang, Yijia","Babu, K. N. Surendra and Kodabagi, Mallikarjun M.","Jiao, Jiajia and Chen, Bo","Sim, Jinwoo and Min, Jinhong and Kim, Seokgoo and Lee, Seok Woo and Choi, Joo-Ho","Revanasiddappa, M B and Harish, B S and Kumar, S V Aruna","Dhali, Maruf A. and Reynolds, Thomas and Alizadeh, Aylar Ziad and Nijdam, Stephan H. and Schomaker, Lambert","Allu, Ramakrishna and Padmanabhuni, Venkata Nageswara Rao","Ye, Jinhuang and Wu, Jiawei and Li, Zuoyong and Zheng, Xianghan","Li, Liangping and Gong, Xun and Wang, Chenzhong and Kong, Weiji","Bhattacharya, Indranil and Ye, Ze and Pavani, Kaushik and Dasgupta, Sunny","Sun, Zhigang and Wang, Guotao and Li, Pengfei and Wang, Hui and Zhang, Min and Liang, Xiaowen","Zhou, Wei and Luo, Danxue","Guo, Qingwen and Wang, Chuntao and Xiao, Deqin and Huang, Qiong","Yang, Rui and Zhou, Jun and Lu, Xiangyu and Shen, Jianxun and Chen, Huizhe and Chen, Mengyuan and He, Yong and Liu, Fei","Ghosh, Arpita and Soni, Badal and Baruah, Ujwala","Lv, Dingyang and Xu, Zhengjia and Zhang, Jinghui and Wang, Yuchen and Dong, Fang","Bei, Yijun and Geng, Jinsong and Liu, Erteng and Gao, Kewei and Huang, Wenqi and Feng, Zunlei","Bae, Youngjae and Kang, Seokho","Xu, Xun and Liao, Jingyi and Cai, Lile and Nguyen, Manh Cuong and Lu, Kangkang and Zhang, Wanyue and Yazici, Yasin and Foo, Chuan Sheng","Aryal, Saurav K. and Prioleau, Howard and Shah, Ujjawal and Acharya, Sameer","Sun, Pengfei and Wang, Zhiping and Jia, Liyan and Xu, Zhaohui","Ning, Chunxiao and Xie, Yazhou","Gehad Ismail Sayed and Aboul Ella Hassanein","Filia, Beatrice Josephine and Lienardy, Filbert Fernandes and Laksana, I Kadek Perry Bagus and Jordan, Jayasidhi Ariyo and Siento, Joyceline Graciella and Honova, Shilvia Meidhi and Hasana, Silviya and Permonangan, Ivan Halim","Ninh, Quoc-Bao and Nguyen, Hai-Chan and Huynh, Triet and Tran, Minh-Triet and Le, Trung-Nghia","Vieira, Guilherme and Valle, Marcos Eduardo and Lopes, Wilder","NaN","Liu, Na and Zhang, Fan and Chang, Liang and Duan, Fuqing","Makmur, Nathanael Matthew and Kwan, Felicia and Rana, Astrid Dewi and Kurniadi, Felix Indra","Shi, Wen and Zhao, Hong and Zhang, Haoran and Song, Lipei and Chen, Ke and Zhang, Bin","Wang, Alex X. and Chukova, Stefanka S. and Nguyen, Binh P.","Yang, Yue and Cheng, Jieren and Liu, Zhaowu and Li, Huimin and Xu, Ganglou","Wang, Ning and Zhang, Zhong-Liang and Luo, Xing-Gang","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","Khokhlova, Maria V. and Blinova, Olga V. and Bogdanova-Beglarian, Natalia and Sherstinova, Tatiana","NaN","Cai, Zeyi and He, Mengyu and Li, Cheng and Qi, Hengnian and Bai, Ruibin and Yang, Jian and Zhang, Chu","Liu, Fan and Yang, Sai and Chen, Delong and Huang, Huaxi and Zhou, Jun","Subudhi, Subhashree and Patro, Ramnarayan and Biswal, Pradyut Kumar and Bhuyan, Kanhu Charan","Wang, Siqi and Zhou, Dongmei and Cheng, Yongjian and Jiang, Meiqi","Rathnayake, Himashi and Sumanapala, Janani and Rukshani, Raveesha and Ranathunga, Surangika","Huang, Weiliang and He, Wenxuan and Liao, Shuhong and Xu, Zhen and Yan, Jingwen","Wang, Huajun and Shao, Yuanhai","Laroca, Rayson and Zanlorensi, Luiz A. and Estevam, Valter and Minetto, Rodrigo and Menotti, David","NaN","Aydogmus, Omur and Bingol, Mustafa Can and Boztas, Gullu and Tuncer, Turker","Sewwandi, Mahawaga Arachchige Nayomi Dulanjala and Li, Yuefeng and Zhang, Jinglan","Dholey, Moumita and Santosham, Ritesh J. M. and Ray, Soumendranath and Das, Jayanta and Chatterjee, Sanjoy and Ahmed, Rosina and Mukherjee, Jayanta","Pourkamali-Anaraki, Farhad and Nasrin, Tahamina and Jensen, Robert E. and Peterson, Amy M. and Hansen, Christopher J.","Bader, Ofek and Lichy, Adi and Dvir, Amit and Dubin, Ran and Hajaj, Chen","Mukherjee, Salankara and Ghosh, Ishita De","Han, Peng and Chen, Zhiming and Jiang, Fei and Si, Jiaxin","Tajalli, Behrad and Abad, Gorka and Picek, Stjepan","Kukreja, Sonia and Sabharwal, Munish and Katiyar, Alok and Gill, D. S.","Gao, Ruiyao and Qi, Kai and Yang, Hu","Jia, Pengfei and Li, Xiaoyu and Xu, Min and Zhang, Lin","Zheng, Xiao and Wang, Minhui and Huang, Kai and Zhu, En","Burada, Sreedhar and Eraiah, Manjunathswamy Byranahalli and Kumar, M. Sunil","Alyami, Sarah and Luqman, Hamzah and Hammoudeh, Mohammad","NaN","Xu, Fan and Zheng, Qihang and Shi, Jia and Yan, Keyu and Wang, Mingwen","St-Vincent Villeneuve, Alexandre and Plaisent, Michel","Gupta, Deepak and Hazarika, Barenya Bikash and Borah, Parashjyoti","Nguyen, Anh Tien and Kwak, Jin Tae","Naveed, Asim and Naqvi, Syed S. and Khan, Tariq M. and Razzak, Imran","Dong, Yumin and Che, Xuanxuan and Fu, Yanying and Liu, Hengrui and Sun, Lina","Wang, Xiaoying and Chen, Xiaohai and Zhang, Zhongwen and He, Haisheng","Nair, Ajith N and Tanwar, Harshwardhan and Arjunan, Pandarasamy and Anand, Prashant and Mahdavi, Ardeshir","Prakash, Jainendra and Ghorai, Mrinmoy and Sanodiya, Rakesh","Shi, Jiechuan and Liu, Kun and Yuan, Hao and Wang, Can and Yang, Bo","Moon, Hyung-Jun and Cho, Sung-Bae","Mahesworo, Bharuno and Cenggoro, Tjeng Wawan and Lumbanraja, Favorisen Rosyking and Pardamean, Bens","Ji, Cun and Du, Mingsen and Wei, Yanxuan and Hu, Yupeng and Liu, Shijun and Pan, Li and Zheng, Xiangwei","Ni, Haotian and Gu, Shilin and Fan, Ruidong and Hou, Chenping","Yin, Yu Jia and Lv, Yan and Guo, Wenwen and Bai, Lan","Nicolini, Marco and Ntalampiras, Stavros","Cao, Alexander and Utke, Jean and Klabjan, Diego","Dibaji, Mahsa and Gianchandani, Neha and Nair, Akhil and Singhal, Mansi and Souza, Roberto and Bento, Mariana","Liao, Yilin and Su, Rixin and Wang, Wenhai and Li, Haozhe and Wang, Hao and Liu, Zhaoran and Liu, Xinggao","Jia, Xibin and Li, Chen and Zeng, Meng and Wang, Luo and Mi, Qing","Achmamad, Abdelouahad and Elfezazi, Mohamed and Chehri, Abdellah and Ahmed, Imran and Jbari, Atman and Saadane, Rachid","Xiong, Jiale and Yang, Jing and Yan, Lei and Awais, Muhammad and Khan, Abdullah Ayub and Alizadehsani, Roohallah and Acharya, U. Rajendra","Fathan, Abderrahim and Alam, Jahangir and Zhu, Xiaolin","Rajabi, Hamid and Ding, Xianzhong and Du, Wan and Cerpa, Alberto","Xu, Yang and Wu, Shanshan and Wang, Biqi and Yang, Ming and Wu, Zebin and Yao, Yazhou and Wei, Zhihui","Jian, Zhongquan and Li, Jiajian and Wu, Qingqiang and Yao, Junfeng","Pingi, Sharon Torao and Nayak, Richi and Bashar, Md Abul","Li, Xiaoyu and Yang, Bei and Chen, Tiandong and Gao, Zheng and Huang, Mengjie","Hajihosseinlou, Mahsa and Maghsoudi, Abbas and Ghezelbash, Reza","Hong, Haoyuan","Xu, Xia and Wang, Wenjie and Yuan, Zengbei and Li, Xinlin and Wu, Tao and Yao, Xufeng","Xu, Jindong and Li, Kang and Li, Ziyi and Chong, Qianpeng and Xing, Haihua and Xing, Qianguo and Ni, Mengying","Chang, Mingzhe and Ji, Luping and Zhu, Jiewen","Dolzhikova, Irina and Abibullaev, Berdakh and Zollanvari, Amin","Khaked, Azhar Ali and Oishi, Nobuyuki and Roggen, Daniel and Lago, Paula","Farooque, Ghulam and Liu, Qichao and Sargano, Allah Bux and Xiao, Liang","Antioquia, Arren Matthew C. and Cordel II, Macario O.","Opanasenko, V. M. and Fazilov, Sh.Kh. and Radjabov, S. S. and Kakharov, Sh.S.","Lai, Kwei-Herng and Zha, Daochen and Chen, Huiyuan and Bendre, Mangesh and Chen, Yuzhong and Das, Mashweta and Yang, Hao and Hu, Xia","Kumar, Upendra","Verma, Atul Kumar and Jadeja, Mahipal","Aryal, Saurav K. and Prioleau, Howard and Aryal, Surakshya and Washington, Gloria","Hu, Tao","Sisodia, Deepti and Sisodia, Dilip Singh","Sun, Lin and Li, Mengmeng and Ding, Weiping and Xu, Jiucheng","NaN","Jia, Jinfang and Feng, Xiang and Yu, Huiqun","Liu, Ju and Huang, Ling-Wei and Shao, Yuan-Hai and Chen, Wei-Jie and Li, Chun-Na","Zhang, Kuangyan and Zhang, Tuyi and Liu, Sanmin","Gallo, Giovanni and Atani, Yaser Gholizade and Leotta, Roberto and Stanco, Filippo and Buscemi, Francesca and Figuera, Marianna","NaN","Edla, Damodar Reddy and Mangalorekar, Kunal and Dhavalikar, Gauri and Dodia, Shubham","Napier, Thomas and Ahn, Euijoon and Allen-Ankins, Slade and Lee, Ickjai","Li, Bo and Tang, Jinhong and Xie, Nengke","Chatterjee, Subhajit and Byun, Yung-Cheol","Pham, Nhat Truong and Phan, Le Thi and Dang, Duc Ngoc Minh and Manavalan, Balachandran","Kamakshi, Vidhya and C Krishnan, Narayanan","Kapoor, Ishita and Mishra, Anju","Avudaiammal, R. and Rajangam, Vijayarajan and Durai Raji V. and Senthil Kumar S.","Lone, Ab Waheed and Aydin, Nizamettin","Dai, Jianhua and Huang, Weiyi and Zhang, Chucai and Liu, Jie","Kaur, Barjinder and Singh, Dinesh and Roy, Partha Pratim","Liu, Bo and He, Lejian and Xie, Yuchen and Xiang, Yuejia and Zhu, Li and Ding, Weiping","Gu, Xingyue and Ding, Yijie and Xiao, Pengfeng","Lin, Kevin and Brown, Donald and Syed, Sana and Greene, Adam","Al-Hindawi, Firas and Rahman Siddiquee, Md Mahfuzur and Wu, Teresa and Hu, Han and Sun, Ying","Kokash, Natallia and Makhnist, Leonid","Saroj and Vashishtha, Jyoti and Goyal, Pooja and Ahuja, Jyoti","Aghaee, Reza and Momeni, Mehdi and Moallem, Payman","Guo, Qingwen and Wang, Chuntao and Xiao, Deqin and Huang, Qiong","Wang, Kaier and Tikhonov, Aristarkh and Hill, Melissa and Litchfield, Lester","Zhang, Xuan and Xu, Yitian and Liu, Xuhua","Rana, Mashud and Rahman, Ashfaqur and Almashor, Mahathir and McCulloch, John and Sethuvenkatraman, Subbu","Kuo, Tzu-Ming and Hung, Hsuan-Yu and Wu, Chienhsing","Ahmadian, Vahid and Beheshti Aval, S. Bahram and Noori, Mohammad and Wang, Tianyu and Altabey, Wael A.","Ramkissoon, Amit Neil and Manohar, Kris and Goodridge, Wayne","Percannella, Gennaro and Petruzzello, Umberto and Tortorella, Francesco and Vento, Mario","Ganaie, M.A. and Kumari, Anuradha and Girard, Anouck and Kasa-Vubu, Josephine and Tanveer, M.","Hort, Max and Chen, Zhenpeng and Zhang, Jie M. and Harman, Mark and Sarro, Federica","Pusuluri, Aditya and Kachhi, Aastha and Patil, Hemant A.","Shi, Shijun and Hu, Kai and Xie, Jie and Guo, Ya and Wu, Huayi","Wang, Xuetao and He, Qiang and Jian, Wanwei and Meng, Haoyu and Zhang, Bailin and Jin, Huaizhi and Yang, Geng and Zhu, Lin and Wang, Linjing and Zhen, Xin","Wang, Wei and Wei, Xueguang and Wang, Bailing and Li, Yan and Xin, Guodong and Wei, Yuliang","NaN","Zou, Xin and Tang, Chang and Zheng, Xiao and Li, Zhenglai and He, Xiao and An, Shan and Liu, Xinwang","Panigrahi, Ranjit and Borah, Samarjeet","Salim, Brigita Vanessa and Chyntia and Indrawan, Jason Orlando and Hidayat, Jessica and Matthew, Steven and Mangkang, Tesalonika Abigail Eikwine and Hasana, Silviya and Permonangan, Ivan Halim","Arhin, Joseph Roger and Zhang, Xiaoling and Coker, Kenneth and Agyemang, Isaac Osei and Attipoe, Wisdom Kwame and Sam, Francis and Adjei-Mensah, Isaac and Agyei, Emmanuel","Behzadidoost, Rashid and Mahan, Farnaz and Izadkhah, Habib","Flores, Christopher A. and Verschae, Rodrigo","Habbat, Nassera and Nouri, Hicham and Anoun, Houda and Hassouni, Larbi","Shwetank and Neeraj and Jitendra and Vikesh and Jain, Kamal","Bao, Wenzheng and Yang, Bin","Goyal, Hemlata and Joshi, Nisheeth and Sharma, Chilka","Zhou, Hai and Xue, Zhe and Liu, Ying and Li, Boang and Du, Junping and Liang, Meiyu and Qi, Yuankai","Ahmed, Zahid and Das, Sufal"],"cluster":[3,2,0,0,0,3,0,4,0,0,0,0,0,0,0,0,5,3,0,0,0,0,1,0,0,0,4,0,0,1,0,0,0,0,0,0,3,0,3,0,0,0,4,0,0,0,0,1,4,1,0,1,0,0,3,0,1,0,0,0,0,0,4,0,0,3,0,0,0,4,0,0,0,0,0,0,4,0,4,0,0,0,4,0,0,0,0,0,0,5,0,0,2,0,5,0,0,0,0,4,0,0,0,0,0,0,0,3,3,0,0,0,0,0,0,0,0,0,2,0,0,0,0,2,0,0,0,0,0,4,0,0,0,0,0,0,0,0,5,0,0,4,0,0,0,3,0,0,3,2,4,0,0,0,0,0,0,0,0,4,0,0,0,3,3,0,0,0,0,0,5,0,0,3,0,0,0,0,0,0,0,0,0,0,2,3,0,1,4,0,0,2,0,0,0,4,0,0,4,3,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,3,0,0,0,2,0,4,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,3,0,0,4,4,0,0,0,0,0,0,0,0,0,0,3,0,0,0,4,4,0,0,0,4,0,0,5,0,0,1,0,3,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,4,0,0,0,0,0,0,0,0,4,0,0,5,0,0,0,0,0,3,0,2,0,0,0,2,0,3,0,3,0,0,0,2,0,0,0,0,0,0,1,3,0,0,3,0,0,0,0,0,4,0,0,3,0,0,0,0,3,2,0,0,0,0,3,3,0,0,0,0,3,0,4,0,0,0,0,0,4,0,0,0,4,5,0,0,0,4,0,4,0,0,0,0,3,1,0,0,0,0,0,0,0,0,2,0,0,0,0,0,2,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,3,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,2,0,0,0,0,0,0,0,0,3,3,0,0,0,0,0],"labels":["C-3","C-2","C-0","C-0","C-0","C-3","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-5","C-3","C-0","C-0","C-0","C-0","C-1","C-0","C-0","C-0","C-4","C-0","C-0","C-1","C-0","C-0","C-0","C-0","C-0","C-0","C-3","C-0","C-3","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-1","C-4","C-1","C-0","C-1","C-0","C-0","C-3","C-0","C-1","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-3","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-4","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-5","C-0","C-0","C-2","C-0","C-5","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-3","C-3","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-5","C-0","C-0","C-4","C-0","C-0","C-0","C-3","C-0","C-0","C-3","C-2","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-3","C-3","C-0","C-0","C-0","C-0","C-0","C-5","C-0","C-0","C-3","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-2","C-3","C-0","C-1","C-4","C-0","C-0","C-2","C-0","C-0","C-0","C-4","C-0","C-0","C-4","C-3","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-3","C-0","C-0","C-0","C-2","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-5","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-3","C-0","C-0","C-4","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-3","C-0","C-0","C-0","C-4","C-4","C-0","C-0","C-0","C-4","C-0","C-0","C-5","C-0","C-0","C-1","C-0","C-3","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-5","C-0","C-0","C-0","C-0","C-0","C-3","C-0","C-2","C-0","C-0","C-0","C-2","C-0","C-3","C-0","C-3","C-0","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-0","C-0","C-1","C-3","C-0","C-0","C-3","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-3","C-0","C-0","C-0","C-0","C-3","C-2","C-0","C-0","C-0","C-0","C-3","C-3","C-0","C-0","C-0","C-0","C-3","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-0","C-4","C-5","C-0","C-0","C-0","C-4","C-0","C-4","C-0","C-0","C-0","C-0","C-3","C-1","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-0","C-2","C-0","C-4","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-3","C-3","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-4","C-0","C-0","C-2","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-0","C-3","C-3","C-0","C-0","C-0","C-0","C-0"],"publication_date":["2023-10-18","2024-02-27","2024-01-09","2024-02-27","2023-11-22","2023-11-27","2023-10-21","2023-10-12","2023-10-02","2023-11-03","2024-02-27","2023-10-21","2023-11-22","2024-02-27","2023-12-13","2023-12-13","2023-10-21","2024-02-27","2024-01-22","2023-10-27","2023-11-22","2023-11-27","2023-12-22","2024-01-01","2023-12-02","2024-02-06","2023-10-21","2024-02-27","2023-11-29","2024-02-13","2024-02-01","2024-01-01","2023-11-14","2023-11-02","2024-02-27","2024-02-02","2023-11-02","2024-02-01","2023-11-22","2023-10-02","2024-02-01","2024-02-06","2024-01-21","2024-02-09","2023-10-26","2023-11-28","2024-02-01","2024-02-27","2023-10-08","2024-02-15","2024-01-30","2024-02-01","2024-02-28","2024-01-10","2024-02-27","2024-01-15","2023-11-27","2023-10-18","2024-02-27","2024-02-27","2024-02-27","2024-02-27","2024-02-27","2024-02-27","2024-02-04","2023-10-24","2024-02-27","2024-02-27","2023-10-21","2023-12-01","2024-02-19","2024-02-01","2024-02-01","2023-10-08","2023-12-13","2023-12-12","2024-01-20","2024-02-22","2023-11-01","2024-01-01","2023-10-08","2024-02-01","2024-02-01","2023-11-20","2024-02-01","2023-10-27","2024-02-27","2023-11-19","2024-02-07","2024-02-28","2024-02-27","2023-10-16","2023-11-15","2023-10-16","2024-02-27","2024-01-03","2023-10-09","2024-02-01","2024-02-01","2024-02-27","2024-02-01","2024-01-17","2024-02-07","2023-10-06","2024-02-27","2023-10-12","2023-10-04","2023-10-08","2024-02-12","2023-11-15","2024-01-01","2024-02-27","2024-02-01","2024-01-08","2023-12-12","2024-02-12","2023-12-01","2023-10-11","2024-02-27","2024-02-03","2023-10-04","2023-12-07","2024-01-21","2024-02-27","2023-10-17","2023-10-21","2024-02-07","2024-02-27","2024-02-27","2024-02-01","2024-02-27","2024-02-01","2024-02-27","2023-12-11","2024-01-12","2024-02-27","2023-11-13","2024-01-04","2023-11-01","2023-12-01","2024-01-01","2024-02-14","2023-11-22","2024-02-27","2024-02-16","2024-02-27","2024-02-04","2023-10-09","2023-10-27","2023-11-25","2023-10-31","2024-02-01","2023-11-27","2023-11-20","2023-12-12","2024-01-20","2023-10-11","2024-02-27","2023-12-04","2024-02-27","2024-02-27","2023-11-27","2024-02-27","2023-11-17","2024-01-20","2024-02-01","2023-12-01","2023-12-19","2024-02-01","2023-12-01","2024-02-27","2023-10-02","2023-12-07","2024-02-27","2024-01-10","2023-11-21","2024-02-27","2024-02-27","2023-11-27","2023-10-18","2024-02-27","2023-11-17","2024-02-01","2023-10-12","2023-10-21","2023-12-04","2024-02-27","2023-10-21","2024-02-28","2023-11-29","2024-02-27","2024-01-01","2024-01-01","2023-11-28","2024-02-27","2024-02-12","2024-02-01","2023-11-16","2023-11-15","2023-10-21","2023-12-12","2024-02-27","2024-02-07","2024-01-01","2023-10-21","2024-01-01","2024-02-27","2024-01-22","2024-02-27","2023-10-12","2024-02-27","2024-02-27","2023-10-27","2023-12-13","2023-10-29","2024-02-27","2024-02-28","2023-11-19","2024-01-15","2024-01-15","2024-02-15","2024-02-17","2024-02-01","2023-10-27","2023-12-01","2024-02-03","2023-11-01","2024-02-27","2024-02-01","2024-01-01","2023-11-02","2023-11-14","2024-02-01","2024-01-04","2024-02-04","2024-02-27","2024-01-16","2023-12-13","2024-02-27","2024-02-27","2024-01-21","2024-02-27","2023-12-01","2023-11-13","2023-11-19","2024-02-27","2023-11-11","2024-02-01","2023-12-13","2024-02-27","2023-11-04","2023-11-14","2024-01-20","2023-12-15","2024-02-01","2023-10-30","2024-02-27","2024-01-01","2024-02-27","2023-11-20","2023-10-23","2024-02-14","2024-02-27","2023-11-27","2024-02-27","2024-02-19","2024-02-27","2023-10-01","2024-02-01","2024-02-27","2023-12-15","2024-02-03","2024-02-27","2024-02-27","2024-02-27","2024-02-19","2024-02-01","2024-02-27","2024-02-27","2024-02-01","2024-02-27","2024-02-15","2023-12-06","2024-01-20","2024-02-03","2024-02-27","2024-01-22","2024-02-27","2023-11-07","2024-02-27","2024-01-11","2023-11-14","2024-02-01","2024-02-01","2023-10-21","2024-02-05","2023-12-01","2023-11-25","2024-01-01","2023-11-22","2024-02-27","2023-12-30","2024-01-23","2023-11-29","2024-02-01","2024-02-27","2023-10-16","2024-02-27","2024-02-28","2024-01-01","2024-01-01","2024-02-27","2024-02-27","2023-12-15","2023-12-12","2023-11-29","2024-02-01","2024-01-03","2023-11-14","2023-10-21","2023-10-13","2023-10-17","2024-02-27","2024-01-01","2024-02-01","2023-10-21","2023-10-21","2024-02-28","2023-10-03","2024-02-01","2024-02-01","2024-02-13","2024-02-27","2024-02-27","2024-02-27","2024-02-15","2024-02-27","2024-02-27","2024-01-05","2023-12-01","2024-02-27","2024-02-27","2024-02-22","2023-11-01","2024-02-04","2023-11-28","2023-10-21","2024-02-01","2024-02-01","2024-02-27","2024-02-27","2024-02-01","2024-02-01","2023-11-20","2024-02-27","2024-02-27","2023-10-01","2024-02-27","2024-01-08","2023-12-01","2024-02-27","2023-12-07","2024-02-03","2024-02-16","2023-11-25","2024-02-27","2024-02-27","2024-02-27","2024-02-03","2024-02-01","2024-01-11","2023-11-29","2023-12-13","2024-02-27","2024-01-01","2024-01-25","2023-10-26","2024-02-01","2024-02-01","2024-02-01","2023-11-27","2024-01-20","2024-02-27","2024-02-27","2023-12-12","2024-02-01","2024-02-27","2024-01-01","2023-11-20","2023-11-21","2024-02-10","2024-02-01","2024-01-22","2024-02-01","2024-01-18","2024-01-15","2023-11-22","2024-01-05","2023-12-06","2024-02-01","2023-12-01","2024-02-01","2024-02-14","2024-02-14","2023-11-15","2023-12-12","2023-12-04","2023-11-22","2024-02-27","2024-02-01","2024-02-01","2023-11-03","2024-02-22","2023-10-09","2023-10-12","2024-02-27","2024-02-27","2023-12-14","2024-02-27","2023-11-29","2023-11-15","2024-02-01","2024-02-01","2024-02-07","2024-02-27","2024-02-01","2024-02-01","2024-01-17","2024-02-01","2024-02-27","2024-02-27","2023-10-08","2024-02-01","2024-02-12","2024-02-08","2023-10-21","2024-02-27","2024-02-27","2023-10-01","2024-02-27","2024-02-27","2024-02-01","2023-11-28","2024-02-01","2024-02-01","2024-02-27","2024-01-21","2024-01-19","2024-02-27","2023-11-28","2024-02-04","2024-02-27","2023-12-07","2024-01-04","2024-02-27","2023-12-01","2024-02-01","2024-01-01","2024-02-27","2024-02-01","2024-02-01","2024-02-27","2024-02-01","2024-02-15","2024-02-27","2024-02-27","2024-02-01","2024-02-12","2024-02-01","2023-11-28","2023-10-16","2024-02-01","2024-01-21","2024-01-21","2024-02-01","2023-11-01","2023-11-29","2024-02-01","2024-02-27","2024-02-27","2023-11-27","2023-10-27","2024-02-27","2024-02-27","2024-02-01","2024-01-01","2023-11-22","2024-02-01","2024-02-27","2024-01-22","2024-02-27","2023-10-27","2023-11-21"],"title":["Examining the Impact of FMRI Preprocessing Steps on Machine Learning-Based Classification of Autism Spectrum Disorder","An Ensemble Classification System for Twitter Sentiment Analysis","Credit Card Fraud Detection: Addressing Imbalanced Datasets with a Multi-phase Approach","Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN","FETCH: A Memory-Efficient Replay Approach for Continual Learning in Image Classification","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook","Revisiting Skin Tone Fairness in Dermatological Lesion Classification","A Joint Analysis of Input Resolution and Quantization Precision in Deep Learning","Fast Twin Support Vector Classification for Large Scale Problems","Improving fMRI-based Autism Spectrum Disorder Classification with Random Walks-informed Feature Extraction and Selection","Unlocking the Potential of Non-PSD Kernel Matrices: A Polar Decomposition-Based Transformation for Improved Prediction Models","Enhanced SVM-SMOTE with Cluster Consistency for Imbalanced Data Classification","Feature selections based on three improved condition entropies and one new similarity degree in interval-valued decision systems","Improving SMOTE with Fuzzy Rough Prototype Selection to Detect Noise in Imbalanced Classification Data","On the Estimation of Predictive Evaluation Measure Baselines for Multi-Label Learning","Retention is All You Need","Word Representations For Gender Classification Using Deep Learning","Capitalizing the Predictive Potential of Machine Learning to Detect Various Fire Types Using NASA's MODIS Satellite Data for the Mediterranean Basin","Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor","Instance Selection Techniques for Large Volumes of Data","FLIPS: Federated Learning Using Intelligent Participant Selection","Graph-Based Text Classification by Contrastive Learning with Text-Level Graph Augmentation","Evaluation of uncertainty quantification methods in multi-label classification: A case study with automatic diagnosis of electrocardiogram","Harnessing the Potential of Deep Learning for Total Shoulder Implant Classification: A Comparative Study","An Optimal Weighted Ensemble of 3D CNNs for Early Diagnosis of Alzheimer\u2019s Disease","Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility","Feature-level SMOTE: Augmenting fault samples in learnable feature space for imbalanced fault diagnosis of gas turbines","Investigating the Effect of Data Impurity on the Detection Performances of Mental Disorders Through Spoken Dialogues","Graph-based Text Classification by Contrastive Learning with Text-level Graph Augmentation","Classification of yoga, meditation, combined yoga\u2013meditation EEG signals using L-SVM, KNN, and MLP classifiers","Joint long and short span self-attention network for multi-view classification","Semi-Supervised Classification and Segmentation of Forest Fire Using Autoencoders","Machine Learning Algorithm-Based Prediction of Machined Surface Quality in End Milling Operation","Credit Scoring Model based on Weighted Voting and Cluster based Feature Selection","Detection of explosives in dustbins using deep transfer learning based multiclass classifiers","Heterogeneous-Training: A Semi-Supervised Text Classification Method","Surface quality prediction and quantitative evaluation of process parameter effects for 3D printing with transfer learning-enhanced gradient-boosting decision trees","Threshold-Based Classification to Enhance Confidence in Open Set of Legal Texts","Improved Decision Module Selection for Hierarchical Inference in Resource-Constrained Edge Devices","An imbalanced classification approach for establishment of cause-effect relationship between Heart-Failure and Pulmonary Embolism using Deep Reinforcement Learning","Three-Dimensional System-Object Classification for Prediction and Control Support","Leukocytes Classification Methods: Effectiveness and Robustness in a Real Application Scenario","Rarity updated ensemble with oversampling: An ensemble approach to classification of imbalanced data streams","Multi-Class Wall Recognition in Complex Architectural Floor Plan Images Using a Convolutional Network","COVID-19 Fake News Detection Using Cross-Domain Classification Techniques","Active diversification of head-class features in bilateral-expert models for enhanced tail-class optimization in long-tailed classification","Two-step multi-view data classification based on dynamic Graph-ELM","GSR Based Generic Stress Prediction System","Multi-scale Heat Kernel Graph Network for Graph Classification","Performance Evaluation of Machine Learning for Recognizing Human Facial Emotions","Collaborative contrastive learning for hypergraph node classification","SupervisedImmuneNet: Training Artificial Immune Networks using a Supervised Learning Approach for Improved Multi-Class Classification","Etemadi reliability-based multi-layer perceptrons for classification and forecasting","A dependency-based hybrid deep learning framework for target-dependent sentiment classification","FOLD-SE: An Efficient Rule-Based Machine Learning Algorithm with Scalable Explainability","Bipartite Graph Coarsening for Text Classification Using Graph Neural Networks","Machine Learning for Leaf Disease Classification: Data, Techniques and Applications","Reservoir characterization through comprehensive modeling of elastic logs prediction in heterogeneous rocks using unsupervised clustering and class-based ensemble machine learning","Fractal belief Jensen\u2013Shannon divergence-based multi-source information fusion for pattern classification","Flexible loss functions for binary classification in gradient-boosted decision trees: An application to credit scoring","A hyperspectral band selection method based on sparse band attention network for maize seed variety identification","An automated earthquake classification model based on a new butterfly pattern using seismic signals","A high order fractal-based Kullback\u2013Leibler divergence with application in classification","RsMmFormer: Multimodal Transformer Using Multiscale Self-attention for Remote Sensing Image Classification","Flocking to Mastodon: Tracking the Great Twitter Migration","Support vector machine with eagle loss function","Class3Dp: A supervised classifier of vegetation species from point clouds","Time-Series Shapelets with Learnable Lengths","BC-Net: Early Diagnostics of Breast Cancer Using Nested Ensemble Technique of Machine Learning","Towards Harmonious Coexistence: A Bioacoustic-Driven Animal-Computer Interaction System for Preventing Ship Collisions with North Atlantic Right Whales","How to identify pollen like a palynologist: A prior knowledge-guided deep feature learning for real-world pollen classification","Review of resampling techniques for the treatment of imbalanced industrial data classification in equipment condition monitoring","Multimodal Sensor Data Fusion and Ensemble Modeling for Human Locomotion Activity Recognition","Enhancing the Performance of SVM on Skewed Data Sets by Exciting Support Vectors","Multi-Modal Multi-Class Parkinson Disease Classification Using CNN and Decision Level Fusion","Lung and Colon Cancer Classification of Histopathology Images Using Convolutional Neural Network","Classification model based on improved K-means clustering algorithm","Checkpoint Classifier for CNN Image Classification","Probability-based label enhancement for multi-dimensional classification","Private, Fair and Secure Collaborative Learning Framework for Human Activity Recognition","Federated contrastive prototype learning: An efficient collaborative fault diagnosis method with data privacy","Lung-EffNet: Lung cancer classification using EfficientNet from CT-scan images","TwiSP: A Framework for Exploring Polarized Issues in Twitter","Material handling machine activity recognition by context ensemble with gated recurrent units","FedGH: Heterogeneous Federated Learning with Generalized Global Header","Using Ensemble StackingC Method and Base Classifiers to Ameliorate Prediction Accuracy of Pedagogical Data","Evidential Generative Adversarial Networks for Handling Imbalanced Learning","FFANet: Dual Attention-Based Flow Field Aware Network for 3D Grid Classification and Segmentation","Robust Sentiment Classification Based on the Backdoor Adjustment","Fuzzy classification with distance-based depth prototypes: High-dimensional unsupervised and/or supervised problems","Multi-Label Feature Selection via Maximum Dynamic Correlation Change and Minimum Label Redundancy","Image and Text Aspect Level Multimodal Sentiment Classification Model Using Transformer and Multilayer Attention Interaction","Classification Model for NAVTEX Navigational Warning Messages Based on Adaptive Weighted TF-IDF","Domain-invariant feature fusion networks for semi-supervised generalization fault diagnosis","Feature-Weighted Naive Bayesian Classifier for Wireless Network Intrusion Detection","Performance Exploration of RNN Variants for Recognizing Daily Life Stress Levels by Using Multimodal Physiological Signals","Dilated-Windows-based Vision Transformer with Efficient-Suppressive-self-attention for insect pests classification","A target intention recognition method based on information classification processing and information fusion","Enhancing Decision Tree Classification Accuracy through Genetically Programmed Attributes for Wart Treatment Method Identification","Label correlations-based multi-label feature selection with label enhancement","Garment Fabric Pattern Classification via ResNet-34","Hybrid compression for LSTM-based encrypted traffic classification model","A Review of the F-Measure: Its History, Properties, Criticism, and Alternatives","Orchard classification based on super-pixels and deep learning with sparse optical images","Automated Hand Joint Classification of Psoriatic Arthritis Patients Using Routinely Acquired Near Infrared Fluorescence Optical Imaging","An Ensemble Machine Learning Approach for Benchmarking and Selection of ScRNA-Seq Integration Methods","Summary of SHL Challenge 2023: Recognizing Locomotion and Transportation Mode from GPS and Motion Sensors","Comparison of Simplified SE-ResNet and SE-DenseNet for Micro-Expression Classification","Heterogeneous Analysis for Clustered Data Using Grouped Finite Mixture Models","Comparison of Convolutional Neural Networks Architectures for Mango Leaf Classification","Predicting the protein structure using random forest approach","A general maximal margin hyper-sphere SVM for multi-class classification","Towards explainability for AI-based edge wireless signal automatic modulation classification","Multi-Criteria Decision-Making Based Classifier Ensemble by Using Prioritized Aggregation Operator","Spatial Variation Sequences for Remote Sensing Applications with Small Sample Sizes","Explainable Product Classification for Customs","Compressed, Real-Time Voice Activity Detection with Open Source Implementation for Small Devices","SKEDS \u2014 An external knowledge supported logistic regression approach for document-level sentiment classification","A Taxonomy for Learning with Perturbation and Algorithms","CBOEP: Generating Negative Enhancer-Promoter Interactions to Train Classifiers","Deep Learning Hierarchical Methods for Insect Pest Recognition on Plants","Vision Transformers for Breast Cancer Histology Image Classification","A Novel approach of Sentiment Classification using Emoticons","Bibliographic Reference Classification in Historiographic Documents Using Supervised Machine Learning and Grammatical Features","Data-Driven Operator Functional State Classification in Smart Manufacturing","SWRM: Similarity Window Reweighting and Margin for Long-Tailed Recognition","ASE: Anomaly scoring based ensemble learning for highly imbalanced datasets\u25aa","The verification of hen egg types by the classification of ultra-weak photon emission data","Molecular subtypes classification of breast cancer in DCE-MRI using deep features","Acoustic scene classification: A comprehensive survey","Signal detection and material identification method for loose particles inside sealed relays based on fusion classification model","Support Vector Machine Method for Predicting Non-Linear Data","An IoT and Deep Learning-Based Smart Healthcare Framework for Thyroid Cancer Detection","Soil Image Classification Using Transfer Learning Approach: MobileNetV2 with CNN","irrelevant attribute resistance approach to binary classification for imbalanced data","Understanding Any Time Series Classifier with a Subsequence-Based Explainer","Electronic Tongue based Classification of Mineral Water Samples using Gramian Angular Field and Deep SAE","Comparing Different Oversampling Methods in Predicting Multi-Class Educational Datasets Using Machine Learning Techniques","Probabilistic Local Equivalence Certification for Robustness Evaluation","Multi-label borderline oversampling technique","Modeling of Aquila Optimizer with Hybrid ResNet-DenseNet enabled Breast Cancer Classification on Histopathological Images","Preliminary Study on Unexploded Ordnance Classification in Underwater Environment Based on the Raw Magnetometry Data","Classification of Facial Expressions from EEG signals using Wavelet Packet Transform and SVM for Wheelchair Control Operations","An Evolutionary Approach to Feature Selection and Classification","Spider Plus: A Text Classifier for Research Article Components","Feature Fusion Gate: Improving Transformer Classifier Performance with Controlled Noise","Interpreting Sign Language Recognition Using Transformers and MediaPipe Landmarks","Automatic Audio Augmentation for Requests Sub-Challenge","FinBERT-FOMC: Fine-Tuned FinBERT Model with Sentiment Focus Method for Enhancing Sentiment Analysis of FOMC Minutes","Multimodal Fuzzy Granular Representation and Classification","A topic modeling and image classification framework: The Generalized Dirichlet variational autoencoder","Detection of Covid-19 in Chest X-Ray Images Using Percolation Features and Hermite Polynomial Classification","Empirical Analysis of Multi-Label Classification on GitterCom Using BERT and ML Classifiers","Handling Small Disjuncts and Class Skew Using Sequential Ellipsoidal Partitioning","Auto Machine Learning Based on Genetic Programming for Medical Image Classification","Classification of Freezing of Gait Using Accelerometer Data: A Systematic Performance Evaluation Approach","Comprehensive wheat lodging detection after initial lodging using UAV RGB images","Multitask, Cross-Lingual Recipe Classification Using Joint Fine-Tuning Mechanisms","A Lightning fast approach to classify Bangla Handwritten Characters and Numerals using newly structured Deep Neural Network","Fault detection and classification with the rebmix R package","Weeds Classification with Deep Learning: An Investigation Using CNN, Vision Transformers, Pyramid Vision Transformers, and Ensemble Strategy","Supervised spectral feature learning for fine-grained classification in small data set","Text Sentiment Classification Model Based on Fusion of DualChannel Features of CNN and BiLSTM","Use of a Surrogate Model for Symbolic Discretization of Temporal Data Sets Through eMODiTS and a Training Set with Varying-Sized Instances","ECC + +: An algorithm family based on ensemble of classifier chains for classifying imbalanced multi-label data","Communication-Efficient Federated Skin Lesion Classification with Generalizable Dataset Distillation","Fruit Calories Estimation Using Convolutional Neural Network","Exploiting local label correlation from sample perspective for multi-label classification via three-way decision theory","Cellular Features Based Interpretable Network for Classifying Cell-Of-Origin from Whole Slide Images for Diffuse Large B-Cell Lymphoma Patients","Unlock the Potential of Counterfactually-Augmented Data in Out-Of-Distribution Generalization","Machine Learning for the Classification of Obesity Levels Based on Lifestyle Factors","A Deep Learning Emotion Classification Framework for Low Resource Languages","Text classification with improved word embedding and adaptive segmentation","Highly effective end-to-end single-to-multichannel feature fusion and ensemble classification to decode emotional secretes from small-scale spontaneous facial micro-expressions","Verifiable Learning for Robust Tree Ensembles","Ordinal classification for interval-valued data and interval-valued functional data","Power transformer fault diagnosis based on a self-strengthening offline pre-training model","Presumably Correct Undersampling","Predicting Autism from Head Movement Patterns during Naturalistic Social Interactions","Novel extended NI-MWMOTE-based fault diagnosis method for data-limited and noise-imbalanced scenarios","An Ensemble Pneumonia Prediction and Classification Model Including InceptionNeXtPneumonia Prediction and Classification","A generalized ensemble approach based on transfer learning for Braille character recognition","An Investigation into Race Bias in Random Forest Models Based on Breast DCE-MRI Derived Radiomics Features","Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond","A Machine Learning Approach to Enterprise Matchmaking Using Multilabel Text Classification Based on Semi-Structured Website Content","A machine learning-based approach for flames classification in industrial Heavy Oil-Fire Boilers","Accelerating Concept Learning via Sampling","Revisiting the K-Fold Approach for a Stable Model on Amyotrophic Lateral Sclerosis Prediction Scheme using LSTM and Attention Mechanism","Preliminary Analysis of Lambani Vowels and Vowel Classification Using Acoustic Features","Concise rule induction algorithm based on one-sided maximum decision tree approach","LSOIT: Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis","Semantic augmentation by mixing contents for semi-supervised learning","Improving CCA Algorithms on SSVEP Classification with Reinforcement Learning Based Temporal Filtering","KD-PAR: A knowledge distillation-based pedestrian attribute recognition model with multi-label mixed feature learning network","Melanoma Classification Using Deep Learning","UACNet: A universal automatic classification network for microseismic signals regardless of waveform size and sampling rate","A Voting Ensemble-Based Model to Predict the Risk of Cardiovascular Disease in Ordinary People","Classification Prediction of Lung Cancer Based on Machine Learning Method","WOT-Class: Weakly Supervised Open-World Text Classification","A Novel Network Architecture for Microplankton Classification in Digital Holographic Images","Pattern recognition based on statistical methods combined with machine learning in railway switches","Self-supervised Contrastive Feature Refinement for Few-Shot Class-Incremental Learning","Understanding open-set recognition by Jacobian norm and inter-class separation","Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning","Landslide Susceptibility Assessment along the Major Transport Corridor Using Decision Tree Model: A Case Study of Kullu-Rohtang Pass","Improving metric-based few-shot learning with dynamically scaled softmax loss","An Interpretability Case Study of Unknown Unknowns Taking Clothes Image Classification CNNs as an Example","Three-way fusion measures and three-level feature selections based on neighborhood decision systems","A Study of Age and Sex Bias in Multiple Instance Learning Based Classification of Acute Myeloid Leukemia Subtypes","Feature selection using a sinusoidal sequence combined with mutual information","Hand gesture classification framework leveraging the entropy features from sEMG signals and VMD augmented multi-class SVM","Multi-Label Emotion Analysis in Conversation via Multimodal Knowledge Distillation","Detecting Survival Patterns in Women with Invasive Cervical Cancer with Decision Trees","Unsupervised Segmentation of Haze Regions as Hard Attention for Haze Classification","Improve label embedding quality through global sensitive GAT for hierarchical text classification","A Study of Classification Techniques Based on Spike Protein Sequences of MERS-CoV","Cautious Decision-Making for Tree Ensembles","Hybrid Classification Model with Tuned Weights for Crop Yield Prediction","Arabic Sentiment Analysis for ChatGPT Using Machine Learning Classification Algorithms: A Hyperparameter Optimization Technique","Proposing a novel multi-label mapping approach for use in SVM-based multi-class classification problems","mBCCf: Multilevel Breast Cancer Classification Framework Using Radiomic Features","Multi-instance learning with application to the profiling of multi-victim homicides","Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning","\nKNNHI: Resilient KNN Algorithm for Heterogeneous Incomplete Data Classification and K Identification Using Rough Set Theory","Leveraging Contrastive Learning with SimSiam for the Classification of Primary and Secondary Liver Cancers","Generalization Bounds in the Predict-Then-Optimize Framework","LSCA-net: A lightweight spectral convolution attention network for hyperspectral image processing","A ship-radiated noise classification method based on domain knowledge embedding and attention mechanism","Hierarchical long-tailed classification based on multi-granularity knowledge transfer driven by multi-scale feature fusion","Research on Bayesian Network Garbage Classification Based on Multi-Source Information Fusion","Improving PPP-RTK-Based Vehicle Navigation in Urban Environments via Multilayer Perceptron-Based NLOS Signal Detection","Handling missing values and imbalanced classes in machine learning to predict consumer preference: Demonstrations and comparisons to prominent methods","Union of Convex Separators (UCS)","Structural Recognition of Handwritten Chinese Characters Using a Modified Part Capsule Auto-encoder","rgfc-Forest: An enhanced deep forest method towards small-sample fault diagnosis of electromechanical system","Sentiment analysis using various machine learning algorithms for disaster related tweets classification","Nearest Prototype Classification of Special School Families Based on Hierarchical Compact Sets Clustering","Palmer amaranth identification using hyperspectral imaging and machine learning technologies in soybean field","In-house data adaptation to public data: Multisite MRI harmonization to predict Alzheimer\u2019s disease conversion","Classification of Turkish and Balkan House Architectures Using Transfer Learning and Deep Learning","Matrix-based vs. vector-based linear discriminant analysis: A comparison of regularized variants on multivariate time series data","Classification of Services through Feature Selection and Machine Learning in 5G Networks","GeoFormer: Predicting Human Mobility Using Generative Pre-Trained Transformer (GPT)","Multi-Label Classification of Mobile Application User Reviews Using Neural Language Models","Known and unknown class recognition on plant species and diseases","LIDACS: A Lightweight Domain Adaptive Cell Segmentation Framework","A sequential three-way classification model based on risk preference and decision correction\u25aa","Prototype Selection with Compact Sets and Extended Rough Sets","Sampling based spherical transformer for 360 degree image classification","A Transfer Learning Approach to Interdisciplinary Document Classification with Keyword-Based Explanation","Pyramid Swin Transformer for Multi-Task: Expanding to More Computer Vision Tasks","COCCI: Context-Driven Clothing Classification Network","Improving Table Tennis Training and Technique Analysis: Accurate Classification of Actions with Informer Encoder","HIE-EDT: Hierarchical interval estimation-based evidential decision tree","Evolutionary Ensembles Based on Prioritized Aggregation Operator","An Analysis Of Convolutional Neural Networks For Image Classification","Unsupervised classification of the spectrogram zeros with an application to signal detection and denoising","Breast Cancer Prediction system","Cross-Domain Bearing Fault Diagnosis Method Using Hierarchical Pseudo Labels","WCDForest: A Weighted Cascade Deep Forest Model toward the Classification Tasks","The reptile optimized deep learning model for land cover classification of the uppal earth region in telangana state using satellite image fusion","Semantic alignment with self-supervision for class incremental learning","Stingless Bee Classification: A New Dataset and Baseline Results","Ischemia and Arrhythmia Classification Using Time-Frequency Domain Features of QRS Complex","Performance comparison of various machine learning classifiers using fusion of LBP, intensity and GLCM feature extraction techniques for thyroid nodules classification","Double similarities weighted multi-instance learning kernel and its application","Plant Disease Detection and Classification Using Deep Learning Models","Cervical cancer classification based on a bilinear convolutional neural network approach and random projection","Indonesian Agricultural-crops Classification Using Transfer Learning Model","A Hybrid Self-Supervised Learning Framework For Hyperspectral Image Classification","Multimodal Context-Aware Detection of Glioma Biomarkers Using MRI and WSI","Learning to complement: Relation complementation network for few-shot class-incremental learning","Hybrid-driven BRBCS-BOM with expert intervention and its application for abnormity recognition in electrolytic cell","Consumer credit risk assessment: A review from the state-of-the-art classification algorithms, data traits, and learning methods","A Natural Language Processing System for Text Classification Corpus Based on Machine Learning","Improving the crop classification performance by unlabeled remote sensing data","A customized deep learning-based framework for classification and analysis of social media posts to enhance the Hajj and Umrah services","Multi-label learning based on instance correlation and feature redundancy","A text classification-based approach for evaluating and enhancing the machine interpretability of building codes","Hybrid Approach for Accurate Fiber Estimation in Brain Tissues: Mixture Model and Deep Learning Technique","On Channel Selection for EEG-Based Mental Workload Classification","Predicting Blood Drop Height and Volume Using Physics Equations, VGG-19, and XGBoost","Optimizing Sheep Breed Classification with Bat Algorithm-Tuned CNN Hyperparameters","Noisy-Consistent Pseudo Labeling Model for Semi-supervised Skin Lesion Classification","Maize seed variety identification using hyperspectral imaging and self-supervised learning: A two-stage training approach without spectral preprocessing","Composite Deep Learning Architecture for Vehicle Classification Using Vision Transformers and Wheel Position Features","Machine-learning-assisted classification of construction and demolition waste fragments using computer vision: Convolution versus extraction of selected features\u25aa","Patch-Based Deep Learning Models for Breast Mammographic Mass Classification","Mineral identification based on natural feature-oriented image processing and multi-label image classification","Malware Classification Using Open Set Recognition and HTTP Protocol Requests","Texture-Based Data Augmentation for Small Datasets","Post-processing automatic transcriptions with machine learning for verbal fluency scoring","Cooperative distillation with X-ray images classifiers for prohibited items detection","Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification","Attribute- and attention-guided few-shot classification","Investigating the Impact of Attention on Mammogram Classification","Bayesian Networks Improve Out-of-Distribution Calibration for Agribusiness Delinquency Risk Assessment","Gradient-based multi-label feature selection considering three-way variable interaction","Language Models for Automatic Distribution of Review Notes in Movie Production","Classification tree algorithm and its application in general archives management system","Deep Learning Multimodal Methods for Geophysical Inversion\u202f: Application to Glacier Ice Thickness Estimation","Should Fairness be a Metric or a Model? A Model-based Framework for Assessing Bias in Machine Learning Pipelines","Dialect Identification in Ao Using Modulation-Based Representation","Inter-domain mixup for semi-supervised domain adaptation","Multiclass autoencoder-based active learning for sensor-based human activity recognition","Intuitive Human-Swarm Interaction with Gesture Recognition and Machine Learning","A criminal macrocause classification model: An enhancement for violent crime analysis considering an unbalanced dataset","Cancer Survival Prediction by Multimodal Disentangled Representation Learning","RiceNet: A deep convolutional neural network approach for classification of rice varieties\u25aa","A quantitative method for the assessment of facial attractiveness based on transfer learning with fine-grained image classification","A framework-based transformer and knowledge distillation for interior style classification","Tourism destination events classifier based on artificial intelligence techniques","SVM in Classification of Stage 0~II and III~IV with Breast Cancer\u202f: A Retrospective Cohort Study on a Bicentric Cohort","Heterogeneous Stacked Ensemble Framework for Surface Electromyography Signal Classification","CrashFormer: A Multimodal Architecture to Predict the Risk of Crash","Customized meta-dataset for automatic classifier accuracy evaluation","Classification of Brain Tumors: A Comparative Approach of Shallow and Deep Neural Networks","Age-Invariant Face Recognition Using Face Feature Vectors and Embedded Prototype Subspace Classifiers","A Momentum Loss Reweighting Method for Improving Recall","Fact-Checking Vietnamese Information Using Knowledge Graph, Datalog, and KG-BERT","Feature Estimation for Punching Tool Wear at the Edge","Lung Cancer Survivability Prediction based on Performance Using Classification Techniques of Support Vector Machines, C4.5 and Naive Bayes Algorithms for Healthcare Analytics","Distance-based one-class time-series classification approach using local cluster balance","Asynchronous optimization approach for evidential reasoning rule-based classifier","LAMM: Language Aware Active Learning for Multilingual Models","Privacy-Preserving Federated Learning via Disentanglement","Leveraging Non-negative Matrix Tri-Factorization and Knowledge-Based Embeddings for Drug Repurposing: an Application to Parkinson's Disease","Research on Multi-Domain Sample Classification Method Based on Baidu API","Deep generative learning for exploration in large electrochemical impedance dataset","A network classification method based on density time evolution patterns extracted from network automata","A Case Study on the Generalization of Chinese Text Classification Methods based on Deep Learning","Classify Human Activities Based On Deepforest","Emotion quantification and classification using the neutrosophic approach to deep learning","Development of hybrid models based on deep learning and optimized machine learning algorithms for brain tumor Multi-Classification","Sensitivity Analysis for Feature Importance in Predicting Alzheimer\u2019s Disease","An adaptive self-correction joint training framework for person re-identification with noisy labels","Aspect category sentiment analysis based on prompt-based learning with attention mechanism","An Efficient Framework for Predicting Future Retail Sales Using Ensemble DNN-BiLSTM Technique","A GCN- and Deep Biaffine Attention-Based Classification Model for Course Review Sentiment","Construction of bearing health indicator under time-varying operating conditions based on Isolation Forest","Meta-cognitive Neural Network based Sequential Learning Framework for Text Categorization","Pattern Recognition Techniques in Image-Based Material Classification of Ancient Manuscripts","Convex Least Angle Regression Based LASSO Feature Selection and Swish Activation Function Model for Startup Survival Rate","Rethinking Distribution Alignment for Inter-class Fairness","Part-Aware Prototype-Aligned Interpretable Image Classification with Basic Feature Domain","RT2S: A Framework for Learning with Noisy Labels","An improved random forest based on the classification accuracy and correlation measurement of decision trees","The hesitant fuzzy BiRNN based on twice-cycle mechanism and its intelligent applications","A lightweight open-world pest image classifier using ResNet8-based matching network and NT-Xent loss function","A robust rice yield estimation framework developed by grading modeling and normalized weight decision-making strategy using UAV imaging technology","Brain haemorrhage classification from CT scan images using fine-tuned transfer learning deep features","Imbalanced node classification with Graph Neural Networks: A unified approach leveraging homophily and label information","CKR-Calibrator: Convolution Kernel Robustness Evaluation and Calibration","Supervised contrastive learning for wafer map pattern classification","Revisiting pretraining for semi-supervised learning in the low-label regime","Term Frequency Features vs Transformers: A Comparision for Sentiment Classification of African Languages","SMOTE-kTLNN: A hybrid re-sampling method based on SMOTE and a two-layer nearest neighbor classifier","Convolutional variational autoencoder for ground motion classification and generation toward efficient seismic fragility assessment","Air Pollutants Classification Using Optimized Neural Network Based on War Strategy Optimization Algorithm","Improving Batik Pattern Classification using CNN with Advanced Augmentation and Oversampling on Imbalanced Dataset","Multi-Branch Network for Imagery Emotion Prediction","Clifford Convolutional Neural Networks for Lymphoblast Image Classification","Automatic classification of the physical surface in sound uroflowmetry using machine learning methods","Scattering-Based Hybrid Network for Facial Attribute Classification","Comparing Local Binary Pattern and Gray Level Co-occurrence Matrix for Feature Extraction in Diabetic Retinopathy Classification","Wire melted mark metallographic image recognition and classification based on semantic segmentation\u25aa","Synthetic minority oversampling using edited displacement-based k-nearest neighbors","A multi-classification detection model for imbalanced data in NIDS based on reconstruction and feature matching","Iterative minority oversampling and its ensemble for ordinal imbalanced datasets","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","On the Most Frequent Sequences of Words in Russian Spoken Everyday Language (Bigrams and Trigrams): An Experience of Classification","Hierarchical Classification of Gene Ontology with Learning Classifier Systems","Identification of chrysanthemum using hyperspectral imaging based on few-shot class incremental learning","Few-shot classification guided by generalization error bound","Texture-based superpixel segmentation algorithm for classification of hyperspectral images","Classification Algorithm for Liquid Dangerous Goods Based on WT-AE and Attention-GRU Network","AdapterFusion-based multi-task learning for code-mixed and code-switched text classification","Efficient SpectralFormer for hyperspectral image classification","Fast generalized ramp loss support vector machine for pattern classification","Leveraging Model Fusion for Improved License Plate Recognition","Analysis of Convolutional Neural Network Models for Classifying the Quality of Dried Chili Peppers (Capsicum Annuum L)","An automated voice command classification model based on an attention-deep convolutional neural network for industrial automation system","Granule-specific feature selection for continuous data classification using neighborhood rough sets","Ensemble Methods With [18F]FDG-PET/CT Radiomics In Breast Cancer Response Prediction","Evaluation of classification models in limited data scenarios with application to additive manufacturing","OSF-EIMTC: An open-source framework for standardized encrypted internet traffic classification","Identification of Personality Traits from Handwritten Text Documents Using Multi-Label Classification Models","Active Learning for Open-Set Annotation Using Contrastive Query Strategy","Poster: Backdoor Attack on Extreme Learning Machines","NaN","Fused robust geometric nonparallel hyperplane support vector machine for pattern classification","Classification techniques of electronic nose: a review","Global and cross-modal feature aggregation for multi-omics data classification and application on drug response prediction","Optimal hybrid classifier with fine-tuned hyper parameter and improved fuzzy C means segmentation: skin cancer detection","Isolated Arabic Sign Language Recognition Using a Transformer-based Model and Landmark Keypoints","Complexity-Driven Sampling for Bagging","Pre-training and ensembling based Alzheimer\u2019s disease detection","Framework for Choosing a Supervised Machine Learning Method for Classification Based on Object Categories\u202f: Classifying Subjectivity of Online Comments by Product Categories","Fuzzy twin kernel ridge regression classifiers for liver disorder detection","GPC: Generative and General Pathology Image Classifier","PCA: Progressive class-wise attention for skin lesions diagnosis","Classification of human protein cell images using deep neural networks","Vehicle type classification in intelligent transportation systems using deep learning","Explainable Occupancy Prediction Using QLattice","Transfer Learning: Kernel-Based Domain Adaptation with Distance-Based Penalization","Fu-W:A Hyperspectral Image Classification Algorithm Combining Mini Graph Convolutional Networks and Convolutional Neural Network","A Subgraph Embedded GIN with Attention for Graph Classification","Standard Multi-Layer Perceptron on Positive - Unlabeled Glycosylation Site Dataset","Time series classification with random temporal features","Feature incremental learning with causality","Fast Support Vector Classifier with Quantile","Gender-Aware Speech Emotion Recognition in Multiple Languages","Early Classifying Multimodal Sequences","Studying the Effects of Sex-Related Differences on Brain Age Prediction Using Brain MR Imaging","Gaussian dynamic recurrent unit for emitter classification","An improved unified domain adversarial category-wise alignment network for unsupervised cross-domain sentiment classification","ML-Based Identification of Neuromuscular Disorder Using EMG Signals for Emotional Health Application","Efficient reinforcement learning-based method for plagiarism detection boosted by a population-based algorithm for pretraining weights","Multi-Task Learning over Mixup Variants for the Speaker Verification Task","TODOS: Thermal SensOr Data-Driven Occupancy Estimation System for Smart Buildings","Two-stage fine-grained image classification model based on multi-granularity feature fusion","Retrieval Contrastive Learning for Aspect-Level Sentiment Classification","Conditional Generative Adversarial Network for Early Classification of Longitudinal Datasets using an Imputation Approach","ProMIL: A weakly supervised multiple instance learning for whole slide image classification based on class proxy","Stacking: A novel data-driven ensemble machine learning strategy for prediction and mapping of Pb-Zn prospectivity in Varcheh district, west Iran","Landslide susceptibility assessment using locally weighted learning integrated with machine learning algorithms","Classification of Alzheimer??s Disease using combined features of fMRI Brain Network and clinical scales","Fuzzy graph convolutional network for hyperspectral image classification","Multi-scale LBP fusion with the contours from deep CellNNs for texture classification","A Jackknife-Inspired Deep Learning Approach to Subject-Independent Classification of EEG","Investigating the Effect of Orientation Variability in Deep Learning-Based Human Activity Recognition","Swin transformer with multiscale 3D atrous convolution for hyperspectral image classification","HAHANet: Towards Accurate Image Classifiers with Less Parameters","Multilevel Face Recognition System","Tackling Diverse Minorities in Imbalanced Classification","A Noval Approach for Object Recognition Using Decision Tree Clustering by Incorporating Multi-Level BPNN Classifiers and Hybrid Texture Features","CB-SAGE: A novel centrality based graph neural network for floor plan classification","Baselining Performance for Multilingual Codeswitching Sentiment Classification","Software Engineering Classification Model and Algorithm Based on Big Data Technology","Prediction of Diabetes using Classification Algorithms","Adaptive fuzzy multi-neighborhood feature selection with hybrid sampling and its application for class-imbalanced data","Systematic Analysis of the Impact of Label Noise Correction on ML Fairness","Few-shot classification via efficient meta-learning with hybrid optimization","A nonlinear kernel SVM classifier via L 0 / 1 soft-margin loss with classification performance","A novel ensemble framework driven by diversity and cooperativity for non-stationary data stream classification","Feature Relevance in Classification of 3D Stone from Ancient Wall Structures","A Dynamic Difficulty Adjustment Algorithm With Generic Player Behavior Classification Unity Plugin In Single Player Games","Classification of EEG data for human mental state analysis using Random Forest Classifier","An Optimised Grid Search Based Framework for Robust Large-Scale Natural Soundscape Classification","Ensemble of Deep Convolutional Network for Citrus Disease Classification Using Leaf Images","Highly imbalanced fault classification of wind turbines using data resampling and hybrid ensemble method approach","SER-Fuse: An Emotion Recognition Application Utilizing Multi-Modal, Multi-Lingual, and Multi-Feature Fusion","SCE: Shared Concept Extractor to Explain a CNN's Classification Dynamics","Automated Classification Method for Early Diagnosis of Alopecia Using Machine Learning","Color Models Aware Dynamic Feature Extraction for Forest Fire Detection Using Machine Learning Classifiers","Wavelet Scattering Transform based Doppler signal classification","Multi-label feature selection by strongly relevant label gain and label mutual aid","EEG Based Emotion Classification Mechanism in BCI","MinJoT: Multimodal infusion Joint Training for noise learning in text and multimodal classification problems","MLapRVFL: Protein sequence prediction based on Multi-Laplacian Regularized Random Vector Functional Link","Uncertainty Quantification for Eosinophil Segmentation","Domain-knowledge Inspired Pseudo Supervision (DIPS) for unsupervised image-to-image translation models to support cross-domain classification","Using Decision Trees for Interpretable Supervised Clustering","A Novel Fitness Computation Framework for Nature Inspired Classification Algorithms","A fusion-based approach to improve hyperspectral images\u2019 classification using metaheuristic band selection","A novel multi-label pest image classifier using the modified Swin Transformer and soft binary cross entropy loss","Evaluating Mammogram Image Classification: Impact of Model Architectures, Pretraining, and Finetuning","Multiple instance learning from similarity-confidence bags","Automatic Classification of Sensors in Buildings: Learning from Time Series Data","Does Removal of Noisy Granulated Datasets Matter to Performance of Decision Tree Generation?","Comparative study of a newly proposed machine learning classification to detect damage occurrence in structures","Examining the Robustness of an Ensemble Learning Model for Credibility Based Fake News Detection","Combined Data Augmentation for HEp-2 Cells Image Classification","Diagnosis of Alzheimer\u2019s disease via Intuitionistic fuzzy least squares twin SVM","Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey","Constant-Q Based Harmonic And Pitch Features For Normal vs. Pathological Infant Cry Classification","Robust scientific text classification using prompt tuning based on data augmentation with L2 regularization","Hybrid feature ranking and classifier aggregation based on multi-criteria decision-making","Hyperplane projection network for few-shot relation classification","DIF-SR: A Differential Item Functioning-Based Sample Reweighting Method","DPNET: Dynamic Poly-Attention Network for Trustworthy Multi-Modal Classification","Rank Allocation to J48 Group of Decision Tree Classifiers using Binary and Multiclass Intrusion Detection Datasets","Face Shape Classification Using Swin Transformer Model","ADCGNet: Attention-based dual channel Gabor network towards efficient detection and classification of electrocardiogram images","Granular computing-based deep learning for text classification","Combining Regular Expressions and Supervised Algorithms for Clinical Text Classification","Sentiment analysis of imbalanced datasets using BERT and ensemble stacking for deep learning","Pixel Based Supervised Classification of Hyperspectral Face Images for Face Recognition","Protein acetylation sites with complex-valued polynomial model","An Empirical Analysis of Geospatial Classification for Agriculture Monitoring","CALM: An Enhanced Encoding and Confidence Evaluating Framework for Trustworthy Multi-View Learning","A Comparative Analysis on Recent Methods for Addressing Imbalance Classification"],"x":{"__ndarray__":"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","dtype":"float64","shape":[493]},"x_backup":{"__ndarray__":"gJ9x4UBAQEDqPgCpTVBCwA9+4gD6rTPA71TAPc8pRUDvKyD+q8gVQLPSpBR0G0HAfUFmwopODcCcpzrkZiBKQOwdyUD5VgbAdeRIZ2AsNsDJdr6fGplAQFiOkIE8eyTAjZlEveCTBEAaogp/hjVCwA2l9iLaXiNAj1Tf+UXRJcA3FhQGZf49QPlNYaWCujDAA7Fs5pAEMkAA4q5eRQJAQGB2Tx4WwiJAq7NaYI9/RkCazk4GRwk7QFc+y/PgokRAUYiAQ6gSOsBOYhBYOQBBQF01zxH5DghAv4BeuHPhzT/Owp52+BNNQBnnb0IhOjtAIv/MID68RkCNYU7QJjcuQL/09ueiJTRA18BWCRYnNMAdrtUe9g4ywOn27X/b9htAIqrwZ3i7L8BpxqLp7Aw/wEph3uNMgy5A0NbBwd7YRsABmzlFw7nOP/+Tv3tHVTBAgIEgQIaGIcC9GwsKgzIMQAddwqG3WEdAcsRafApmQ8B16PS8GwvhPw9gkV8/bDRA0NbBwd5STED/XDRkPNI1QH4YITza5EZAXW3F/rIrNEAPrsrPVxrmPyaMZmX76CLA6j9rfvy1JMCJISD8F0rYP3jRV5BmvDZADJV/La90K0A6AyMva5oqQPkRv2INhwzA9iaG5GS6PsB+ObNdoYcrwJgUH5+QZUNARyHJrN4BD8Cc3sX7caMywCgpsACmkELAsI7jh0rTMcAcCMkCJjxLQOXQItv5jiZARzgteNFHPMB32a873SkswDPC24MQkEBA718P3DdNAECvPsNAfO0eQLWmeccpaivA02pI3GOdOMDC3Vm77co7wDcclgZ+bDJAofuLA1zO078hdxGmKMszQIZa07zjhEVAj/tW68TFIcDE0VW6uxI8wJLoZRTLjULAtafknNjVRkDUu3g/bllGQHnSHR+I7xxAFuk0wSbxEsAwxKACFl8dwEDdQIF3cENA4pANpItJN0AKuVLPglAqQJEKYwtBJjHAfUSnQpeLD0BZiXlW0gIiwP1LUpliujVApdqn4zEJTEC8JZQZypQHwOSd6F830fS/1np1RHQe8j/pt68D5+gyQGsnSkIivTBADWyVYHGQN0DLZ3ke3LkwwHhCrz+J2yHANWH7yRiPJcA3jliLT5EzwAeWI2QghyBA+CKLSNX1hr87qpog6so2QOAtkKD4jSlALZW3I5xcQEDwGB77WSwxwDzcDg2L6SBAbcfUXdmlScDTbB6HwYAzwDkn9tA+TijAHCYapOCZMECCPLt866MmwAkWhzO/zkJAvoV1493JQ8CCV8udmfAfwA39E1ysBkDA9n8O8+VtQsB6whIPKGtBwFInoImwyS1Ald9YBos54z8zaykg7fcwwEXxKmubQiBAUMjO29i8PcArwHebN/47QP32deCcg0jArkoi+yDTMMDLviuC//VAwInPnWD/dTTAy87sBEVNC0AE5bZ9j/49QENWt3pOxkjAPpP98zRYIUA6d7temjI7wNudWiK8Yg/A8Z9uoMCnP8DF5uPaUClEQAM+P4wQokdAdv2C3bDJMECUh4Va01A8wKmEJ/T6QyJAbwwBwLGfQUBsskY9RL1JQK+ZfLPNcUHAI2jMJOq1EkDQfqSIDOtLwHZUNUHUwUPAJUBNLVsTMcBIMUCiCWQXQF71gHnIFDnAnN1aJsNFNUD1XbZC/SsZQCOERxtHNEDAcHfWbrsYSMBLJVU+eKvhv5hsPNhivzDAXaeRlsrzJsCh9fBlougFwGNFDaZhmD9A1ZwXgnfNDEA/48KBkMJGQEVKs3kchh7AajNOQ1RJKUD9L9eiBUA6wGRYxRuZp0NA/Urnw7N8NsDFWKZfIvJFQMK+nUSElzDADyibcoU3D8DWSFwRRn3rPzNUxVT6SSTASyAldm3vG8BNLzGW6QcoQKYes/11qAJANUzIYvZ1GUAu51JcVThEwFPsaBzqDUfAxRuZR/5gK0A3ww34/JwwwIeowp/hnTTAGLSQgNGxNUBYAFMGDuw6QL7aUZyjWETAN+M0RBWWIMCY273cJ68hwHpsy4CzBCnA5h4Svvd1QEBPgYJBiJoBwEnHizuUtwXA/N6mP/tBS0B+jSRBuBY4QEil2NE49BNA1T4djxnwOcBuCEQ+nhwYwNUqVf2lgBnAcegtHt5/RMCcxYuFIRI/QALxun7BKFBAdH0fDhJCAsB/Ep87wZI1wHS9yF+11RpA7pi6K7uoIkDB4nDmVw9CwMSxLm6j4TZAfzFbsiqqL0B8urpjsZUnwBUZHZCEfew/2xZlNsg8PsBmHUQhuNATwNbEAl/RfT9A4c6FkV7ELEAmW5f5krbIP9RhhVs+ohFA56vkY3d9QcAVAU7v4pUrwAiOy7ipCT3A6a/8nv0lG8CX1YVpKerQv02giEUMwytAM1Naf0vgOkBTd2UXDA4KQBnJHqFmUDDAsv0a//Q1HkAfrLXmfTIBwE58taM4dyNAFAg7xarxKcAZkSi0rNsTQMKUN3Y/XfE/BcQkXMjdR8BC7iJMUTYoQCeIug9A5kLABTbn4JmQMECFX+rnTS0xwOxph78moz9ABirj32dsOcDrNqj91n4yQOHQWzy8SUPAb2OzI9WPJEBSgZNt4P4rwBXkZyPXzSRAY7X5f9XxLcAVgmYhS1Dtv1uU2SCT3C5APUZ55uUgLcC4W5IDdi0/wJ8ih4ib0xfARbqfU5CXJ0Av+grSjDlDwPdNqzKdp+K/lNkgk4xcScAcA1ceSeYTwNqtZTIcTx9AF7oSgerXPcAf2PFfIGQrwKddTDPdWyhAwK+RJAjnKsDaqbncYFhAQOtXOh+eD0tA1Lt4P25/JsDwFd16TWclQLTMIhRbiSHAMswJ2uT4KEAZAoBjz0o/wObUhKOauAVAqoHmc+5eI8DxQK4eQTvrPxhBYyZRGz5Adw/QfTnzJMC6TE2CNxAzwO0pOSf2EDtAQlpj0AlRE0By+nq+ZnkjQAWk/Q+wHipADB6mfXPPJcAw9fOmIh0zQMYWghyUaElARdrGn6gUNECynlp9dW9EwGwhyEEJe0lAyecVTz3iKcDz4sRXO1I3QBLYnINnzjTAKsk6HF2JP8DvG197ZrFIwO9VKxN+MVBA2BAcl3FjFMD27SQi/DVCQFhYcD/g3SzASkT4F0EDNkCQVQBC2jUDQHbDtkWZhUlA+BdBYyZtMsCKHY1D/boyQKFKzR5o3UJAYDcRoiHo/7+espquJwokQNffEoB/xjVAZ2Ml5lmZIEBagoyACosswO87hsd+3jRAVFVoIJYVNMBVwhN6/QkvQKlNnNzvgBNAhNiZQudFGUAwV1BiIWQXwAMn28AdPklANlmjHqKpNkDshJfg1Jc8wN8Vwf9WWiHATFXa4ho/J0AxC+2cZqECwGLboswG/UBAx7lNuFfaP0AcsoF0sZEgQPZcpibBaxhAsryrHjCvGcC4HoXrUQA9wMcPlUbMEDdAj5KyoIspH8C2EOSghGFAwJUO1v85WkVA5Nh6hnD8J0A9RQ4RN68pwOgSDr3F+UvAba6a54h8AUBnnfF9cW09wFlqvd9oyUZAwVWeQNgTQsC+TBQhdRsywLU3+MJk6kBAiLoPQGrrO0AbS1gbY1MxwOQPBp573UBAzha1oJytBsBhcM0d/b9GwE39F2O7HhPAJlMFo5KeN8CSsG8nEeE7wGZJgJpahkNAzhq8r8q9I8CpM/eQ8EUmQDdvnBTmNS1AmpZYGY3YM8BpGan3VJ4XwBCbI4Z4vw1AU7MHWoElQUCuDRXj/A04QHVyhuKOfybAA+s4fqhORUCFeCRenqxDQCbhQh7BCUDAxh41gX3nE0BTJcreUlY4QA5ORL+2mjtAlKRrJt8sG8BH5pE/GPZGQGACt+7m4SpAXeLIA5HxSMBk8fZ7vVbtP6Rt/InKXidAzv5AuW2DMkDIpeDfVkAQQPcdw2M/EzZAwmuXNhzGI8Cz0qQUdBtBwO/GgsKgrELA7WZGPxpuNECRlm8inzQQQF5m2Cjr9yXAfNhmvt7gHcC4rS08L4UwwECk374OAD7Aww34/DBaIcAiNe1imhkxwEQX1LfMxTRAecxAZfybMsCgwDv59IQ2wO7of7kWfTBAQ8u6fyywPUCcw7Xaw7YyQNhJfVnaCTlA6gPJO4c+NMABE7h1N681QA+cM6K0H0VAsmg6OxmoPcCIhO/9DboywD/IsmDiZz/AyZI5lne1JkARGOsbmKRKQMmrcwzITkFAH0dzZOV/McCDM/j7xWpBQHyZKELqpkDAM6g2OBEdOkB0tRX7yzYzwEm8PJ0r5klAxHx5AfaJQEA4E9OFWPU3QAskKH6MwTLAOlyrPezVLsBvLZPheBozwMbE5uPalDVAlzjyQGQPQkDs2XOZmuw9QKUTCaaamTtAZXCUvDqLNsBxxjAnaHMIQMeA7PXuHxFAUwd5PZhUN0AOZhNgWBYmwL98smK4eirA1gCloUaRRMDefq/XqjP+vwyx+iMM+zDAC2MLQQ5OM8AR8otcgdIMwKM/NPPkGiRArvIEwk4ZEMAEHEKVmjU7wD0bA/xk1gHA+kFdpFBGNcD7Bbth2+5AQDIFa5xNGzHAICFvXkHnFMChuU4jLWlIQFvQe2MIfDRA843onnXdHsDTM73EWCYiwDcawFsgNT9A7wIlBRbgK8DgvaPGhOgQQK4q+64IDkdAHClbJO0WPsDhXS7iO5dBwFjIXBlUrz/AJT/iV6wFOECnzqPi/8owQIcHgyFh3gTAiWAcXDr6MMDfpj/7kVYzwI0OSMK+DUhA3/jaM0taTEDfGtgqwRZIQNswCoLHnyHAtqD3xhCwJ0Cwh0A/nRz1vwg8MIDw0QxADR07qMRBPUAa+ie4WLErQLuX++QoWDNAA4eC36emxD+oVfSHZq4xQGwGuCBb/kZAxPnl3aINGEA1e6AVGPpAQOM2GsBbQEVA48EWu31WKsAUQgddwt01QAmISbiQjyHAXdxGA3hjLsB3FOeoo6MZwMFz7+GSs0NAxy5RvTVwIMApWU5C6a80wHC9XHrqhwLA8aFESx4XJMAlzLT9K5FEwPPtuDwxFh3AnKc65GaAO0DK4Ch5dZY1QKVL/5JUZinAVaaYg6CLO8CL4H8r2UFKwNOiPskdtvC/6fF7m/5wMED99+C1S6MlQOVV52IdWOE/yECeXb5BQEDIpxFEJ9XnP40kQbgCyhFABi/6CtIMMsCQMuIC0K5AwJiiXBq/sCjAv9TPm4rIQECMv+0JEtsYwG9nX3mQfi5AWvCiryCtBUA=","dtype":"float64","shape":[493]},"y":{"__ndarray__":"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","dtype":"float64","shape":[493]},"y_backup":{"__ndarray__":"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","dtype":"float64","shape":[493]}},"selected":{"id":"1071","type":"Selection"},"selection_policy":{"id":"1072","type":"UnionRenderers"}},"id":"1011","type":"ColumnDataSource"},{"attributes":{"formatter":{"id":"1056","type":"BasicTickFormatter"},"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1025","type":"LinearAxis"},{"attributes":{},"id":"1021","type":"LinearScale"},{"attributes":{"margin":[20,20,20,20],"sizing_mode":"scale_both","style":{"color":"#BF0A30","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Click on a plot to see the info about the article.","width":150},"id":"1064","type":"Div"},{"attributes":{"children":[{"id":"1076","type":"Div"}]},"id":"1078","type":"Row"},{"attributes":{"children":[{"id":"1064","type":"Div"}]},"id":"1086","type":"Row"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Time Range:&lt;/h3&gt;&lt;p1&gt;Click on the button to change the time range of the plot.&lt;/p1&gt;"},"id":"1002","type":"Div"},{"attributes":{"callback":null},"id":"1017","type":"DataRange1d"},{"attributes":{},"id":"1023","type":"LinearScale"},{"attributes":{"label":{"field":"labels"},"renderers":[{"id":"1052","type":"GlyphRenderer"}]},"id":"1061","type":"LegendItem"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Clustering of literature on supervised learning by classification from ACM Digital Library. \n    The dataset is extracted from &lt;a href=\"https://dl.acm.org/topic/ccs2012/10010147.10010257.10010258.10010259.10010263?expand=all&amp;startPage=\"&gt;here&lt;/a&gt;."},"id":"1006","type":"Div"},{"attributes":{"children":[{"id":"1003","type":"Div"},{"id":"1004","type":"Div"},{"id":"1005","type":"Div"}]},"id":"1081","type":"Row"},{"attributes":{"args":{"current_selection":{"id":"1064","type":"Div"},"source":{"id":"1011","type":"ColumnDataSource"}},"code":"\n        var titles = [];\n        var authors = [];\n        var abstracts = [];\n        var publicationDates = [];\n        var clusters = [];\n\n        cb_data.source.selected.indices.forEach(index =&gt; {\n            titles.push(source.data['title'][index]);\n            authors.push(source.data['author'][index]);\n            abstracts.push(source.data['abstract'][index]);\n            publicationDates.push(source.data['publication_date'][index]);\n            clusters.push(source.data['cluster'][index]);\n        });\n\n        var title = \"&lt;p1&gt;&lt;b&gt;Title:&lt;/b&gt; \" + (titles[0] ? titles[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var author = \"&lt;p1&gt;&lt;b&gt;Author:&lt;/b&gt; \" + (authors[0] ? authors[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var abstract = \"&lt;p1&gt;&lt;b&gt;Abstract:&lt;/b&gt; \" + abstracts[0].toString() + \"&lt;br&gt;\";\n        var publicationDate = \"&lt;p1&gt;&lt;b&gt;Publication Date:&lt;/b&gt; \" + publicationDates[0].toString() + \"&lt;/p1&gt;&lt;br&gt;\";\n        var cluster = \"&lt;p1&gt;&lt;b&gt;Cluster:&lt;/b&gt; \" + clusters[0].toString() + \"&lt;/p1&gt;\";\n\n        current_selection.text = title + author + abstract + publicationDate + cluster;\n        current_selection.change.emit();\n    "},"id":"1065","type":"CustomJS"},{"attributes":{"source":{"id":"1011","type":"ColumnDataSource"}},"id":"1053","type":"CDSView"},{"attributes":{"children":[{"id":"1062","type":"Paragraph"}]},"id":"1084","type":"Row"},{"attributes":{"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1029","type":"Grid"},{"attributes":{"text":"Clustering of the ACM papers on Supervised Learning by Classification"},"id":"1015","type":"Title"},{"attributes":{},"id":"1031","type":"BasicTicker"},{"attributes":{},"id":"1035","type":"PanTool"},{"attributes":{},"id":"1038","type":"ResetTool"},{"attributes":{"children":[{"id":"1074","type":"Slider"},{"id":"1075","type":"TextInput"}]},"id":"1083","type":"Row"},{"attributes":{"text":"&lt;a href=\"clusters_last_month.html\" target=\"_blank\"&gt;&lt;button&gt;Last Month&lt;/button&gt;&lt;/a&gt;"},"id":"1003","type":"Div"},{"attributes":{},"id":"1056","type":"BasicTickFormatter"},{"attributes":{"children":[{"id":"1006","type":"Div"}]},"id":"1079","type":"Row"},{"attributes":{"children":[{"id":"1002","type":"Div"}]},"id":"1080","type":"Row"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1051","type":"Scatter"},{"attributes":{"callback":null,"point_policy":"follow_mouse","tooltips":[["Title","@title"],["Author","@author"],["Abstract","@abstract{safe}"],["Publication Date","@publication_date"],["Cluster","@cluster"]]},"id":"1012","type":"HoverTool"},{"attributes":{"callback":null},"id":"1019","type":"DataRange1d"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"margin":[15,15,15,15],"sizing_mode":"scale_both","title":"Search:"},"id":"1075","type":"TextInput"},{"attributes":{},"id":"1036","type":"WheelZoomTool"},{"attributes":{"high":5,"low":0,"palette":["#1f77b4","#aec7e8","#ff7f0e","#ffbb78","#2ca02c","#98df8a"]},"id":"1013","type":"LinearColorMapper"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"color":"#2e484c","font-family":"Julius Sans One, sans-serif;"},"text":"&lt;h1&gt;Clustering Literature on Supervised Learning by Classification (Last Half Year)&lt;/h1&gt;"},"id":"1076","type":"Div"},{"attributes":{},"id":"1071","type":"Selection"},{"attributes":{"text":"&lt;a href=\"clusters_last_half_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Half Year&lt;/button&gt;&lt;/a&gt;"},"id":"1004","type":"Div"},{"attributes":{"children":[{"id":"1014","subtype":"Figure","type":"Plot"}]},"id":"1085","type":"Row"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by Text:&lt;/h3&gt;&lt;p1&gt;Search keyword to filter out the plot. It will search abstracts, titles and authors. \n    Press enter when ready. Clear and press enter to reset the plot.&lt;/p1&gt;"},"id":"1007","type":"Div"},{"attributes":{"overlay":{"id":"1059","type":"BoxAnnotation"}},"id":"1037","type":"BoxZoomTool"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1059","type":"BoxAnnotation"},{"attributes":{"height":75,"margin":[20,20,20,20],"sizing_mode":"stretch_width","style":{"color":"#0269A4","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Keywords: Slide to specific cluster to see the keywords."},"id":"1062","type":"Paragraph"},{"attributes":{"below":[{"id":"1025","type":"LinearAxis"}],"center":[{"id":"1029","type":"Grid"},{"id":"1034","type":"Grid"},{"id":"1060","type":"Legend"}],"left":[{"id":"1030","type":"LinearAxis"}],"margin":[5,5,5,5],"plot_height":500,"plot_width":500,"renderers":[{"id":"1052","type":"GlyphRenderer"}],"sizing_mode":"scale_both","title":{"id":"1015","type":"Title"},"toolbar":{"id":"1041","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1017","type":"DataRange1d"},"x_scale":{"id":"1021","type":"LinearScale"},"y_range":{"id":"1019","type":"DataRange1d"},"y_scale":{"id":"1023","type":"LinearScale"}},"id":"1014","subtype":"Figure","type":"Plot"},{"attributes":{},"id":"1058","type":"BasicTickFormatter"},{"attributes":{"data_source":{"id":"1011","type":"ColumnDataSource"},"glyph":{"id":"1050","type":"Scatter"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1051","type":"Scatter"},"selection_glyph":null,"view":{"id":"1053","type":"CDSView"}},"id":"1052","type":"GlyphRenderer"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"end":6,"margin":[15,15,15,15],"sizing_mode":"stretch_width","start":0,"title":"Cluster #","value":6},"id":"1074","type":"Slider"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.4.0"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('1176').textContent;
                  var render_items = [{"docid":"6638c113-28a2-4ff8-95c5-f106ba7431f2","roots":{"1087":"c1a1ffa6-2589-4153-89ff-86179dbf7dad"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>