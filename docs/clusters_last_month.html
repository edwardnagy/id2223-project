



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Clustering papers on Supervised Learning by Classification</title>
      
      
        
          
        
        
          
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="8b91ed45-e52e-42a8-b073-e6969419ebea" data-root-id="1087"></div>
            
          
        
      
      
        <script type="application/json" id="1176">
          {"26c31e1b-f7bd-4c41-9ff6-8244afe30bd5":{"roots":{"references":[{"attributes":{"children":[{"id":"1002","type":"Div"}]},"id":"1080","type":"Row"},{"attributes":{"text":"&lt;a href=\"clusters_last_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Year&lt;/button&gt;&lt;/a&gt;"},"id":"1005","type":"Div"},{"attributes":{"callback":null},"id":"1019","type":"DataRange1d"},{"attributes":{"dimension":1,"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1034","type":"Grid"},{"attributes":{"label":{"field":"labels"},"renderers":[{"id":"1052","type":"GlyphRenderer"}]},"id":"1061","type":"LegendItem"},{"attributes":{"children":[{"id":"1078","type":"Row"},{"id":"1079","type":"Row"},{"id":"1080","type":"Row"},{"id":"1081","type":"Row"},{"id":"1082","type":"Row"},{"id":"1083","type":"Row"},{"id":"1084","type":"Row"},{"id":"1085","type":"Row"},{"id":"1086","type":"Row"}]},"id":"1087","type":"Column"},{"attributes":{"formatter":{"id":"1056","type":"BasicTickFormatter"},"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1025","type":"LinearAxis"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by the Clusters:&lt;/h3&gt;&lt;p1&gt;The slider below can be used to filter the target cluster. \nSimply slide the slider to the desired cluster number to display the plots that belong to that cluster. \nSlide back to the last cluster to show all the plots.&lt;/p1&gt;"},"id":"1008","type":"Div"},{"attributes":{"children":[{"id":"1003","type":"Div"},{"id":"1004","type":"Div"},{"id":"1005","type":"Div"}]},"id":"1081","type":"Row"},{"attributes":{"fill_color":{"field":"cluster","transform":{"id":"1013","type":"LinearColorMapper"}},"line_alpha":{"value":0.3},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1050","type":"Scatter"},{"attributes":{},"id":"1072","type":"Selection"},{"attributes":{"text":"&lt;a href=\"clusters_last_month.html\" target=\"_blank\"&gt;&lt;button&gt;Last Month&lt;/button&gt;&lt;/a&gt;"},"id":"1003","type":"Div"},{"attributes":{"text":"Clustering of the ACM papers on Supervised Learning by Classification"},"id":"1015","type":"Title"},{"attributes":{"formatter":{"id":"1058","type":"BasicTickFormatter"},"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1030","type":"LinearAxis"},{"attributes":{},"id":"1036","type":"WheelZoomTool"},{"attributes":{"overlay":{"id":"1059","type":"BoxAnnotation"}},"id":"1037","type":"BoxZoomTool"},{"attributes":{"children":[{"id":"1008","type":"Div"},{"id":"1007","type":"Div"}]},"id":"1082","type":"Row"},{"attributes":{"children":[{"id":"1074","type":"Slider"},{"id":"1075","type":"TextInput"}]},"id":"1083","type":"Row"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"margin":[15,15,15,15],"sizing_mode":"scale_both","title":"Search:"},"id":"1075","type":"TextInput"},{"attributes":{"children":[{"id":"1064","type":"Div"}]},"id":"1086","type":"Row"},{"attributes":{"callback":{"id":"1065","type":"CustomJS"}},"id":"1040","type":"TapTool"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Clustering of literature on supervised learning by classification from ACM Digital Library. \n    The dataset is extracted from &lt;a href=\"https://dl.acm.org/topic/ccs2012/10010147.10010257.10010258.10010259.10010263?expand=all&amp;startPage=\"&gt;here&lt;/a&gt;."},"id":"1006","type":"Div"},{"attributes":{"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1029","type":"Grid"},{"attributes":{"callback":null,"data":{"abstract":["Parkinson\u2019s disease (PD) is the second most common neurodegenerative disorder, as reported by the World Health Organization (WHO). In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit (SWEDD) and Healthy Control (HC). We use white matter (WM) and gray matter (GM) from the MRI and fractional anisotropy (FA) and mean diffusivity (MD) from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53% for the direct three-class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.","In this paper, we present a prototype selection technique for imbalanced data, Fuzzy Rough Imbalanced Prototype Selection (FRIPS), to improve the quality of the artificial instances generated by the Synthetic Minority Over-sampling TEchnique (SMOTE). Using fuzzy rough set theory, the noise level of each instance is measured, and instances for which the noise level exceeds a certain threshold level are deleted. The threshold is determined using a wrapper approach that evaluates the training Area Under the Curve of candidate subsets. This proposal aims to clean noisy data before applying SMOTE, such that SMOTE can generate high quality artificial data.\nExperiments on artificial data show that FRIPS in combination with SMOTE outperforms state-of-the-art methods, and that it particularly performs well in the presence of noise.","Machine learning research relies to a large extent on experimental observations. The evaluation of classifiers is often carried out by empirical comparison with classifiers generated by different learning algorithms, allowing the identification of the best algorithm for the problem at hand. Nevertheless, previously to this evaluation, it is important to state if the classifiers have truly learned the domain class concepts, which can be done by comparing the classifiers\u2019 predictive measures with the ones from the baseline classifiers. A baseline classifier is the one constructed by a na\u00efve learning algorithm which only uses the class distribution of the dataset. However, finding na\u00efve classifiers in multi-label learning is not as straightforward as in single-label learning. This work proposes a simple way to find baseline multi-label classifiers. Three specific and one general na\u00efve multi-label classifiers are proposed to estimate the baseline values for multi-label predictive evaluation measures. Experimental results show the suitability of our proposal in revealing the learning power of multi-label learning algorithms.","Skip Abstract Section\nAbstract\nBreast cancer is a divergent and prominent cancer that is responsible for the morbidity and mortality of women throughout the world. This paper aims at early detection and accurate diagnosis of this fatal disease, which is one of the most important steps in breast cancer treatment. Therefore, various nested ensemble machine learning techniques are used to help doctors determine breast cancer at an early stage. The two-layer nested ensemble model has been proposed, which encompasses stacking and voting techniques to detect benign and malignant breast cancer tumors. A total of four two-layer nested ensemble models have been proposed. S(NaiveBayes)-V(3-Meta_Learner), S(BayesNet)-V(3-Meta_Learner), S(NaiveBayes)-V(4-Meta_Learner), and S(BayesNet)-V(4-Meta_Learner) have been designed to contain base learners and meta learners. The experiments have been conducted with the k-fold cross-validation technique for model evaluation. The proposed model is capable of classifying benign and malignant breast cancer tumors with 99.50% accuracy. The aforementioned four models have been compared with previous works in terms of classification accuracy, ROC, recall, precision, TP rate, FP rate, and F1 measure. The experiments showed that the proposed two-layer nested ensemble model S(BayesNet)-V(4-Meta_Learner) performed better than the other three models mentioned supra and competed with all the previously published works. This would help the scientific community and health practitioners diagnose breast cancer with early and accurate results.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts, however they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","Orthopedic implant identification is an important and necessary step prior to performing revision surgery of different joints. The inability to identify an implant can lead to significant surgical difficulties with consequent unfavorable outcomes. This paper proposes a novel framework to identify the make and model of seven (7) different total shoulder arthroplasty implants utilizing plain X-ray images and Artificial intelligence. The proposed work classified implants with an accuracy of 91.48% and with an AUC (Area under curve) of 0.9932 showing higher effectiveness in orthopedic implant identification. Further work is required to enhance and progress this work, with a goal of greater accuracy and fewer errors.","In pattern recognition and data mining a data set is named skewed or imbalanced if it contains a large number of objects of certain type and a very small number of objects of the opposite type. The imbalance in data sets represents a challenging problem for most classification methods, this is because the generalization power achieved for classic classifiers is not good for skewed data sets. Many real data sets are imbalanced, so the development of new methods to face this problem is necessary. The SVM classifier has an exceptional performance for data sets that are not skewed, however for imbalanced sets the optimal separating hyper plane is not enough to achieve acceptable results. In this paper a novel method that improves the performance of SVM for skewed data sets is presented. The proposed method works by exciting the support vectors and displacing the separating hyper plane towards majority class. According to the results obtained in experiments with different skewed data sets, the method enhances not only the accuracy but also the sensitivity of SVM classifier on this kind of data sets.","We explore solutions for text classification applied to online cooking recipes, in a multitask, multilingual approach. The main objective is designing a solution that ensures high accuracy on the prediction tasks from, but not constrained to, 6 European Languages, considering also the cross-lingual transferability. The challenges of the problem are structured on two main dimensions: (1) data driven - such as imbalance and noise in the training data, and (2) solution driven - such as multilingualism, or the need to easily extend the model to new languages. We propose a solution focused on the XLM-R architecture, fine-tuned jointly on all tasks. We apply self-supervised domain adaptation via additional pre-training and analyze the enhancements produced by performing a 0-shot evaluation for underrepresented languages. Compared to basic language modeling solutions, we obtained an increase of 1.32% and 2.42%, respectively for the two most difficult classification tasks. In the 0-shot context, the absolute improvements are of 16.71% and 7.83% respectively, on underrepresented languages.","Finding the right business partner to drive innovation or acquire technology transfer is a labor and time-intensive process. To simplify this process, there is a need for improved methods of automated matchmaking that can quickly identify the best potential collaboration partners. This paper presents a novel approach for semi-automated business matchmaking between companies and research institutes, that is applied to a first case study. For this purpose, we compare two transformer-based text classification models and evaluate how dataset quality affects few-shot learning performance. Flair's TARS classifier performed very well in our use case, requiring only 40 examples per class to achieve an F1 score of about 90%. This is already very close to the Hugging Face standard text classifier, which achieved an F1 score of 92% with much more annotation effort. The results show that few-shot learning models like TARS can achieve accurate results even with few training samples compared to regular transformer-based language models. Our novel approach allows the time-consuming and labor-intensive task of manual partner matchmaking to be significantly reduced.","A world of healthcare possibilities has been opened with the development of the Internet of Medical Things and related machine learning, deep learning, and artificial intelligence approaches. It has a broad range of uses: when linked to the Internet, common medical equipment and sensors may gather important data; deep learning and artificial intelligence algorithms use this data to understand symptoms and patterns and allow remote healthcare. There are a large number of people affected by thyroid disorders across the world. The ultrasound-based thyroid nodule detection using traditional methods increased the burden on the expertise. Therefore, alternate methods are required to overcome this problem. In order to facilitate early thyroid disorder detection, this research aims to offer an IoT-based ensemble learning framework. In the proposed ensemble model, three pre-trained models DeiT, Mixer-MLP and Swin Transformer, are used for feature extraction. The mRMR technique is used for relevant feature selection. A total of 24 machine learning models have been trained, and weighted average ensemble learning is employed using the Improved Jaya optimization algorithm and Coronavirus Herd Immunity optimization algorithm. The ensemble model with the improved Jaya optimization algorithm achieved excellent results. The best value for accuracy, precision, sensitivity, specificity, F2-score and ROC-AUC score are 92.83%, 87.76%, 97.66%, 88.89%, 0.9551 and 0.9357, respectively. The main focus of this research is to increase the specificity. A poor value of specificity can lead to a high false positive rate. This situation can increase anxiety and emotionally weaken the patient. The proposed ensemble model with the Improved Jaya optimization algorithm outperformed state-of-the-art techniques and can assist medical experts.","Federated learning (FL) has recently been applied to skin lesion analysis, but the challenges of huge communication requirements and non-independent and identical distributions have not been fully addressed. The former problem arises from model parameter transfer between the server and clients, and the latter problem is due to differences in imaging protocols and operational customs. To reduce communication costs, dataset distillation methods have been adopted to distill thousands of real images into a few synthetic images (1 image per class) in each local client, which are then used to train a global model in the server. However, these methods often overlook the possible inter-client distribution drifts, limiting the performance of the global model. In this paper, we propose a generalizable dataset distillation-based federated learning (GDD-FL) framework to achieve communication-efficient federated skin lesion classification. Our framework includes the generalization dataset distillation (GDD) method, which explicitly models image features of the dataset into an uncertain Gaussian distribution and learns to produce synthetic images with features close to this distribution. The uncertainty in the mean and variance of the distribution enables the synthetic images to obtain diverse semantics and mitigate distribution drifts. Based on the GDD method, we further develop a communication-efficient FL framework that only needs to transmit a few synthesized images once for training a global model. We evaluate our approach on a large skin lesion classification dataset and compare it with existing dataset distillation methods and several powerful baselines. Our results show that our model consistently outperforms them, particularly in comparison to the classical FL method. All resources can be found at https://github.com/jcwang123/GDD-FL.","This paper proposes a novel approach for classifier ensemble by employing the concepts of multi-criteria decision-making (MCDM) and aggregation operators. In this framework, a heterogeneous ensemble process has been incorporated where we consider varied set of classifiers to train the model. Each considered classifier is trained on the training data and a score correspondent to it is generated by utilizing the MCDM process. Subsequently, during the training phase, the priority is generated among the classifiers. For the testing phase, these prioritized classifiers are combined using prioritized aggregation operator. The priority order determined during the training phase is used to ensemble the classifiers during the testing phase. The proposed method is tested on UCI benchmark datasets and outperforms existing state-of-the-art methods.","A fit person who is health conscious always considers weighing what they eat and takes the calories on the food they eat. There is a certain number of calories per day that helps bodybuilders or people who want to stay fit. Taking in considerations of eating Fruits to have the calories, macros and nutrients they need. This study presents fruit calorie estimation using CNN or Convolutional Neural Network, the program was able to detect all the fruits with recognition accuracy of 70% and the percentage difference calorie estimation for each fruit are as follows: apple has 30.58%, banana garnered 21.15%, grapes garnered 44.07% and orange has 32.20%.","Diffuse large B-cell lymphoma (DLBCL) is an aggressive and most common type of non-Hodgkin lymphoma. The two major molecular subtypes of DLBCL, i.e. germinal center B-cell-like (GCB) and activated B-cell-like (ABC) types of DLBCL, have different clinical outcomes when treated with combined therapy R-CHOP. Cell-of-origin (COO) is a published prognostic method. Up to now, this classification requires either complex gene expression analysis or multiple immunohistochemistry (IHC) stains requiring expert scoring and assessment. In this paper, we aim to develop an effective and tissue-saving COO classification method based on H&amp;E stained whole slide images (WSIs). Specifically, we develop a new approach named Cellular Features Based Interpretable Network (CellFiNet), by leveraging both interpretable cellular features derived from image tiles and attention based multi-instance learning (AMIL) framework to train a WSI classification model. In comparison with the conventional AMIL approach based on image embeddings derived from convolutional neural networks (CNNs), the proposed approach achieved comparable classification accuracy, while being favorable in terms of explainability, as the model behavior can be interpreted through both attention scores and biologically relevant feature importances at whole slide as well as image tile levels.","The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.","To evaluate the robustness of non-classifier models, we propose probabilistic local equivalence, based on the notion of randomized smoothing, as a way to quantitatively evaluate the robustness of an arbitrary function. For a given function\nf\n, probabilistic local equivalence evaluates whether, when sampling a normally-distributed point\nx\n\u2032\nin a neighborhood of a point\nx\n, there is a probability\n&gt;\n0.5\nthat\nf\n(\nx\n\u2032\n)\nis equivalent to\nf\n(\nx\n)\n, according to a user-defined notion of equivalence. We use probabilistic local equivalence to evaluate the effect of data augmentation methods for improving robustness, including adversarial training, on a model\u2019s performance. We also use probabilistic local equivalence to evaluate the effect on robustness of model architecture, number of parameters, pre-training, quantization, and other model properties.","Emotion classification from text is the process of identifying and classifying emotions expressed in textual data. Emotions can be feelings such as anger, joy, suspense, sadness and neutral. Developing a machine learning model to identify emotions in a low-resourced language with a limited set of linguistic resources and annotated corpora is a challenge. This research proposes a Deep Learning Emotion Classification Framework to identify and classify emotions in low-resourced languages such as Hindi. The proposed framework combines a classification model and a low resource optimization technique in a novel way. An annotated corpus of Hindi short stories consisting of 20,304 sentences is used to train the models for predicting five categories of emotions: anger, joy, suspense, sadness, and neutral talk. To resolve the class imbalance in the dataset SMOTE technique is applied. The optimal classification model is selected through experimentation that compares machine learning models and pre-trained models. Machine learning and deep learning models are SVM, Logistic Regression, Random Forest, CNN, BiLSTM, and CNN+BiLSTM. The pre-trained models, mBERT, IndicBERT, and a hybrid model, mBERT+BiLSTM. The models are evaluated based on macro average recall, macro average precision, and macro average F1 score. Results demonstrate that the hybrid model mBERT+BiLSTM out perform other models with a test accuracy of 57%.","Insect pests have always been a global agricultural problem because the severity and extent of their occurrence threaten crop yield. Recognizing them early can help farmers have efficient measures to handle them, which can help mitigate negative impacts from insect pests. However, insect pest recognition still relies heavily on experts, which is expensive and time-consuming. With the power of Deep Learning, we propose two methods to solve this task in this paper. First, we proposed a method that uses models pre-trained on the ImageNet dataset, including ResNet-50, EfficientNet-B4, and VisionTransformer-B16, respectively. We also change the structure of these models by adding a Dropout layer before the output layer of these pre-trained models to avoid overfitting. Second, we apply hierarchical learning for this task. In the latter approach, we first use the baseline model to create a confusion matrix. Through this matrix, we cluster classes that the baseline model misses to each other because of the similar appearance across classes into bigger classes, and we consider them as sub-datasets. Then, we build each model for each sub-dataset using the identical backbones as the baseline methods with the hope that it helps the method classify better in these classes. We do experiments to evaluate the performance of methods on the IP102 dataset. From experiments, our proposed method, which uses VisionTransformer-B16 backbone combined with hierarchical learning, gets the best accuracy of 74.50% on the IP102 dataset. When ensemble 3 above models and combine with hierarchical learning, we get the best accuracy of 76.24% on this dataset.","Planktons are the building blocks of marine food webs and key indicators of ocean health. Monitoring of plankton populations help study the biological diversity of microbial eukaryotes. Recent years have witnessed the wide usage of digital holographic microscopes (DHM) for in situ detection of underwater microplanktons. Holography has an edge over other imaging techniques due to its unique ability to provide a 3D hologram of the microplankton without disturbing its orientations. In this paper, a novel network architecture with 5.29 GFLOPs is developed for the classification of microplanktons in digital holographic images. The proposed method achieved a class-wise F1-scores above\n80\n%\nat a lower computational cost. The proposal provided competitive performance with respect to six baseline network architectures. This technique has the potential to be appealing for future applications of in situ classification of microplanktons.","Data irregularities, such as small disjuncts, class skew and imbalance, and outliers significantly affect the performance of classifiers. In this paper, we focus on identifying small disjuncts, which hitherto, has been addressed mainly by rule-based or inductive algorithms. Small disjuncts have been identified as distribution-based irregularities which provide significant learning, although they cover a subset of examples in the training set, which may be considered as being rare. Such samples are more error-prone than large disjuncts. Eliminating small disjuncts by removal or pruning is seen to affect the learning of the classifier adversely. Widely used non-rule-based learning algorithms like SVM, kNN, Logistic Regression, and Neural networks perform poorly in the presence of small disjuncts in the dataset. In this paper, a novel Sequential Ellipsoidal Partitioning method is proposed to identify small disjuncts in the dataset. This method is a supervised classifier that iteratively partitions the dataset into Minimum Volume Ellipsoids that contain points of the same label; this is performed based on the idea of Reduced Convex Hulls. By allowing an ellipsoid that contains points of one label to contain a few points of the other, such small disjuncts may be identified. As we discuss, the proposed technique is agnostic of underlying data distributions and is applicable as a supervised classifier when the datasets are highly skewed and imbalanced even. We demonstrate the performance of the approach using a few publicly available datasets.","Hyperspectral image(HSI) classification is a crucial topic within remote sensing. Recently, deep self-supervised learning methods have gained widespread use in HSI classification, effectively addressing the scarcity of labeled samples issue. In particular, masked image modeling and contrastive learning have achieved commendable performance in the field of self-supervised learning. Therefore, to better investigate the association and synergy between the two self-supervised learning methods, we propose a novel hybrid self-supervised learning framework (HSL) for HSI classification that conforms to the properties of hyperspectral data. The HSL exploits the efficacy of masked image modeling and contrastive learning, and combines masked image reconstruction and instance contrastive learning to improve performance. The HSL specifically employs an asymmetric encoder-decoder two-branch structure. The structure adopts the Vision Transformer as the backbone network to efficiently extract spatial spectral information. Experiments on two commonly used HSI datasets demonstrate that this pre-training task results in better modeling of the feature relationships between shallow and deep layers and achieves superior performance.","In this paper the first results of the process of extracting survival patterns in diagnosed women with invasive cervical cancer with classification techniques from data reported in population-based cancer registry of the municipality of Pasto (Colombia) for a time period of 10 years are presented. The generated knowledge will allow to understand the different socioeconomic and clinical factors affecting the survival of this population group. This knowledge will support effective decision making of government agencies and private health sector in relation to the approach of public policies and prevention programs designed to detect new cases of women with this disease early.","Glaciers play a critical role in the Earth\u2019s climate system, and accurate estimates of their behaviours are essential for understanding the impacts of climate change and informing policy decisions. One of the most important parameters for such a task is ice distribution, which is difficult to measure and predict using traditional physics-based models. In this study, we propose a deep learning approach to predict glacier thickness by learning directly from ice velocity and topography. Our approach overcomes the limitations of traditional physics-based models, such as computational cost and the need for expert knowledge to calibrate the models. In addition, deep learning models are flexible enough to explore the relevance of multimodality and multitasking to address the physical problem. Our results demonstrate the feasibility of quickly training a neural network model with sufficient training data and producing stable, high-quality ice thickness estimates. We highlight the importance of some specific input features suggested by geophysicists that have a positive impact on model stability.","In this paper, we propose a generalization of classical Rough Sets, the Nearest Neighborhood Rough Sets, by modifying the indiscernible relation without using any similarity threshold. We also combine these Rough Sets with Compact Sets, to obtain a prototype selection algorithm for Nearest Prototype Classification of mixed and incomplete data as well as arbitrarily dissimilarity functions. We introduce a set of rules to a priori predict the performance of the proposed prototype selection algorithm. Numerical experiments over repository databases show the high quality performance of the method proposed in this paper according to classifier accuracy and object reduction.","The original K-nearest neighbour (KNN) algorithm was meant to classify homogeneous complete data, that is, data with only numerical features whose values exist completely. Thus, it faces problems when used with heterogeneous incomplete (HI) data, which has also categorical features and is plagued with missing values. Many solutions have been proposed over the years but most have pitfalls. For example, some solve heterogeneity by converting categorical features into numerical ones, inflicting structural damage. Others solve incompleteness by imputation or elimination, causing semantic disturbance. Almost all use the same K for all query objects, leading to misclassification. In the present work, we introduce KNNHI, a KNN-based algorithm for HI data classification that avoids all these pitfalls. Leveraging rough set theory, KNNHI preserves both categorical and numerical features, leaves missing values untouched and uses a different K for each query. The end result is an accurate classifier, as demonstrated by extensive experimentation on nine datasets mostly from the University of California Irvine repository, using a 10-fold cross-validation technique. We show that KNNHI outperforms six recently published KNN-based algorithms, in terms of precision, recall, accuracy and F-Score. In addition to its function as a mighty classifier, KNNHI can also serve as a K calculator, helping KNN-based algorithms that use a single K value for all queries that find the best such value. Sure enough, we show how four such algorithms improve their performance using the K obtained by KNNHI. Finally, KNNHI exhibits impressive resilience to the degree of incompleteness, degree of heterogeneity and the metric used to measure distance.","Blood Pattern Analysis is a technique in forensic science that focuses on leftover bloodstains from the crime to recreate the event. However, the fluctuation in air resistance and drop deformity causes the calculations to deviate from the exact values. Therefore, machine learning models were constructed to overcome this limitation of calculations. A series of experiments was conducted by dropping porcine blood on paper across nine distinct heights: 20, 40, 60, 80, 100, 120, 140, 160, and 180 cm with four different drop volumes: 13, 16, 25, and 30 \u03bcL resulting in 36 classes. A simple simulation of a free-fall spherical object was also created to convert any drop height into impact velocity. Regarding both the empirical data and simulation, the correlation between the spreading factor and modified Reynold number, along with the number of spines and modified Weber number, were expressed as equations that can be used to determine drop height and drop volume. Concurrently, the same dataset used in physics calculations was used to train machine learning models that implement VGG-19 and XGBoost. For VGG-19, the inputs are images of bloodstains, while for XGBoost, the inputs are stain area, stain perimeter, and the number of spines. As a result, the accuracy for physics equations VGG-19 and XGBoost were 0.26, 0.56, and 0.49, respectively.","This paper introduces a binary classification network that utilizes the Informer Encoder to classify ping pong actions as either correct or incorrect. The dataset used in this study comprises 949 action videos capturing two fundamental ping pong stroke actions performed by athletes, including both correct and incorrect actions. The average frame count for each action is 38.62. Temporal skeletal data is extracted from the videos using a 2D pose estimation model, and a fully connected layer is employed to perform binary classification on the temporal skeletal data. During training and testing, the extracted skeletal data is segmented into temporal sequences of 39 frames for training and evaluation. On the test set, the Informer Encoder-based model achieves 100% accuracy, while the MLP-based model reaches 94%.","The family orientation process in Cuban Schools for children with Affective \u2013 Behavioral Maladies (SABM) involves clustering and classification of mixed type data with non-symmetric similarity functions. To improve this process, this paper includes some novel characteristics in clustering and prototype selection. The proposed approach uses a hierarchical clustering based on compact sets, making it suitable for dealing with non-symmetric similarity functions, as well as with mixed and incomplete data. The proposal obtains very good results on the SABM data, and over repository databases. In addition, the proposed clustering method is able to detect the true partitions of data and it was significantly better with respect to others according to external validity indexes. In prototype selection, the proposal obtains a highly reduced prototype set, while maintains the original classifier accuracy.","Skip Abstract Section\nAbstract\nNetwork slicing (Ns) is a key enabling technology to support the concurrent provisioning of better quality of service (QoS) in 5G networks. These services have become essential for a telecom service provider (SP) to offer better QoS and QoE (quality of experience). The QoS parameters are used to estimate the performance of the network, and QoE determines user satisfaction with the network services. The main challenges faced by the service provider are to select the appropriate slice for each service and accurately classify these services on a timely basis to satisfy the Service level agreement (SLA) while improving the QoS and QoE. To overcome this issue, machine learning (ML) is a good solution. In this paper, we have proposed a 5G-KPQI (5G-key performance and quality indicator) model that considers the 5G service-based dataset for the 5G services classification. Next, we used feature selection (FS) methods to rank and select the best feature subset, which increases the performance of ML models and also reduces the training time required by the models. We subsequently considered various ML models to classify the services. Results demonstrate that the 5G-KPQI model ranks the features using Relief-F and mrMR methods and also reduces the training time of the model, hence improving classification performance measured by precision, accuracy, F1-score, recall, MCC, and time. The evaluation of the key approach outperforms in high classification accuracy and less training time using decision tree (DT) and random forest (RF).","Attention, one of the most important features of modern CNNs, has been shown to improve the performance of mammogram classification, but our understanding of why attention offers improvements is rather limited. In this paper, we present the first comprehensive comparison of different combinations of baseline models and attention methods at multiple resolutions for whole mammogram image classification of masses and calcifications. Our findings indicate that attention generally helps to improve the baseline model scores, but the benefits are variable depending on the resolution and abnormality type. Furthermore, we find that pooling and overall model architecture (i.e., combination of baseline and attention) significantly impact mammogram classification scores. Specifically, scores are generally improved by architectural features that allow the model to retain as much information as possible while still focusing on relevant features. We also find that attention improves the correlation between model performance and LayerCAM activation in the region of interest. Our work provides insightful information to help guide the future construction of attention-based models for mammogram classification.","Objective: The objective is to develop a predictive model utilizing Support Vector Machines (SVM) for the purpose of classifying the clinical stage of breast cancer.\nMaterials and Methods: Accurate determination of the clinical stage of breast cancer patients holds significant importance in selecting suitable treatment options and minimizing avoidable complications. In this study, we present the application of radiomics and SVM for breast cancer computed tomography (CT) to anticipate the preoperative clinical stage in breast cancer patients. The training dataset encompasses 166 cases obtained from the Affiliated Hospital of Xiangnan University, while the test dataset comprises 91 cases from Chenzhou Third People's Hospital. The integration of clinical parameters with radiomics exhibits the most superior diagnostic efficacy in forecasting the clinical stage of breast cancer. As part of the evaluation, various metrics were calculated, including the area under the curve (AUC), the accuracy (ACC), sensitivity (Sen), specificity (Spe), positive predictive value (PPV) and negative predictive value (NPV). To differentiate between the radiomics model, clinical data model, and fusion model, the Delong test was utilized. The precision of the prediction model was evaluated by generating a calibration curve using 1,000 bootstrap weight samples. Furthermore, the decision curve analysis (DCA) was conducted to assess the model's practicality.\nResults: The fusion model exhibits superior predictive performance compared to both the single radiomics model and clinical model. The fusion model's test sets of AUC, ACC, Sen, Spe, PPV, and NPV are 0.824, 0.780, 0.932, 0.652, 0.707, and 0.909, respectively.\nConclusion: The fusion model exhibits greater efficacy than both the single radiomics model and clinical model, and thus holds significant potential for facilitating the diagnosis of breast cancer stage and the development of individualized treatment plans.CCS","Pathological complete response (pCR) after neoadjuvant che-motherapy (NAC) in patients with breast cancer was found to improve survival, and it has a great prognostic value in the aggressive tumor subtype. This study aims to predict pCR before NAC treatment with a radiomic feature-based ensemble learning model using both positron emission tomography/computed tomography (PET/CT) images taken from the online QIN-Breast dataset. It studies the problem of constructing an end-to-end classification pipeline that includes a large-scale radiomic feature extraction, a hybrid iterative feature selection and a heterogeneous weighted ensemble classification. The proposed hybrid feature selection procedure can identify significant radiomic predictors out of 2153 features extracted from delineated tumour regions. The proposed weighted ensemble approach aggregates the outcomes of four weak classifiers (Decision tree, Naive Bayes, K-nearest neighbour, and Logistics regression) based on their importance. The empirical study demonstrates that the proposed feature selection-cum-ensemble classification method has achieved 92% and 88.4% balanced accuracy in PET and CT, respectively. The PET/CT aggregated model performed better and achieved 98% balanced accuracy and 94.74% F1-score. Furthermore, this study is the first classification work on the online QIN-Breast dataset.","Surface electromyography (sEMG) signal is essential for accurately controlling prosthetic devices with numerous degrees of freedom in human-machine interfaces for robotics and assistive technologies. The controlling method of the upper-limb prosthesis device depends on electromyogram (EMG) pattern recognition, which requires the efficient blending of conventional signal processing and machine learning. This paper focuses on stacked ensemble models, one of the popular methods for reducing generalization error. The proposed work uses a dataset of sEMG signals from different upper-limb positions in subjects. The raw signals are transformed into correlated time-domain descriptors (cTDD) for feature extraction, which are then used to train the stacked ensemble framework. The framework includes four base classifiers (support vector machine (SVM), K-nearest neighbours (KNN), logistic regression (LR), and decision tree (DT)) and two meta-classifiers (random forest (RF) and multi-layer perceptrons (MLP). The performance of the meta-classifiers is evaluated on two test sets, showing superior classification accuracy compared to the basic classifiers. The proposed approach demonstrates the capability to accurately classify limb position invariant EMG signal classification for prosthetic device control.","Skip Abstract Section\nAbstract\nAir quality prediction is considered one of complex problems. This is due to volatility, dynamic nature, and high variability in space and time of particulates and pollutants. Meanwhile, designing an automated model for monitoring and predicting air quality becomes more and more relevant, particularly in urban regions. Air pollution can significantly affect the environment and eventually citizens\u2019 health. In this paper, one of the popular machine learning algorithms, the neural network algorithm, is employed to classify different species of air pollutants. To boost the performance of the traditional neural network, the war strategy optimization algorithm tunes the neural network\u2019s parameters. The experimental results demonstrate that the proposed optimized neural network based on the war strategy algorithm can accurately classify air pollutant species.","For a long time, images have proved perfect at both storing and conveying rich semantics, especially human emotions. A lot of research has been conducted to provide machines with the ability to recognize emotions in photos of people. Previous methods mostly focus on facial expressions but fail to consider the scene context, meanwhile scene context plays an important role in predicting emotions, leading to more accurate results. In addition, Valence-Arousal-Dominance (VAD) values offer a more precise quantitative understanding of continuous emotions, yet there has been less emphasis on predicting them compared to discrete emotional categories. In this paper, we present a novel Multi-Branch Network (MBN), which utilizes various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image. Experimental results on EMOTIC dataset, which contains large-scale images of people in unconstrained situations labeled with 26 discrete categories of emotions and VAD values, show that our proposed method significantly outperforms state-of-the-art methods with 28.4% in mAP and 0.93 in MAE. The results highlight the importance of utilizing multiple contextual information in emotion prediction and illustrate the potential of our proposed method in a wide range of applications, such as effective computing, human-computer interaction, and social robotics.","In recent years, the increasing use of online surveys for course evaluation in schools has led to an outpouring of evaluation texts. These texts, with their emotional polarity, can give schools the most direct feedback. Emotional analysis on course evaluation, therefore, has great implications. However, the not-so-rigid text grammar and rich text content pose a challenge for sentiment analysis in Chinese course evaluation. To solve this problem, this paper proposes a sentiment classification model BiLSTM-GCN-Att (BGAN). Here, BiLSTM is used to extract the features of the text and output the hidden state vector. Then, the deep biaffine attention mechanism is used to analyze the dependence of the text and generate a dependency matrix. Next, input the hidden state vector to the GCN. Finally, the softmax function is used as the output layer of the model to perform sentiment classification. The model proves effective and experimental results, showing that the BGAN achieved a maximum improvement of 11.02% and 14.47% in precision and F1-score respectively compared with the classical models.","The Gene Ontology (GO) project is a major bioinformatics initiative with the aim of standardizing the representation of gene and gene product attributes across species and databases. The classes in GO are hierarchically structured in the form of a directed acyclic graph (DAG), what makes its prediction more complex. This work proposes an adapted Learning Classifier Systems (LCS) in order to predict protein functions described in the GO format. Hence, the proposed approach, called HLCS (Hierarchical Learning Classifier System) builds a global classifier to predict all classes in the application domain and its is expressed as a set of IF-THEN classification rules, which have the advantage of representing more comprehensible knowledge. The HLCS is evaluated in four different ion-channel data sets structured in GO terms and compared with a Ant Colony Optimisation algorithm, named hAnt-Miner. In the tests realized the HLCS outperformed the hAnt-Miner in two out of four data sets.","The core objective of this research is to develop a methodology for selecting a supervised machine learning classification technique based on the specific categories of objects that need to be classified. The study focuses on product categories extracted from Amazon's Product Reviews database, which are utilized to evaluate the subjectivity of post-purchase feedback. The primary supervised machine learning methods are utilized to efficiently perform the classification task. The resulting insights will enable the prioritization and choice of the best approach based on the selected categories. In the context of accelerated technological adoption due to the COVID-19 pandemic, this research contributes by showcasing how AI/ML can play a pivotal role in enhancing decision-making processes across various sectors and highlighting the significance of adapting to emerging technologies for sustainable growth.","Deep learning has been increasingly incorporated into various computational pathology applications to improve its efficiency, accuracy, and robustness. Although successful, most previous approaches for image classification have crucial drawbacks. There exist numerous tasks in pathology, but one needs to build a model per task, i.e., a task-specific model, thereby increasing the number of models, training resources, and cost. Moreover, transferring arbitrary task-specific model to another task is still a challenging problem. Herein, we propose a task-agnostic generative and general pathology image classifier, so called GPC, that aims at learning from diverse kinds of pathology images and conducting numerous classification tasks in a unified model. GPC, equipped with a convolutional neural network and a Transformer-based language model, maps pathology images into a high-dimensional feature space and generates pertinent class labels as texts via the image-to-text classification mechanism. We evaluate GPC on six datasets for four different pathology image classification tasks. Experimental results show that GPC holds considerable potential for developing an effective and efficient universal model for pathology image analysis.","This paper introduces a novel approach to address the challenges of transfer learning, which aims to efficiently train a classifier for a new domain using supervised information from similar domains. Traditional transfer learning methods may fail to maintain the discriminative features of the target domain due to the scarcity of labelled data and the use of irrelevant source domain data distribution subspace, resulting in poor metrics. To overcome these challenges, the proposed approach, called KDADP, transforms the data distribution of both the source and target domains into a lower-dimensional subspace while preserving their discriminatory information. The KDADP model maximizes between-class variance and minimizes within-class variance with L1 penalization, enabling the recovery of the most useful characteristics and reducing the model\u2019s complexity. Experimental results on three real-world domain adaptation datasets demonstrate that the proposed KDADP model significantly improves classification performance and outperforms state-of-the-art primitive, shallow, and deeper domain adaptation methods.","Convolutional Neural Network (CNN) is a widely used neural network in deep learning, and Graph Convolutional Network (GCN) is one of the most effective semi -supervised methods. It spread node information in a conversion way. In this article, we have studied the differences between CNN and GCN in the classification of high -spectrum image. Because the traditional GCN algorithm needs to build an adjacent matrix on all data, the calculation cost is very high, especially in large -scale remote sensing problems. MinigCNS uses a small -batch learning method to solve the problem of CCN calculation costs, and then it has not solved the problem of low efficiency of single model classification. This article studies the advantages of minigcns and CNN, and proposes a weighted fusion network FU-W, which weighs the minigcns and CNN weighted integration to break the bottleneck of single model performance. We experimented with the fusion algorithm on the two high -spectrum data sets, and its overall accuracy can reach 88.8%in Indian Pines. The experiment proves the superiority of the fusion strategy for a single CNN or GCN model.","Speech emotion recognition (SER) is a crucial aspect of affective computing and human-computer interaction, yet effectively identifying emotions in different speakers and languages remains challenging. This paper introduces SER-Fuse, a multi-modal SER application that is designed to address the complexities of multiple speakers and languages. Our approach leverages diverse audio/speech embeddings and text embeddings to extract optimal features for multi-modal SER. We subsequently employ multi-feature fusion to integrate embedding features across modalities and languages. Experimental results archived on the English-Chinese emotional speech (ECES) dataset reveal that SER-Fuse attains competitive performance in the multi-lingual approach compared to the single-lingual approaches. Furthermore, we provide the implementation of SER-Fuse for download at https://github.com/nhattruongpham/SER-Fuse to support reproducibility and local deployment.","Skip Abstract Section\nAbstract\nThe earth\u2019s ecology is well balanced and protected by forests. On the other hand, forest fires affect forest resources, thus causing both economical and ecological losses. Hence, preserving forest resources from fires is very essential to reduce environmental disasters. Controlling forest fire at an early stage is necessary to control their spread. This requirement enforces the necessity of fast and reliable fire detection algorithms. In this paper, a color models aware dynamic feature extraction for forest fire detection using machine learning classifiers is proposed to achieve early detection of fire and reduced false alarm rate. The proposed algorithm extracts fire detection index, wavelet energy, and gray level co-occurrence matrix features from RGB, L*a*b*, and YCbCr color models respectively to train the machine learning classifiers. The performance of the proposed model is analysed using various machine learning algorithms and the standard classification metrics. The proposed color-aware feature extraction gives precision, recall, F1-score, and accuracy of 99, 95, 94, and 97% respectively for the K-nearest neighbourhood model. The support vector machine model delivers 98, 95, 93, and 96.5% respectively. The accuracy of the proposed model is improved by a minimum of 3%, and a maximum of 11% than other color models. Similarly, the false rate reduction is a minimum of 5% and a maximum of 17% than other models.","Abstract: The electromyogram (EMG), also known as an EMG, is used to assess nerve impulses in motor nerves, sensory nerves, and muscles. EMS is a versatile tool used in various biomedical applications. It is commonly employed to determine physical health, but it also finds utility in evaluating emotional well-being, such as through facial electromyography. Classification of EMG signals has attracted the interest of scientists since it is crucial for identifying neuromuscular disorders (NMDs). Recent advances in the miniaturization of biomedical sensors enable the development of medical monitoring systems. This paper presents a portable and scalable architecture for machine learning modules designed for medical diagnostics. In particular, we provide a hybrid classification model for NMDs. The proposed method combines two supervised machine learning classifiers with the discrete wavelet transform (DWT). During the online testing phase, the class label of an EMG signal is predicted using the classifiers\u2019 optimal models, which can be identified at this stage. The simulation results demonstrate that both classifiers have an accuracy of over 98%. Finally, the proposed method was implemented using an embedded CompactRIO-9035 real-time controller."],"author":["Sahu, Sushanta Kumar and Chowdhury, Ananda S.","Verbiest, Nele and Ramentol, Enislay and Cornelis, Chris and Herrera, Francisco","NaN","Kuljeet Singh and Shastri, Sourabh and Kumar, Sachin and Mansotra, Vibhakar","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","Mishra, Aakriti and Ramanathan, A. and Batta, Vineet and Malathy, C. and Kundu, Soumya Snigdha and Gayathri, M. and Vathana, D. and Kamineni, Srinath","NaN","Negru, Vlad-Andrei and Lemnaru, Camelia and Potolea, Rodica","NaN","Sharma, Rohit and Mahanti, Gautam Kumar and Chakraborty, Chinmay and Panda, Ganapati and Rath, Adyasha","Tian, Yuchen and Wang, Jiacheng and Jin, Yueming and Wang, Liansheng","Debnath, Chandrima and Guha, Debashree and Hait, Swati Rani and Guria, Soumita and Chakraborty, Debjani","Yumang, Analyn N and Banguilan, Dave Emilson S and Veneracion, Clark Kent S","Gu, Qiangqiang and Shaikh, Nazim and Lin, Ping-chang and Jayachandran, Srinath and Porwal, Prasanna and Li, Xiao and Nie, Yao","Lee, Eunji and Kim, Sihyeon and Kim, Sundong and Jung, Soyeon and Kim, Heeja and Cha, Meeyoung","Bond, Jacob and Gupta, Siddhartha and Elvitigala, Thanura","Manisha and Clifford, William and McLaughlin, Eugene and Stynes, Paul","Diep, Tuong-Nghiem and Tran, Thien-Phuc and Ho-Ngoc, Vinh-Phat and Yang, Tuan-Anh and Do, Trong-Le","Shrihari, A. and Guha, Prithwijit and Kulkarni, Rishikesh Dilip","Niranjan, Ranjani and Rao, Sachit","Fang, Xiaoqi and Zhang, Guoyun and Zhang, Guifeng and Zhou, Xuhui and Wu, Jianhui and Zhao, Lin","NaN","Lopez Uroz, Lorenzo and Benoit, Alexandre and Yan, Yajing and Lin-Kwong-Chon, Christophe and Giffard-Roisin, Sophie and Rabatel, Antoine","NaN","Hamed, Ahmed and Tahoun, Mohamed and Nassar, Hamed","Ukanchanakitti, Phatsakorn and Winaichatsak, Nattapong and Cho, Natthawin and Sumetpipat, Kanes","Luo, Jueling and Long, Hui and Xie, Si and Zhang, Yalu and Ma, Haodong and Meng, Guangyao","NaN","Anjali Rajak and Rakesh Tripathi","Berghouse, Marc and Bebis, George and Tavakkoli, Alireza","Guo, Yeang and Tao, Tan and Ronglin, Ronglin and Xiao, Liangfen and Ding, Lijuan and Li, Qing and Xie, Hui","Dholey, Moumita and Santosham, Ritesh J. M. and Ray, Soumendranath and Das, Jayanta and Chatterjee, Sanjoy and Ahmed, Rosina and Mukherjee, Jayanta","Samui, Suman and Garai, Soumen and Ghosh, Anindya and Mukhopadhyay, Anand Kumar","Gehad Ismail Sayed and Aboul Ella Hassanein","Ninh, Quoc-Bao and Nguyen, Hai-Chan and Huynh, Triet and Tran, Minh-Triet and Le, Trung-Nghia","Jiao, Jiajia and Chen, Bo","NaN","St-Vincent Villeneuve, Alexandre and Plaisent, Michel","Nguyen, Anh Tien and Kwak, Jin Tae","Prakash, Jainendra and Ghorai, Mrinmoy and Sanodiya, Rakesh","Shi, Jiechuan and Liu, Kun and Yuan, Hao and Wang, Can and Yang, Bo","Pham, Nhat Truong and Phan, Le Thi and Dang, Duc Ngoc Minh and Manavalan, Balachandran","Avudaiammal, R. and Rajangam, Vijayarajan and Durai Raji V. and Senthil Kumar S.","Achmamad, Abdelouahad and Elfezazi, Mohamed and Chehri, Abdellah and Ahmed, Imran and Jbari, Atman and Saadane, Rachid"],"cluster":[2,2,2,2,1,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,0,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,2,2,2,2,1,2,2,2],"labels":["C-2","C-2","C-2","C-2","C-1","C-2","C-2","C-1","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-0","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-1","C-2","C-2","C-2","C-2","C-1","C-2","C-2","C-2"],"publication_date":["2023-12-12","2023-12-13","2023-12-13","2023-12-01","2023-12-22","2023-12-02","2023-12-13","2023-12-04","2023-12-04","2023-12-11","2023-12-01","2023-12-12","2023-12-19","2023-12-01","2023-12-01","2023-12-01","2023-12-07","2023-12-07","2023-12-12","2023-12-12","2023-12-15","2023-12-13","2023-12-30","2023-12-13","2023-12-01","2023-12-06","2023-12-15","2023-12-13","2023-12-01","2023-12-01","2023-12-15","2023-12-12","2023-12-12","2023-12-01","2023-12-07","2023-12-01","2023-12-13","2023-12-06","2023-12-01","2023-12-12","2023-12-04","2023-12-07","2023-12-01","2023-12-14"],"title":["Multi-Modal Multi-Class Parkinson Disease Classification Using CNN and Decision Level Fusion","Improving SMOTE with Fuzzy Rough Prototype Selection to Detect Noise in Imbalanced Classification Data","On the Estimation of Predictive Evaluation Measure Baselines for Multi-Label Learning","BC-Net: Early Diagnostics of Breast Cancer Using Nested Ensemble Technique of Machine Learning","Graph-Based Text Classification by Contrastive Learning with Text-Level Graph Augmentation","Harnessing the Potential of Deep Learning for Total Shoulder Implant Classification: A Comparative Study","Enhancing the Performance of SVM on Skewed Data Sets by Exciting Support Vectors","Multitask, Cross-Lingual Recipe Classification Using Joint Fine-Tuning Mechanisms","A Machine Learning Approach to Enterprise Matchmaking Using Multilabel Text Classification Based on Semi-Structured Website Content","An IoT and Deep Learning-Based Smart Healthcare Framework for Thyroid Cancer Detection","Communication-Efficient Federated Skin Lesion Classification with Generalizable Dataset Distillation","Multi-Criteria Decision-Making Based Classifier Ensemble by Using Prioritized Aggregation Operator","Fruit Calories Estimation Using Convolutional Neural Network","Cellular Features Based Interpretable Network for Classifying Cell-Of-Origin from Whole Slide Images for Diffuse Large B-Cell Lymphoma Patients","Explainable Product Classification for Customs","Probabilistic Local Equivalence Certification for Robustness Evaluation","A Deep Learning Emotion Classification Framework for Low Resource Languages","Deep Learning Hierarchical Methods for Insect Pest Recognition on Plants","A Novel Network Architecture for Microplankton Classification in Digital Holographic Images","Handling Small Disjuncts and Class Skew Using Sequential Ellipsoidal Partitioning","A Hybrid Self-Supervised Learning Framework For Hyperspectral Image Classification","Detecting Survival Patterns in Women with Invasive Cervical Cancer with Decision Trees","Deep Learning Multimodal Methods for Geophysical Inversion\u202f: Application to Glacier Ice Thickness Estimation","Prototype Selection with Compact Sets and Extended Rough Sets","\nKNNHI: Resilient KNN Algorithm for Heterogeneous Incomplete Data Classification and K Identification Using Rough Set Theory","Predicting Blood Drop Height and Volume Using Physics Equations, VGG-19, and XGBoost","Improving Table Tennis Training and Technique Analysis: Accurate Classification of Actions with Informer Encoder","Nearest Prototype Classification of Special School Families Based on Hierarchical Compact Sets Clustering","Classification of Services through Feature Selection and Machine Learning in 5G Networks","Investigating the Impact of Attention on Mammogram Classification","SVM in Classification of Stage 0~II and III~IV with Breast Cancer\u202f: A Retrospective Cohort Study on a Bicentric Cohort","Ensemble Methods With [18F]FDG-PET/CT Radiomics In Breast Cancer Response Prediction","Heterogeneous Stacked Ensemble Framework for Surface Electromyography Signal Classification","Air Pollutants Classification Using Optimized Neural Network Based on War Strategy Optimization Algorithm","Multi-Branch Network for Imagery Emotion Prediction","A GCN- and Deep Biaffine Attention-Based Classification Model for Course Review Sentiment","Hierarchical Classification of Gene Ontology with Learning Classifier Systems","Framework for Choosing a Supervised Machine Learning Method for Classification Based on Object Categories\u202f: Classifying Subjectivity of Online Comments by Product Categories","GPC: Generative and General Pathology Image Classifier","Transfer Learning: Kernel-Based Domain Adaptation with Distance-Based Penalization","Fu-W:A Hyperspectral Image Classification Algorithm Combining Mini Graph Convolutional Networks and Convolutional Neural Network","SER-Fuse: An Emotion Recognition Application Utilizing Multi-Modal, Multi-Lingual, and Multi-Feature Fusion","Color Models Aware Dynamic Feature Extraction for Forest Fire Detection Using Machine Learning Classifiers","ML-Based Identification of Neuromuscular Disorder Using EMG Signals for Emotional Health Application"],"x":{"__ndarray__":"V5V9VwTyYUA/kBctm3T4P7XgRV9B6FHABf2FHjFuQ8A+7fDXZPtlQEcDeAskYlbAaVch5SdKYsAWNZiG4X9dQD0K16NwWUrA97GC34YoLcCfy9QkePM5QMKjjSPWZFtAoS3nUlyhRsB3vp8aLy1TwKd0sP7PL17ArejFPyJ8CUBf0hito75WQLAD54woqVHArir7rgg+QMCjkjoBTTZiwMcuUb01gldAgGWlSSnCVEA0ngjiPPAwwKdZoN0hXSVA71UrE37pUEDUuDe/YahPQPDeUWNCtDRACWzOwTOBBcAzp8tiYgdAQB/0bFZ9bFrA81SH3AyHSMBruMg9Xe9PwHFa8KKvBDBA4cXKgYEU6j/tgVZgyIJTQEJbzqW48GJAcv27PnPeQUBHHLKBdOlbQNHKvcCsFE5A9wFIbeK2WECxFp8CYOw/wByxFp8C4FBAAFKbOLlrWcC8IvjfSrBHQA==","dtype":"float64","shape":[44]},"x_backup":{"__ndarray__":"V5V9VwTyYUA/kBctm3T4P7XgRV9B6FHABf2FHjFuQ8A+7fDXZPtlQEcDeAskYlbAaVch5SdKYsAWNZiG4X9dQD0K16NwWUrA97GC34YoLcCfy9QkePM5QMKjjSPWZFtAoS3nUlyhRsB3vp8aLy1TwKd0sP7PL17ArejFPyJ8CUBf0hito75WQLAD54woqVHArir7rgg+QMCjkjoBTTZiwMcuUb01gldAgGWlSSnCVEA0ngjiPPAwwKdZoN0hXSVA71UrE37pUEDUuDe/YahPQPDeUWNCtDRACWzOwTOBBcAzp8tiYgdAQB/0bFZ9bFrA81SH3AyHSMBruMg9Xe9PwHFa8KKvBDBA4cXKgYEU6j/tgVZgyIJTQEJbzqW48GJAcv27PnPeQUBHHLKBdOlbQNHKvcCsFE5A9wFIbeK2WECxFp8CYOw/wByxFp8C4FBAAFKbOLlrWcC8IvjfSrBHQA==","dtype":"float64","shape":[44]},"y":{"__ndarray__":"HAjJAiZASMDPvvIgPVtUwDYC8bp+VTZAf8Fu2LbIH8DKwWwCDGNBQINpGD4i7ErA9Z81P/62R8BzK4TVWPISQD6zJEBN+1tAyEqCJngJAsAMdsO2RTdiwInvxKwXf1jAaD9SRIajU8BeS8gHPe9gwBxfe2ZJslFAfH4YITyVUUAJibSNPzkiQD19BP7wYUlA7zzxnC2CQsDfwU8cQI8hQAJIbeLk0jbAz9ptF5rWYsDmV3OAYGtewFioNc07Ck7AGHjuPVzsUcCc+dUcIGVgQAe3tYXnrTbAceZXc4DcSMDyBwPPvUtYwE7udygKolnAjGmme50kGUA/xXHg1Yo3wIczv5oDuDdAL2mM1lHlXUC7RsuBHlo3QOoDyTuH6j1A3J212y4oTMCR8pNqn3hVQIv/llu1Bg/Ayaze4XZkRUAZOQt72q1CQFclkX2QdU5Annx6bMtwIcCuKCUEq9I/QA==","dtype":"float64","shape":[44]},"y_backup":{"__ndarray__":"HAjJAiZASMDPvvIgPVtUwDYC8bp+VTZAf8Fu2LbIH8DKwWwCDGNBQINpGD4i7ErA9Z81P/62R8BzK4TVWPISQD6zJEBN+1tAyEqCJngJAsAMdsO2RTdiwInvxKwXf1jAaD9SRIajU8BeS8gHPe9gwBxfe2ZJslFAfH4YITyVUUAJibSNPzkiQD19BP7wYUlA7zzxnC2CQsDfwU8cQI8hQAJIbeLk0jbAz9ptF5rWYsDmV3OAYGtewFioNc07Ck7AGHjuPVzsUcCc+dUcIGVgQAe3tYXnrTbAceZXc4DcSMDyBwPPvUtYwE7udygKolnAjGmme50kGUA/xXHg1Yo3wIczv5oDuDdAL2mM1lHlXUC7RsuBHlo3QOoDyTuH6j1A3J212y4oTMCR8pNqn3hVQIv/llu1Bg/Ayaze4XZkRUAZOQt72q1CQFclkX2QdU5Annx6bMtwIcCuKCUEq9I/QA==","dtype":"float64","shape":[44]}},"selected":{"id":"1072","type":"Selection"},"selection_policy":{"id":"1073","type":"UnionRenderers"}},"id":"1011","type":"ColumnDataSource"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Time Range:&lt;/h3&gt;&lt;p1&gt;Click on the button to change the time range of the plot.&lt;/p1&gt;"},"id":"1002","type":"Div"},{"attributes":{"margin":[20,20,20,20],"sizing_mode":"scale_both","style":{"color":"#BF0A30","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Click on a plot to see the info about the article.","width":150},"id":"1064","type":"Div"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1012","type":"HoverTool"},{"id":"1035","type":"PanTool"},{"id":"1036","type":"WheelZoomTool"},{"id":"1037","type":"BoxZoomTool"},{"id":"1038","type":"ResetTool"},{"id":"1039","type":"SaveTool"},{"id":"1040","type":"TapTool"}]},"id":"1041","type":"Toolbar"},{"attributes":{"callback":null},"id":"1017","type":"DataRange1d"},{"attributes":{},"id":"1031","type":"BasicTicker"},{"attributes":{"children":[{"id":"1076","type":"Div"}]},"id":"1078","type":"Row"},{"attributes":{"below":[{"id":"1025","type":"LinearAxis"}],"center":[{"id":"1029","type":"Grid"},{"id":"1034","type":"Grid"},{"id":"1060","type":"Legend"}],"left":[{"id":"1030","type":"LinearAxis"}],"margin":[5,5,5,5],"plot_height":500,"plot_width":500,"renderers":[{"id":"1052","type":"GlyphRenderer"}],"sizing_mode":"scale_both","title":{"id":"1015","type":"Title"},"toolbar":{"id":"1041","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1017","type":"DataRange1d"},"x_scale":{"id":"1021","type":"LinearScale"},"y_range":{"id":"1019","type":"DataRange1d"},"y_scale":{"id":"1023","type":"LinearScale"}},"id":"1014","subtype":"Figure","type":"Plot"},{"attributes":{},"id":"1038","type":"ResetTool"},{"attributes":{},"id":"1026","type":"BasicTicker"},{"attributes":{"high":2,"low":0,"palette":["#1f77b4","#aec7e8","#ff7f0e"]},"id":"1013","type":"LinearColorMapper"},{"attributes":{},"id":"1023","type":"LinearScale"},{"attributes":{"children":[{"id":"1062","type":"Paragraph"}]},"id":"1084","type":"Row"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"color":"#2e484c","font-family":"Julius Sans One, sans-serif;"},"text":"&lt;h1&gt;Clustering Literature on Supervised Learning by Classification (Last Month)&lt;/h1&gt;"},"id":"1076","type":"Div"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1051","type":"Scatter"},{"attributes":{"data_source":{"id":"1011","type":"ColumnDataSource"},"glyph":{"id":"1050","type":"Scatter"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1051","type":"Scatter"},"selection_glyph":null,"view":{"id":"1053","type":"CDSView"}},"id":"1052","type":"GlyphRenderer"},{"attributes":{"background_fill_alpha":{"value":0.6},"items":[{"id":"1061","type":"LegendItem"}]},"id":"1060","type":"Legend"},{"attributes":{"source":{"id":"1011","type":"ColumnDataSource"}},"id":"1053","type":"CDSView"},{"attributes":{"text":"&lt;a href=\"clusters_last_half_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Half Year&lt;/button&gt;&lt;/a&gt;"},"id":"1004","type":"Div"},{"attributes":{"children":[{"id":"1006","type":"Div"}]},"id":"1079","type":"Row"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by Text:&lt;/h3&gt;&lt;p1&gt;Search keyword to filter out the plot. It will search abstracts, titles and authors. \n    Press enter when ready. Clear and press enter to reset the plot.&lt;/p1&gt;"},"id":"1007","type":"Div"},{"attributes":{"children":[{"id":"1014","subtype":"Figure","type":"Plot"}]},"id":"1085","type":"Row"},{"attributes":{"args":{"out_text":{"id":"1062","type":"Paragraph"},"p":{"id":"1014","subtype":"Figure","type":"Plot"},"slider":{"id":"1074","type":"Slider"},"source":{"id":"1011","type":"ColumnDataSource"},"text":{"id":"1075","type":"TextInput"},"topics":["","","ensemble, images, multi, image, proposed, time, neural"]},"code":"\n\t\t\t\tvar key = text.value;\n\t\t\t\tkey = key.toLowerCase();\n\t\t\t\tvar cluster = slider.value;\n                var clusters_count = slider.end;\n                var data = source.data; \n                \n                \n                x = data['x'];\n                y = data['y'];\n                x_backup = data['x_backup'];\n                y_backup = data['y_backup'];\n                labels = data['cluster'];\n                abstract = data['abstract'];\n                title = data['title'];\n                author = data['author'];\n                if (cluster == clusters_count) {\n                    out_text.text = 'Keywords: Slide to specific cluster to see the keywords.';\n                    for (i = 0; i &lt; x.length; i++) {\n\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key) || \n                        (title[i] &amp;&amp; title[i].toLowerCase().includes(key)) ||\n                        (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t}\n                    }\n                }\n                else {\n                    out_text.text = 'Keywords: ' + topics[Number(cluster)];\n                    for (i = 0; i &lt; x.length; i++) {\n                        if(labels[i] == cluster) {\n\t\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key)\n                            || (title[i] &amp;&amp; title[i].toLowerCase().includes(key))\n                            || (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t\t}\n                        } else {\n                            x[i] = undefined;\n                            y[i] = undefined;\n                        }\n                    }\n                }\n            source.change.emit();\n            "},"id":"1063","type":"CustomJS"},{"attributes":{},"id":"1039","type":"SaveTool"},{"attributes":{"callback":null,"point_policy":"follow_mouse","tooltips":[["Title","@title"],["Author","@author"],["Abstract","@abstract{safe}"],["Publication Date","@publication_date"],["Cluster","@cluster"]]},"id":"1012","type":"HoverTool"},{"attributes":{},"id":"1056","type":"BasicTickFormatter"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1059","type":"BoxAnnotation"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"end":3,"margin":[15,15,15,15],"sizing_mode":"stretch_width","start":0,"title":"Cluster #","value":3},"id":"1074","type":"Slider"},{"attributes":{"height":75,"margin":[20,20,20,20],"sizing_mode":"stretch_width","style":{"color":"#0269A4","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Keywords: Slide to specific cluster to see the keywords."},"id":"1062","type":"Paragraph"},{"attributes":{},"id":"1021","type":"LinearScale"},{"attributes":{},"id":"1035","type":"PanTool"},{"attributes":{},"id":"1058","type":"BasicTickFormatter"},{"attributes":{},"id":"1073","type":"UnionRenderers"},{"attributes":{"args":{"current_selection":{"id":"1064","type":"Div"},"source":{"id":"1011","type":"ColumnDataSource"}},"code":"\n        var titles = [];\n        var authors = [];\n        var abstracts = [];\n        var publicationDates = [];\n        var clusters = [];\n\n        cb_data.source.selected.indices.forEach(index =&gt; {\n            titles.push(source.data['title'][index]);\n            authors.push(source.data['author'][index]);\n            abstracts.push(source.data['abstract'][index]);\n            publicationDates.push(source.data['publication_date'][index]);\n            clusters.push(source.data['cluster'][index]);\n        });\n\n        var title = \"&lt;p1&gt;&lt;b&gt;Title:&lt;/b&gt; \" + (titles[0] ? titles[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var author = \"&lt;p1&gt;&lt;b&gt;Author:&lt;/b&gt; \" + (authors[0] ? authors[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var abstract = \"&lt;p1&gt;&lt;b&gt;Abstract:&lt;/b&gt; \" + abstracts[0].toString() + \"&lt;br&gt;\";\n        var publicationDate = \"&lt;p1&gt;&lt;b&gt;Publication Date:&lt;/b&gt; \" + publicationDates[0].toString() + \"&lt;/p1&gt;&lt;br&gt;\";\n        var cluster = \"&lt;p1&gt;&lt;b&gt;Cluster:&lt;/b&gt; \" + clusters[0].toString() + \"&lt;/p1&gt;\";\n\n        current_selection.text = title + author + abstract + publicationDate + cluster;\n        current_selection.change.emit();\n    "},"id":"1065","type":"CustomJS"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.4.0"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('1176').textContent;
                  var render_items = [{"docid":"26c31e1b-f7bd-4c41-9ff6-8244afe30bd5","roots":{"1087":"8b91ed45-e52e-42a8-b073-e6969419ebea"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>