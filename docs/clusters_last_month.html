



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Clustering papers on Supervised Learning by Classification</title>
      
      
        
          
        
        
          
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="c07cd757-6e83-4b03-8f4e-6c217e03303b" data-root-id="1087"></div>
            
          
        
      
      
        <script type="application/json" id="1176">
          {"728e6fda-3ebb-43ba-b76a-3008e5d01b11":{"roots":{"references":[{"attributes":{"fill_color":{"field":"cluster","transform":{"id":"1013","type":"LinearColorMapper"}},"line_alpha":{"value":0.3},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1050","type":"Scatter"},{"attributes":{"children":[{"id":"1006","type":"Div"}]},"id":"1079","type":"Row"},{"attributes":{"children":[{"id":"1014","subtype":"Figure","type":"Plot"}]},"id":"1085","type":"Row"},{"attributes":{"source":{"id":"1011","type":"ColumnDataSource"}},"id":"1053","type":"CDSView"},{"attributes":{"margin":[20,20,20,20],"sizing_mode":"scale_both","style":{"color":"#BF0A30","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Click on a plot to see the info about the article.","width":150},"id":"1064","type":"Div"},{"attributes":{"children":[{"id":"1062","type":"Paragraph"}]},"id":"1084","type":"Row"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Clustering of literature on supervised learning by classification from ACM Digital Library. \n    The dataset is extracted from &lt;a href=\"https://dl.acm.org/topic/ccs2012/10010147.10010257.10010258.10010259.10010263?expand=all&amp;startPage=\"&gt;here&lt;/a&gt;."},"id":"1006","type":"Div"},{"attributes":{},"id":"1072","type":"UnionRenderers"},{"attributes":{"args":{"current_selection":{"id":"1064","type":"Div"},"source":{"id":"1011","type":"ColumnDataSource"}},"code":"\n        var titles = [];\n        var authors = [];\n        var abstracts = [];\n        var publicationDates = [];\n        var clusters = [];\n\n        cb_data.source.selected.indices.forEach(index =&gt; {\n            titles.push(source.data['title'][index]);\n            authors.push(source.data['author'][index]);\n            abstracts.push(source.data['abstract'][index]);\n            publicationDates.push(source.data['publication_date'][index]);\n            clusters.push(source.data['cluster'][index]);\n        });\n\n        var title = \"&lt;p1&gt;&lt;b&gt;Title:&lt;/b&gt; \" + (titles[0] ? titles[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var author = \"&lt;p1&gt;&lt;b&gt;Author:&lt;/b&gt; \" + (authors[0] ? authors[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var abstract = \"&lt;p1&gt;&lt;b&gt;Abstract:&lt;/b&gt; \" + abstracts[0].toString() + \"&lt;br&gt;\";\n        var publicationDate = \"&lt;p1&gt;&lt;b&gt;Publication Date:&lt;/b&gt; \" + publicationDates[0].toString() + \"&lt;/p1&gt;&lt;br&gt;\";\n        var cluster = \"&lt;p1&gt;&lt;b&gt;Cluster:&lt;/b&gt; \" + clusters[0].toString() + \"&lt;/p1&gt;\";\n\n        current_selection.text = title + author + abstract + publicationDate + cluster;\n        current_selection.change.emit();\n    "},"id":"1065","type":"CustomJS"},{"attributes":{"children":[{"id":"1076","type":"Div"}]},"id":"1078","type":"Row"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"margin":[15,15,15,15],"sizing_mode":"scale_both","title":"Search:"},"id":"1075","type":"TextInput"},{"attributes":{"height":75,"margin":[20,20,20,20],"sizing_mode":"stretch_width","style":{"color":"#0269A4","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Keywords: Slide to specific cluster to see the keywords."},"id":"1062","type":"Paragraph"},{"attributes":{"text":"Clustering of the ACM papers on Supervised Learning by Classification"},"id":"1015","type":"Title"},{"attributes":{"background_fill_alpha":{"value":0.6},"items":[{"id":"1061","type":"LegendItem"}]},"id":"1060","type":"Legend"},{"attributes":{},"id":"1023","type":"LinearScale"},{"attributes":{"high":2,"low":0,"palette":["#1f77b4","#aec7e8","#ff7f0e"]},"id":"1013","type":"LinearColorMapper"},{"attributes":{},"id":"1031","type":"BasicTicker"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"end":3,"margin":[15,15,15,15],"sizing_mode":"stretch_width","start":0,"title":"Cluster #","value":3},"id":"1074","type":"Slider"},{"attributes":{"overlay":{"id":"1059","type":"BoxAnnotation"}},"id":"1037","type":"BoxZoomTool"},{"attributes":{},"id":"1058","type":"BasicTickFormatter"},{"attributes":{},"id":"1039","type":"SaveTool"},{"attributes":{"dimension":1,"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1034","type":"Grid"},{"attributes":{"formatter":{"id":"1058","type":"BasicTickFormatter"},"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1025","type":"LinearAxis"},{"attributes":{"callback":{"id":"1065","type":"CustomJS"}},"id":"1040","type":"TapTool"},{"attributes":{},"id":"1026","type":"BasicTicker"},{"attributes":{},"id":"1036","type":"WheelZoomTool"},{"attributes":{"children":[{"id":"1002","type":"Div"}]},"id":"1080","type":"Row"},{"attributes":{"text":"&lt;a href=\"clusters_last_half_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Half Year&lt;/button&gt;&lt;/a&gt;"},"id":"1004","type":"Div"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1051","type":"Scatter"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by Text:&lt;/h3&gt;&lt;p1&gt;Search keyword to filter out the plot. It will search abstracts, titles and authors. \n    Press enter when ready. Clear and press enter to reset the plot.&lt;/p1&gt;"},"id":"1007","type":"Div"},{"attributes":{"callback":null,"data":{"abstract":["The greatest significant contributor to cancer-related morbidity and mortality worldwide is malignant lung tumors. Lung cancer frequency has been seen to be on the rise recently. Lung cancer histopathology diagnosis is a crucial part of the patient\u2019s treatment. The current study aims to demonstrate the efficiency of convolutional neural networks for the identification of squamous cell carcinoma and adenocarcinoma of the lung and colon by investigating the diagnosis of histopathology images. Five state-of-the-art pre-trained (ImageNet) convolutional neural network architectures, VGG-19, InceptionResNetV2, DenseNet201, EfficientNetB6, and MobileNetV2, are employed in this investigation to tri-categorize lung cancer images (normal, adenocarcinoma, and squamous cell carcinoma), together with colon cancer images (normal and adenocarcinoma). Regularization strategies have been applied to fine-tune the learning rate for improving accuracy. The LC25000 dataset has been used to validate the proposed method. EfficientNetB6, VGG19, InceptionResNetV2, DenseNet201, and MobileNetV2 accuracy on test data is reported to be 93.12, 98.00, 97.92, 99.12, and 99.32 percent respectively.","Credit card fraud detection plays a crucial role in safeguarding the financial security of individuals and organizations. However, imbalanced datasets pose significant challenges to accurately identifying fraudulent transactions. In this research paper, we propose a novel approach that combines autoencoder (AE) and fully connected deep networks (FCDN) models to address this issue. The process involves three phases: training an AE on fraudulent transactions, utilizing another AE for dimensionality reduction, and using the encoded representations as input for FCDN classification. To further enhance the model\u2019s performance, we introduce an additional FCDN trained on the preprocessed data using the synthetic minority oversampling technique (SMOTE). The predictions from both AE, AE\u2013FCDN, and the FCDN are combined using a majority voting approach. We evaluate the proposed method using standard performance metrics, including accuracy, precision, recall, and F1-score. Our experimental results demonstrate the effectiveness and robustness of the integrated model architecture in accurately detecting credit card fraud. These findings provide valuable insights for improving financial security measures and mitigating potential losses associated with credit card fraud.","Multi-dimensional classification (MDC) assumes that each instance has multiple heterogeneous class spaces simultaneously, and each class variable describes the semantic information of instances from a specific dimension. Recent studies have proven that encoding heterogeneous class spaces into a special logical-label space and employing the label enhancement technique to learn latent real-number labels (i.e., label distributions) of instances is an effective strategy for MDC. However, the adopted label enhancement methods can result that data whose features are quite different to each other have similar label distributions. To tackle this problem, we propose a novel probability-based label enhancement approach for MDC. Specifically, manifold structures of the feature and label distribution spaces are transformed into two different probability distributions, and we expect them to be close. Subsequently, it makes label distributions of samples whose features have large differences be more differentiated. Moreover, the logical-label mapping and reconstruction terms are designed to preserve the intrinsic information from the logical-label space. Besides, an improved multi-output support vector regression is developed as the prediction model, where we introduce mean squared error to reduce the risk of model underfitting. Experimental results on ten benchmark datasets clearly validate the superiority of our method over state-of-the-art MDC baselines.","We present FOLD-SE, an efficient, explainable machine learning algorithm for classification tasks given tabular data containing numerical and categorical values. The (explainable) model generated by FOLD-SE is represented as a set of default rules. FOLD-SE uses a novel heuristic called Magic Gini Impurity for literal selection that we have devised. FOLD-SE uses a refined data comparison operator and eliminates the long tail effect. Thanks to these innovations, explainability provided by FOLD-SE is scalable, meaning that regardless of the size of the dataset, the number of learned rules and learned literals stay quite small while good accuracy in classification is maintained. Additionally, the rule-set constituting the model that FOLD-SE generates does not change significantly if the training data is slightly varied. FOLD-SE is competitive with state-of-the-art traditional machine learning algorithms such as XGBoost and Multi-Layer Perceptrons (MLP) w.r.t. accuracy of prediction while being an order of magnitude faster. However, unlike XGBoost and MLP, FOLD-SE generates explainable models. The FOLD-SE algorithm outperforms prior rule-learning algorithms such as RIPPER in efficiency, performance, and scalability, especially for large datasets. FOLD-SE generates a far smaller number of rules than earlier algorithms that learn default rules.","Multi-view classification aims to efficiently utilize information from different views to improve classification performance. In recent researches, many effective multi-view learning methods have been proposed to perform multi-view data analysis. However, most existing methods only consider the correlations between views but ignore the potential correlations between samples. Normally, the views of samples belonging to the same category should have more consistency information and those belonging to different categories should have more distinctions. Therefore, we argue that the correlations and distinctions between the views of different samples also contribute to the construction of feature representations that are more conducive to classification. In order to construct a end-to-end general multi-view classification framework that can better utilize sample information to obtain more reasonable feature representation, we propose a novel joint long and short span self-attention network (JLSSAN). We designed two different self-attention spans to focus on different information. They enable each feature vector to be iteratively updated based on its attention to other views and other samples, which provides better integration of information from different views and different samples. Besides, we adopt a novel weight-based loss fusion strategy, which facilitates the model to learn more reasonable self-attention map between views. Our method outperforms the state-of-the-art methods by more than 3% in accuracy on multiple benchmarks, which demonstrates that our method is effective.\nHighlights\n\u2022\nA novel end-to-end unified multi-view classification framework is proposed.\n\u2022\nA long and short span self-attention layer is constructed.\n\u2022\nAn adaptive weight loss fusion strategy is designed.\n\u2022\nThe performance of our method outperforms the popular models.","Classification and differentiation of leukocyte sub-types are important in peripheral blood smear analysis. Fully-automated systems for leukocyte analysis are grouped into segmentation- and detection-based methods. The accuracy of classification depends on the accuracy of segmentation and detection steps. Real-world applications often produce inaccurate ROIs due to image quality factors, e.g., colour and lighting conditions, absence of standards, or even density and presence of overlapping cells. To this end, we investigated the scenario in-depth with ROIs simulating segmentation and detection methods and evaluating different image descriptors on two tasks: differentiation of leukocyte sub-types and leukaemia detection. The obtained results show that even simpler approaches can lead to accurate and robust results in both tasks when exploiting appropriate images for model training. Traditional handcrafted features are more effective when extracted from tight bounding boxes or masks, while deep features are more effective when extracted from large bounding boxes or masks.","Objective. Wireless sensor networks, crucial for various applications, face growing security challenges due to the escalating complexity and diversity of attack behaviours. This paper presents an advanced intrusion detection algorithm, leveraging feature-weighted Naive Bayes (NB), to enhance network attack detection accuracy. Methodology. Initially, a feature weighting algorithm is introduced to assign context-based weights to different feature terms. Subsequently, the NB algorithm is enhanced by incorporating Jensen\u2013Shannon (JS) divergence, feature weighting, and inverse category frequency (ICF). Eventually, the improved NB algorithm is integrated into the intrusion detection model, and network event classification results are derived through a series of data processing steps applied to corresponding network traffic data. Results. The effectiveness of the proposed intrusion detection algorithm is evaluated through a comprehensive comparative analysis using the NSL-KDD dataset. Results demonstrate a significant enhancement in the detection accuracy of various attack types, including normal, denial of service (DoS), probe, remote-to-local (R2L), and user-to-root (U2R). Moreover, the proposed algorithm exhibits a lower false alarm rate compared to other algorithms. Conclusion. This paper introduces a wireless network intrusion algorithm that not only ensures improved detection accuracy and rate but also reduces the incidence of false detections. Addressing the evolving threat landscape faced by wireless sensor networks, this contribution represents a valuable advancement in intrusion detection technology.","This study investigates the realm of machine learning for the classification of different fire types using NASA's FIRMS MODIS satellite data for the Mediterranean basin. Concentrating on the Mediterranean basin and utilizing data spanning from 2019 to 2021 for model training, XGBoost and Random Forest models were subsequently validated for the 2022 data. The findings distinctly illustrate XGBoost's superior predictive precision as compared to Random Forest by showcasing an impressive overall F1 score surpassing 95% and 84% macro F1 score across various fire types. This study emphasizes the prospect of machine learning to improve worldwide wildfire monitoring and response by providing exact, real-time fire type forecasts.","Artificial Intelligence (AI) use in automated Electrocardiogram (ECG) classification has continuously attracted the research community\u2019s interest, motivated by their promising results. Despite their great promise, limited attention has been paid to the robustness of their results, which is a key element for their implementation in clinical practice. Uncertainty Quantification (UQ) is a critical for trustworthy and reliable AI, particularly in safety-critical domains such as medicine. Estimating uncertainty in Machine Learning (ML) model predictions has been extensively used for Out-of-Distribution (OOD) detection under single-label tasks. However, the use of UQ methods in multi-label classification remains underexplored.\nThis study goes beyond developing highly accurate models comparing five uncertainty quantification methods using the same Deep Neural Network (DNN) architecture across various validation scenarios, including internal and external validation as well as OOD detection, taking multi-label ECG classification as the example domain. We show the importance of external validation and its impact on classification performance, uncertainty estimates quality, and calibration. Ensemble-based methods yield more robust uncertainty estimations than single network or stochastic methods. Although current methods still have limitations in accurately quantifying uncertainty, particularly in the case of dataset shift, incorporating uncertainty estimates with a classification with a rejection option improves the ability to detect such changes. Moreover, we show that using uncertainty estimates as a criterion for sample selection in active learning setting results in greater improvements in classification performance compared to random sampling.\nHighlights\n\u2022\nLarge comparison of Uncertainty Quantification (UQ) methods in multi-label setting.\n\u2022\nEnsemble methods are more robust for UQ and calibration under dataset shift.\n\u2022\nThe quality of current UQ methods degrade when dealing with dataset shifts.\n\u2022\nUQ for active learning improves performance faster than random sampling.","This article presents a novel automatic classification method for garment fabric pattern images using the vanilla Reset. The study begins by collecting industry-standard garment fabric images, which are further subjected to preprocessing techniques such as cropping, rotation, and contrast enhancement. These steps contribute to an expanded garment fabric image dataset. The dataset is then divided into a validation set and a training set for conducting image classification experiments. Different ResNet frameworks are employed to analyze the datasets and compare the results. The findings demonstrate that the classification model based on ResNet-34, serving as the backbone network, achieves the highest accuracy of 91.8% in garment fabric pattern classification. This performance surpasses the accuracy achieved by alternative backbone networks, namely AlexNet, VGG16, and GoogleNet, by a substantial margin. The superiority of ResNet-34 as a backbone network is thus affirmed. The proposed method's effectiveness is validated by the significant improvement in classification accuracy achieved by ResNet-34 compared to other backbone networks. These results highlight the potential of ResNet-34 in garment fabric pattern classification tasks. By leveraging the strengths of the ResNet architecture, our approach offers a promising solution for automating the classification of garment fabric patterns, contributing to efficiency and accuracy in the fashion industry. Overall, this study establishes the value of employing the ResNet-34 backbone network for garment fabric pattern image classification, as it outperforms competing networks and achieves remarkable classification accuracy. Future research can build upon these findings to explore further advancements in automatic garment fabric pattern classification.","Facial expression recognition is a human emotion classification problem attracting much attention from scientific research. Classifying human emotions can be a challenging task for machines. However, more accurate results and less execution time are still the issues when extracting features of human emotions. To cope with these challenges, the authors propose an automatic system that provides users with a well-adopted classifier for recognizing facial expressions in a more accurate manner. The system is based on two fundamental machine learning stages, namely feature selection and feature classification. Feature selection is realized by active shape model (ASM) composed of landmarks while the feature classification algorithm is based on seven well-known classifiers. The authors have used CK+ dataset, implemented and tested seven classifiers to find the best classifier. The experimental results show that quadratic classifier (DA) provides excellent performance, and it outperforms the other classifiers with the highest recognition rate of 100% for the same dataset.","Multi-layer perceptrons (MLPs) rank among the most popular and widely employed intelligent approaches for approximating the relationships between dependent and independent variables, demonstrating a wide range of successful applications. MLPs are flexible techniques capable of universally modeling and analyzing real-world problems in forecasting and classification domains with a desirable level of accuracy. In conventional MLPs, cost functions are formulated based on the error term. Subsequently, the learning process aims to estimate the unknown parameters to minimize the error-based cost function. The logic of the procedure is founded on the assumption that maximum generalization will be achieved from models displaying the highest accuracy within the training sample. While this learning process is rational and beneficial, a model's generalization capability depends simultaneously on the model's accuracy and the reliability level of that accuracy. In this manner, reliability is not taken into consideration when formulating the conventional cost function for MLPs. This paper introduces a reliability-based cost function for estimating the unknown weights and biases of MLP models during the learning process. The proposed cost function is designed to calculate the variation of the performances in dissimilar data situations. In the learning process of the proposed reliability-based multi-layer perceptron, in contrast to traditionally developed models, the goal is to minimize variation rather than error, or equivalently, to maximize reliability instead of accuracy. The generalizability of the proposed reliability-based MLP (EMLP) model in forecasting and classification domains is comprehensively evaluated using 30 benchmark data sets in each domain. Empirical results in the forecasting area indicate that, from a general perspective, the proposed EMLP model exhibits superior generalizability in 23 cases (76.67%) compared to traditional models. Furthermore, numerical results in the classification area reveal that the proposed model outperforms or matches the performance of the conventional MLP in 26 cases (86.67%). These outcomes clearly underscore the significance of reliability, a factor not considered in any of the conventional MLP modeling procedures. Therefore, the proposed MLP model represents a suitable alternative in modeling, especially when greater generalizability is desired.","This paper presents a novel study on soil image classification, leveraging the synergistic potential of transfer learning and convolutional neural networks (CNNs). The proposed approach combines the strengths of the MobileNetV2 architecture with a customized CNN model for accurate and efficient soil type recognition. The pre-trained MobileNetV2 is used to capture generic features before fine-tuning it with a dedicated soil image dataset comprising four distinct classes: red, clay, black, and yellow soils. To enhance the model\u2019s capacity for discerning intricate soil textures, a specially designed CNN architecture is incorporated. The model\u2019s performance is rigorously evaluated on a dataset of 108 images, each sized at 256\u2009\u00d7\u2009256 pixels, achieving an exceptional accuracy rate of 100% on the test dataset. The promising results demonstrate the efficacy of the proposed methodology in soil image classification tasks, offering potential applications in precision agriculture, environmental monitoring, and land management. While these findings showcase remarkable accuracy, further investigations are recommended to assess the model\u2019s generalization across diverse environmental conditions and an expanded range of soil image datasets.","Time series classification is a supervised task in the field of temporal data mining. Time series naturally tend to be highly dimensional, requiring the use of reduction techniques such as discretization. eMODiTS is a data-driven method for symbolically discretizing time series, which determines the best scheme by modifying the number of time (word segments) and values (alphabet) cuts, generating a unique alphabet set for every word segment. However, due to the high computational cost required, a surrogate model is incorporated to minimize this cost, using the K-Nearest Neighbors approach for regression and Dynamic Time Warping (DTW) as the similarity measure. Results suggest that the surrogate model effectively estimates the objective functions\u2019 values similarly to the original ones, leading to similar classification rates. It is validated with the statistical test where there is no significant statistical difference between the surrogate and original models. The surrogate model produces modified acceptance index (\nd\nj\n) values regarding predicting ability, indicating that the predictive performance is on average. On the other hand, the Mean Squared Error (MSE) consistently stays below 0.15, demonstrating that even when surrogate models cannot estimate the same values as the original model, the similarity of the values remains clear.","Plant diseases are a threat to the food supply as they reduce the yield, and reduce the quality of fruits and grains. Hence, early identification and classification of plant diseases are essential. This paper aims to classify mango plant leaves into healthy and diseased using convolutional neural networks (CNNs). The performance comparison of CNN architectures, AlexNet, VGG-16 and ResNet-50 for mango plant disease classification is provided. These models are trained using the Mendeley dataset, validation accuracies are found and compared with and without the use of transfer learning models. AlexNet (25 layers, 6.2 million parameters) produces a testing accuracy of 94.54% and consumes less training time. ResNet-50 (117 layers, 23 million parameters) and VGG-16 (16 layers, 138 million parameters) have given testing accuracies of 98.56% and 98.26% respectively. Therefore, based on the accuracies achieved and complexity, this paper recommends AlexNet followed by ResNet-50 and VGG-16 for plant leaf disease classification.","With the development of artificial intelligence technology and edge computing technology, deep learning-based automatic modulation classification (AI-based AMC) deployed at edge devices using centralised or distributed learning methods for optimisation has emerged in recent years, and has made great progress in the recognition accuracy and recognisable range of wireless signals. However, the lack of sufficient explanation of these models leads to low accuracy and training efficiency of model training, and their applications and further improvements are limited. Researchers have started to propose interpretable methods for technical analysis of deep learning-based AMC. In this paper, based on the research and application development of interpretable methods in recent years, we review the applicable methods and existing research challenges of interpretable automatic modulation classification. And an interpretable AI-based automatic modulation classification framework is proposed to map the interpretability of automatic modulation classification results by obtaining the contribution of wireless signal features to deep learning network training. Experimental results show that the proposed method possesses the ability to explore the classification mechanism of non-transparent auto-modulated classification networks and has the potential to help edge devices train networks with lower energy consumption and higher accuracy.","Aspect-based sentiment analysis (ABSA) is a subtask of sentiment classification, and the difficulty is how to capture the sentiment aspect and sentiment polarity pairs in a sentence. Early studies applied serialization models with attention mechanisms to mine sentiment information. These models are simple and effective, but cannot accurately capture sentiment pairs when encountering complex sentences. Recently, scholars have applied dependency information to construct various graph neural networks for the ABSA task. Compared with serialized models, these structured models demonstrate the graph neural network is powerful in capturing information, and further illustrates the syntactic information is effective for sentiment analysis. However, these syntactic models are usually influenced by syntactic parsers, especially for complex sentences. Hence, this paper builds a Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis (LSOIT). Specifically, inducing knowledge-aware opinion induction trees for each aspect word applied by reinforcement learning and attention mechanisms that integrate the lexicon knowledge (i.e. sememe knowledge) and syntax knowledge (i.e. phrase structures, and dependency relationships). Finally, we establish graph neural networks on knowledge-aware opinion induction tree for ABSA. Experimental results on four benchmarking datasets (i.e., Rest14, Laptop14, Twitter and MAMS) demonstrate that LSOIT significantly improves 2.21%, 0.47%, and 0.18% on Rest14, Laptop14, and MAMS comparing with state-of-the-art models, respectively. Ablation Study and Case Study manifest that external knowledge is useful, especially for datasets with standardized grammar rules.\nHighlights\n\u2022\nLexicon and Syntax Enhanced Opinion Induction Tree is proposed.\n\u2022\nUsing reinforcement learning and attention mechanism builds opinion induction trees.\n\u2022\nKnowledge enhanced opinion induction tree is presented.\n\u2022\nGCNs is constructed based on knowledge opinion induction tree for ABSA.","Leveraging unlabeled examples is a crucial issue for boosting performances in semi-supervised learning. In this work, we introduce the SAMOSA framework based on semantic augmentation for mixing semantic components from labeled examples and non semantic characteristics from unlabeled data. Our approach is based on a novel reconstruction module that can be grafted onto most state of the art networks. The proposed approach leans on two main aspects: an architectural component optimized to disentangle semantic and auxiliary non semantic representations using an unsupervised loss, and a semantic augmentation scheme that leverages this disentangling module to generate artificially labeled examples preserving known class information while controlling auxiliary variations. We demonstrate the ability of our method to improve the performance of models trained according to standard semi-supervised procedures Mean Teacher (Tarvainen and Valpola, 2017) MixMatch (Berthelot et al., 2019) and FixMatch (Sohn et al., 2020).\nHighlights\n\u2022\nSAMOSA regularizes classifiers through reconstruction in semi-supervised learning.\n\u2022\nOur Auto-encoder separates semantic and non-semantic information.\n\u2022\nNon-semantic information is isolated thanks to an asymmetrical decoder architecture.\n\u2022\nThe asymmetrical decoder allows for a novel semantic reconstruction regularizer.\n\u2022\nMixing samples\u2019 semantic and non-semantic contents yields a novel data augmentation.","Time series imaging technique: Gramian Angular Field (GAF), and a deep stacked Autoencoder (SAE) are employed to develop a multi-class classifier for the classification and authentication of water samples of bottled water brands: Aquafina (AF), Bisleri (BS), Kingfisher (KF), Oasis (OS), Dolphin (DL) and McDowell (MD) that are attainable in Indian market. The electronic tongue is an artificial taste sensor that is used in the present wok to taste the mineral water samples and subsequently produce one-dimensional current waveforms (CWFs). GAF is used to transform the 1D CWFs into images that are used to train the deep SAE based classifier. The trained classifier is tested on the test GAF images belonging to the water samples of six unknown mineral water brands. Results show that the classifier exhibits satisfactory performance with high classification rate of 93.9%.","Class imbalance problem commonly exists in multi-label classification (MLC) tasks. It has non-negligible impacts on the classifier performance and has drawn extensive attention in recent years. Borderline oversampling has been widely used in single-label learning as a competitive technique in dealing with class imbalance. Nevertheless, the borderline samples in multi-label data sets (MLDs) have not been studied. Hence, this paper deeply discussed the borderline samples in MLDs and found they have different neighboring relationships with class borders, which makes their roles different in the classifier training. For that, they are divided into two types named the self-borderline samples and the cross-borderline samples. Further, a novel MLDs resampling approach called Multi-Label Borderline Oversampling Technique (MLBOTE) is proposed for multi-label imbalanced learning. MLBOTE identifies three types of seed samples, including interior, self-borderline, and cross-borderline samples, and different oversampling mechanisms are designed for them, respectively. Meanwhile, it regards not only the minority classes but also the classes suffering from one-vs-rest imbalance as those in need of oversampling. Experiments on eight data sets with nine MLC algorithms and three base classifiers are carried out to compare MLBOTE with some state-of-art MLDs resampling techniques. The results show MLBOTE outperforms other methods in various scenarios.\nHighlights\n\u2022\nA new borderline oversampling technique for multi-label imbalanced learning.\n\u2022\nDefining self-borderline and cross-borderline samples in multi-label data sets.\n\u2022\nHandling one-vs-rest imbalance in multi-label imbalanced learning.\n\u2022\nPerforming competitively in the experiments with C4.5, RBF kernel SVM and linear SVM.","Facial Micro-Expression (ME) is one of the pre-dominating non-verbal clues to demystify the true emotional states that people try to conceal cautiously. But emotion recognition from spontaneous ME images limits the high accuracy due to short duration and low intensity, lack of sufficient samples and consistencies among publicly available ME datasets. In this study, we have proposed two highly effective, lightweight, and generalized single-channel DLRRF-MER, and multi-channel DLH-3C-FUSION fusion models inspired by deep dense convolutional models and texture-based feature descriptors Local Binary Pattern (LBP) and Histogram of Oriented Gradients (HOG) to recognize ME from apex frame by constructing a composite dataset from five publicly available ME datasets CASME, CASMEII, CAS(ME)2, SAMM and MMEW. Pre-training has been done on a new composition of five facial macro expressions datasets CK+, MUGFE, OuluCasia, SFEW, and RAF-DB. The proposed models are fine-tuned on the target ME dataset rigorously with Stratified 5-Fold and 10-Fold, Leave-One-Subject-Out, and Leave-One-Dataset-Out(LODO) cross-validations(CV). In all evaluations, our proposed algorithms show remarkable improvement in effectiveness which surpasses the state-of-the-art accuracies and results in higher generalization capacity.","We propose a self-attention Vision Transformer (ViT) model tailored for breast cancer histology image classification. The proposed architecture uses a stack of transformer layers, with each layer consisting of a multi-head self-attention mechanism and a position-wise feed-forward network, and it is trained with different strategies and configurations, including pretraining, resize dimension, data augmentation, patch overlap, and patch size, to investigate their impact on performance on the histology image classification task. Experimental results show that pretraining on ImageNet and using geometric and color data augmentation techniques significantly improve the model\u2019s accuracy on the task. Additionally, a patch size of 16 \n\u00d7\n 16 and no patch overlap were found to be optimal for this task. These findings provide valuable insights for the design of future ViT-based models for similar image classification tasks.","The findings on open-set recognition (OSR) show that models trained on classification datasets are capable of detecting unknown classes not encountered during the training process. Specifically, after trainig, the learned representations of known classes dissociate from the representations of the unknown class, facilitating OSR. In this paper, we investigate this emergent phenomenon by examining the relationship between the Jacobian norm of representations and the inter/intra-class learning dynamics. We provide a theoretical analysis, demonstrating that intra-class learning reduces the Jacobian norm for known class samples, while inter-class learning increases the Jacobian norm for unknown samples, even in the absence of direct exposure to any unknown sample. Overall, the discrepancy in the Jacobian norm between the known and unknown classes enables OSR. Based on this insight, which highlights the pivotal role of inter-class learning, we devise a marginal one-vs-rest (m-OvR) loss function that promotes strong inter-class separation. To further improve OSR performance, we integrate the m-OvR loss with additional strategies that maximize the Jacobian norm disparity. We present comprehensive experimental results that support our theoretical observations and demonstrate the efficacy of our proposed OSR approach.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThe underlying principle of OSR is demystified by the Jacobian norm of representation.\n\u2022\nA marginal one-vs-rest loss function is devised for effective OSR.","To lessen damages from landslides, the key challenge is to predict the events precisely and accurately. The objective of this study is to assess landslide susceptibility in the study area. To achieve this objective, a detailed landslide inventory has been prepared based on imagery data and frequent field visits of 153 rock slides and 44 debris slides. Nine landslide factors were prepared initially and their relationships with each other and with the type of landslide was analysed. Information gain ratio measure is used to eliminate triggering factors with least score. Train_test_split method was used to classify the dataset into training and testing groups. Decision tree classification model of machine learning was applied for landslide susceptibility model (LSM). The performance was evaluated using classification report and receiver operating characteristic (ROC) curve. Results obtained have proven that the decision tree classification model performed well with good accuracy in forecasting landslide susceptibility.","Medical imaging classification is an area that has taken relevance in recent years due to the capability to support the medical specialist at the time of diagnosis. However, there are different instruments to obtain images from the body, and each body organ is captured differently due to its chemical composition. In this way, there are some difficulties in working with different imaging modalities. Firstly, using different functions or methods to extract features from the images is necessary. Secondly, the classification performance depends on the relevant features extracted from the images, and thirdly, it is necessary to find the classifier that performs with the minimum error. Following the concept of Auto-Machine Learning (AutoML), where the feature engineering and the hyperparameter tuning of the classifier are done automatically, this work proposes an automated approach for feature extraction and image classification based on Genetic Programming. The approach modifies the functions and their parameters and the hyperparameters for the classifier. The results show that the approach can deal with different imaging modalities, demonstrating that feature extraction is necessary to increase the classification performance. For X-ray images, it achieves a classification accuracy of 0.99, and for computerized tomography, it achieves an accuracy of 0.96. On the other hand, the solutions given by the approach are easily reproducible and easy to interpret.","\u201cUnknown unknowns\u201d are instances predicted models assign incorrect labels with high confidence, greatly reducing the generalization ability of models. In practical applications, unknown unknowns may lead to significant decision-making mistakes and reduce the application value of models. As unknown unknowns are agnostic to models, it is extremely difficult to figure out why models would make highly confident but incorrect predictions. In this paper, based on identification of unknown unknowns, we investigate the interpretability of unknown unknowns arising from convolutional neural network models in image classification tasks by interpretable methods. We employ visualization methods to interpret prediction results on unknown unknowns, further understand predictive models and analyze the predictive basis of unknown unknowns. We focus the application scenario of interpretability of unknown unknowns on a clothes category recognition task (dress vs shorts) in e-commerce platforms, and observe some patterns of models making wrong classifications that lead to unknown unknowns, which indicates that a CNN model that lacks of common sense can make mistakes even for a large dataset. Besides, we observe some interesting phenomena: certain correct predictions of instances are unreliable due to wrongly identified features by CNNs.","Nowadays, Multi-Label Feature Selection (MLFS) attracts more and more attention to tackle the high-dimensional problem in multi-label data. A key characteristic of existing gradient-based MLFS methods is that they typically consider two-way variable correlations between features and labels, including feature-feature and label-label correlations. However, two-way correlations are not sufficient to steer feature selection since such correlations vary given different additional variables in practical scenarios, which leads to the selected features with relatively-poor classification performance. Motivated by this, we capture three-way variable interactions including feature-feature-label and feature-label-label interactions to further characterize the fluctuating correlations in the context of another variable, and propose a new gradient-based MLFS approach incorporating the above three-way variable interactions into a global optimization objective. Specifically, based on information theory, we develop second-order regularization penalty terms to regard three-way interactions while jointly combining with the main loss term in regard to feature relevance. Then the objective function can be efficiently optimized via a block-coordinate gradient descent schema. Meanwhile, we provide a theoretical analysis demonstrating the effectiveness of the regularization terms in exploiting three-way interaction. In addition, experiments conducted on a series of benchmark data sets also verify the validity of the proposed method on multiple evaluation metrics.\nHighlights\n\u2022\nFirst gradient-based multi-label feature selection method tackling three-way interactions.\n\u2022\nModel three-way interactions via two regularization terms, whose effectiveness is shown in theory.\n\u2022\nOptimize objective via iterative coordinate descent for feature importance blocks.","One of the difficult problems in agriculture is predicting the crop production. At the international, regional, and crop level, it is crucial to make decisions on this. In Most of the cases, agricultural, land, climatic, atmospheric, and other characteristics are used to forecast crop production. ML is a crucial decision-support model for estimating agricultural yields, enabling choices about which crops to cultivate and what to do while they are in the growing season. Numerous ML and DL algorithms have been applied to support studies on agricultural yield prediction. In this paper, a new crop yield prediction model is proposed which includes preprocessing, feature extraction and yield prediction phase. In preprocessing, data cleaning will takes place. Higher order statistical feature, information gain and improved entropy based features are extracted in feature extraction phase. The prediction is done by the hybrid model that combines Bi-GRU model and Maxout classifiers. To enhance the performance of this hybrid classifier, a new Self Adaptive Archimedes Optimization Algorithm (SAAOA) is introduced for training the weight parameters optimally. Finally the overall performance is evaluated and the better result is determined.","Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don\u2019t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn\u2019t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame\u2019s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI are becoming an imperative.","In the realm of ChatGPT's language capabilities, exploring Arabic Sentiment Analysis emerges as a crucial research focus. This study centers on ChatGPT, a popular machine learning model engaging in dialogues with users, garnering attention for its exceptional performance and widespread impact, particularly in the Arab world. The objective is to assess people's opinions about ChatGPT, categorizing them as positive or negative. Despite abundant research in English, there is a notable gap in Arabic studies. We assembled a dataset from Twitter, comprising 2,247 tweets, classified by Arabic language specialists. Employing various machine learning algorithms, including Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), and Naive Bayes (NB), we implemented hyperparameter optimization techniques such as Bayesian optimization, Grid Search, and random search to select the best hyperparameters which contribute to achieve the best performance. Through training and testing, performance enhancements were observed with optimization algorithms. SVM exhibited superior performance, achieving 90% accuracy, 88% precision, 95% recall, and 91% F1 score with Grid Search. These findings contribute valuable insights into ChatGPT's impact in the Arab world, offering a comprehensive understanding of sentiment analysis through machine learning methodologies.","Long-tailed learning is attracting increasing attention due to the unbalanced distributions of real-world data. The aim is to train well-performing depth models. Traditional knowledge transfer methods for long-tailed learning are classified into feature-based horizontal knowledge transfer (HKT) and class-based vertical knowledge transfer (VKT). HKT transfers head-to-tail feature knowledge from different classes to improve classification performance when there are few tail classes. However, HKT easily leads to invalid transfer due to the deviation caused by the difference between the knowledge of head and tail classes. Fortunately, the class space has a multi-grained relationship and can form a multi-granularity knowledge graph (MGKG), which can be recast as coarse-grained and fine-grained losses to guide VKT. In this paper, we propose a hierarchical long-tailed classification method based on multi-granularity knowledge transfer (MGKT), which vertically transfers knowledge from coarse- to fine-grained classes. First, we exploit the semantic information of classes to construct an MGKG, which forms an affiliation of fine- and coarse-grained classes. Fine-grained knowledge can inherit coarse-grained knowledge to reduce transfer bias with the help of MGKG. We then propose a multi-scale feature fusion network, which aims to fully mine the rich information of the features to drive MGKT. Experiments show that the proposed model outperforms several state-of-the-art models in classifying long-tailed data. For example, our model performed 4.46% better than the next-best model on the SUN-LT dataset.\nHighlights\n\u2022\nWe propose a multi-scale feature fusion network about channel and spatial features.\n\u2022\nWe investigate a multi-granularity relationship of class space.\n\u2022\nWe explore a vertical transfer of coarse- to fine-grained knowledge.","Efficiently classifying sheep breeds through image analysis is pivotal in modern animal husbandry, influencing critical management and breeding decisions. This study delves into automating this process by harnessing Convolutional Neural Networks (CNNs), with a particular focus on optimizing key hyperparameters\u2014the learning rate and dropout rate\u2014essential for refining model performance. Manual hyperparameter tuning is often time-consuming and demands expertise. To overcome this challenge, we introduce an innovative approach that utilises the Bat algorithm, a bio-inspired optimization technique. This algorithm mimics bat echolocation behaviors, skillfully navigating the complex hyperparameter search space to determine optimal values. By dynamically adjusting CNN hyperparameters, our research aims to boost classification accuracy while simplifying the tuning process. Empirical results highlight significant gains in classification accuracy and emphasizes the Bat algorithm's efficacy. The optimized CNN model, empowered by fine-tuned hyperparameters, demonstrates superior performance, promising practical applicability in real-world sheep breed classification scenarios. This study meticulously adjusts pulse rate and loudness, revealing an optimal combination of [0.001, 0.24404868], which substantially improves model performance. The findings emphasize the Bat algorithm's role in streamlining hyperparameter tuning and its potential impact on automated sheep breed classification.","Clothing classification serves as a fundamental task for clothing retrieval, clothing recommendation, etc. In this task, there are two inherent challenges: suppressing complex backgrounds outside the clothing region and disentangling the feature entanglement of shape-similar clothing samples. These challenges arise from insufficient attention to key distinctions of clothing, which hinders the accuracy of clothing classification. Also, the high computational resource requirement of some complex and large-scale models also decreases the inference efficiency. To tackle these challenges, we propose a new COntext-driven Clothing ClassIfication network (COCCI), which improves inference accuracy while reducing model complexity. First, we design a self-adaptive attention fusion (SAAF) module to enhance category-exclusive clothing features and prevent misclassification by suppressing ineffective features with confused image contexts. Second, we propose a novel multi-scale feature aggregation (MSFA) module to establish spatial context correlations by using multi-scale clothing features. This helps disentangle feature entanglement among shape-similar clothing samples. Finally, we introduce knowledge distillation to extract reliable teacher knowledge from complex datasets, which helps student models learn clothing features with rich representation information, thereby improving generalization while reducing model complexity. In comparison to state-of-the-art networks trained with one single model, our method achieves SOTA performance on the widely-used clothing classification benchmark.","Once a crisis arises, people use social media platforms (such as Twitter) to communicate real-time updates. This data is incredibly helpful to disaster relief and response organisations and may offer rapid notifications for prioritising requests. Text mining and machine learning algorithms can scan enormous amounts of unstructured data created by social media outlets like Twitter to recognise disaster-related content based on keywords and phrases. One of the difficulties that algorithms may confront is determining whether the tweet content discusses actual disasters or uses these keywords as metaphors. As a result, this research aims to apply natural language processing (NLP) and classification models to discriminate between authentic and bogus disaster tweets. This dataset from the Kaggle website includes tweets about genuine disasters and fictional disasters. Four machine learning classifier methods were used: KNN, SVM, XGBoostand, and Naive Bayes. KNN offers the highest accuracy.","We present a novel algorithm for learning a union of convex separators (UCS) to separate a class from another using decision boundaries, each of which is a convex separator. A convex separator is defined by a collection of hyperplanes that separate one class from another class using an intersection of half-spaces. A union of convex separators can be thought of as an ensemble of such convex separators that collectively separate all points of one class from the other. In this work, we put forth the notion of separability using a UCS previously known in earlier works as min-max separability, provide a gradient-based algorithm for learning UCS, and assess it against popular classifiers using recent datasets of interest.","Vehicle classification holds significant importance in various domains such as infrastructure design and freight analysis. This study presents an innovative composite deep-learning framework for accurate vehicle classification. The framework exploits two distinct types of features extracted from vehicle images: (1) high-level encodings from state-of-the-art vision transformers (ViTs), and (2) localized vehicle wheel position features obtained through real-time object detection models. The former encapsulates global and semantic characteristics, while the latter focuses on specific wheel (axle) positions. Within this composite model paradigm, we evaluate and compare the efficacy of four ViT models: the original ViT, Cross ViT, Transformer-in-Transformer, and Swin Transformer. Similarly, we assess four object detection models for extracting wheel position features: two Faster R-CNN models (with ResNet-50 and MobileNetv3 backbones) and two YOLO models (YOLOv4 and YOLOR). The ViT encodings and wheel position features are then combined and channeled into a multi-layer perceptron classifier for precise vehicle classification. To enhance the ViT model's effectiveness, we employ a wheel masking strategy during its training, which acts as a regularizer, promoting robust and complementary encodings. Our experimental results reveal that introducing randomness by masking a single wheel significantly enhances the inference performance across all composite models. However, masking more wheels introduces excessive noise and causes performance degradation. Furthermore, initializing ViT encoders with pretrained weights through self-supervised methods leads to additional performance improvements. Notably, our best model achieves an impressive Top-1 classification accuracy of 96.7% when categorizing 13 vehicle classes as defined by the Federal Highway Administration. The results underscore the efficacy of the proposed composite architecture in achieving high precision in vehicle classification tasks.","Spectrogram zeros, originated by the destructive interference between the components of a signal in the time\u2013frequency plane, have proven to be a relevant feature to describe the time-varying frequency structure of a signal. In this work, we first introduce a classification of the spectrogram zeros in three classes that depend on the nature of the components that interfere to produce them. Then, we describe an algorithm to classify these points in an unsupervised way, based on the analysis of the stability of their location with respect to additive noise. Finally, potential uses of the classification of zeros of the spectrogram for signal detection and denoising are investigated, and compared with other methods on both synthetic and real-world signals.\nHighlights\n\u2022\nSpectrogram zeros can be classified in three kinds.\n\u2022\nAn unsupervised, noise-assisted method to classify spectrogram zeros is introduced.\n\u2022\nThe classification helped to overcome limitations of previous zero-based methods.\n\u2022\nOur approaches for signal detection and denoising are effective in low SNR cases.","Malware is a serious threat to the modern Internet, as it is used to, e.g., sending spam or stealing bank login credentials. Typically, to communicate with the attacker, it utilizes popular network protocols such as the HyperText Transfer Protocol (HTTP). The network traffic characteristics related to this protocol can be used to detect malware and identify its family. The latter is a standard multi-class classification problem for which machine learning algorithms are utilized. However, existing methods cannot identify a real-world situation of encountering a new malware family, which was not known during their training phase. To address this issue, an Open Set Recognition (OSR) approach can be used, capable of a multi-class classification and identification of unknown class occurrence. In this paper, we apply OSR to the malware classification using HTTP requests and compare it with the existing solutions. In more detail, we analyze the classification performance of three OSR and two standard algorithms and their computation time. Additionally, we utilize two request representations: one based on Hfinger tool and the other relying on trigrams. The obtained experimental results allowed to select an optimal set of algorithms and HTTP request representations suitable for OSR scenarios.","Classifying architectural structures is an important and challenging task that requires expertise. Convolutional Neural Networks (CNN), which are a type of deep learning (DL) approach, have shown successful results in computer vision applications when combined with transfer learning. In this study, we utilized CNN based models to classify regional houses from Anatolia and Balkans based on their architectural styles with various pretrained models using transfer learning. We prepared a dataset using various sources and employed data augmentation and mixup techniques to solve the limited data availability problem for certain regional houses to improve the classification performance. Our study resulted in a classifier that successfully distinguishes 15 architectural classes from Anatolia and Balkans. We explain our predictions using grad-cam methodology.","The cultivation of desired grain varieties holds immense significance as about 67% of the world\u2019s population is associated with the agriculture sector. Unknowingly sowing the wrong variety of seeds may lead to a colossal waste of effort and money. Furthermore, the growing issue of rice grain adulteration in high-quality rice poses a threat to the trust of rice importers and exporters. While traditional methods are expensive, laborious, and error-prone, Computer Vision provides a good alternative that constitutes a current, advanced technology for image processing and data evaluation that holds tremendous promise and potential. In this research study, five varieties of rice grains including Jehlum Sr-1, Mushkibudji, Sr-2, and Sr-4 were collected from local grain and were used for research analysis. A computer vision system \u201cRiceNet\u201d contingent upon Deep Convolutional Neural Network (DCNN) framework has been designed for ameliorating the accuracy of identifying five unique groups of rice grain varieties. Deep Learning (DL) based pre-trained architectures including InceptionV3 and InceptionResNetV2 models were also adopted for classifying five specific groups of rice species. To optimize model parameters and alleviate back-propagation error during training, the Adam optimizer with a learning rate (lr) of 0.00003 has been employed to fine-tune the pre-trained InceptionV3 and ResNetInceptionV2 models. The proposed RiceNet architecture and pre-trained models were also compared with traditional ML approaches of HOG-SVM, SIFT-SVM, HOG-Logistic Regression(HOG-LR), SIFT-Logistic Regression(SIFT-LR), HOG-KNN, and SIFT-KNN for rice grain classification. With these experimentations at hand, it was observed that our proposed model \u201cRiceNet\u201d outperformed other approaches in similar computer vision tasks. The prediction accuracy outcome for the test dataset by HOG-SVM, SIFT-SVM, HOG-LR, SIFT-LR, HOG-KNN, and SIFT-KNN models were 66.0%, 65.33%, 62.67%, 65.0%, 54.0%, and 52.0% respectively. RiceNet, InceptionV3 and ResNetInceptionV2 have the best prediction accuracy of 94%, 84% and 81.333%. The remarkably high success rate of DCNN models makes them highly valuable and can be extended to endorse an integrated grain identification system that can operate in real-world situations.\nHighlights\n\u2022\nRice grain classification is crucial to ensure quality in the agricultural sector.\n\u2022\nDeep Convolutional Neural Network based RiceNet model achieved high accuracy of 94%.\n\u2022\nRiceNet outperforms ML traditional methods for rice grain identification.\n\u2022\nInceptionV3 and ResNetInceptionV2 achieved 84% and 81.333% prediction rates.","Highlights\n\u2022\nA pretrained model on augmented data and fine-tuned by using AI and 3D contour features for assessing facial attractiveness is proposed.\n\u2022\nThe proposed model overcomes the subjective inconsistency and unreliability common to all traditional rating methods.\n\u2022\nThis model provides an accurate 3D information of full facial that is unavailable in previous studies using either 2D or 3D measurement.\n\u2022\n3D facial images and deep transfer learning have been firstly combined for evaluating the facial attractiveness in patients undergoing OGS.\n\u2022\nThe developed web browser\u2013based user interface contributes to effective doctor\u2013patient communication and decision-making.\nAbstract\nIn this paper, we investigate a new approach based on a combination of three-dimensional (3D) facial images and deep transfer learning (TL) with fine-grained image classification (FGIC) for quantitative evaluation of facial attractiveness. The 3D facial surface images of patients with and without filtering and the publicly available SCUT-FBP5500 dataset was used for transfer training and model pre-training, respectively. Experimental results show that a bilinear CNN model with a Gaussian filter freezing 80 % of the weights exhibit the strongest performance and lowest average error as a deep learning prediction model; the model was subsequently adopted for automatic assessment of facial attractiveness in clinical application. This is the first TL model with FGIC using 3D facial images for automatic quantitative evaluation of facial attractiveness in patients undergoing Orthognathic surgery (OGS). The developed web browser\u2013based user interface enables effective and rapid assessment, thus contributing to effective patient\u2013clinician communication and decision-making.","Brain tumors can be generated anywhere in the brain, with an extensive size range and morphology that makes it challenging to identify and classify. Classifying brain tumors is essential for developing personalized treatment plans. Different types of brain tumors have different responses to treatment, and an accurate classification can help medical professionals develop treatment plans tailored to each patient\u2019s needs. Therefore, this case study aimed to classify T1-weighted contrast-enhanced images of three types of tumors through various approaches, from shallow neural networks to fine-tuning deep neural networks trained. Comparing shallow and deep neural network approaches could help to understand the trade-offs between their performance, interoperability, interpretability, benefits, limitations, scopes, and overall, choosing the best method for a given problem.","This study develops an end\u2010to\u2010end deep learning framework to learn and analyze ground motions (GMs) through their latent features, and achieve reliable GM classification, selection, and generation of simulated motions. The framework is composed of an analysis workflow that transforms and reconstructs GMs through short\u2010time Fourier transform (STFT), encodes and decodes their latent features through convolutional variational autoencoder (CVAE), and classifies and generates GMs by grouping and interpolating latent variables. A benchmark study is established to confirm the minor difference between original GMs and the corresponding reconstructed accelerograms. The encoded latent space reveals that certain latent variables are directly linked to the dominant physical features of GMs. Resultantly, clustering latent variables using the k\u2010means algorithm successfully classifies GMs into different groups that vary in earthquake magnitude, soil type, field distance, and fault mechanism. By linearly interpolating two parent latent variables, simulated GMs are generated with consistent class information and matching response spectra. Furthermore, seismic fragility models are developed for a steel frame building and a concrete bridge using different sets of GMs. Using five classified, top\u2010ranked motions, regardless of recorded or simulated accelerograms, can achieve reasonable and efficient fragility estimates compared to the case that adopts 230 GMs. The proposed deep learning framework addresses two compelling questions regarding seismic fragility assessment: How many GMs are sufficient and what types of motions should be selected.","Handwriting is widely investigated to mark emotional states and personality. However, the majority of the studies are based on graphology, and do not utilise personality factor models. We use the well-known five-factor model which says that people possess five basic traits, together known as big-five. Hence the problem of personality prediction from handwriting is essentially a multi-label problem. In addition to that, the predicted values should be non-binary decimal numbers since the model says people possess the traits in various degrees. Multi-label classifiers have not been explored for personality assessment using handwriting features. The current work aims to bridge the gap. Multi-label classifiers are trained by trait scores obtained by big-five inventory as well as handwriting features. A number of classifiers including classifier chain, binary relevance and label power-set are employed in the work. Best accuracies of 95.9% with non-binary label values and 97.9% with binary label values are achieved.","Forecasting retail sales often requires various number of products from different stores. Existing deep or machine learning techniques fall short of producing accurate classification results because of overfitting and two-class problem that affects the performance of evaluation parameters like precision, recall, accuracy and F-measure. Hence there is a need for an efficient prediction framework that addresses the existing problems. This work proposes an efficient framework for predicting retail sales using an ensemble DNN-BiLSTM framework. We suggest creating a base forecaster pool that includes both individual and pooled forecasting techniques for developing this ensemble approach to forecasting retail sales. Instead of focusing on finding the best individual technique, we suggest finding the optimal combination of forecasts. Classification Accuracy, Precision, Recall, and F-measure performance metrics of the experiment utilizing the proposed ensemble approach DNN\u2009+\u2009BiLSTM surpass the current DNN, CNN, and LSTM classifiers by 98.3%, 98.1%, 97.8%, and 97.94%, respectively.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201cco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","Electronic nose (e-nose) is composed of a set of gas sensors combined with a series of algorithmic models. The practical application of the electronic nose system can prove that the electronic nose is more widely used in the classification problems, and always has a good performance. Moreover, it can be inferred that classification methods significantly influence e-nose. So far, the classification models proposed in e-nose can generally be divided into two categories. One is the linear classifier, representing the model of the Bayesian classifier, principal component analysis (PCA), and K-nearest neighbour (KNN), etc. The other is the nonlinear classifier, including support vector machine (SVM), random forest (RF), and extreme learning machine (ELM), etc. This review aims to supply a summary of the various classification methods used in e-nose, and provides a reference for the choice of an appropriate classification model used in e-nose in the specific application.","Deciding the signal length is an important challenge for one-class time-series classification (OCTSC). This paper aims to develop an OCTSC algorithm that does not require model retraining for different signal lengths. For this purpose, a distance-based one-class time-series classification approach using local cluster balance (OCLCB) is proposed. OCLCB extracts feature vectors, namely, local cluster balance (LCB), from the clustering results of sliding windows. K-means clustering is applied to the sliding windows extracted from the training signal. Then, the local prototype (LP) is calculated as the average of the local cluster balance (LCB) in the training data. Unseen scores are computed as the distance metrics between LP and LCBs in the testing data. Since the sliding window size is independent of the entire signal size, OCLCB does not need to retrain the model. This aspect gives the benefit of reducing the parameter tuning costs. The source code is uploaded at https://github.com/ToshiHayashi/OCLCB.","Skin cancer is regarded as the hazardous as well as widespread disease. Worldwide, there is been a 53% increment in present melanoma cases annually, and the mortality rate is also expected to be increasing in the coming decade. Hence, it is an urgent requirement to design a new early-detection model so that skin cancer can be more treatable without many complications. This work focuses on recognising skin cancer. The model includes the median filter (MF)-based pre-processing. The pre-processed image is subjected to a modified fuzzy C means (FCM)-based segmentation process. Finally, the recognition is done by employing a hybrid model with bi-LSTM and ANN. The proposed model's error rate was 0.091694, whereas the greatest error values for the other approaches were 0.20377 for BOA, 0.62192 for BRO, 0.170028 for ALO, 0.17168 for AOA, and 0.187915 for FIREFLY.","Pose-based approaches for sign language recognition provide light-weight and fast models that can be adopted in real-time applications. This article presents a framework for isolated Arabic sign language recognition using hand and face keypoints. We employed MediaPipe pose estimator for extracting the keypoints of sign gestures in the video stream. Using the extracted keypoints, three models were proposed for sign language recognition: Long-Term Short Memory, Temporal Convolution Networks, and Transformer-based models. Moreover, we investigated the importance of non-manual features for sign language recognition systems and the obtained results showed that combining hand and face keypoints boosted the recognition accuracy by around 4% compared with only hand keypoints. The proposed models were evaluated on Arabic and Argentinian sign languages. Using the KArSL-100 dataset, the proposed pose-based Transformer achieved the highest accuracy of 99.74% and 68.2% in signer-dependent and -independent modes, respectively. Additionally, the Transformer was evaluated on the LSA64 dataset and obtained an accuracy of 98.25% and 91.09% in signer-dependent and -independent modes, respectively. Consequently, the pose-based Transformer outperformed the state-of-the-art techniques on both datasets using keypoints from the signer\u2019s hands and face.","Skip BACKGROUND: Section\nBACKGROUND:\nAlzheimer\u2019s disease (AD) endangers the physical and mental health of the elderly, constituting one of the most crucial social challenges. Due to lack of effective AD intervention drugs, it is very important to diagnose AD in the early stage, especially in the Mild Cognitive Impairment (MCI) phase.\nSkip OBJECTIVE: Section\nOBJECTIVE:\nAt present, an automatic classification technology is urgently needed to assist doctors in analyzing the status of the candidate patient. The artificial intelligence enhanced Alzheimer\u2019s disease detection can reduce costs to detect Alzheimer\u2019s disease.\nSkip METHODS: Section\nMETHODS:\nIn this paper, a novel pre-trained ensemble-based AD detection (PEADD) framework with three base learners (i.e., ResNet, VGG, and EfficientNet) for both the audio-based and PET (Positron Emission Tomography)-based AD detection is proposed under a unified image modality. Specifically, the effectiveness of context-enriched image modalities instead of the traditional speech modality (i.e., context-free audio matrix) for the audio-based AD detection, along with simple and efficient image denoising strategy has been inspected comprehensively. Meanwhile, the PET-based AD detection based on the denoised PET image has been described. Furthermore, different voting methods for applying an ensemble strategy (i.e., hard voting and soft voting) has been investigated in detail.\nSkip RESULTS: Section\nRESULTS:\nThe results showed that the classification accuracy was 92% and 99% on the audio-based and PET-based AD datasets, respectively. Our extensive experimental results demonstrate that our PEADD outperforms the state-of-the-art methods on both audio-based and PET-based AD datasets simultaneously.\nSkip CONCLUSIONS: Section\nCONCLUSIONS:\nThe network model can provide an objective basis for doctors to detect Alzheimer\u2019s Disease.","Recently, transfer learning has generated promising performance in few-shot classification by pre-training a backbone network on base classes and then applying it to novel classes. Nevertheless, there lacks a theoretical analysis on how to reduce the generalization error during the learning process. To fill this gap, we prove that the classification error bound on novel classes is mainly determined by the base-class generalization error, given the base-novel domain divergence and the novel-class generalization error produced by an incremental learner using novel samples. The novel-class generalization error is further decided by the base-class empirical error and the VC-dimension of the hypothesis space. Based on this theoretical analysis, we propose a Born-Again Networks under Self-supervised Label Augmentation (BANs-SLA) method to improve the generalization capability of classifiers. In this method, cross-entropy and supervised contrastive losses are simultaneously used to minimize the base-class empirical error in the expanded space with SLA. Afterward, BANs are adopted to transfer the knowledge sequentially across generations, which acts as an effective regularizer to trade-off the VC-dimension. Extensive experimental results have verified the effectiveness of our method, which establishes the new state-of-the-art performance on popular few-shot classification benchmark datasets.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThis is the first theoretical study on FSC in the context of the transfer learning paradigm.\n\u2022\nWe propose a Born-Again Networks under Self-supervised Label Augmentation method.\n\u2022\nWe conduct experiments on multiple benchmarks to demonstrate the effectiveness.","To increase classification accuracy, a variety of feature extraction techniques have been presented. A pre-processing method called superpixel segmentation divides an image into meaningful sub-regions, which simplifies the image. This substantially reduces single-pixel misclassification. In this work, a texture-based superpixel segmentation technique is developed for the accurate classification of hyperspectral images (HSI). Initially, the local binary pattern and Gabor filters are employed to extract local and global image texture information. The extracted texture features are then provided as input to the simple linear iterative clustering (SLIC) algorithm for segmentation map generation. The final classification map is constructed by utilising a majority vote strategy between the superpixel segmentation map and the pixel-wise classification map. The proposed method was validated on standard HSI datasets. In terms of classification performance, it outperformed other state-of-the-art algorithms. Furthermore, the algorithm may be incorporated into the UAV's onboard camera to automatically classify HSI.","In this paper, an analysis of convolutional neural network (CNN) models to classify the quality of dried chili pepper is described. The classifier models can determine the categories of a set of images that could be encountered in a sorting machine, such as \u201cExtra\u201d, \u201cFirst class\u201d, and \u201cSecond class\u201d which correspond to different qualities of dried chili peppers. Additionally, two more classes were added as \u201cTrash\u201d and \u201cEmpty\u201d which corresponds to cases that could occur in a sorting machine. To determine the best model for image classification, a set of state-of-the-art architectures were compared from the Torchvision library, including ResNet, ResNeXt, Wide ResNet, EfficientNet, and RegNet. The models were trained using feature extraction on the transfer learning approach, and were evaluated using cross-validation method and various advanced metrics such as Precision, Recall, Specificity, F1-score, Geometric mean, and Index of Balanced Accuracy. The results of the cross-validation process indicate that ResNet-152 is the best CNN model for implementation in a sorting machine, with a mean validation accuracy of 95.04%. By using this model, agricultural producers can ensure that their products are sorted according to international standards.","To better understand how accurate opaque black box models work, it is necessary to explain their internal workings in terms of human-interpretable image sub-regions known as concepts. This explanation will provide insights into how these models perceive the sharedness of concepts across related classes, as frequently observed in the real world. With this objective in mind, the proposed work aims to leverage an incremental Non-negative Matrix Factorization technique to extract shared concepts in a memory-efficient manner, thereby reflecting the sharedness of concepts across classes. The relevance of the extracted concepts towards prediction, as well as the encoding of primitive image aspects such as color, texture, and shape by the concept, will be estimated after training the concept extractor. This approach reduces training overhead and simplifies the explanation pipeline, enabling the elucidation of various concepts - some genuine, some spurious - on which different black box architectures trained on the Imagenet dataset group and distinguish related classes.","Multi-label feature selection, which addresses the challenge of high dimensionality in multi-label learning, has wide applicability in pattern recognition, machine learning, and related domains. Most existing studies on multi-label feature selection assume that all labels have the same importance with respect to features, however, they overlook the differences between labels and candidate features relative to selected features and the internal influence of the label space. To address this issue, we propose a novel method for multi-label feature selection that accounts for both the strongly relevant label gain and the label mutual aid. Firstly, we advance two new potential relationships between labels and candidate features relative to selected features, and the label discriminant function is introduced. Secondly, the mutual aid information between labels is presented to describe the internal correlation of the label space. Thirdly, the concept of strongly relevant label gain is defined based on the label discriminant function, which allows better exploration of positive correlation between features. Finally, the experimental results on sixteen multi-label benchmark datasets indicate that the proposed method outperforms other compared representative multi-label feature selection methods.\nHighlights\n\u2022\nTwo relationships are proposed from the perspective of fuzzy information measures.\n\u2022\nA label discriminant function is defined according to two proposed relationships.\n\u2022\nStrongly relevant label gain is proposed based on the label discriminant function.\n\u2022\nThe label mutual aid is defined based on fuzzy conditional mutual information.\n\u2022\nA novel multi-label feature selection algorithm is proposed.","Alzheimer's disease (AD) represents a prevalent, progressive neurodegenerative ailment marked by the gradual deterioration of memory and cognitive faculties. Resting-state functional magnetic resonance imaging (rs-fMRI) offers good specificity in AD by reflecting the early changes in the brain network. As a result, combining the popular deep learning methods with rs-fMRI brain network features has attracted a wide attention. In our experiment, A cohort comprising 325 participants, sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, was stratified into three distinct groups: Alzheimer's Disease (AD, 53), mild cognitive impairment (MCI, 140) and normal control (NC, 152). With the preprocessed rs-fMRI data, the functional brain networks were constructed. Though the obtained features of rs-fMRI network and clinical scales, one improved BrainNet-graph convolutional network (GCN) was proposed for AD classification. In the realm of performance assessment, we conducted a comparative analysis between our BrainNet-GCN model and the GCN model. Our proposed BrainNet-GCN demonstrated better capability than those of GCN with high accuracies (ACCs) of AD vs.MCI of 91.89%, MCI vs.NC of 91.38%, and AD vs.NC of 92.50% for binary classification, and with an improved ACC of 83.58% for multi-class classification. The proposed BrainNet-GCN using the combined features of rs-fMRI network and clincal scales demonstrated robust capability in AD classification owing to its high sensitivity and specificity.","Granular computing involves a comprehensive process that encompasses theories, methodologies, and techniques to solve complex problems, rather than being just an algorithm. As the volume of generated data continues to grow rapidly, data-driven problems have become increasingly complex. Although deep learning models have outperformed traditional machine learning models in solving complex problems, there is still room for enhancing their performance. In this paper, we propose a granular computing-based deep learning model, aimed at enhancing classifier accuracy in complex natural language-based problems. The proposed approach involves a new granulation method, which comprises a novel algorithm built on combinatorial concepts and ten rule-based numerical granules. By utilizing this granulation method, each granule adds a new representation and concept to the existing data. The proposed model consists of multiple models that perform learning separately in a granular view. In the final step, the model pays attention to the granulated matrices generated by various models. The proposed model is evaluated using datasets related to cyberbullying and two hate speech datasets, resulting in significant improvements in accuracy compared to state-of-the-art models.\nHighlights\n\u2022\nProposing a granular computing-based deep learning model for text classification.\n\u2022\nUsing granular computing for data augmentation from a new representation in the context of deep learning-based text classification.\n\u2022\nUtilizing different representations of the existing texts.\n\u2022\nProposing the first stacked-BILSTM-SVM model in granular computing.","Ensemble learning is a technique of combining multiple base machine learning models and using the blended results as the final classification output. Such models provide a unique perspective on the classification results as it produces a more comprehensive and encompassing output. As such ensemble learning techniques are widely used for classification in today. Hence it is important that any ensemble learning model be robust and resilient to any type of data and not just applicable to one dataset. This research investigates and evaluates the robustness and the resilience of the proposed Legitimacy ensemble learning model. This ensemble learning model was previously proposed for Credibility Based Fake News Detection. This research evaluates Legitimacy\u2019s performance with a variety of datasets. In the first scenario, the Legitimacy ensemble learning model is evaluated with 3 different binary classification datasets for training and testing purposes, respectively. In the second scenario, the Legitimacy model is assessed where one dataset is used for training whilst another dataset is used for testing. In the final scenario the Legitimacy ensemble learning model is evaluated against a multiclass dataset for multiclass classification. The results of all the above tests are assimilated and evaluated. The results suggest that the Legitimacy ensemble learning model performs well in all three scenarios giving AUC values all equal to or greater than 0.500. As such it can be concluded that the Legitimacy model is a robust and resilient ensemble learning technique and can be employed for the task of classification with any dataset.","The Antinuclear Antibody (ANA) test is a valuable diagnostic tool for autoimmune disorders that uses Indirect Immunofluorescence (IIF) microscopy with HEp-2 cells as the substrate to identify antibodies and their distinct staining patterns. Machine learning-based approaches have shown promise in automating this diagnosis process, with Data Augmentation (DA) techniques playing a crucial role in improving performance. Even though traditional DA methods have yielded positive results, generative techniques like Variational AutoEncoders (VAEs) have shown potential in exploring the input distribution and generating new images. To address the limitations of traditional DA and explore the potential of generative approaches, this paper focuses on applying Conditional Variational AutoEncoders (CVAEs) to HEp-2 cell image classification. A customized CVAE architecture is proposed, considering multiple labels during generation to enhance versatility. Extensive experiments were conducted with the largest publicly available dataset of HEp-2 cell images, the I3A dataset. The performance of traditional and generative data augmentation techniques were compared while investigating potential synergies between them. The findings highlight the benefits of combining these techniques, especially in scenarios with class imbalance. Thorough statistical analysis provides valuable insights from the experimental results.","With the game market growing year by year, game developers find themselves in an extremely competitive scenario. To draw players attention towards their game and to engage them even more during gameplay, one alternative is to apply a Dynamic Difficulty Adjustment algorithm. But the problem of the DDA approach is usually not the algorithm itself, but the player classification step. Therefore, we created a generic Unity Plugin that, allied with a Python API, will be able to classify players, using unsupervised and supervised Machine Learning techniques, based on game telemetry. We also implemented our own simple DDA algorithm, to test how it would work allied with the online classification process. The results show that the DDA version outperforms the standard one in the Video-Game category (CEGE Framework). The resultant classification was 63% completely accurate and 100% partially accurate. Moreover, no other work was able to create a generic plugin that simplified the use of ML in the game development context, allowing to test 28 different algorithm combinations.","Protein acetylation refers to a process of adding acetyl groups (CH3CO-) to lysine residues on protein chains. As one of the most commonly used protein post-translational modifications, lysine acetylation plays an important role in different organisms. In our study, we developed a human-specific method which uses a cascade classifier of complex-valued polynomial model (CVPM), combined with sequence and structural feature descriptors to solve the problem of imbalance between positive and negative samples. Complex-valued gene expression programming and differential evolution are utilized to search the optimal CVPM model. We also made a systematic and comprehensive analysis of the acetylation data and the prediction results. The performances of our proposed method aie 79.15% in Sp, 78.17% in Sn, 78.66% in ACC 78.76% in F1, and 0.5733 in MCC, which performs better than other state-of-the-art methods.","The increasing availability of quantitative data in archaeological studies has prompted the research of Machine Learning methods to support archaeologists in their analysis. This paper considers in particular the problem of automatic classification of 3D surface patches of \u201crubble stones\u201d and \u201cwedges\u201d obtained from Prehistorical and Protohistorical walls in Crete. These data come from the W.A.L.(L) Project aimed to query 3D photogrammetric models of ancient architectonical structures in order to extract archaeologically significant features. The principal aim of this paper is to address the issue of a clear semantically correspondence between data analysis concepts and archaeology. Classification of stone patches has been performed with several Machine Learning methods, and then feature relevance has been computed for all the classifiers. The results show a good correspondence between the most relevant features of the classification and the qualitative features that human experts adopt typically to classify the wall facing stones."],"author":["Singh, Onkar and Kashyap, Kanchan Lata and Singh, Koushlendra Kumar","El Hlouli, Fatima Zohra and Riffi, Jamal and Mahraz, Mohamed Adnane and Yahyaouy, Ali and El Fazazy, Khalid and Tairi, Hamid","Tang, Jun and Chen, Wenhui and Wang, Ke and Zhang, Yan and Liang, Dong","Wang, Huaduo and Gupta, Gopal","Chen, Zhikui and Lou, Kai and Liu, Zhenjiao and Li, Yue and Luo, Yiming and Zhao, Liang","Putzu, Lorenzo and Loddo, Andrea","NaN","Kamali Lassem, Nima and Gaafar, Obai Mohamed Hisham Abdelmohsen and Ali, Seyid Amjad","NaN","Geng, Zengmin and Lin, Bijun and Yuan, Ye and Liu, Shiyu and Gao, Dandan and Du, Jianxia","Adel, Alti and Farid, Ayeche","Etemadi, Sepideh and Khashei, Mehdi and Tamizi, Saba","Banoth, Ravi Kumar and Murthy, B. V. Ramana","NaN","Jayanthi, B. and Kumar, Lakshmi Sutha","Xu, Bo and Bhatti, Uzair Aslam and Tang, Hao and Yan, Jialin and Wu, Shulei and Sarhan, Nadia and Awwad, Emad Mahrous and M. S., Syam and Ghadi, Yazeed Yasin","Wu, Haiyan and Zhou, Di and Sun, Chaoqun and Zhang, Zhiqiang and Ding, Yong and Chen, Yanhong","NaN","Damarla, Seshu Kumar","Teng, Zeyu and Cao, Peng and Huang, Min and Gao, Zheming and Wang, Xingwei","Islam, MD. Sajjatul and Sang, Yongsheng and Mohammed, Adam A.Q. and Yuan, Lei and Lv, Jiancheng","Baroni, Giulia L. and Rasotto, Laura and Roitero, Kevin and Siraj, Ameer Hamza and Della Mea, V.","Park, Jaewoo and Park, Hojin and Jeong, Eunju and Teoh, Andrew Beng Jin","Nirbhav and Malik, Anand and Maheshwar and Prasad, Mukesh","NaN","Li, Huan and Wang, Yue","Zou, Yizhang and Hu, Xuegang and Li, Peipei","Kolipaka, Venkata Rama Rao and Namburu, Anupama","Lalor, John P. and Abbasi, Ahmed and Oketch, Kezia and Yang, Yi and Forsgren, Nicole","Nasayreh, Ahmad and Al Mamlook, Rabia Emhamed and Samara, Ghassan and Gharaibeh, Hasan and Aljaidi, Mohammad and Alzu'Bi, Dalia and Al-Daoud, Essam and Abualigah, Laith","Zhao, Wei and Zhao, Hong","Ravikiran, H. K. and Jayanth, J. and Sathisha, M. S. and Bindu, K.","Jiang, Minghua and Liu, Shuqing and Shi, Yankang and Du, Chenghu and Tang, Guangyu and Liu, Li and Peng, Tao and Hu, Xinrong and Yu, Feng","Sudha, S. Baby and Dhanalakshmi, S.","Prasad, Amit and Garg, Rahul and Sabharwal, Yogish","Ma, Shihan and Yang, Jidong J. and Chorzepa, Mi Geum and Morris, Clint and Kim, S. Sonny and Durham, Stephan A.","NaN","NaN","NaN","Din, Nusrat Mohi Ud and Assad, Assif and Dar, Rayees Ahmad and Rasool, Muzafar and Sabha, Saqib Ul and Majeed, Tabasum and Islam, Zahir Ul and Gulzar, Wahid and Yaseen, Aamir","Lo, Lun-Jou and Yang, Chao-Tung and Chiang, Wen-Chung and Lin, Hsiu-Hsia","NaN","Ning, Chunxiao and Xie, Yazhou","Mukherjee, Salankara and Ghosh, Ishita De","Babu, K. N. Surendra and Kodabagi, Mallikarjun M.","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","Jia, Pengfei and Li, Xiaoyu and Xu, Min and Zhang, Lin","NaN","Burada, Sreedhar and Eraiah, Manjunathswamy Byranahalli and Kumar, M. Sunil","Alyami, Sarah and Luqman, Hamzah and Hammoudeh, Mohammad","Xu, Fan and Zheng, Qihang and Shi, Jia and Yan, Keyu and Wang, Mingwen","Liu, Fan and Yang, Sai and Chen, Delong and Huang, Huaxi and Zhou, Jun","Subudhi, Subhashree and Patro, Ramnarayan and Biswal, Pradyut Kumar and Bhuyan, Kanhu Charan","NaN","Kamakshi, Vidhya and C Krishnan, Narayanan","Dai, Jianhua and Huang, Weiyi and Zhang, Chucai and Liu, Jie","Xu, Xia and Wang, Wenjie and Yuan, Zengbei and Li, Xinlin and Wu, Tao and Yao, Xufeng","Behzadidoost, Rashid and Mahan, Farnaz and Izadkhah, Habib","Ramkissoon, Amit Neil and Manohar, Kris and Goodridge, Wayne","Percannella, Gennaro and Petruzzello, Umberto and Tortorella, Francesco and Vento, Mario","NaN","Bao, Wenzheng and Yang, Bin","Gallo, Giovanni and Atani, Yaser Gholizade and Leotta, Roberto and Stanco, Filippo and Buscemi, Francesca and Figuera, Marianna"],"cluster":[1,2,2,2,1,2,2,0,1,2,2,2,2,2,1,2,1,2,2,2,2,1,0,2,1,2,2,2,2,0,1,2,2,2,2,1,2,0,1,2,1,2,2,1,1,2,2,2,2,2,2,2,2,1,1,2,2,1,1,1,2,2,2],"labels":["C-1","C-2","C-2","C-2","C-1","C-2","C-2","C-0","C-1","C-2","C-2","C-2","C-2","C-2","C-1","C-2","C-1","C-2","C-2","C-2","C-2","C-1","C-0","C-2","C-1","C-2","C-2","C-2","C-2","C-0","C-1","C-2","C-2","C-2","C-2","C-1","C-2","C-0","C-1","C-2","C-1","C-2","C-2","C-1","C-1","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-2","C-1","C-1","C-2","C-2","C-1","C-1","C-1","C-2","C-2","C-2"],"publication_date":["2024-01-20","2024-01-09","2024-01-01","2024-01-15","2024-01-01","2024-01-21","2024-01-03","2024-01-22","2024-01-01","2024-01-17","2024-01-30","2024-01-10","2024-01-12","2024-01-20","2024-01-01","2024-01-08","2024-01-01","2024-01-01","2024-01-04","2024-01-01","2024-01-10","2024-01-21","2024-01-01","2024-01-01","2024-01-20","2024-01-22","2024-01-01","2024-01-15","2024-01-23","2024-01-15","2024-01-01","2024-01-20","2024-01-20","2024-01-16","2024-01-04","2024-01-22","2024-01-01","2024-01-11","2024-01-21","2024-01-01","2024-01-01","2024-01-03","2024-01-08","2024-01-01","2024-01-05","2024-01-11","2024-01-22","2024-01-01","2024-01-18","2024-01-15","2024-01-05","2024-01-01","2024-01-25","2024-01-20","2024-01-04","2024-01-01","2024-01-17","2024-01-01","2024-01-21","2024-01-21","2024-01-19","2024-01-22","2024-01-21"],"title":["Lung and Colon Cancer Classification of Histopathology Images Using Convolutional Neural Network","Credit Card Fraud Detection: Addressing Imbalanced Datasets with a Multi-phase Approach","Probability-based label enhancement for multi-dimensional classification","FOLD-SE: An Efficient Rule-Based Machine Learning Algorithm with Scalable Explainability","Joint long and short span self-attention network for multi-view classification","Leukocytes Classification Methods: Effectiveness and Robustness in a Real Application Scenario","Feature-Weighted Naive Bayesian Classifier for Wireless Network Intrusion Detection","Capitalizing the Predictive Potential of Machine Learning to Detect Various Fire Types Using NASA's MODIS Satellite Data for the Mediterranean Basin","Evaluation of uncertainty quantification methods in multi-label classification: A case study with automatic diagnosis of electrocardiogram","Garment Fabric Pattern Classification via ResNet-34","Performance Evaluation of Machine Learning for Recognizing Human Facial Emotions","Etemadi reliability-based multi-layer perceptrons for classification and forecasting","Soil Image Classification Using Transfer Learning Approach: MobileNetV2 with CNN","Use of a Surrogate Model for Symbolic Discretization of Temporal Data Sets Through eMODiTS and a Training Set with Varying-Sized Instances","Comparison of Convolutional Neural Networks Architectures for Mango Leaf Classification","Towards explainability for AI-based edge wireless signal automatic modulation classification","LSOIT: Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis","Semantic augmentation by mixing contents for semi-supervised learning","Electronic Tongue based Classification of Mineral Water Samples using Gramian Angular Field and Deep SAE","Multi-label borderline oversampling technique","Highly effective end-to-end single-to-multichannel feature fusion and ensemble classification to decode emotional secretes from small-scale spontaneous facial micro-expressions","Vision Transformers for Breast Cancer Histology Image Classification","Understanding open-set recognition by Jacobian norm and inter-class separation","Landslide Susceptibility Assessment along the Major Transport Corridor Using Decision Tree Model: A Case Study of Kullu-Rohtang Pass","Auto Machine Learning Based on Genetic Programming for Medical Image Classification","An Interpretability Case Study of Unknown Unknowns Taking Clothes Image Classification CNNs as an Example","Gradient-based multi-label feature selection considering three-way variable interaction","Hybrid Classification Model with Tuned Weights for Crop Yield Prediction","Should Fairness be a Metric or a Model? A Model-based Framework for Assessing Bias in Machine Learning Pipelines","Arabic Sentiment Analysis for ChatGPT Using Machine Learning Classification Algorithms: A Hyperparameter Optimization Technique","Hierarchical long-tailed classification based on multi-granularity knowledge transfer driven by multi-scale feature fusion","Optimizing Sheep Breed Classification with Bat Algorithm-Tuned CNN Hyperparameters","COCCI: Context-Driven Clothing Classification Network","Sentiment analysis using various machine learning algorithms for disaster related tweets classification","Union of Convex Separators (UCS)","Composite Deep Learning Architecture for Vehicle Classification Using Vision Transformers and Wheel Position Features","Unsupervised classification of the spectrogram zeros with an application to signal detection and denoising","Malware Classification Using Open Set Recognition and HTTP Protocol Requests","Classification of Turkish and Balkan House Architectures Using Transfer Learning and Deep Learning","RiceNet: A deep convolutional neural network approach for classification of rice varieties\u25aa","A quantitative method for the assessment of facial attractiveness based on transfer learning with fine-grained image classification","Classification of Brain Tumors: A Comparative Approach of Shallow and Deep Neural Networks","Convolutional variational autoencoder for ground motion classification and generation toward efficient seismic fragility assessment","Identification of Personality Traits from Handwritten Text Documents Using Multi-Label Classification Models","An Efficient Framework for Predicting Future Retail Sales Using Ensemble DNN-BiLSTM Technique","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","Classification techniques of electronic nose: a review","Distance-based one-class time-series classification approach using local cluster balance","Optimal hybrid classifier with fine-tuned hyper parameter and improved fuzzy C means segmentation: skin cancer detection","Isolated Arabic Sign Language Recognition Using a Transformer-based Model and Landmark Keypoints","Pre-training and ensembling based Alzheimer\u2019s disease detection","Few-shot classification guided by generalization error bound","Texture-based superpixel segmentation algorithm for classification of hyperspectral images","Analysis of Convolutional Neural Network Models for Classifying the Quality of Dried Chili Peppers (Capsicum Annuum L)","SCE: Shared Concept Extractor to Explain a CNN's Classification Dynamics","Multi-label feature selection by strongly relevant label gain and label mutual aid","Classification of Alzheimer??s Disease using combined features of fMRI Brain Network and clinical scales","Granular computing-based deep learning for text classification","Examining the Robustness of an Ensemble Learning Model for Credibility Based Fake News Detection","Combined Data Augmentation for HEp-2 Cells Image Classification","A Dynamic Difficulty Adjustment Algorithm With Generic Player Behavior Classification Unity Plugin In Single Player Games","Protein acetylation sites with complex-valued polynomial model","Feature Relevance in Classification of 3D Stone from Ancient Wall Structures"],"x":{"__ndarray__":"6N1YUBi0IsCPw2D+CtNDwBu62R8oEUFAjnVxGw2ISUBY5ULlX0s0wLAgzVg0UUlAm49rQ8VQOMDFjsahfq80QLPNjekJm0jAtJQsJ6GUPsAzUBn/PixTQGiSWFLuzihA7DNnfcoXQsC+TBQhdSMjQFCOAkTBCDfAUnx8QnaqRMBMa9PYXhc7QIsXC0PkdCTAs5jYfFyVTsAwLlVpiyslwJUsJ6H0qU9A+s+aH381N8A/MOzVbIriP2iXb31YgUlAJ71vfO0tSsBCs+veiiQWwG1thsA2jxhARPtYwW8dQEAIjsu4qUE8QPgaguMyXEBAbO7of7nmOkBrKSDtf+AJwPtXVpqUSjbAMxe4PNYkK0CsAUpDjU5EwN6rVib8bjnAyCWOPBCnREDwUuqScdwWQAQdrWpJjyxA4p6dwgD4BEB07+GS46RRQPROqiKBWxJAwYu+gjR5TsDiV6zhIuchwIKQLGACjUrAylLr/UbXTsBmFqHYCiY4wEmCcAUU+jhA8M6Q4Px8BcDm0lM/ygMKwLpMTYI37DLAkuhlFMtlOUCJB5RNuQhQQA9gkV8/uELAqRPQRNj4Q8DUd0Sm+E/NP5NWfEPhUyjAZAYq498PUsDN5JttbspQwDFBDd/CoFLAFK5H4XoAOsBan3JMFgckwEqYaftXZFJA","dtype":"float64","shape":[63]},"x_backup":{"__ndarray__":"6N1YUBi0IsCPw2D+CtNDwBu62R8oEUFAjnVxGw2ISUBY5ULlX0s0wLAgzVg0UUlAm49rQ8VQOMDFjsahfq80QLPNjekJm0jAtJQsJ6GUPsAzUBn/PixTQGiSWFLuzihA7DNnfcoXQsC+TBQhdSMjQFCOAkTBCDfAUnx8QnaqRMBMa9PYXhc7QIsXC0PkdCTAs5jYfFyVTsAwLlVpiyslwJUsJ6H0qU9A+s+aH381N8A/MOzVbIriP2iXb31YgUlAJ71vfO0tSsBCs+veiiQWwG1thsA2jxhARPtYwW8dQEAIjsu4qUE8QPgaguMyXEBAbO7of7nmOkBrKSDtf+AJwPtXVpqUSjbAMxe4PNYkK0CsAUpDjU5EwN6rVib8bjnAyCWOPBCnREDwUuqScdwWQAQdrWpJjyxA4p6dwgD4BEB07+GS46RRQPROqiKBWxJAwYu+gjR5TsDiV6zhIuchwIKQLGACjUrAylLr/UbXTsBmFqHYCiY4wEmCcAUU+jhA8M6Q4Px8BcDm0lM/ygMKwLpMTYI37DLAkuhlFMtlOUCJB5RNuQhQQA9gkV8/uELAqRPQRNj4Q8DUd0Sm+E/NP5NWfEPhUyjAZAYq498PUsDN5JttbspQwDFBDd/CoFLAFK5H4XoAOsBan3JMFgckwEqYaftXZFJA","dtype":"float64","shape":[63]},"y":{"__ndarray__":"JO1GH/P9UcC8BKc+kGRPwFdAoZ4+4v8/8zy4O2vPJ8CkcD0K10suQKGhf4KLtSlAK97IPPKnSMBqwYu+ghZEwFCJ6xhXRCHAhU+EHnuXHsDVl6WdmkswwC7nUlxVrkBAbe0zHfDPEkAuAI3Spe8twKrlGNpKWf0/MbYQ5KCEQsBLH7qgvgkzwO2ZJQFqBFBAStBf6BGTOcBklGdeDjsWQG+ERUWc8jPA0GOUZ15eO0AziuWWVkswQIf+CS5WiEZAArfu5qnGJkAxQQ3fwvI1QLCMDd3s70lA2T9PAwYxQECs4/ih0hxOQO8gdqbQUTzAlialoNvfKcBQ4978hnNBQHxhMlUw0jDAnb0z2qo4M0DEXihgO6ZQQI/DYP4K90BAMgIqHEEWS8Cp+L8jKmwpQHP/R1y2TPY/N1DgnXycSMCFzJVBtYE1wImxTL9EiDzAPbZlwFmaR8D2tMNfkzlCwByWBn5Uu0NAiSMPRBaBKECpF3yak9s+wNDVVuwvI1DAJlMFo5KgUcAPRYE+kV8mwIyEtpxLORrAYajDCrcMLEB7wac5ebE1QFvTvOMUvTPAVKnZA624NED267GhWWHVP8OedvhrgiLAJlRweEHEL0CuZTIcz71EQBX/d0SFEiPA0uP3Nv1JSUD+1eO+1TI1wCE+sOO/oD7A","dtype":"float64","shape":[63]},"y_backup":{"__ndarray__":"JO1GH/P9UcC8BKc+kGRPwFdAoZ4+4v8/8zy4O2vPJ8CkcD0K10suQKGhf4KLtSlAK97IPPKnSMBqwYu+ghZEwFCJ6xhXRCHAhU+EHnuXHsDVl6WdmkswwC7nUlxVrkBAbe0zHfDPEkAuAI3Spe8twKrlGNpKWf0/MbYQ5KCEQsBLH7qgvgkzwO2ZJQFqBFBAStBf6BGTOcBklGdeDjsWQG+ERUWc8jPA0GOUZ15eO0AziuWWVkswQIf+CS5WiEZAArfu5qnGJkAxQQ3fwvI1QLCMDd3s70lA2T9PAwYxQECs4/ih0hxOQO8gdqbQUTzAlialoNvfKcBQ4978hnNBQHxhMlUw0jDAnb0z2qo4M0DEXihgO6ZQQI/DYP4K90BAMgIqHEEWS8Cp+L8jKmwpQHP/R1y2TPY/N1DgnXycSMCFzJVBtYE1wImxTL9EiDzAPbZlwFmaR8D2tMNfkzlCwByWBn5Uu0NAiSMPRBaBKECpF3yak9s+wNDVVuwvI1DAJlMFo5KgUcAPRYE+kV8mwIyEtpxLORrAYajDCrcMLEB7wac5ebE1QFvTvOMUvTPAVKnZA624NED267GhWWHVP8OedvhrgiLAJlRweEHEL0CuZTIcz71EQBX/d0SFEiPA0uP3Nv1JSUD+1eO+1TI1wCE+sOO/oD7A","dtype":"float64","shape":[63]}},"selected":{"id":"1071","type":"Selection"},"selection_policy":{"id":"1072","type":"UnionRenderers"}},"id":"1011","type":"ColumnDataSource"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"color":"#2e484c","font-family":"Julius Sans One, sans-serif;"},"text":"&lt;h1&gt;Clustering Literature on Supervised Learning by Classification (Last Month)&lt;/h1&gt;"},"id":"1076","type":"Div"},{"attributes":{"children":[{"id":"1003","type":"Div"},{"id":"1004","type":"Div"},{"id":"1005","type":"Div"}]},"id":"1081","type":"Row"},{"attributes":{"data_source":{"id":"1011","type":"ColumnDataSource"},"glyph":{"id":"1050","type":"Scatter"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1051","type":"Scatter"},"selection_glyph":null,"view":{"id":"1053","type":"CDSView"}},"id":"1052","type":"GlyphRenderer"},{"attributes":{"callback":null},"id":"1019","type":"DataRange1d"},{"attributes":{},"id":"1038","type":"ResetTool"},{"attributes":{"below":[{"id":"1025","type":"LinearAxis"}],"center":[{"id":"1029","type":"Grid"},{"id":"1034","type":"Grid"},{"id":"1060","type":"Legend"}],"left":[{"id":"1030","type":"LinearAxis"}],"margin":[5,5,5,5],"plot_height":500,"plot_width":500,"renderers":[{"id":"1052","type":"GlyphRenderer"}],"sizing_mode":"scale_both","title":{"id":"1015","type":"Title"},"toolbar":{"id":"1041","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1017","type":"DataRange1d"},"x_scale":{"id":"1021","type":"LinearScale"},"y_range":{"id":"1019","type":"DataRange1d"},"y_scale":{"id":"1023","type":"LinearScale"}},"id":"1014","subtype":"Figure","type":"Plot"},{"attributes":{"formatter":{"id":"1056","type":"BasicTickFormatter"},"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1030","type":"LinearAxis"},{"attributes":{},"id":"1021","type":"LinearScale"},{"attributes":{"children":[{"id":"1078","type":"Row"},{"id":"1079","type":"Row"},{"id":"1080","type":"Row"},{"id":"1081","type":"Row"},{"id":"1082","type":"Row"},{"id":"1083","type":"Row"},{"id":"1084","type":"Row"},{"id":"1085","type":"Row"},{"id":"1086","type":"Row"}]},"id":"1087","type":"Column"},{"attributes":{"children":[{"id":"1064","type":"Div"}]},"id":"1086","type":"Row"},{"attributes":{},"id":"1035","type":"PanTool"},{"attributes":{"callback":null,"point_policy":"follow_mouse","tooltips":[["Title","@title"],["Author","@author"],["Abstract","@abstract{safe}"],["Publication Date","@publication_date"],["Cluster","@cluster"]]},"id":"1012","type":"HoverTool"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1059","type":"BoxAnnotation"},{"attributes":{"children":[{"id":"1074","type":"Slider"},{"id":"1075","type":"TextInput"}]},"id":"1083","type":"Row"},{"attributes":{"text":"&lt;a href=\"clusters_last_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Year&lt;/button&gt;&lt;/a&gt;"},"id":"1005","type":"Div"},{"attributes":{},"id":"1056","type":"BasicTickFormatter"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by the Clusters:&lt;/h3&gt;&lt;p1&gt;The slider below can be used to filter the target cluster. \nSimply slide the slider to the desired cluster number to display the plots that belong to that cluster. \nSlide back to the last cluster to show all the plots.&lt;/p1&gt;"},"id":"1008","type":"Div"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Time Range:&lt;/h3&gt;&lt;p1&gt;Click on the button to change the time range of the plot.&lt;/p1&gt;"},"id":"1002","type":"Div"},{"attributes":{"args":{"out_text":{"id":"1062","type":"Paragraph"},"p":{"id":"1014","subtype":"Figure","type":"Plot"},"slider":{"id":"1074","type":"Slider"},"source":{"id":"1011","type":"ColumnDataSource"},"text":{"id":"1075","type":"TextInput"},"topics":["","multi, different, attention, images, cnn, transfer, aims, best","multi, proposed, detection, novel, image, time, recognition"]},"code":"\n\t\t\t\tvar key = text.value;\n\t\t\t\tkey = key.toLowerCase();\n\t\t\t\tvar cluster = slider.value;\n                var clusters_count = slider.end;\n                var data = source.data; \n                \n                \n                x = data['x'];\n                y = data['y'];\n                x_backup = data['x_backup'];\n                y_backup = data['y_backup'];\n                labels = data['cluster'];\n                abstract = data['abstract'];\n                title = data['title'];\n                author = data['author'];\n                if (cluster == clusters_count) {\n                    out_text.text = 'Keywords: Slide to specific cluster to see the keywords.';\n                    for (i = 0; i &lt; x.length; i++) {\n\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key) || \n                        (title[i] &amp;&amp; title[i].toLowerCase().includes(key)) ||\n                        (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t}\n                    }\n                }\n                else {\n                    out_text.text = 'Keywords: ' + topics[Number(cluster)];\n                    for (i = 0; i &lt; x.length; i++) {\n                        if(labels[i] == cluster) {\n\t\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key)\n                            || (title[i] &amp;&amp; title[i].toLowerCase().includes(key))\n                            || (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t\t}\n                        } else {\n                            x[i] = undefined;\n                            y[i] = undefined;\n                        }\n                    }\n                }\n            source.change.emit();\n            "},"id":"1063","type":"CustomJS"},{"attributes":{"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1029","type":"Grid"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1012","type":"HoverTool"},{"id":"1035","type":"PanTool"},{"id":"1036","type":"WheelZoomTool"},{"id":"1037","type":"BoxZoomTool"},{"id":"1038","type":"ResetTool"},{"id":"1039","type":"SaveTool"},{"id":"1040","type":"TapTool"}]},"id":"1041","type":"Toolbar"},{"attributes":{"children":[{"id":"1008","type":"Div"},{"id":"1007","type":"Div"}]},"id":"1082","type":"Row"},{"attributes":{},"id":"1071","type":"Selection"},{"attributes":{"text":"&lt;a href=\"clusters_last_month.html\" target=\"_blank\"&gt;&lt;button&gt;Last Month&lt;/button&gt;&lt;/a&gt;"},"id":"1003","type":"Div"},{"attributes":{"callback":null},"id":"1017","type":"DataRange1d"},{"attributes":{"label":{"field":"labels"},"renderers":[{"id":"1052","type":"GlyphRenderer"}]},"id":"1061","type":"LegendItem"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.4.0"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('1176').textContent;
                  var render_items = [{"docid":"728e6fda-3ebb-43ba-b76a-3008e5d01b11","roots":{"1087":"c07cd757-6e83-4b03-8f4e-6c217e03303b"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>