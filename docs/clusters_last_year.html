



<!DOCTYPE html>
<html lang="en">
  
  <head>
    
      <meta charset="utf-8">
      <title>Clustering papers on Supervised Learning by Classification</title>
      
      
        
          
        
        
          
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js"></script>
        <script type="text/javascript" src="https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js"></script>
        <script type="text/javascript">
            Bokeh.set_log_level("info");
        </script>
        
      
      
    
  </head>
  
  
  <body>
    
      
        
          
          
            
              <div class="bk-root" id="7cb350b3-8823-4263-b4fe-120cd6f673ab" data-root-id="1087"></div>
            
          
        
      
      
        <script type="application/json" id="1176">
          {"9decfde2-eee6-4faf-bc14-12f7d453bf22":{"roots":{"references":[{"attributes":{"text":"&lt;a href=\"clusters_last_month.html\" target=\"_blank\"&gt;&lt;button&gt;Last Month&lt;/button&gt;&lt;/a&gt;"},"id":"1003","type":"Div"},{"attributes":{"height":75,"margin":[20,20,20,20],"sizing_mode":"stretch_width","style":{"color":"#0269A4","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Keywords: Slide to specific cluster to see the keywords."},"id":"1062","type":"Paragraph"},{"attributes":{"callback":null},"id":"1017","type":"DataRange1d"},{"attributes":{},"id":"1056","type":"BasicTickFormatter"},{"attributes":{"children":[{"id":"1006","type":"Div"}]},"id":"1079","type":"Row"},{"attributes":{"dimension":1,"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1034","type":"Grid"},{"attributes":{"children":[{"id":"1014","subtype":"Figure","type":"Plot"}]},"id":"1085","type":"Row"},{"attributes":{"children":[{"id":"1062","type":"Paragraph"}]},"id":"1084","type":"Row"},{"attributes":{"fill_alpha":{"value":0.1},"fill_color":{"value":"#1f77b4"},"line_alpha":{"value":0.1},"line_color":{"value":"#1f77b4"},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1051","type":"Scatter"},{"attributes":{"formatter":{"id":"1056","type":"BasicTickFormatter"},"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1025","type":"LinearAxis"},{"attributes":{"callback":null,"data":{"abstract":["The use of functional magnetic resonance imaging (fMRI) data in machine learning (ML)-based classification of autism spectrum disorder (ASD) has been a topic of increasing research interest in past years due to the noninvasiveness of the fMRI technique and its potential for providing valuable biomarkers. However, there are still controversies surrounding some fMRI data preprocessing steps, such as bandpass filtering and global signal regression (GSR). It still needs to be determined whether or how these preprocessing steps impact the classification accuracy of ML algorithms. This paper uses fMRI signals from the ABIDE-I dataset to train a long short-term memory (LSTM) network to classify subjects into ASD or healthy controls (HC). We considered 18 preprocessing pipelines comprising all combinations of with and without filtering, with and without global signal regression, and three different segment lengths of 1 min, 2 min, and 3 min. The best model was obtained when using a segment length of 2 min. Our results suggest that not filtering produces significantly higher classification accuracies than filtering, whereas there were no significant differences in classification accuracies when removing or not the global signal.","Twitter Sentiment Analysis is the way of identifying sentiments and opinions in tweets. The main computational steps in this process are determining the polarity or sentiment of the tweet and then categorizing them into the positive tweet or negative tweet. The primary issue with Twitter sentiment analysis is the identification of the most suitable sentiment classifier that can correctly classify the tweets. Generally, base classification technique like Naive Bayes classifier, Random Forest classifier, SVMs and Logistic Regression are being used. In this paper, an ensemble classifier has been proposed that combines the base learning classifier to form a single classifier, with an aim of improving the performance and accuracy of sentiment classification technique. The results show that the proposed ensemble classifier performs better than stand-alone classifiers and majority voting ensemble classifier. In addition, the role of data pre-processing and feature representation in sentiment classification technique is also explored as part of this work.","Highlights\n\u2022\nIntroduction of a novel model that integrates OBIA and the attention mechanism for precise orchard mapping.\n\u2022\nThe contribution of SAR is studied in orchard classification.\n\u2022\nThe model obtains more accurate classification results than RNN-based and CNN-based deep learning models.\n\u2022\nThe uncertainty of the super-pixel size on classification accuracy is investigated.\nAbstract\nReliable and accurate classification of orchards is important for the dynamic monitoring of large-scale orchards and food security evaluation. At present, the very similar spectral profiles of different fruit trees and the high susceptibility of optical data to interference by weather conditions limit the resolution of orchard classification. Synthetic Aperture Radar (SAR) imagery provides an advanced solution to this problem, with the advantages of being immune to weather conditions and advances in deep learning techniques. This paper presents an orchard classification model (STCM) with optical and SAR fusion, which integrates the advantages of the Simple Non-Iterative Clustering (SNIC) super-pixel algorithm with a deep learning algorithm based on a multi-headed attention mechanism, and it achieves the best classification accuracy of above 0.82 in comparison with existing deep learning models. Meanwhile, the model has exceptional classification accuracy and robustness in a study area with fragmented plots, many fruit tree species, and various distributions of optical images. In the absence of optical data, the classification accuracy of the STCM model using only SAR data is around 0.70, which makes the model have a promising potential application value. This study provides a technical solution for accurately obtaining different orchard categories in high-resolution remotely sensed orchard images. The study helps to improve the management and operation of orchards and provides a strong basis for decision-making in the fruit industry to enhance the sustainability of the global fruit industry.","Credit card fraud detection plays a crucial role in safeguarding the financial security of individuals and organizations. However, imbalanced datasets pose significant challenges to accurately identifying fraudulent transactions. In this research paper, we propose a novel approach that combines autoencoder (AE) and fully connected deep networks (FCDN) models to address this issue. The process involves three phases: training an AE on fraudulent transactions, utilizing another AE for dimensionality reduction, and using the encoded representations as input for FCDN classification. To further enhance the model\u2019s performance, we introduce an additional FCDN trained on the preprocessed data using the synthetic minority oversampling technique (SMOTE). The predictions from both AE, AE\u2013FCDN, and the FCDN are combined using a majority voting approach. We evaluate the proposed method using standard performance metrics, including accuracy, precision, recall, and F1-score. Our experimental results demonstrate the effectiveness and robustness of the integrated model architecture in accurately detecting credit card fraud. These findings provide valuable insights for improving financial security measures and mitigating potential losses associated with credit card fraud.","Wafer Bin Map (WBM) defect patterns are a critical aspect of identifying the root cause of manufacturing defects in the semiconductor industry. Semi-supervised learning (SSL) approaches have gained popularity for this purpose, as they can leverage both labeled and unlabeled data to improve model performance. However, SSL of WBM defect patterns is challenging due to class imbalance, where some defect classes have many more examples than others. Most of the existing SSL approaches assume a balanced dataset and often fail to provide satisfactory results when applied to imbalanced class problems. To address this issue, this work proposes a novel Dual-Head Convolutional Neural Network (CNN) architecture that contains two classifier heads. One classifier head maximizes overall classification scores, while the other aims to maximize per-class classification scores, providing equal attention to both majority and minority classes. The proposed CNN architecture uses pseudo-labels selected based on the outputs of these two classifiers to expand the labeled training set, which is then used to retrain the CNN. In this way, highly confident pseudo-labels are selected even from the minority classes, leading to better model training. Experiments show that the proposed approach is effective in handling class-imbalanced classification of WBM defect patterns, reporting state-of-the-art classification with an F1 score of 0.918, accuracy of 98.2% and a mean per-class accuracy of 91.7% using a lightweight ResNet-10 model as the backbone on the real-world public WBM dataset, WM-811K. The proposed approach\u2019s success suggests that it could be a valuable tool for improving the accuracy and reliability of WBM defect pattern classification in semiconductor manufacturing. The code is available at https://github.com/M-Siyamalan/SSL-DHCNN.\nHighlights\n\u2022\nNovel semi-supervised approach is proposed for wafer bin map defect classification.\n\u2022\nThe approach effectively handles imbalanced class semi-supervised classification.\n\u2022\nExperimental results show that the proposed approach outperforms other approaches.","Class-incremental continual learning is an important area of research, as static deep learning methods fail to adapt to changing tasks and data distributions. In previous works, promising results were achieved using replay and compressed replay techniques. In the field of regular replay, GDumb [23] achieved outstanding results but requires a large amount of memory. This problem can be addressed by compressed replay techniques. The goal of this work is to evaluate compressed replay in the pipeline of GDumb. We propose FETCH, a two-stage compression approach. First, the samples from the continual datastream are encoded by the early layers of a pre-trained neural network. Second, the samples are compressed before being stored in the episodic memory. Following GDumb, the remaining classification head is trained from scratch using only the decompressed samples from the reply memory. We evaluate FETCH in different scenarios and show that this approach can increase accuracy on CIFAR10 and CIFAR100. In our experiments, simple compression methods (e.g., quantization of tensors) outperform deep autoencoders. In the future, FETCH could serve as a baseline for benchmarking compressed replay learning in constrained memory scenarios.","Aspect-based sentiment analysis (ABSA) aims to analyze the sentiment polarity of a given text towards several specific aspects. For implementing the ABSA, one way is to convert the original problem into a sentence semantic matching task, using pre-trained language models, such as BERT. However, for such a task, the intra- and inter-semantic relations among input sentence pairs are often not considered. Specifically, the semantic information and guidance of relations revealed in the labels, such as positive, negative and neutral, have not been completely exploited. To address this issue, we introduce a self-supervised sentence pair relation classification task and propose a model named Multi-level Semantic Relation-enhanced Learning Network (MSRL-Net) for ABSA. In MSRL-Net, after recasting the original ABSA task as a sentence semantic matching task, word dependency relations and word-sentence relations are utilized to enhance the word-level semantic representation for the sentence semantic matching task, while sentence semantic relations and sentence pairs relations are utilized to enhance the sentence-level semantic representation for sentence pair relation classification. Empirical experiments on SemEval 2014 Task 4, SemEval 2016 Task 5 and SentiHood show that MSRL-Net significantly outperforms other baselines such as BERT in terms of accuracy, Macro-F1 and AUC.\nHighlights\n\u2022\nA Multi-level Semantic Relation-enhanced Learning Network model is proposed.\n\u2022\nA new self-supervised relation classification task is introduced.\n\u2022\nFour types of relations at different levels are selectively leveraged.\n\u2022\nThe experiments on three public datasets demonstrate the effectiveness of our model.","Social media's explosive growth brings with it a variety of societal risks ranging from severely harmful issues such as dangerous organizations and child sexual exploitation to moderately harmful content like displays of aggression, borderline nudity to benign or distasteful contents like gross videos and baity content. In recent times, the multitude and magnitude of these harms is being further exacerbated with the advent of generative AI [5]. Meta is committed to ensuring that Facebook is a place where people feel empowered to communicate and we take our role seriously in keeping abuse off the platform [7]. In this talk, I will describe practical challenges and lessons learned from tackling bad experiences for users on Facebook, particularly in the subjective, borderline and low quality spectrum of harms using state of the art, scalable machine learning approaches to content understanding, user behavior understanding and personalized ranking.","Highlights\n\u2022\nAn estimate of the Bayes cost is proposed as the loss to train neural networks for ordinal classification of imbalanced data.\n\u2022\nThe network parameters, as well as the decision thresholds, are updated during training to minimize the Bayes cost.\n\u2022\nThe neural network architecture has a single neuron in the output layer (one-dimensional input space).\n\u2022\nBoth shallow networks and deep networks can be used.\n\u2022\nExperiments with real data show the accuracy and flexibility of the proposed method, specially in imbalanced problems.\nAbstract\nOrdinal classification of imbalanced data is a challenging problem that appears in many real world applications. The challenge is to simultaneously consider the order of the classes and the class imbalance, which can notably improve the performance metrics. The Bayesian formulation allows to deal with these two characteristics jointly: It takes into account the prior probability of each class and the decision costs, which can be used to include the imbalance and the ordinal information, respectively. We propose to use the Bayesian formulation to train neural networks, which have shown excellent results in many classification tasks. A loss function is proposed to train networks with a single neuron in the output layer and a threshold based decision rule. The loss is an estimate of the Bayesian classification cost, based on the Parzen windows estimator, which is fitted for a thresholded decision. Experiments with several real datasets show that the proposed method provides competitive results in different scenarios, due to its high flexibility to specify the relative importance of the errors in the classification of patterns of different classes, considering the order and independently of the probability of each class.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201dco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","Addressing fairness in lesion classification from dermatological images is crucial due to variations in how skin diseases manifest across skin tones. However, the absence of skin tone labels in public datasets hinders building a fair classifier. To date, such skin tone labels have been estimated prior to fairness analysis in independent studies using the Individual Typology Angle (ITA). Briefly, ITA calculates an angle based on pixels extracted from skin images taking into account the lightness and yellow-blue tints. These angles are then categorised into skin tones that are subsequently used to analyse fairness in skin cancer classification. In this work, we review and compare four ITA-based approaches of skin tone classification on the ISIC18 dataset, a common benchmark for assessing skin cancer classification fairness in the literature. Our analyses reveal a high disagreement among previously published studies demonstrating the risks of ITA-based skin tone estimation methods. Moreover, we investigate the causes of such large discrepancy among these approaches and find that the lack of diversity in the ISIC18 dataset limits its use as a testbed for fairness analysis. Finally, we recommend further research on robust ITA estimation and diverse dataset acquisition with skin tone annotation to facilitate conclusive fairness assessments of artificial intelligence tools in dermatology. Our code is available at https://github.com/tkalbl/RevisitingSkinToneFairness.","Recognizing threats in baggage X-ray scans is one of the most crucial tasks for ensuring safety in high-risk areas, including airports, shopping malls, and cargoes, radiograph. Due to the rise in terrorist activity, particularly in the previous two decades, the identification of baggage threats has received the most attention. Nevertheless, this process is time-consuming and restricted by the security officer\u2019s inspection capabilities. To overcome this, several frameworks based on deep learning have been suggested to effectively detect contraband items. However, these approaches primarily suffer from the issue of class imbalance, where prohibited objects are rarely seen in the real world compared to harmless baggage content. This paper proposes a novel classification network optimized with the novel compound balanced affinity loss function to address the class imbalance. This proposed loss function is based on the synergic integration of max-margin learning and the effective sample representation. The suggested method is tested on two datasets, COMPASS-XP and SIXray, where it outperforms the state-of-the-art in terms of F1-score by 2.55% and 2.52%, respectively. Also, the proposed approach has surpassed the existing frameworks by attaining accuracy of 89.16% and 70.31%, respectively. To the best of our knowledge, this is the first contour-driven classification framework injected with a compound loss function for highly imbalanced threat classification.","Deep learning models have become increasingly prevalent in various domains, necessitating their deployment on resource-constrained devices. Quantization is a promising way to reduce the model complexity in that it keeps model architecture intact and enables the model to operate on specialized hardwares(e.g., NPU, DSP). Input resolution is also essential in making a trade-off between accuracy and computation.\nIn this paper, we conduct a joint analysis of input resolution and quantization precision on their influence on accuracy for three popular models: ResNet-18, ResNet-50, and MobileNet-V2. By exploring the combined configuration space, we found that better accuracy can be achieved by jointly optimizing the input resolution and quantization bit-width while maintaining the computational complexity.","The twin support vector machines (TWSVM) is a milestone in multi-plane classification with state-of-the-art performance on many classification problems. However, on large scale datasets, the learning speed of TWSVM is expensive. In this paper, we propose a fast twin support vector machines (FTWSVM). In our FTWSVM, a pair of hyperplanes are computed directly from the training dataset without numerical iterations. Experiments on several benchmark datasets show that our method can exhibit good generalization performance and fast learning compared to the fast support vector classifier (FSVC), which specializes in big data problems, and TWSVM, which generalizes well speed.","Functional magnetic resonance imaging (fMRI) is a non-invasive technique measuring brain activity by detecting blood flow changes, enabling the study of cognitive processes and brain states. However, the high dimensionality of resting-state (rs) fMRI data poses challenges for machine learning applications. Feature extraction (FE) and feature selection (FS) are critical for developing efficient machine learning models. Transforming raw data into meaningful features and selecting the most relevant ones, allows models to achieve improved generalization, accuracy, and robustness. Previous studies demonstrated the effectiveness of FE and FS methods for analyzing rs-fMRI data for Autism Spectrum Disorder (ASD) classification. In this study, we apply a random walks technique for correlation-based brain networks to extract features from rs-fMRI data, specifically the number of random walkers on each brain area. We then select significant features, i.e., brain areas with a statistically significant difference in the number of random walkers between neurotypical and ASD subjects. Our random walks-based FE and FS approach reduces the number of brain areas used in the classification and converts the functional connectivity matrix into a manageable vector, enabling faster computation. We examined 16 pipelines and tested support vector machines (SVM) and logistic regression for classification, identifying the optimal pipeline to consist of no filtering, no global signal regression (GSR), and FS, achieving a 76.54% classification accuracy with SVM. Our findings suggest that random walks capture a wide range of interactions and dynamics in brain networks, providing a deeper characterization of their structure and function, ultimately enhancing classification performance.","Despite its wide applications in criminal investigations and clinical communications with patients suffering from autism, automatic micro-expression recognition remains a challenging problem because of the lack of training data and imbalanced classes problems. In this study, we proposed a meta-learning-based multi-model fusion network (Meta-MMFNet) to solve the existing problems. The proposed method is based on the metric-based meta-learning pipeline, which is specifically designed for few-shot learning and is suitable for model-level fusion. The frame difference and optical flow features were fused, deep features were extracted from the fused feature, and finally in the meta-learning-based framework, weighted sum model fusion method was applied for micro-expression classification. Meta-MMFNet achieved better results than state-of-the-art methods on four datasets. The code is available at https://github.com/wenjgong/meta-fusion-based-method.","Enhancing the interpretability of AI techniques is paramount for increasing their acceptability, especially in highly interdisciplinary fields such as remote sensing, in which scientists and practitioners with diverse backgrounds work together to monitor the Earth\u2019s surface. In this context, counterfactual explanations are an emerging tool to characterize the behaviour of machine learning systems, by providing a post-hoc analysis of a given classification model. Focusing on the important task of land cover classification from remote sensing data, we propose a counterfactual explanation approach called CFE4SITS (CounterFactual Explanation for Satellite Image Time Series). One of its distinctive features over existing strategies is the lack of prior assumption on the targeted class for a given counterfactual explanation. This inherent flexibility allows for the automatic discovery of relationship between classes. To assess the quality of the proposed approach, we consider a real-world case study in which we aim to characterize the behavior of a ready-to-use land cover classifier. To this end, we compare CFE4SITS to recent time series counterfactual-based strategies and, subsequently, perform an in-depth analysis of its behaviour.","The issue of imbalanced data in machine learning has gained significant attention in recent years. Imbalanced data, where one class has significantly fewer samples than others, can lead to poor performance for machine learning models, especially in detecting minority class samples. To address this problem, various resampling techniques have been proposed, including the popular SMOTE (Synthetic Minority Over-sampling TEchnique). However, SMOTE suffers from the overlapping problem and may misclassify samples near the separation boundaries. This paper presents a novel framework to optimise border-based-SMOTEs, including Borderline-SMOTE and SVM-SMOTE which were specifically developed to solve the problem of misclassifying border samples. The proposed method ensures that generated samples improve the decision boundaries and are free from overlapping issues. The proposed method is evaluated on synthetic and real-world datasets, and results demonstrate its effectiveness in enhancing the performance of machine learning models, particularly in classifying minority class samples.","Kernel functions are a key element in many machine learning methods to capture the similarity between data points. However, a considerable number of these functions do not meet all mathematical requirements to be a valid positive semi-definite kernel, a crucial precondition for kernel-based classifiers such as Support Vector Machines or Kernel Fisher Discriminant classifiers. In this paper, we propose a novel strategy employing a polar decomposition to effectively transform invalid kernel matrices to positive semi-definite matrices, while preserving the topological structure inherent to the data points. Utilizing polar decomposition allows the effective transformation of indefinite kernel matrices from Krein space to positive semi-definite matrices in Hilbert space, thereby providing an efficient out-of-sample extension for new unseen data and enhancing kernel method applicability across diverse classification tasks. We evaluate our approach on a variety of benchmark datasets and demonstrate its superiority over competitive methods.","Feature selections facilitate classification learning in various data environments. Aiming at interval-valued decision systems (IVDSs), feature selections rely on information measures and similarity degrees, whereas current selection algorithms on credibility-based condition entropy and classical similarity degree are accompanied with some measurement limitations and advancement space. In this paper based on IVDSs, three coverage-credibility-based condition entropies and one geometry-probabilistic similarity degree are proposed across two dimensions of informationization and granulation, and they improve the existing condition entropy and similarity degree; accordingly, 4 \u00d7 2 feature selections emerge for optimization and applicability, and they systematically contain one initial selection algorithm and seven new/robuster algorithms. At first, three-way granular measures (i.e., credibility, coverage, and integrated coverage-credibility) are formulated in IVDSs, and three novel condition entropies are established by implementing three information structures on coverage-credibility. These condition entropies acquire in-depth improvements, hierarchical algorithms, size relationships, maximum/minimum conditions, and granulation non-monotonicity. Then, the probabilistic similarity degree is defined by a six-piecewise function with quadratic factors, and this new measure gains the geometry-probability mechanism and high-quality improvement. Furthermore, feature selections are determined by preserving condition entropies and by mining feature significances, so eight selection algorithms are obtained by combining condition entropies and similarity degrees. Finally, data experiments are performed to validate relevant uncertainty measures and feature selections, and seven constructional selection algorithms outperform three contrastive algorithms to achieve better classification performances.\nHighlights\n\u2022\n3 improved CEs are constructed by 3 information structures on coverage-credibilities.\n\u2022\n3 improved CEs gain mechanisms, algorithms, properties, granulation non-monotonicity.\n\u2022\nNew PSD gives the probability semantics, function reinforcement, quality improvement.\n\u2022\nNon-monotonic FSs and heuristic algorithms are designed by preserving 3 CEs on 2 SDs.\n\u2022\n7 combined FS algorithms outperform 3 current algorithms from classification effects.","Partial label learning (PLL) is a typical weakly supervised learning problem in which each instance is associated with a candidate label set, and among which only one is true. However, the assumption that the ground-truth label is always among the candidate label set would be unrealistic, as the reliability of the candidate label sets in real-world applications cannot be guaranteed by annotators. Therefore, a generalized PLL named Unreliable Partial Label Learning (UPLL) is proposed, in which the true label may not be in the candidate label set. Due to the challenges posed by unreliable labeling, previous PLL methods will experience a marked decline in performance when applied to UPLL. To address the issue, we propose a two-stage framework named Unreliable Partial Label Learning with Recursive Separation (UPLLRS). In the first stage, the self-adaptive recursive separation strategy is proposed to separate the training set into a reliable subset and an unreliable subset. In the second stage, a disambiguation strategy is employed to progressively identify the ground-truth labels in the reliable subset. Simultaneously, semi-supervised learning methods are adopted to extract valuable information from the unreliable subset. Our method demonstrates state-of-the-art performance as evidenced by experimental results, particularly in situations of high unreliability. Code and supplementary materials are available at https://github.com/dhiyu/UPLLRS.","In this paper, we present a prototype selection technique for imbalanced data, Fuzzy Rough Imbalanced Prototype Selection (FRIPS), to improve the quality of the artificial instances generated by the Synthetic Minority Over-sampling TEchnique (SMOTE). Using fuzzy rough set theory, the noise level of each instance is measured, and instances for which the noise level exceeds a certain threshold level are deleted. The threshold is determined using a wrapper approach that evaluates the training Area Under the Curve of candidate subsets. This proposal aims to clean noisy data before applying SMOTE, such that SMOTE can generate high quality artificial data.\nExperiments on artificial data show that FRIPS in combination with SMOTE outperforms state-of-the-art methods, and that it particularly performs well in the presence of noise.","Machine learning research relies to a large extent on experimental observations. The evaluation of classifiers is often carried out by empirical comparison with classifiers generated by different learning algorithms, allowing the identification of the best algorithm for the problem at hand. Nevertheless, previously to this evaluation, it is important to state if the classifiers have truly learned the domain class concepts, which can be done by comparing the classifiers\u2019 predictive measures with the ones from the baseline classifiers. A baseline classifier is the one constructed by a na\u00efve learning algorithm which only uses the class distribution of the dataset. However, finding na\u00efve classifiers in multi-label learning is not as straightforward as in single-label learning. This work proposes a simple way to find baseline multi-label classifiers. Three specific and one general na\u00efve multi-label classifiers are proposed to estimate the baseline values for multi-label predictive evaluation measures. Experimental results show the suitability of our proposal in revealing the learning power of multi-label learning algorithms.","Skilled employees are the most important pillars of an organization. Despite this, most organizations face high attrition and turnover rates. While several machine learning models have been developed to analyze attrition and its causal factors, the interpretations of those models remain opaque. In this paper, we propose the HR-DSS approach, which stands for Human Resource (HR) Decision Support System, and uses explainable AI for employee attrition problems. The system is designed to assist HR departments in interpreting the predictions provided by machine learning models. In our experiments, we employ eight machine learning models to provide predictions. We further process the results achieved by the best-performing model by the SHAP explainability process and use the SHAP values to generate natural language explanations which can be valuable for HR. Furthermore, using \"What-if-analysis\", we aim to observe plausible causes for attrition of an individual employee. The results show that by adjusting the specific dominant features of each individual, employee attrition can turn into employee retention through informative business decisions.","When data is of an extraordinarily large size or physically stored in different locations, the distributed nearest neighbor (NN) classifier is an attractive tool for classification. We propose a novel distributed adaptive NN classifier for which the number of nearest neighbors is a tuning parameter stochastically chosen by a data-driven criterion. An early stopping rule is proposed when searching for the optimal tuning parameter, which not only speeds up the computation but also improves the finite sample performance of the proposed algorithm. Convergence rate of excess risk of the distributed adaptive NN classifier is investigated under various sub-sample size compositions. In particular, we show that when the sub-sample sizes are sufficiently large, the proposed classifier achieves the nearly optimal convergence rate. Effectiveness of the proposed approach is demonstrated through simulation studies as well as an empirical application to a real-world dataset.","The aggregation of multiple opinions plays a crucial role in decision-making, such as in hiring and loan review, and in labeling data for supervised learning. Although majority voting and existing opinion aggregation models are effective for simple tasks, they are inappropriate for tasks without objectively true labels in which disagreements may occur. In particular, when voter attributes such as gender or race introduce bias into opinions, the aggregation results may vary depending on the composition of voter attributes. A balanced group of voters is desirable for fair aggregation results but may be difficult to prepare. In this study, we consider methods to achieve fair opinion aggregation based on voter attributes and evaluate the fairness of the aggregated results.\nTo this end, we consider an approach that combines opinion aggregation models such as majority voting and the Dawid and Skene model (D&amp;S model) with fairness options such as sample weighting. To evaluate the fairness of opinion aggregation, probabilistic soft labels are preferred over discrete class labels. First, we address the problem of soft label estimation without considering voter attributes and identify some issues with the D&amp;S model. To address these limitations, we propose a new Soft D&amp;S model with improved accuracy in estimating soft labels. Moreover, we evaluated the fairness of an opinion aggregation model, including Soft D&amp;S, in combination with different fairness options using synthetic and semi-synthetic data. The experimental results suggest that the combination of Soft D&amp;S and data splitting as a fairness option is effective for dense data, whereas weighted majority voting is effective for sparse data. These findings should prove particularly valuable in supporting decision-making by human and machine-learning models with balanced opinion aggregation.","As an important branch of weakly supervised learning, partial label learning (PLL) tackles the problem where each training instance is associated with a set of candidate labels, among only one is correct. Most existing PLL algorithms elaborately designed loss functions and update strategies to learn potential ground-truth labels among candidate labels with deep neural networks. However, these algorithms are susceptible to the cumulative error caused by noisy label propagation when updating label confidences, this will make the deep models tend to overfit the noisy labels, thereby achieving poor generation performance. To remedy this issue, we propose a general framework multi-class partial hinge loss (MPHL) for PLL, which can disambiguate the candidate labels by optimizing the margin between the maximum modeling output from partial labels and that from non-partial ones. More importantly, the partial hinge loss can adaptively optimize the separation hyperplane to reduce the influence of cumulative error. Meanwhile, we introduce graph laplacian regularization to full mine the relationship between candidate labels of similar instances to constrain the separation hyperplane to improve the robustness of disambiguation. Extensive experimental results demonstrate that the multi-class partial hinge loss significantly outperforms the state-of-the-art counterparts.","In this work, we try to address the two challenging problems in machine learning (ML) which are: (a) the need for large amounts of labeled images for training supervised classifiers and (b) the supervised classification for time series data. We formulate the problem as an image classification task by transforming time series into domain-specific 2D features such as the scalogram and recurrence plot (RP). Such domain-specific features provide additional information to the models in contrast to raw time series data and enable us to take advantage of powerful state-of-the-art image classifiers for learning the patterns from these textured images. However, the requirement for large amounts of labeled image data is a major drawback in image classification. Thus, to address this problem, we propose to develop a multimodal fusion-deep reinforcement learning (MMF-DRL) approach as an alternative technique to traditional supervised image classifiers for the classification of time series. The two modalities scalograms and RP are fused together to make a multimodal dataset which is then fed into various models for comparison between supervised and RL approaches for time series classification. Our approach produces better accuracy than the state-of-the-art ChronoNet while needing fewer training examples. We validated our MMF-DRL approach using two different physiological time series datasets. Our results show the merit of using multiple modalities and RL in achieving better classification performance than training on a single modality. Moreover, with our approach, we got the highest accuracy of 90.20% and 89.63% respectively for the two datasets with less training data in contrast to the state-of-the-art SL model ChronoNet which gave 87.62% and 88.02% accuracy respectively for the two datasets with higher training data.","This study investigates the realm of machine learning for the classification of different fire types using NASA's FIRMS MODIS satellite data for the Mediterranean basin. Concentrating on the Mediterranean basin and utilizing data spanning from 2019 to 2021 for model training, XGBoost and Random Forest models were subsequently validated for the 2022 data. The findings distinctly illustrate XGBoost's superior predictive precision as compared to Random Forest by showcasing an impressive overall F1 score surpassing 95% and 84% macro F1 score across various fire types. This study emphasizes the prospect of machine learning to improve worldwide wildfire monitoring and response by providing exact, real-time fire type forecasts.","The feature selection problem is a significant challenge in pattern recognition, especially for classification tasks. The quality of the selected features plays a critical role in building effective models, and poor-quality data can make this process more difficult. This work explores the use of association analysis in data mining to select meaningful features, addressing the issue of duplicated information in the selected features. A novel feature selection technique for text classification is proposed, based on frequent and correlated items. This method considers both relevance and feature interactions, using association as a metric to evaluate the relationship between the target and features. The technique was tested using the SMS spam collecting dataset from the UCI machine learning repository and compared with well-known feature selection methods. The results showed that the proposed technique effectively reduced redundant information while achieving high accuracy (95.155%) using only 6% of the features.","Federated learning encounters a critical challenge of data heterogeneity, adversely affecting the performance and convergence of the federated model. Various approaches have been proposed to address this issue, yet their effectiveness is still limited. Recent studies have revealed that the federated model suffers severe forgetting in local training, leading to global forgetting and performance degradation. Although the analysis provides valuable insights, a comprehensive understanding of the vulnerable classes and their impact factors is yet to be established. In this paper, we aim to bridge this gap by systematically analyzing the forgetting degree of each class during local training across different communication rounds. Our observations are: (1) Both missing and non-dominant classes suffer similar severe forgetting during local training, while dominant classes show improvement in performance. (2) When dynamically reducing the sample size of a dominant class, catastrophic forgetting occurs abruptly when the proportion of its samples is below a certain threshold, indicating that the local model struggles to leverage a few samples of a specific class effectively to prevent forgetting. Motivated by these findings, we propose a novel and straightforward algorithm called Federated Knowledge Anchor (FedKA). Assuming that all clients have a single shared sample for each class, the knowledge anchor is constructed before each local training stage by extracting shared samples for missing classes and randomly selecting one sample per class for non-dominant classes. The knowledge anchor is then utilized to correct the gradient of each mini-batch towards the direction of preserving the knowledge of the missing and non-dominant classes. Extensive experimental results demonstrate that our proposed FedKA achieves fast and stable convergence, significantly improving accuracy on popular benchmarks.","Instance selection (IS) serves as a vital preprocessing step, particularly in addressing the complexities associated with high-dimensional problems. Its primary goal is the reduction of data instances, a process that involves eliminating irrelevant and superfluous data while maintaining a high level of classification accuracy. IS, as a strategic filtering mechanism, addresses these challenges by retaining essential instances and discarding hindering elements. This refinement process optimizes classification algorithms, enabling them to excel in handling extensive datasets. In this research, IS offers a promising avenue to strengthen the effectiveness of classification in various real-world applications.","This paper presents the design and implementation of FLIPS, a middleware system to manage data and participant heterogeneity in federated learning (FL) training workloads. In particular, we examine the benefits of label distribution clustering on participant selection in federated learning. FLIPS clusters parties involved in an FL training job based on the label distribution of their data apriori, and during FL training, ensures that each cluster is equitably represented in the participants selected. FLIPS can support the most common FL algorithms, including FedAvg, FedProx, FedDyn, FedOpt and FedYogi. To manage platform heterogeneity and dynamic resource availability, FLIPS incorporates a straggler management mechanism to handle changing capacities in distributed, smart community applications. Privacy of label distributions, clustering and participant selection is ensured through a trusted execution environment (TEE). Our comprehensive empirical evaluation compares FLIPS with random participant selection, as well as three other \"smart\" selection mechanisms -- Oort [51], TiFL [15] and gradient clustering [27] using four real-world datasets, two different non-IID distributions and three common FL algorithms (FedYogi, FedProx and FedAvg). We demonstrate that FLIPS significantly improves convergence, achieving higher accuracy by 17-20 percentage points with 20-60% lower communication costs, and these benefits endure in the presence of straggler participants.","This paper studies the effect of word representations on gender classification using deep learning. There are two main objectives: how well do popular deep learning architectures, namely LSTM and CNNs, perform on gender classification task and investigate how the choice of word representation effects the performance. Three networks, LSTM, CNN and LeNet-5, were trained on a dataset containing about 18000 names from India, Western countries, Sri Lanka and Japan. These names, encoded using the popular One-Hot representation and Word Embeddings in addition to Integer representation and an Enhanced Integer representation (proposed in this paper), were given as Input and the performance is evaluated on accuracy, training times and size of input layer. Experimental results show that LSTM in combination with word embedding derived from the proposed Enhanced Integer representation gives the best performance of about 85%. One-Hot representation is superior to Integer and Enhanced Integer representation but appears to perform lower than word embeddings.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts, however they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","Artificial Intelligence (AI) use in automated Electrocardiogram (ECG) classification has continuously attracted the research community\u2019s interest, motivated by their promising results. Despite their great promise, limited attention has been paid to the robustness of their results, which is a key element for their implementation in clinical practice. Uncertainty Quantification (UQ) is a critical for trustworthy and reliable AI, particularly in safety-critical domains such as medicine. Estimating uncertainty in Machine Learning (ML) model predictions has been extensively used for Out-of-Distribution (OOD) detection under single-label tasks. However, the use of UQ methods in multi-label classification remains underexplored.\nThis study goes beyond developing highly accurate models comparing five uncertainty quantification methods using the same Deep Neural Network (DNN) architecture across various validation scenarios, including internal and external validation as well as OOD detection, taking multi-label ECG classification as the example domain. We show the importance of external validation and its impact on classification performance, uncertainty estimates quality, and calibration. Ensemble-based methods yield more robust uncertainty estimations than single network or stochastic methods. Although current methods still have limitations in accurately quantifying uncertainty, particularly in the case of dataset shift, incorporating uncertainty estimates with a classification with a rejection option improves the ability to detect such changes. Moreover, we show that using uncertainty estimates as a criterion for sample selection in active learning setting results in greater improvements in classification performance compared to random sampling.\nHighlights\n\u2022\nLarge comparison of Uncertainty Quantification (UQ) methods in multi-label setting.\n\u2022\nEnsemble methods are more robust for UQ and calibration under dataset shift.\n\u2022\nThe quality of current UQ methods degrade when dealing with dataset shifts.\n\u2022\nUQ for active learning improves performance faster than random sampling.","Orthopedic implant identification is an important and necessary step prior to performing revision surgery of different joints. The inability to identify an implant can lead to significant surgical difficulties with consequent unfavorable outcomes. This paper proposes a novel framework to identify the make and model of seven (7) different total shoulder arthroplasty implants utilizing plain X-ray images and Artificial intelligence. The proposed work classified implants with an accuracy of 91.48% and with an AUC (Area under curve) of 0.9932 showing higher effectiveness in orthopedic implant identification. Further work is required to enhance and progress this work, with a goal of greater accuracy and fewer errors.","Alzheimer disease (AD) is a chronic neurological disorder in which the loss of brain cells causes dementia. Early and accurate diagnosis of AD will lead to better treatment of the disease before irreversible brain damage has been occurred. This paper proposes the classification of Alzheimer's disease using 3D structural Magnetic Resonance Imaging (sMRI) images through 3D convolutional neural networks (CNNs). Most existing methods utilizing 3D subject-level CNNs for Alzheimer's disease classification design a single model which relies on a very large training dataset for improved generalization. Herein, we address this issue through 3D transfer learning which makes use of knowledge gained from a pre-trained task. We train 3D versions of five classical 2D image classification architectures\u2014ResNet, ResNeXt, SE-ResNet, SE-ResNeXt, and SE-Net\u2014by initializing each model with pre-trained weights from their 2D counterparts, and combine their predictions through a weighted average method. The weights assigned to each model of the ensemble are optimized to achieve a performance better than any single 3D CNN model. With a relatively smaller training dataset, the proposed model obtains 97.27%, 82.33%, 90.41%, 84.22%, 84.26%, and 77.1% accuracies for the Alzheimer\u2019s disease (AD) versus cognitively normal (CN), early mild cognitive impairment (EMCI) versus CN, late mild cognitive impairment (LMCI) versus CN, EMCI versus AD, LMCI versus AD, and EMCI versus LMCI classification tasks, outperforming current state-of-the-art methods, and indicating the effectiveness of our proposed model.","Binary classification models are ubiquitous, and reliably measuring their performance is critical for their proper usage. Ideally, the performance of supervised models is measured using high-quality labeled datasets that are sufficiently large and representative of the population. However, obtaining labels for all segments of the population can be difficult, and model performance typically varies across different segments of the population (e.g., in different countries). In this work, we present a novel methodology to estimate the performance of a binary classifier in segments of the population where labels are unavailable. The main idea is that if two segments are \"similar,'' then the performance of the classifier in these two segments would also be \"similar.'' Specifically, we define a way to measure similarity between segments, and propose a statistical model that describes the performance of the model in unlabeled segments as a function of the performance in labeled segments. With extensive numerical experiments on synthetic and real-world datasets, we demonstrate that the proposed method substantially improves over existing methods in both estimation accuracy and computational efficiency. We also showcase the application of our method on the Instagram Adult Classifier to improve the geographic coverage and usability of the model.","Since Bitcoin first appeared on the scene in 2009, cryptocurrencies have become a worldwide phenomenon as important decentralized financial assets. Their decentralized nature, however, leads to notable volatility against traditional fiat currencies, making the task of accurately forecasting the crypto-fiat exchange rate complex. In this study, we examine the various independent factors that affect the Bitcoin-Dollar exchange rate's volatility. To this end, we propose CoMForE, a multimodal AdaBoost-LSTM ensemble model, which not only utilizes historical trading data but also incorporates public sentiments from related tweets, public interest demonstrated by search volumes, and blockchain hash-rate data. Our developed model goes a step further by predicting fluctuations in the overall cryptocurrency value distribution, thus increasing its value for investment decision-making. We have subjected this method to extensive testing via comprehensive experiments, thereby validating the importance of multimodal combination over exclusive reliance on trading data. Further experiments show that our method significantly surpasses existing forecasting tools and methodologies, demonstrating a 19.29% improvement. This result underscores the influence of external independent factors on cryptocurrency volatility.","Geological disasters result in significant human and property losses. It is imperative to identify areas prone to geological disasters for prevention and monitoring purposes. Identifying disaster-prone areas can be approached as a machine-learning classification problem. Various factors such as elevation, slope, aspect, terrain undulation, vegetation coverage, landform, and soil moisture content can be utilized as input variables for the classification algorithm to determine the probability of landslide occurrence within a specific range. Previous research in this area has been limited and fails to encompass diverse geological environments. This paper addresses this gap by utilizing a dataset collected within a province, which exhibits ample diversity and coverage. The dataset incorporates both continuous and discrete variables, allowing for a comprehensive evaluation of different classification algorithms. The primary objective of this study is to identify the most suitable classification algorithm for those conditions. By comparing the accuracy, ROC curves, and training duration of AdaBoost, cart, gbdt, xgboost, and random forest on multiple test datasets, it was determined that random forest yielded the best performance. The findings of this research can serve as a valuable reference for future related studies.","Remote sensing image scene classification aims to commit the semantic labels according to the content of images. Convolutional Neural Network (CNN) is often used here to extract deep discriminative feature of remote sensing images for classification. In practice, CNN is usually trained by images in the Red Green Blue (RGB) color space. Whereas, CNN also can be trained by images in some other color spaces, e.g., Hue Saturation Value. The CNN models trained by images in diverse color spaces will perform differently because different color spaces often emphasize diverse color information. Thus, we present an Evidential Combination method with Multi-color Spaces (ECMS) to integrate the complementary information of different color spaces for classification performance improvement. In ECMS, labeled remote sensing images in the RGB color space are first converted into other color spaces, and then they are used to train CNN models, respectively. The soft classification results (of query images) yielded by these CNN models are combined by evidence theory. During fusion, the reliabilities/weights of these outputs of different CNN models are usually different, so they should not be equally treated for combination. In our approach, the weights are learnt by minimizing the mean squared error between the combination results and ground truth on labeled images. By doing this, weighted evidence combination of soft classification results is employed to make scene class decision. We conducted experiments on several datasets to verify the effectiveness of ECMS, and the results show ECMS can significantly improve classification accuracy compared with many existing methods.\nHighlights\n\u2022\nEvidential combination method integrates CNNs trained in different color spaces.\n\u2022\nThe optimal weights are learnt by minimizing the constructed objective function.\n\u2022\nDS rule is employed to combine classification results yielded by different CNNs.\n\u2022\nResults on benchmarks verify the effectiveness of new method.","Graphical abstract\nDisplay Omitted\nAbstract\nA challenge in gas turbine fault diagnosis is that labeled fault samples are relatively rare and much fewer than normal samples. Conventional data augmentation techniques generate fault samples in original data spaces, resulting in the issue that synthetic fault samples highly overlap with normal samples. Aiming at the issue, a feature-level data augmentation method, namely feature-level SMOTE, is developed by integrating deep Siamese multi-head self-attention network (DSMHSA) with synthetic minority over-sampling technique (SMOTE) to reduce inter-class imbalance and overlap simultaneously. First, the DSMHSA maps original data into a feature space with better inter-class separability, in which inter-class samples stay far away from one another. Second, the SMOTE generates synthetic fault samples in the well-separable space, in order to balance the data set. Finally, the effectiveness of the developed feature-level SMOTE in imbalanced fault diagnosis has been evaluated through two case studies including the real gas turbine fault dataset and the public robot execution failures dataset. To be specific, its average balanced accuracy is 90.38% on the gas turbine dataset, yielding 9.67%, 13.94%, and 12.39% improvements compared to the OUPS, A-SUWO, and NRAS, respectively.","Explaining predictions made by inductive classifiers has become crucial with the rise of complex models acting more and more as black-boxes. Abductive explanations are one of the most popular types of explanations that are provided for the purpose. They highlight feature-values that are sufficient for making predictions. In the literature, they are generated by exploring the whole feature space, which is unreasonable in practice. This paper solves the problem by introducing explanation functions that generate abductive explanations from a sample of instances. It shows that such functions should be defined with great care since they cannot satisfy two desirable properties at the same time, namely existence of explanations for every individual decision (success) and correctness of explanations (coherence). The paper provides a parameterized family of argumentation-based explanation functions, each of which satisfies one of the two properties. It studies their formal properties and their experimental behaviour on different datasets.","The automatic detection of mental disorders has been mainly performed through binary classifiers trained on the behavioral data collected through an interview setup. Such classifiers are usually trained by keeping the data from the participants having the disorder of interest in the positive class while the data from all other participants are kept in the negative class. In practice, it is well known that some mental disorders have common symptoms. Thus, the behavioral data may carry a mixed bag of attributes related to multiple disorders. As a result, the negative class may carry attributes related to the mental disorder of interest. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, the MDD detection performances are significantly improved. However, such improvement is not observed consistently for PTSD detection, which may attribute to PTSD being a subtype of MDD.","Human-centric artificial intelligence struggles to build automated procedures that recognize emotions which can be integrated in artificial systems, such as user interfaces or social robots. In this context, this paper researches on building an Emotion Multi-modal Aggregator (EMmA) that will rely on a collection of open-source single source emotion classification methods aggregated to produce an emotion prediction. Although extendable, tested solution takes a video clip and divides into its frames and audio. Then a collection of primary classifiers are applied to each source and their results are combined in a final classifier utilizing machine learning aggregator techniques. The aggregator techniques that have been put to the test were Random Forest and k-Nearest Neighbors which, with an accuracy of 80%, have demonstrated superior performance over primary classifiers on the selected dataset.","Text Classification (TC) is a fundamental task in the information retrieval community. Nowadays, the mainstay TC methods are built on the deep neural networks, which can learn much more discriminative text features than the traditional shallow learning methods. Among existing deep TC methods, the ones based on Graph Neural Network (GNN) have attracted more attention due to the superior performance. Technically, the GNN-based TC methods mainly transform the full training dataset to a graph of texts; however, they often neglect the dependency between words, so as to miss potential semantic information of texts, which may be significant to exactly represent them. To solve the aforementioned problem, we generate graphs of words instead, so as to capture the dependency information of words. Specifically, each text is translated into a graph of words, where neighboring words are linked. We learn the node features of words by a GNN-like procedure and then aggregate them as the graph feature to represent the current text. To further improve the text representations, we suggest a contrastive learning regularization term. Specifically, we generate two augmented text graphs for each original text graph, we constrain the representations of the two augmented graphs from the same text close and the ones from different texts far away. We propose various techniques to generate the augmented graphs. Upon those ideas, we develop a novel deep TC model, namely Text-level Graph Networks with Contrastive Learning (TGNcl). We conduct a number of experiments to evaluate the proposed TGNcl model. The empirical results demonstrate that TGNcl can outperform the existing state-of-the-art TC models.","In this study, we compare the classification accuracy achievable with linear support vector machine (L-SVM), K-nearest neighbor (KNN), and multilayer perceptron (MLP) methods for a multi-class EEG signal. This can be done in three phases. In phase one, band-pass filtering is applied to raw electroencephalogram (EEG) signals to decompose into five different frequency subbands. In phase two, we extract 10 important features from each subband. In phase three, these extracted feature sets are used as input to L-SVM, KNN, and MLP classifiers which categorize the sample data into three classes namely yoga, meditation, and combined yoga\u2013meditation. Various performance measures for each classifier are evaluated and then compared to know which classifier is effective in the classification of the EEG data into yoga, meditation, and combined yoga\u2013meditation groups. Performance measures such as confusion matrix, accuracy, sensitivity, specificity, precision, and F1 score are used to validate the performance of classifiers. Kruskal\u2013Wallis test has been conducted to compare the classification performance of the linear SVM, KNN, and MLP classifier models. By comparing the classification accuracy between the three classifiers, L-SVM achieved the highest accuracy of 91.67%.","In recent years, the imbalanced classification problem has received much attention. SMOTE is one of the most popular methods to improve the performance of unbalanced data classification models. SMOTE changes the data distribution of unbalanced data sets by adding a few generated class samples, but the SMOTE algorithm has some limitations of its own, which may lead to problems such as the generated samples are noisy, the generated samples aggravate the boundary blurring, etc., which are especially obvious in the presence of samples with label noise. Granular-ball computing is an efficient, robust and scalable modeling method developed in the field of granular computing in recent years, and we can obtain clear decision boundaries by dividing data sets through granular-ball. Accordingly, this paper proposes a method, called Granular-ball SMOTE(GBSMOTE),to solve the above problems by first dividing the data set by granular-ball computing and then using SMOTE oversampling inside the granular-ball. The experimental results show the effectiveness of the proposed method, which is more prominent in the samples with label noise.","Multi-view classification aims to efficiently utilize information from different views to improve classification performance. In recent researches, many effective multi-view learning methods have been proposed to perform multi-view data analysis. However, most existing methods only consider the correlations between views but ignore the potential correlations between samples. Normally, the views of samples belonging to the same category should have more consistency information and those belonging to different categories should have more distinctions. Therefore, we argue that the correlations and distinctions between the views of different samples also contribute to the construction of feature representations that are more conducive to classification. In order to construct a end-to-end general multi-view classification framework that can better utilize sample information to obtain more reasonable feature representation, we propose a novel joint long and short span self-attention network (JLSSAN). We designed two different self-attention spans to focus on different information. They enable each feature vector to be iteratively updated based on its attention to other views and other samples, which provides better integration of information from different views and different samples. Besides, we adopt a novel weight-based loss fusion strategy, which facilitates the model to learn more reasonable self-attention map between views. Our method outperforms the state-of-the-art methods by more than 3% in accuracy on multiple benchmarks, which demonstrates that our method is effective.\nHighlights\n\u2022\nA novel end-to-end unified multi-view classification framework is proposed.\n\u2022\nA long and short span self-attention layer is constructed.\n\u2022\nAn adaptive weight loss fusion strategy is designed.\n\u2022\nThe performance of our method outperforms the popular models.","Forests play a crucial role in sustaining life on earth by providing vital ecosystem services and supporting a wide range of species. The unprecedented increase in forest fires aka \u2018infernos\u2019 due to global warming i.e. rising temperatures and changing weather patterns, is quite alarming. Recently, machine learning and computer vision-based techniques are leveraged to proactively analyze forest fire events. To this end, we propose novel semi-supervised classification and segmentation techniques using autoencoders to analyse forest fires, that require significantly less labelling effort in contrast to the fully-supervised methods. In particular, semi-supervised classification of forest fire using Convolutional autoencoders is proposed. Further, Class Activation Map-based techniques and patch-wise extraction methods are envisaged for the segmentation task. Extensive experiments are carried out on two publicly available large datasets i.e. FLAME and Corsican datasets. The proposed models are found to be outperforming the state-of-the-art approaches.","Machine learning (ML) has become an important tool for the development of Industry 4.0. It assists the machining processes by monitoring and maintaining the conditions. Support vector machine (SVM) is one such algorithm of ML used to train and classify the data. The present work uses the SVM for predicting the surface roughness in the end milling of the low-carbon steel. The experiments were performed at nine different combinations of process parameters. Moreover, to monitor the cutting process online, the current drawn is measured using a current sensor. In this regard, a correlation between the current drawn and variation in surface roughness is reported. The average value of the surface roughness was predicted using the SVM at each combination. The results show that the SVM estimates the surface roughness with an approximate error of 0.4 %-10%. On the other hand, the surface roughness variation does not fit well with the current signals due to the variation in tool wear.","Credit scoring concerns with developing empirical model to support financial decision making process for financial institutions. It makes use of applicants\u2019 historical data and statistical or machine learning techniques to access the risk associated with an applicant. However, the data may have redundant and irrelevant information and features, which degrades the classification accuracy and increases the complexity. So, effective feature selection technique can resolve the problem of credit scoring dataset with huge number of features. In various studies, it is shown that ensemble classifier improves the classification performances as compared to its base classifiers. This study focuses to combine the benefits of feature selection and ensemble framework. For feature selection an approach based on feature clustering have been proposed in this study. Moreover, dataset with selected features is applied on five base classifiers and output obtained by base classifiers are aggregated by weighted voting approach for prediction of final output. For validating the proposed approach, three real world credit scoring datasets are utilized and results compared with some existing feature selection techniques in terms of classification accuracy and F1 -score.","In spite of recent advances in computer vision, the classic problem of offline handwritten signature verification still remains challenging. The signature verification task has a high intra-class variability because a given user often shows high variability between its samples. Besides, signature verification is harder in the presence of skilled forgeries. Recently, in order to tackle these challenges, the research community has investigated deep learning methods for learning feature representations of handwritten signatures. When mapping signatures to a feature space, it is desired to obtain dense clusters of signature\u2019s representations, in order to deal with intra-class variability. Besides, not only dense clusters are required but also a larger separation between different user\u2019s clusters in the feature space. Finally, it is also desired to move away feature representations of skilled forgeries in relation to the respective dense cluster of genuine representations. This last property is hard to achieve in the real-world scenario because skilled forgeries are not readily available during training. In this work, we hypothesize that such properties can be achieved by means of a multi-task framework for learning handwritten signature feature representations based on deep contrastive learning. The proposed framework is composed of two objective-specific tasks. The first task aims to map signature examples of the same user closer within the feature space, while separating the feature representations of signatures of different users. The second task aims to adjust the skilled forgeries representations by adopting contrastive losses with the ability to perform hard negative mining. Hard negatives are examples from different classes with some degree of similarity that can be applied for training. We evaluated models obtained with the proposed framework in terms of the equal error rate on GPDSsynthetic, CEDAR and MCYT-75 datasets in writer-dependent and writer-independent verification approaches. Using synthetic and real signature datasets, Friedman tests with Bonferroni\u2013Dunn post hoc tests were performed to compare the proposed multi-task contrastive models against the popular SigNet model as a baseline. Experiments demonstrated an statistically significant improvement in signature verification with a multi-task contrastive model based on the Triplet loss. Implementation of the method is available for download at https://github.com/tallesbrito/contrastive_sigver.\nHighlights\n\u2022\nWe propose a framework for the contrastive learning of signature representations.\n\u2022\nThe method uses similar signatures from different users to discriminate forgeries.\n\u2022\nModels following the proposed framework generalize well to 4 different datasets.\n\u2022\nExperiments show a statistically significant improvement to the SigNet model.\n\u2022\nWe found improvements for writer-dependent and writer-independent verification.","Skip Abstract Section\nAbstract\nThe concealment of improvised explosive devices in dustbins aimed at destroying people and property is causing the mass removal of dustbins from public places and vehicular public transport in cities around the world. Such action of dustbin removal results in littering, stench, pests, contamination of water bodies, the spread of diseases, and increased greenhouse gases. The current solutions to the problem are blast-resistant dustbins which are bulky and expensive, and transparent dustbins which display the awful appearance of wastes in public places. This article proposes equipping dustbins with artificial intelligence-based classifiers to detect explosives concealed in wastes in public dustbins to minimise the risk to public safety. There was the need to construct a new database of explosive images to augment the existing TrashNet dataset. Then, through transfer learning using eight state-of-the-art convolutional neural networks as base models, the augmented dataset was used to search for optimum convolutional neural networks to detect explosives. One of the trained networks based on DenseNet-121 achieved the Top-1 accuracy of 80% with about 26 minutes learning time, which is 6.7% better than the Top-1 accuracy achieved by the base model on the benchmark ImageNet dataset. This finding demonstrates that the designed neural networks are promising cutting-edge techniques for detecting explosives concealed in dustbins to threaten public safety. To the best of our knowledge, this is the first time that convolutional neural networks have been proposed to identify explosives concealed in dustbins.\nSkip Graphical abstract Section\nGraphical abstract","With the advent of the information age, there are more and more text data on the Internet. As the most widely distributed information carrier with the largest amount of data, it is particularly important to use text classification technology to organize and manage massive data scientifically. In this paper, a semi-supervised ensemble learning algorithm Heterogeneous-training is proposed and applied to the field of text classification. Based on the Tri-training algorithm, the Heterogeneous-training algorithm improves the traditional Tri-training algorithm by using different classifiers, dynamically updating the probability threshold and adaptively editing data. A large number of experiments show that our method always outperforms Tri-training algorithm in text classification on benchmark text data sets.","3D printing has the potential to revolutionize industrial manufacturing through efficient and sustainable techniques. Fused Deposition Modeling (FDM) is a broadly deployed technique among various 3D printing methods. However, the surface quality of FDM is greatly influenced by multiple factors, making it challenging to unravel the relationship between printing quality and parameter settings. To break through this bottleneck, this study proposes an intelligent approach that combines Transfer Learning (TL)-based Feature Extractor (FE) and Gradient-Boosting Decision Trees (GBDT) to investigate the effects of FDM printing parameters on surface quality. Experiments are conducted in the laboratory to validate the effectiveness of the FE-GBDT, which is then compared with the exemplary Machine Learning (ML) algorithms. The results show that our proposed TL model can achieve high precision and accuracy over 0.9900, demonstrating the efficacy of FE-GBDT in deciphering the impact of FDM printing parameters on surface quality. The contribution of each parameter is evaluated and indicates that layer height could dramatically affect the surface quality with an importance score of 0.626. The results provide valuable insights for the 3D printing community, proving that the FE-GBDT approach offers improved generalization, faster training, enhanced feature extraction, addressing data scarcity, and the ability to leverage the strengths of both approaches for superior performance across various tasks.","Machine Learning has revolutionized the categorization of vast legal documents, minimizing costs and improving evaluations. However, conventional models struggle with unseen data categories in real-world scenarios, a challenge termed Open Set Classification. Our study tackles the issue faced by the Court of Justice in S\u00e3o Paulo, Brazil, to identify recurring lawsuit themes from texts, as manual sorting is inefficient. We introduce a method to enhance confidence in text classification using an open dataset by converting multiclass challenges into binary ones with four confidence tiers. By testing various techniques, we found that combining doc2vec with the Support Vector Machine classifier delivers trustworthy results and robust performance. Ultimately, our method offers an effective solution for classifying legal texts confronting Open Set Classification issues in the legal sector.","The Hierarchical Inference (HI) paradigm has recently emerged as an effective method for balancing inference accuracy, data processing, transmission throughput, and offloading cost. This approach proves particularly efficient in scenarios involving resource-constrained edge devices like micro controller units (MCUs), tasked with executing tinyML inference. Notably, it outperforms strategies such as local inference execution, inference offloading, and split inference (i.e., inference execution distributed between two endpoints). Building upon the HI paradigm, this work explores different techniques aimed at further optimizing inference task execution. We propose three distinct HI approaches and evaluate their utility for image classification.","Pulmonary Embolism (PE) \u2014 a non-cardiac cause of cardiac arrest is a strenuous job to perform as it is non-specific in presentation and shares various overlapping features with various other clinical disorders like Myocardial Infarction, Pneumonia, etc. This paper delineates a method to identify Pulmonary Embolism (PE) as a reason for Heart Failure using Deep Reinforcement Learning (DRL) algorithm. The methodology has been partitioned into two phases. Phase I acts towards the creation of a novel dataset as there was no data available for this particular problem statement. Phase II deals with the scope and application of the DRL algorithm on the above-invented dataset. The dataset formed is imbalanced in its essence. To effectively tackle the imbalanced dataset challenge, a cutting-edge imbalanced classification algorithm rooted in the power of Deep Reinforcement Learning (DRL) has been embraced. The classification model has been drawn up as a Sequential Decision-Making procedure and is resolved by making use of the DRL algorithm viz Double Deep Q-Network (DDQN). A classification action is performed by an agent on a single sample at each time step. Classification actions are assessed by the environment, based on the assessment, a reward is given to an agent. In order to make the agent more responsive towards the minority class samples, rewards belonging to the minority class are higher. Under the supervision of this reward system, the agent finally learns the optimal classification policy for this imbalanced dataset problem. Comparative analysis of the DDQN algorithm with other Deep Reinforcement Learning algorithms, including Dueling DQN, and Proximal Policy Optimization (PPO) algorithms has been performed in order to arrive at the best learning technique for the dataset. Furthermore, the DDQN algorithm has been evaluated against a selection of Machine Learning (ML) algorithms. From the experimentation, it is demonstrated that the DDQN model outperformed other approaches with an accuracy of 99.99%, G-mean 0.9999, Recall 1.0000, and Specificity 0.9999.","Imbalanced data has been the focus of ongoing classification research. It describes a scenario where the distribution of data samples is uneven, and one or more classes in the dataset are underrepresented as a result. When trained on such datasets, this mismatch has a negative impact on the performance of conventional learning models. The key problem is in finding appropriate samples for creating synthetic data, even though numerous strategies have been developed to overcome class imbalance during data pre-processing. In this study, we offer an efficient method for overcoming imbalance classification issues caused by oversampling called Informative Sample Selection (ISS). The main goal of ISS is to find useful samples from the minority class in the dataset that may be used to produce data that is synthetic. We conducted experiments on 22 imbalanced datasets to evaluate the performance of our suggested model. We assessed the performance of ISS in comparison to several cutting-edge techniques, including SMOTE, Borderline-SMOTE, ADASYN, safe-level SMOTE, and ROS. AUC and F-Measure were the evaluation measures employed in our study. The outcomes of our tests show that ISS works better than the current approaches, showing significant progress in tackling the challenges brought on by imbalanced data in classification.","Classification and differentiation of leukocyte sub-types are important in peripheral blood smear analysis. Fully-automated systems for leukocyte analysis are grouped into segmentation- and detection-based methods. The accuracy of classification depends on the accuracy of segmentation and detection steps. Real-world applications often produce inaccurate ROIs due to image quality factors, e.g., colour and lighting conditions, absence of standards, or even density and presence of overlapping cells. To this end, we investigated the scenario in-depth with ROIs simulating segmentation and detection methods and evaluating different image descriptors on two tasks: differentiation of leukocyte sub-types and leukaemia detection. The obtained results show that even simpler approaches can lead to accurate and robust results in both tasks when exploiting appropriate images for model training. Traditional handcrafted features are more effective when extracted from tight bounding boxes or masks, while deep features are more effective when extracted from large bounding boxes or masks.","Skip Abstract Section\nAbstract\nThe disadvantages of modern methods of classifying objects and processes are considered. We propose a method of constructing three-dimensional classifications that allows the elimination of some of these shortcomings, based on the system-object approach, using the ideas of multidimensional classification and natural classification. Three basic system characteristics are used as classification planes: structural (node), functional (function), and substantive (object), which allows for the classification by types of functional request to the system from a higher-order system (supersystem) by types of system formation processes and by the obtained results. Each classification is a tree-type graph with one vertex that is common to all three planes. The formal description of the three-dimensional graph by means of descriptive logic is presented, which not only allows for the phenomena and objects of the subject area to be classified, but also for the cause-and-effect relations existing in this area to be traced. The procedures for the use of three-dimensional system-object classification for forecasting and management support are described. An example of three-dimensional classification for functional diagnostic devices is given.","Imbalanced data are widely available in the real world, and it is difficult to effectively identify the minority class instances in imbalanced data. Various imbalanced classification models have been proposed. However, these models neglect the data density and the location of instances which can be important factors affecting classification performance. To tackle this issue, this paper proposes a hybrid imbalanced classification model based on data density (HICD). In data-level, the density-based resampling method is presented. The data partition Algorithm is given, which divides the data space into five regions based on the data density. The corresponding subsets are generated by sampling from the divided regions to improve the recognition of different classes of instances. In algorithm-level, we construct the corresponding ensemble models for different classes of instances. In addition, the model selection Algorithm is presented. On this basis, an appropriate model is selected for each instance based on its distribution. The performance of the proposed HICD was evaluated on 18 imbalanced datasets in the real world in terms of recall, the area under the roc curve (AUC), and G-mean. The experimental results validate that our method has better performance than other competitive algorithms in imbalanced classification.","Hyperspectral image (HSI) provides rich spectral\u2013spatial information and the light detection and ranging (LiDAR) data reflect the elevation information, which can be jointly exploited for better land-cover classification. However, due to different imaging mechanisms, HSI and LiDAR data always present significant image difference, current pixel-wise feature fusion classification methods relying on concatenation or weighted fusion are not effective. To achieve accurate classification result, it is important to extract and fuse similar high-order semantic information and complementary discriminative information contained in multimodal data. In this paper, we propose a novel coupled adversarial learning based classification (CALC) method for fusion classification of HSI and LiDAR data. In specific, a coupled adversarial feature learning (CAFL) sub-network is first trained, to effectively learn the high-order semantic features from HSI and LiDAR data in an unsupervised manner. On one hand, the proposed CAFL sub-network establishes an adversarial game between dual generators and discriminators, so that the learnt features can preserve detail information in HSI and LiDAR data, respectively. On the other hand, by designing weight-sharing and linear fusion structure in the dual generators, we can simultaneously extract similar high-order semantic information and modal-specific complementary information. Meanwhile, a supervised multi-level feature fusion classification (MFFC) sub-network is trained, to further improve the classification performance via adaptive probability fusion strategy. In brief, the low-level, mid-level and high-level features learnt by the CAFL sub-network lead to multiple class estimation probabilities, which are then adaptively combined to generate a final accurate classification result. Both the CAFL and MFFC sub-networks are collaboratively trained by optimizing a designed joint loss function, which consists of unsupervised adversarial loss and supervised classification loss. Overall, by optimizing the joint loss function, the proposed CALC network is pushed to learn highly discriminative fusion features from multimodal data, leading to higher classification accuracies. Extensive experiments on three well-known HSI and LiDAR data sets demonstrate the superior classification performance by the proposed CALC method than several state-of-the-art methods. The source code of the proposed method will be made publicly available at https://github.com/Ding-Kexin/CALC.\nHighlights\n\u2022\nPropose a novel coupled adversarial learning method for multi-modal classification.\n\u2022\nFuse high-order semantic information and multi-modal complementary information.\n\u2022\nExplore effective multi-level feature fusion strategy to improve discrimination.\n\u2022\nDesign an end-to-end deep learning framework for two sub-network joint training.","Today's ever\u2010increasing generation of streaming data demands novel data mining approaches tailored to mining dynamic data streams. Data streams are non\u2010static in nature, continuously generated, and endless. They often suffer from class imbalance and undergo temporal drift. To address the classification of consecutive data instances within imbalanced data streams, this research introduces a new ensemble classification algorithm called Rarity Updated Ensemble with Oversampling (RUEO). The RUEO approach is specifically designed to exhibit robustness against class imbalance by incorporating an imbalance\u2010specific criterion to assess the efficacy of the base classifiers and employing an oversampling technique to reduce the imbalance in the training data. The RUEO algorithm was evaluated on a set of 20 data streams and compared against 14 baseline algorithms. On average, the proposed RUEO algorithm achieves an average\u2010accuracy of 0.69 on the real\u2010world data streams, while the chunk\u2010based algorithms AWE, AUE, and KUE achieve average\u2010accuracies of 0.48, 0.65, and 0.66, respectively. The statistical analysis, conducted using the Wilcoxon test, reveals a statistically significant improvement in average\u2010accuracy for the proposed RUEO algorithm when compared to 12 out of the 14 baseline algorithms. The source code and experimental results of this research work will be publicly available at https://github.com/vkiani/RUEO.","Architectural floor plan is an essential document to share the building information among designers, and engineers. Automatic floor plan image analysis is useful to extract various information from the floor plan. Wall segmentation is an important step in floor plan image analysis. However, few research works have been conducted for automatic wall recognition in an architectural floor plan. In this paper, a convolution neural network, namely WallNet, is proposed to recognize the multi-class walls. The WallNet consists of an encoder and a decoder. The encoder captures low-level features, as well as multiscale contextual information. Based on these extracted feature maps, the walls are detected. The proposed network is applied to recognize five different classes of walls: solid-wall, dot-wall, diagonal-wall, hollow-wall and gray-wall. The experimental results show that the proposed architecture can obtain a mean average precision of 72%, which is superior compared to the state-of-the-art techniques.","The recent pandemic has witnessed a parallel infodemic happening on social media platforms, leading to fear and anxiety within the population. Traditional machine learning (ML) frameworks for fake news detection are limited by the availability of data for training the model. By the time sufficient labeled datasets are available, the existing infodemic may itself come to an end. We propose a COVID-19 fake news detection framework using cross-domain classification techniques to achieve high levels of accuracy while reducing the waiting time for large training datasets to become available. We investigate the effectiveness of three approaches: Domain Adaptive Training, Transfer Learning, and Knowledge Distillation that reuse ML models from past infodemics to improve the accuracy in detecting COVID-19 fake news. Experiments with real-world datasets depict that Transfer Learning performs better than Domain Adaptive Training and Knowledge Distillation techniques.","Training deep learning models on long-tailed datasets is a challenging task since the classification performance of tail classes with fewer samples is always unsatisfactory. Currently, many long-tailed methods have achieved success. However, some methods always improve tail-class performance at the expense of head-class performance due to limited model capability. To address this issue, we propose a novel algorithm-level method inspired by information theory to balance the information space of each class and boost tail-class performance while minimizing head-class sacrifice. Our method involves actively eliminating the redundant feature information of head classes to save space for tail classes during training. Specifically, we use a bilateral-expert model and design a duplicate information disentanglement (DID) module that can extract duplicate and redundant information from bilateral-expert features. This allows us to develop a head diversity loss to decrease the extracted duplicate and redundant information of head classes and a tail distillation loss to increase the label information of tail classes. The joint result of these two losses allows our model to fully leverage the information space for improved tail-class performance without compromising head-class performance. The effectiveness and practicability of our method are verified by five datasets with long-tailed distributions for visual recognition or fault diagnosis tasks. Experimental results demonstrate that our method outperforms currently available mainstream methods, which we attribute to the effectiveness of our proposed DID module and the incorporation of two long-tailed losses.","Learning from noisy labels is a challenge that arises in many real-world applications where training data can contain incorrect or corrupted labels. When fine-tuning language models with noisy labels, models can easily overfit the label noise, leading to decreased performance. Most existing methods for learning from noisy labels use static input features for denoising, but these methods are limited by the information they can provide on true label distributions and can result in biased or incorrect predictions. In this work, we propose the Dynamics-Enhanced Generative Model (DyGen), which uses dynamic patterns in the embedding space during the fine-tuning process of language models to improve noisy label predictions. DyGen uses the variational auto-encoding framework to infer the posterior distributions of true labels from noisy labels and training dynamics. Additionally, a co-regularization mechanism is used to minimize the impact of potentially noisy labels and priors. DyGen demonstrates an average accuracy improvement of 3.10% on two synthetic noise datasets and 1.48% on three real-world noise datasets compared to the previous state-of-the-art. Extensive experiments and analyses show the effectiveness of each component in DyGen. Our code is available for reproducibility on GitHub.","This paper focuses on the classification problem of multi-view data, aiming to improve the classification accuracy of current algorithms on multi-view data. Previous multi-view classification algorithms are usually based on exploiting the complementarity of different views and fusing features from different views. A representative category is the graph-based method, which builds a graph matrix for each view, and then fuses the graph matrices of different views to obtain a unified graph. These methods have the following problems: firstly, the graph matrix is simply based on sample similarity usually; secondly, the learned graph matrix does not change dynamically; thirdly, the weight of the graph representation matrix for a single view cannot be learned in the unified graph matrix. Therefore, this paper designs a Two-step classification algorithm based on Dynamic Graph-ELM, called TSDGELM. In the TSDGELM, the dynamic Graph-ELM is used to obtain the graph representation matrix of each view to save the local neighbor information of the data, and then a joint graph learning algorithm is designed based on the GBS (Graph-Based System) mechanism to fuse the graph matrix of the single-view, and finally the united graph is input into the classifier. To evaluate the effectiveness of the proposed method in this work, we conduct a series of experiments on eight datasets, and the results demonstrate the superiority of the proposed method.","Stress detection is important for ensuring overall mental well-being of an individual. Literature suggests several approaches for prediction or classification of stress. However, the performance of these approaches varies a lot across subjects and tasks. Moreover, perception of stress is highly subjective and hence it is difficult to create a generic model/devices for prediction of stress. In this study, we have proposed an approach for creating a generic stress prediction model by combining the knowledge and variety from multiple public datasets containing galvanic skin response (GSR) data recorded during different context and activities. Most significant features are selected from these recorded signals and a voting based approach was finally adopted to develop a model for predicting mental stress. Proposed model has been validated using test data as well as a set of completely unseen data collected in our lab. We achieved an average classification accuracy of 89% (F-score 0.87) for test data and similar performance for completely unseen data as well. Results show that the proposed model outperforms the training models created using individual datasets. In addition, our model is created using skin response data recorded using off-the-shelf devices. Thus, our proposed model with selected feature set can be used for monitoring stress in real life scenarios and to create mass-market stress prediction products.","For any digital application with document images such as retrieval, the classification of document images becomes an essential stage. Conventionally for the purpose, the full versions of the documents, that is the uncompressed document images make the input dataset, which poses a threat due to the big volume required to accommodate the full versions of the documents. Therefore, it would be novel, if the same classification task could be accomplished directly (with some partial decompression) with the compressed representation of documents in order to make the whole process computationally more efficient. In this research work, a novel deep learning model\u2014DWT-CompCNN\u2014is proposed for classification of documents that are compressed using High Throughput JPEG 2000 (HTJ2K) algorithm. The proposed DWT-CompCNN comprises of five convolutional layers with filter sizes of 16, 32, 64, 128, and 256 consecutively for each increasing layer to improve learning from the wavelet coefficients extracted from the compressed images. Experiments are performed on two benchmark datasets, Tobacco-3482 and RVL-CDIP, which demonstrate that the proposed model is time and space efficient, and also achieves a better classification accuracy in compressed domain.","In the healthcare industry, developing an efficient diagnostic system to classify liver cancer cells is a very perplexing and arduous task. Recently, several studies demonstrate that deep ensemble classifiers can achieve better predictive accuracy than individual deep learning classifiers. The deep ensemble learners exploit more than one individual deep learner to achieve better classification results and improved generalization performance. When implementing an ensemble learning (multiple classifier) approach, the selection of the optimum learners from a crew is a critical issue and an effective learner assortment strategy is used to achieve better results. Several researchers have applied different approaches (e.g., rule-based algorithms, evolutionary computing, simulated annealing, etc.) to determine the optimal learners that can increase the performance of the diagnostic system. This work proposes a new classifier selection strategy to construct an ensemble called a contribution-based iterative base learner removal algorithm (CIBRA). The proposed algorithm finds out the best subset of individual learners by considering both prediction accuracy and diversity. The proposed CIBRA enables each base learner in a pool to have multiple chances to partake in an iteration of selection. CIBRA drops the classifiers only if they have no residual opportunities. This procedure is reiterated till no learner in the crew has any remaining possibility to partake in the selection round. In this study, we test various decision synthesis techniques to increase the performance of the ensemble classifier. To assess the performance of CIBRA, 8 standard cancer databases are exploited. Extensive simulation results divulge that two base classifiers are enough to classify liver cancer cells from hematoxylin and eosin (H&amp;E) scans successfully. Based on the results obtained from this study, we construct an ensemble classifier using Dropout Extreme Learning Machine (DrpXLM) and Enhanced Convolutional Block Attention Modules (ECBAM) based residual network to classify liver cancer images. Besides, CIBRA generates better results when it operates with average probability as the decision synthesis technique.","Graph neural networks (GNNs) have been shown to be useful in a variety of graph classification tasks, from bioinformatics to social networks. However, most GNNs represent the graph using local neighbourhood aggregation. This mechanism is inherently difficult to learn about the global structure of a graph and does not have enough expressive power to distinguish simple non-isomorphic graphs. To overcome the limitation, here we propose multi-head heat kernel convolution for graph representation. Unlike the conventional approach of aggregating local information from neighbours using an adjacency matrix, the proposed method uses multiple heat kernels to learn the local information and the global structure simultaneously. The proposed algorithm outperforms the competing methods in most benchmark datasets or at least shows comparable performance.","Facial expression recognition is a human emotion classification problem attracting much attention from scientific research. Classifying human emotions can be a challenging task for machines. However, more accurate results and less execution time are still the issues when extracting features of human emotions. To cope with these challenges, the authors propose an automatic system that provides users with a well-adopted classifier for recognizing facial expressions in a more accurate manner. The system is based on two fundamental machine learning stages, namely feature selection and feature classification. Feature selection is realized by active shape model (ASM) composed of landmarks while the feature classification algorithm is based on seven well-known classifiers. The authors have used CK+ dataset, implemented and tested seven classifiers to find the best classifier. The experimental results show that quadratic classifier (DA) provides excellent performance, and it outperforms the other classifiers with the highest recognition rate of 100% for the same dataset.","Plenty of models have been presented to handle the hypergraph node classification. However, very few of these methods consider contrastive learning, which is popular due to its great power to represent instances. This paper makes an attempt to leverage contrastive learning to hypergraph representation learning. Specifically, we propose a novel method called Collaborative Contrastive Learning (CCL), which incorporates a generated standard graph with the hypergraph. The main technical contribution here is that we develop a collaborative contrastive schema, which performs contrast between the node views obtained from the standard graph and hypergraph in each network layer, thus making the contrast collaborative. To be precise, in the first layer, the view from the standard graph is used to augment that from the hypergraph. Then, in the next layer, the augmented features are adopted to train a new representation to augment the view from the standard graph conversely. With this setting, the learning procedure is alternated between the standard graph and hypergraph. As a result, the learning on the standard graph and hypergraph is collaborative and leads to the final informative node representation. Experimental results on several widely used datasets validate the effectiveness of the proposed model.\nHighlights\n\u2022\nCCL is proposed to handle hypergraph node classification problem.\n\u2022\nCCL considers the contrast in each layer from GCN and HGCN.\n\u2022\nCCL exploits the convolutional networks on the standard graph and hypergraph.\n\u2022\nExperimental results demonstrate the superior performance of the proposed model.","The most common application of artificial immune networks (AINs) is on unsupervised learning tasks. This is due to the fact that AINs are inspired by the adaptive immune system, which consists of a network of antibodies that self-organises to form a memory of external antigens. The self-organising nature of AINs makes them a natural approach for solving problems involving learning and adapting to patterns or structures present in a dataset to form an abstract representation. Training AINs in this fashion means that the dataset need not have class labels because the typical aim of the learning process is not to perform classification. However, there have been attempts to use AINs for classification tasks by considering the resulting clusters of antibodies as representative of the classes present in a dataset. This has also been done when applying AINs to the task of recognising handwritten characters. However, in all the approaches found in the literature, the common method was to leave the task of discovering classes to the AINs. Doing so is contrary to how other models are trained to do classification tasks where data samples are provided along with their class labels to guide the learning process. Therefore, this paper presents a novel supervised learning approach to training AINs for multi-class classification. The proposed approach was tested on the MNIST handwritten digits dataset and achieved a classification accuracy of 99.45%.","The last decades have witnessed significant progress in machine learning with applications in different safety-critical domains, such as medical, law, education, and transportation. In high-stake domains, machine learning predictions have far-reaching consequences on the end-users. With the aim of applying machine learning for societal goods, there have been increasing efforts to regulate machine learning by imposing interpretability, fairness, robustness, privacy, etc. in predictions. Towards responsible and trustworthy machine learning, we propose two research themes in our dissertation research: interpretability and fairness of machine learning classifiers. In particular, we design algorithms to learn interpretable rule-based classifiers, formally verify fairness, and explain the sources of unfairness. Prior approaches to these problems are often limited by scalability, accuracy, or both. To overcome these limitations, we closely integrate automated reasoning and formal methods with fairness and interpretability to develop scalable and accurate solutions.","Multi-layer perceptrons (MLPs) rank among the most popular and widely employed intelligent approaches for approximating the relationships between dependent and independent variables, demonstrating a wide range of successful applications. MLPs are flexible techniques capable of universally modeling and analyzing real-world problems in forecasting and classification domains with a desirable level of accuracy. In conventional MLPs, cost functions are formulated based on the error term. Subsequently, the learning process aims to estimate the unknown parameters to minimize the error-based cost function. The logic of the procedure is founded on the assumption that maximum generalization will be achieved from models displaying the highest accuracy within the training sample. While this learning process is rational and beneficial, a model's generalization capability depends simultaneously on the model's accuracy and the reliability level of that accuracy. In this manner, reliability is not taken into consideration when formulating the conventional cost function for MLPs. This paper introduces a reliability-based cost function for estimating the unknown weights and biases of MLP models during the learning process. The proposed cost function is designed to calculate the variation of the performances in dissimilar data situations. In the learning process of the proposed reliability-based multi-layer perceptron, in contrast to traditionally developed models, the goal is to minimize variation rather than error, or equivalently, to maximize reliability instead of accuracy. The generalizability of the proposed reliability-based MLP (EMLP) model in forecasting and classification domains is comprehensively evaluated using 30 benchmark data sets in each domain. Empirical results in the forecasting area indicate that, from a general perspective, the proposed EMLP model exhibits superior generalizability in 23 cases (76.67%) compared to traditional models. Furthermore, numerical results in the classification area reveal that the proposed model outperforms or matches the performance of the conventional MLP in 26 cases (86.67%). These outcomes clearly underscore the significance of reliability, a factor not considered in any of the conventional MLP modeling procedures. Therefore, the proposed MLP model represents a suitable alternative in modeling, especially when greater generalizability is desired.","Vertical federated learning (VFL) is an emerging paradigm for cross-silo organizations to build more accurate machine learning (ML) models. In this setting, multiple organizations (i.e., parties) hold the same set of samples with different features. However, different parties may have redundant or highly correlated features, leading to inefficient and ineffective VFL model training. Effective feature selection in VFL is therefore essential to mitigate such a problem and improve model effectiveness, as well as computation and communication efficiency. To this end, in this paper, we propose a federated feature selection framework, called FEAST, which leverages conditional mutual information (CMI) to select more informative features while having low redundancy. Furthermore, we design a communication-efficient method to reduce the information exchanged among the parties while protecting the parties' raw data. Extensive experiments on four real-world datasets demonstrate that the proposed framework achieves state-of-the-art performance in terms of accuracy, communication and computation costs.","Writer identification based on handwriting recognition is considered one of the most common research areas in pattern recognition and biometrics. It has attracted much attention in recent decades due to the urgent need to develop biometric systems for many security applications. In this paper, Deep Writer Identification Network (DeepWINet), an effective deep Convolutional Neural Network (CNN) for writer identification, is proposed. The proposed model is evaluated in two different ways. In the first scenario, DeepWINet\u2019s CNN activation features, computed from the connected components of the writing, are passed to a customized nearest neighbor classifier for writer identification. In the second scenario, DeepWINet is evaluated as an end-to-end CNN network where the predicted results are averaged using an efficient strategy, Score Averaging Component-Decision Combiner. The proposed approach achieves competitive or the highest State-Of-The-Art performance on eight challenging handwritten databases with different languages.","One of the main challenges in target-dependent sentiment classification (TDSC) is dealing with sentences that contain multiple targets with varying polarities. Traditional sentiment analysis has shown the effectiveness of language characteristics. Therefore, we propose a method to extract target semantic-related tokens from sentences in order to simplify the sentiment classification task. To achieve this, we establish six grammatical principles that utilize grammatical knowledge to filter the relevant descriptions of targets. Since a target is typically a noun and acts as a subject, we summarize the six rules to extract the contexts contained in the objects and subordinate clauses. We use dependency parsing to analyze the grammatical relations between the target and its context. We design a data pre-processing method called Text Filtering (TF) to automate this procedure. After executing the TF algorithm, we pass the target-related words to a simple classifier to predict their sentiment polarities. Rather than feeding these features directly to a network and letting it learn features on its own, our approach employs dependency relations to extract context linked to the target. This provides the network with meaningful and representative features, resulting in superior results. We conduct ablation studies to investigate the effectiveness of the proposed TF algorithm. In the restaurant hard dataset, our approach improves accuracy by 13.76% and macro-F1 by 14.65% compared to a CNN-based method where TF is not implemented.\nHighlights\n\u2022\nIncorporate linguistic knowledge to the model by a two-step framework for effective handling of multiple targets.\n\u2022\nTarget-related contexts were extracted by the summarized rules which distinguish content and function words.\n\u2022\nA hierarchical and recursive data process method was designed specifically for TDSC named Text filtering (TF).","We present FOLD-SE, an efficient, explainable machine learning algorithm for classification tasks given tabular data containing numerical and categorical values. The (explainable) model generated by FOLD-SE is represented as a set of default rules. FOLD-SE uses a novel heuristic called Magic Gini Impurity for literal selection that we have devised. FOLD-SE uses a refined data comparison operator and eliminates the long tail effect. Thanks to these innovations, explainability provided by FOLD-SE is scalable, meaning that regardless of the size of the dataset, the number of learned rules and learned literals stay quite small while good accuracy in classification is maintained. Additionally, the rule-set constituting the model that FOLD-SE generates does not change significantly if the training data is slightly varied. FOLD-SE is competitive with state-of-the-art traditional machine learning algorithms such as XGBoost and Multi-Layer Perceptrons (MLP) w.r.t. accuracy of prediction while being an order of magnitude faster. However, unlike XGBoost and MLP, FOLD-SE generates explainable models. The FOLD-SE algorithm outperforms prior rule-learning algorithms such as RIPPER in efficiency, performance, and scalability, especially for large datasets. FOLD-SE generates a far smaller number of rules than earlier algorithms that learn default rules.","Text classification is a fundamental task in Text Mining (TM) with applications ranging from spam detection to sentiment analysis. One of the current approaches to this task is Graph Neural Network (GNN), primarily used to deal with complex and unstructured data. However, the scalability of GNNs is a significant challenge when dealing with large-scale graphs. Multilevel optimization is prominent among the methods proposed to tackle the issues that arise in such a scenario. This approach uses a hierarchical coarsening technique to reduce a graph, then applies a target algorithm to the coarsest graph and projects the output back to the original graph. Here, we propose a novel approach for text classification using GNN. We build a bipartite graph from the input corpus and then apply the coarsening technique of the multilevel optimization to generate ten contracted graphs to analyze the GNN\u2019s performance, training time, and memory consumption as the graph is gradually reduced. Although we conducted experiments on text classification, we emphasize that the proposed method is not bound to a specific task and, thus, can be generalized to different problems modeled as bipartite graphs. Experiments on datasets from various domains and sizes show that our approach reduces memory consumption and training time without significantly losing performance.","The growing demand for sustainable development brings a series of information technologies to help agriculture production. Especially, the emergence of machine learning applications, a branch of artificial intelligence, has shown multiple breakthroughs which can enhance and revolutionize plant pathology approaches. In recent years, machine learning has been adopted for leaf disease classification in both academic research and industrial applications. Therefore, it is enormously beneficial for researchers, engineers, managers, and entrepreneurs to have a comprehensive view about the recent development of machine learning technologies and applications for leaf disease detection. This study will provide a survey in different aspects of the topic including data, techniques, and applications. The paper will start with publicly available datasets. After that, we summarize common machine learning techniques, including traditional (shallow) learning, deep learning, and augmented learning. Finally, we discuss related applications. This paper would provide useful resources for future study and application of machine learning for smart agriculture in general and leaf disease classification in particular.","For some named entities in the Chinese finance domain that are long, with difficult to delineate boundaries and diverse forms of expression, we propose a method based on pretrained language models for named entity recognition with enhanced features. First, the method considers entity boundary delineation and entity classification as two separate tasks and learns enhanced Chinese character features by introducing a gating-based multi-channel attention mechanism to delineate financial entity boundaries on the basis of a pretrained language model. Then, the boundary demarcation results are input into the pretrained language model in the form of mask units for data enhancement. Subsequently, document-level entity-based enhancement features are introduced to construct a finance entity classification model. We experimentally identified the best-performing Chinese pretrained language model from several state-of-the-art models and then embedded it into our method to compare against other benchmark models. The experimental results showed that our model is superior to other benchmark models on the named entity recognition task in the finance domain.","Geophysical reservoir characterization is a significant task in the oil and gas industry and elastic logs prediction of subsurface formations is a fundamental aspect of this process. However, elastic log prediction in a high-dimensional and complex geological environment, such as the Lower Indus Basin Pakistan, poses a significant challenge where traditional empirical methods often fail to provide competitively accurate results. Therefore, this study proposes a novel machine learning approach that combines unsupervised clustering (K-means) and ensemble-based machine learning (random forest) to improve prediction accuracy. By clustering data based on statistical similarity and ensemble algorithms to each cluster, the methodology addresses the challenges of sonic log prediction in the Lower Indus Basin (Pakistan). This approach was evaluated using real-world data, outperforming several baseline methods with a root mean square error of 98% accuracy. Its effectiveness to predict elastic log makes it a valuable tool in reservoir characterization, earthquake analysis, and geothermal energy exploration. Overall, combining this methodology with other techniques can enhance seismic data analysis and enable better decision-making in the oil and gas industry. This novel approach presents an effective solution for predicting sonic log in the Lower Indus Basin and contributes to advancements in geophysical reservoir characterization.\nHighlights\n\u2022\nA novel machine learning method is proposed to predict elastic log response.\n\u2022\nThis method integrates K-means clustering with random forest for prediction.\n\u2022\nThe accuracy of predictions significantly improved in complex geological settings.\n\u2022\nThis method can predict petrophysical parameters in complex geological environment.\n\u2022\nThis proposed approach effectively reduces cumbersome human efforts and save time.","Deep neural networks have shown promising results on a wide variety of tasks using large-scale and well-annotated training datasets. However, data collected from real-world applications can suffer from two prevalent biases, i.e., long-tailed class distribution and label noise. Previous efforts on long-tailed learning and label-noise learning can only address a single type of data bias, leading to a severe deterioration of their performance. In this paper, we propose a distance-based sample selection algorithm called Stochastic Feature Averaging (SFA), which fits a Gaussian using the exponential running average of class centroids to capture uncertainty in representation space due to label noise and data scarcity. With SFA, we detect noisy samples based on their distances to class centroids sampled from this Gaussian distribution. Based on the identified clean samples, we then propose to train an auxiliary balanced classifier to improve the generalization for the minority class and facilitate the update of Gaussian parameters. Extensive experimental results show that SFA can enhance the performance of existing methods on both simulated and real-world datasets. Further, we propose to combine SFA with the sample-selection approach, distribution-robust, and noise-robust loss functions, resulting in significant improvement in performance over the baselines. Our code is available at https://github.com/HotanLee/SFA.","How can we accurately identify new memory workloads while classifying known memory workloads? Verifying DRAM (Dynamic Random Access Memory) using various workloads is an important task to guarantee the quality of DRAM. A crucial component in the process is open-set recognition which aims to detect new workloads not seen in the training phase. Despite its importance, however, existing open-set recognition methods are unsatisfactory in terms of accuracy since they fail to exploit the characteristics of workload sequences.\nIn this article, we propose Acorn, an accurate open-set recognition method capturing the characteristics of workload sequences. Acorn extracts two types of feature vectors to capture sequential patterns and spatial locality patterns in memory access. Acorn then uses the feature vectors to accurately classify a subsequence into one of the known classes or identify it as the unknown class. Experiments show that Acorn achieves state-of-the-art accuracy, giving up to 37% points higher unknown class detection accuracy while achieving comparable known class classification accuracy than existing methods.","The increasing use of machine learning in high-stakes domains \u2013 where people\u2019s livelihoods are impacted \u2013 creates an urgent need for interpretable, fair, and highly accurate algorithms. With these needs in mind, we propose a mixed integer optimization (MIO) framework for learning optimal classification trees \u2013 one of the most interpretable models \u2013 that can be augmented with arbitrary fairness constraints. In order to better quantify the \u201cprice of interpretability\u201d, we also propose a new measure of model interpretability called decision complexity that allows for comparisons across different classes of machine learning models. We benchmark our method against state-of-the-art approaches for fair classification on popular datasets; in doing so, we conduct one of the first comprehensive analyses of the trade-offs between interpretability, fairness, and predictive accuracy. Given a fixed disparity threshold, our method has a price of interpretability of about 4.2 percentage points in terms of out-of-sample accuracy compared to the best performing, complex models. However, our method consistently finds decisions with almost full parity, while other methods rarely do.","Multi-source information fusion is an effective method to handle pattern classification problems. Dempster\u2013Shafer evidence theory (DSET) plays an important role in handling uncertainty problems in multi-source information fusion. However, highly conflicting evidence in DSET may cause counter-intuitive fusion results. Belief divergence theory is one of the solutions to conflict management, which is also beneficial for the improvement of accuracies of pattern classification. In this paper, a novel belief divergence measurement method, fractal belief Jensen\u2013Shannon (F B J S) divergence is proposed to better measure the discrepancy between Basic probability assignments (BPAs) and address the problem of highly conflicting evidence in DSET. The proposed F B J S divergence is the first belief divergence that incorporates the belief divergence theory and the concept of fractal. In addition, it has the properties of non-negativeness and symmetry. Then, based on F B J S divergence, a novel multi-source information fusion algorithm is proposed. Ultimately, the proposed algorithm is effectively applied to solve a pattern classification problem with a higher classification accuracy.","This paper introduces new flexible loss functions for binary classification in Gradient-Boosted Decision Trees (GBDT) that combine Dice-based and cross-entropy-based losses and offer link functions from either a generalized extreme value (GEV) or exponentiated exponential logistic (EEL) distribution. Testing 27 different GBDT models using XGBoost on a Freddie Mac mortgage loan database showed that the choice of the loss function is useful. Specifically, when the class imbalance ratio (IR) is less than 99, using a skewed GEV distribution-based link function in XGBoost enhances discriminatory power and classification accuracy while retaining a simple model structure, which is particularly important in credit scoring applications. In cases where class imbalances are severe, typically between IRs of 99 and 200, we found that an advanced loss function, which is composed of a symmetric hybrid loss function and a link derived from a positively skewed EEL distribution, outperforms other XGBoost variants. Based on our findings, the accuracy improvements of these proposed extensions result in lower misclassification costs, which are especially evident when IR is below 99, which results in higher profitability for the business. Furthermore, the study highlights the transparency associated with GBDT, which is also an integral component of financial applications. Researchers and practitioners can use these insights to create more accurate and discriminative machine learning models, with possible extensions to other GBDT implementations and machine learning techniques that take into account loss functions. The source code for the proposed approach is publicly available at https://github.com/jm-ml/flexible-losses-for-binary-classification-with-GBDT.","Highlights\n\u2022\nA novel hyperspectral band selection network is proposed for seed classification.\n\u2022\nBand attention and sparse constraint (SC) maximizes the removal of redundant bands.\n\u2022\nA new loss function is defined to solve the gradient update problem caused by SC.\n\u2022\nThe selected bands carry important spectrochemical information.\n\u2022\nThis method is also applicable to other hyperspectral data of food and agro-products.\nAbstract\nThe development of a real-time online system for rapid and nondestructive identification of seed varieties can greatly improve production efficiency in modern agriculture. Hyperspectral imaging (HSI) is a powerful tool for seed variety identification. Nevertheless, hyperspectral data are not only high in dimensionality but also contain redundant information, which is very unfriendly to real-time online applications. Selecting a few representative bands from the entire working spectral region can significantly reduce the equipment cost and computational load of HSI. In the field of food and agr-products quality evaluation, Band selection (BS) methods based on chemometrics have been dominant for a long time. Most of these methods, however, fail to take full account of the nonlinearities and global interactions between spectral bands, which may result in the selection of some adjacent bands that still retain more redundant information. In this paper, a novel BS network is proposed, which is composed of sparse band attention module and classification net module. The former is used to generate weight of each band, and sparse constraint is applied to the weights of redundant bands, while the latter is used to achieve high-performance classification with reweighted data. Furthermore, to solve the problem of gradient updating caused by sparse constraint, a auxiliary loss function is defined to assist optimization. Finally, comparative experiments is conducted on our maize seed hyperspectral dataset. The results demonstrate that the presented method selects a subset of informative bands with less redundant information to obtain better classification performance and outperforms several other existing BS methods.","In this paper, we examine several methods of acquiring Czech data for automated fact-checking, which is a task commonly modeled as a classification of textual claim veracity w.r.t. a corpus of trusted ground truths. We attempt to collect sets of data in form of a factual claim, evidence within the ground truth corpus, and its veracity label (supported, refuted or not enough info). As a first attempt, we generate a Czech version of the large-scale FEVER dataset built on top of Wikipedia corpus. We take a hybrid approach of machine translation and document alignment; the approach and the tools we provide can be easily applied to other languages. We discuss its weaknesses, propose a future strategy for their mitigation and publish the 127k resulting translations, as well as a version of such dataset reliably applicable for the Natural Language Inference task\u2014the CsFEVER-NLI. Furthermore, we collect a novel dataset of 3,097 claims, which is annotated using the corpus of 2.2 M articles of Czech News Agency. We present an extended dataset annotation methodology based on the FEVER approach, and, as the underlying corpus is proprietary, we also publish a standalone version of the dataset for the task of Natural Language Inference we call CTKFactsNLI. We analyze both acquired datasets for spurious cues\u2014annotation patterns leading to model overfitting. CTKFacts is further examined for inter-annotator agreement, thoroughly cleaned, and a typology of common annotator errors is extracted. Finally, we provide baseline models for all stages of the fact-checking pipeline and publish the NLI datasets, as well as our annotation platform and other experimental data.","Skip Background Section\nBackground\nSeismic signals are useful for earthquake detection and classification. Therefore, various artificial intelligence (AI) models have been used with seismic signals to develop automated earthquake detection systems. Our primary goal is to present an accurate feature engineering model for earthquake detection and classification using seismic signals.\nSkip Material and model Section\nMaterial and model\nWe have used a public dataset in this work containing three categories: (1) noise, (2) P waves, and (3) S waves. P and S waves are used to define earthquakes. We have presented two applied use cases using this dataset: (i) earthquake detection and (ii) wave classification. In this work, a new textural feature extractor has been presented by using a graph pattern similar to a butterfly. Thus, this feature extraction function is named Butterfly pattern (BFPat). We have created a new feature engineering architecture by deploying BFPat, statistics, and wavelet packet decomposition (WPD) functions. The recommended BFPat and statistics have been applied to the wavelet bands created by WPD and the raw seismic signals. Multilevel features have been extracted from both frequency and space domains. The used dataset contains signals with three channels. Using these three channels, seven signals have been created. Seven feature vectors have been created from 7 input signals used in this study. The most meaningful/informative features from the generated feature set are then selected using the iterative neighborhood component analysis feature selector method. Seven chosen feature vectors have been considered as inputs of the two shallow classifiers: k nearest neighbors (kNN) and support vector machine (SVM). A total of 14 (=7 \u00d7 2) results have been obtained in the classification phase. A majority voting process was applied in the last phase to choose the best results and improve the classification performance.\nSkip Results Section\nResults\nWe have presented two use cases for our new BFPat method in this work to obtain superior results. Our model reached an accuracy of 99.58% in detecting the earthquake detection and 93.13% accuracy in 3-class classifications of waves.\nSkip Conclusions Section\nConclusions\nOur recommended model has achieved over 90% classification performance for both cases. Also, we have presented the most valuable channel and combinations in our work. Our developed system is ready to be tested with a bigger database.","Dempster\u2013Shafer evidence theory (DSET) is extensively employed in multi-source data fusion applications. Nonetheless, when belief probability assignments (BPAs) exhibit considerable conflict, unexpected results can occur. To address this limitation, the high-order fractals are explored and a K-order fractal-based Kullback\u2013Leibler divergence (KO-FKL) is introduced, which defines the K-order as the optimal fractal epoch. This measure is employed to quantify the divergence between BPAs and demonstrates superior performance in assessing the conflict between two BPAs in numerical examples, compared to existing belief divergence methods. To utilize the KO-FKL divergence measure to real-world problems, a novel KO-FKL-based multi-source data fusion (KO-FKL-MSDF) algorithm is designed. Through comparisons with well-known related methods, our proposed KO-FKL-MSDF algorithm demonstrates superiority and enhanced robustness. Lastly, the KO-FKL-MSDF algorithm is applied to real-world classification problems, underlining its high practical applicability.\nHighlights\n\u2022\nHigh-order fractal BPA and KL divergence using continuous Pignistic process.\n\u2022\nOptimal fractal high-order K via proposed Difference of Deng entropy convergence.\n\u2022\nK-order fractal KL divergence outperforms existing measures in plentiful examples.\n\u2022\nKO-FKL multi-source data fusion algorithm via extensive validation and analysis.\n\u2022\nKO-FKL-MSDF algorithm excels in pattern classification on multiple datasets.","Image classification is one of the most fundamental tasks in Computer Vision. In practical applications, the datasets are usually not as abundant as those in the laboratory and simulation, which is always called as Data Hungry. How to extract the information of data more completely and effectively is very important. Therefore, an Adaptive Data Augmentation Framework based on the tensor T-product Operator is proposed in this paper, to triple one image data to be trained and gain the result from all these three images together with only &lt;0.1% increase in the number of parameters. At the same time, this framework serves the functions of column image embedding and global feature intersection, enabling the model to obtain information in not only spatial but frequency domain, and thus improving the prediction accuracy of the model. Numerical experiments have been designed for several models, and the results demonstrate the effectiveness of this adaptive framework. Numerical experiments show that our data augmentation framework can improve the performance of original neural network model by 2%, which provides competitive results to state-of-the-art methods.","Remote Sensing (RS) has been widely utilized in various Earth Observation (EO) missions, including land cover classification and environmental monitoring. Unlike computer vision tasks on natural images, collecting remote sensing data is more challenging. To fully exploit the available data and leverage the complementary information across different data sources, we propose a novel approach called Multimodal Transformer for Remote Sensing (RsMmFormer) for image classification, which utilizes both Hyperspectral Image (HSI) and Light Detection and Ranging (LiDAR) data. In contrast to the conventional Vision Transformer (ViT), which does not incorporate the inherent biases and assumptions of convolutions, we improve our RsMmFormer model by incorporating convolutional layers. This allows us to integrate the favorable characteristics of convolutional neural networks (CNNs). Next, we introduce the Multi-scale Multi-head Self-Attention (MSMHSA) module, which enables learning detailed representations, facilitating the detection of small targets occupying only a few pixels in the remote sensing image. The proposed MSMHSA module facilitates the integration of Hyperspectral Imaging (HSI) and LiDAR data in a progressive and detailed manner, effectively attending to both global and local contexts using self-attention mechanisms. Comprehensive experiments conducted on popular benchmarks such as Trento and MUUFL showcase the effectiveness and superiority of our proposed RsMmFormer model for remote sensing image classification.","The acquisition of Twitter by Elon Musk has spurred controversy and uncertainty among Twitter users. The move raised both praise and concerns, particularly regarding Musk's views on free speech. As a result, a large number of Twitter users have looked for alternatives to Twitter. Mastodon, a decentralized micro-blogging social network, has attracted the attention of many users and the general media. In this paper, we analyze the migration of 136,009 users from Twitter to Mastodon. We inspect the impact that this has on the wider Mastodon ecosystem, particularly in terms of user-driven pressure towards centralization. We further explore factors that influence users to migrate, highlighting the effect of users' social networks. Finally, we inspect the behavior of individual users, showing how they utilize both Twitter and Mastodon in parallel. We find a clear difference in the topics discussed on the two platforms. This leads us to build classifiers to explore if migration is predictable. Through feature analysis, we find that the content of tweets as well as the number of URLs, the number of likes, and the length of tweets are effective metrics for the prediction of user migration.","SVM utilizes the hinge loss function and maximum margin to find the separating hyperplane. In SVM, only the boundary instances/support vectors confine the separating hyperplane, making it susceptible to noisy samples near the decision boundary. This work proposes a novel noise-robust eagle loss function and presents Eagle-SVM based on the proposed loss function. The formulation of the eagle loss function was motivated by examining the state-of-the-art loss assignment policy. It allocates the loss value as per instance significance. The more important instances are assigned higher loss values, whereas those corresponding to outliers and noise are assigned lower loss values. The experiments were conducted on the benchmark datasets downloaded from the UCI repository to compare the performance of the proposed variant of SVM with hinge loss SVM, pinball loss SVM, \u03f5-pinball loss SVM, SVM-CL, relabel SVM, 2medianSVM and 2meanSVM. The experimental results demonstrate that the eagle loss SVM outperforms all the state-of-the-art variants of SVM and is robust due to the incorporation of the novel loss assignment policy.\nHighlights\n\u2022\nA noise-robust loss function entitled Eagle Loss Function.\n\u2022\nNoise-robust EagleSVM using Eagle Loss Function.\n\u2022\nRobust classifiers towards feature noise and target noise.","Recognizing the species composition of an ecosystem is essential for conservation and land management. This study presents the software Class3Dp, a supervised classifier of vegetation species for coloured point clouds. Class3Dp is run through a graphical user interface (GUI) that allows for the selection of training samples from RGB or MS (multispectral) clouds and their classification based on geometric, spectral and neighbourhood features, along with different machine learning methods, obtaining the point cloud classified according to the classes (species) introduced. A case study is shown where a classification of ground and vegetation is carried out, obtaining an overall accuracy (OA) of 0.94 in the RGB classification and 0.95 in the MS. Points classified as vegetation were re-classified in the species Anthyllis cytisoides L., Chamaerops humilis L., Cistus monspeliensis L., Pistacia lentiscus L. and Quercus coccifera L., obtaining an OA of 0.86 in the RGB classification and 0.87 in the MS.\nHighlights\n\u2022\nClass3Dp is a supervised classifier software of coloured point clouds based on 3D and spectral information.\n\u2022\nThe software is designed to classify plant species in RGB and multispectral point clouds.\n\u2022\nClass3Dp calculates up to 48 features and supports five machine learning models.","Tsetlin machine (TM) is a logic-based machine learning approach with the crucial advantages of being transparent and hardware-friendly. While TMs match or surpass deep learning accuracy for an increasing number of applications, large clause pools tend to produce clauses with many literals (long clauses). As such, they become less interpretable. Further, longer clauses increase the switching activity of the clause logic in hardware, consuming more power. This paper introduces a novel variant of TM learning - Clause Size Constrained TMs (CSC-TMs) - where one can set a soft constraint on the clause size. As soon as a clause includes more literals than the constraint allows, it starts expelling literals. Accordingly, oversized clauses only appear transiently. To evaluate CSC-TM, we conduct classification, clustering, and regression experiments on tabular data, natural language text, images, and board games. Our results show that CSC-TM maintains accuracy with up to 80 times fewer literals. Indeed, the accuracy increases with shorter clauses for TREC, IMDb, and BBC Sports. After the accuracy peaks, it drops gracefully as the clause size approaches a single literal. We finally analyze CSC-TM power consumption and derive new convergence properties.","Frauds using credit card are easily done by the fraudsters. Due to increase in fraud rates all over the world, various machine learning algorithms are being used by analysts and researchers to detect and analyze frauds in online transactions. However, training data set may have a few instances of one and more instances of another class in case of binary classification particular class which makes result biased. Hence, this paper sets an objective to give methodology which is able to detect fraud accurately in case for skewness of data. The proposed method compares different techniques to handle imbalance problem and chooses best approach out of these and uses XGBoost as classifier to predict whether transaction is fraudulent or not. The developed method is evaluated using European credit card fraud dataset and obtained better F1 score, recall and accuracy as 82.78%, 78.9% and 99.3% respectively as compared to other algorithms taken under study.","Over the past few decades, a lot of new neural network architectures and deep learning (DL)-based models have been developed to tackle problems more efficiently, rapidly, and accurately. For classification problems, it is typical to utilize fully connected layers as the network head. These dense layers used in such architectures have always remained the same \u2013 they use a linear transformation function that is a sum of the product of output vectors with weight vectors, and a trainable linear bias. In this study, we explore a different mechanism for the computation of a neuron\u2019s output. By adding a new feature, involving a product of higher order output vectors with their respective weight vectors, we transform the conventional linear function to higher order functions, involving powers over two. We compare and analyze the results obtained from six different transformation functions in terms of training and validation accuracies, on a custom neural network architecture, and with two benchmark datasets for image classification (CIFAR-10 and CIFAR-100). While the dense layers perform better in all epochs with the new functions, the best performance is observed with a quadratic transformation function. Although the final accuracy achieved by the existing and new models remain the same, initial convergence to higher accuracies is always much faster in the proposed approach, thus significantly reducing the computational time and the computational resources required. This model can improve the performance of every DL architecture that uses a dense layer, with remarkably higher improvement in larger architectures that incorporate a very high number of parameters and output classes.","Shapelets are subsequences that are effective for classifying time-series instances. Learning shapelets by a continuous optimization has recently been studied to improve computational efficiency and classification performance. However, existing methods have employed predefined and fixed shapelet lengths during the continuous optimization, despite the fact that shapelets and their lengths are inherently interdependent and thus should be jointly optimized. To efficiently explore shapelets of high quality in terms of interpretability and inter-class separability, this study makes the shapelet lengths continuous and learnable. The proposed formulation jointly optimizes not only a binary classifier and shapelets but also shapelet lengths. The derived SGD optimization can be theoretically interpreted as improving the quality of shapelets in terms of shapelet closeness to the time series for target / off-target classes. We demonstrate improvements in area under the curve, total training time, and shapelet interpretability on UCR binary datasets.","The robustness of graph classification models plays an essential role in providing highly reliable applications. Previous studies along this line primarily focus on seeking the stability of the model in terms of overall data metrics (e.g., accuracy) when facing data perturbations, such as removing edges. Empirically, we find that these graph classification models also suffer from semantic bias and confidence collapse issues, which substantially hinder their applicability in real-world scenarios. To address these issues, we present MGRL, a multi-view representation learning model for graph classification tasks that achieves robust results. Firstly, we proposes an instance-view consistency representation learning method, which utilizes multigranularity contrastive learning technique to perform semantic constraints on instance representations at both the node and graph levels, thus alleviating the semantic bias issue. Secondly, we proposes a class-view discriminative representation learning method, which employs the prototype-driven class distance optimization technique to adjust intra- and interclass distances, thereby mitigating the confidence collapse issue. Finally, extensive experiments and visualizations on eight benchmark dataset demonstrate the effectiveness of MGRL.","The North Atlantic Right Whale (NARW) population is currently teetering on the brink of extinction, with a mere approximate count of 350 individuals remaining. These animals have been protected under the Endangered Species Act since 1970. Today, the survival of right whales is imperiled primarily due to vessel collisions, net entanglements, and habitat degradation. This paper presents a novel system of animal-computer interaction founded on the identification of bioacoustic signatures. Initially, NARWs\u2019 vocalizations were transformed into spectrograms, which were subsequently inputted into a Convolutional Neural Network (CNN). To enhance robustness against environmental noise, techniques such as time warping, frequency masking, and time masking were employed. The outcomes of our study indicate that the proposed system holds potential for establishing a closed-loop interaction framework between vessels and NARWs. This framework could enable vessels to adapt their speed or avoid routes frequented by NARWs. Furthermore, this article discusses the potential benefits of employing networked sensors, such as Internet of Things (IoT) devices, to augment NARW monitoring and data collection efforts.","Airborne pollen identification is crucial to help patients prevent pollinosis symptoms. Existing data-driven methods rely on large-scale pollen images with simple backgrounds. In real scenarios, the background is complex and the data scale is small. Therefore, these methods suffer from two challenges: (1) Irrelevant information interference; (2) Incomplete feature attention. To overcome these challenges, we propose a prior knowledge-guided deep feature learning (PK-DFL) for real-world optical microscope image classification. Its main steps are as follows: Pollen location is designed to locate pollen grains based on color features, aiming to boost the accuracy of shape and texture prior feature extraction. Shape-texture awareness helps to extract the shape and texture of pollen grains via predefined feature extractors (i.e., a set of shape descriptors and an improved SFTA). These features are used to construct two types of prior knowledge, namely shape-texture attention maps (STA maps) and shape-texture feature vectors (STF vectors). Pollen classification uses a deep network (CNN) to classify pollen via imitating the pollen identification procedure of palynologists. It uses STA maps to weight pollen images and convolutional feature maps for instructing the CNN to focus on critical areas of pollen images (for the first challenge). STF vectors are employed to obtain the inter-class similarity of pollen via template matching. This information is further converted to soft targets that are used to supervise the CNN attending to comprehensive key features (for the second challenge). Extensive experiments on real-world datasets demonstrate the effectiveness of our PK-DFL (with accuracy and F1-score over 88%).\nHighlights\n\u2022\nA deep learning model for identifying allergic pollen like a palynologist.\n\u2022\nPollen location and predefined feature extractors for shape-texture extraction.\n\u2022\nAttention instruction manner for guiding CNNs to focus on critical areas.\n\u2022\nSoft target supervision manner for guiding CNNs to attend to key features.\n\u2022\nExtensive experiments for performance evaluation (accuracy over 88%).","Skip Abstract Section\nAbstract\nBreast cancer is a divergent and prominent cancer that is responsible for the morbidity and mortality of women throughout the world. This paper aims at early detection and accurate diagnosis of this fatal disease, which is one of the most important steps in breast cancer treatment. Therefore, various nested ensemble machine learning techniques are used to help doctors determine breast cancer at an early stage. The two-layer nested ensemble model has been proposed, which encompasses stacking and voting techniques to detect benign and malignant breast cancer tumors. A total of four two-layer nested ensemble models have been proposed. S(NaiveBayes)-V(3-Meta_Learner), S(BayesNet)-V(3-Meta_Learner), S(NaiveBayes)-V(4-Meta_Learner), and S(BayesNet)-V(4-Meta_Learner) have been designed to contain base learners and meta learners. The experiments have been conducted with the k-fold cross-validation technique for model evaluation. The proposed model is capable of classifying benign and malignant breast cancer tumors with 99.50% accuracy. The aforementioned four models have been compared with previous works in terms of classification accuracy, ROC, recall, precision, TP rate, FP rate, and F1 measure. The experiments showed that the proposed two-layer nested ensemble model S(BayesNet)-V(4-Meta_Learner) performed better than the other three models mentioned supra and competed with all the previously published works. This would help the scientific community and health practitioners diagnose breast cancer with early and accurate results.","In an actual industrial scenario, machines typically operate normally for the majority of the time, with malfunctions occurring only occasionally. As a result, there is very little recorded data on defects. Consequently, the fault diagnostic dataset becomes imbalanced, with a significantly lower number of fault samples compared to normal samples. Furthermore, with the rapid development of the manufacturing industry, the increasing complexity of machines and equipment leads to various challenges in collecting fault data, such as noise, within-class imbalance, multi-class imbalance, and time series imbalance. It is worth noting that this study is the first to comprehensively summarize these four specific challenges. Therefore, addressing these issues has become a critical research focus and a pain point in the field of fault diagnosis, and numerous solutions have emerged. This study provides a comprehensive overview of these solutions at three levels: data preprocessing, feature extraction, and classifier improvement. It also describes the applications of imbalanced data classification methods, including pure resampling techniques, as well as sampling techniques that combine resampling algorithms with feature extraction and classifier improvement in industrial scenarios. Finally, we summarize the challenges facing imbalanced data classification research and suggest potential directions for future studies.\nHighlights\n\u2022\nThis paper showcases using imbalance classification for diagnosing industrial faults.\n\u2022\nThis study is the first to comprehensively summarize these five specific challenges.\n\u2022\nChallenges include noise, class overlap, and imbalance within/multi-class/time series.\n\u2022\nStudy covers data pre-processing, feature extraction, and classifier improvement.\n\u2022\nStudy suggests the future research directions for imbalanced fault diagnosis.","The primary research objective of this study is to develop an algorithm pipeline for recognizing human locomotion activities using multimodal sensor data from smartphones, while minimizing prediction errors due to data differences between individuals. The multimodal sensor data provided for the 2023 SHL recognition challenge comprises three types of motion data and two types of radio sensor data. Our team, \u2018HELP,\u2019 presents an approach that aligns all the multimodal data to derive a form of vector composed of 106 features, and then blends predictions from multiple learning models which are trained using different number of feature vectors. The proposed neural network models, trained solely on data from a specific individual, yield F1 scores of up to 0.8 in recognizing the locomotion activities of other users. Through post-processing operations, including the ensemble of multiple learning models, it is expected to achieve a performance improvement of 10% or greater in terms of F1 score.","In pattern recognition and data mining a data set is named skewed or imbalanced if it contains a large number of objects of certain type and a very small number of objects of the opposite type. The imbalance in data sets represents a challenging problem for most classification methods, this is because the generalization power achieved for classic classifiers is not good for skewed data sets. Many real data sets are imbalanced, so the development of new methods to face this problem is necessary. The SVM classifier has an exceptional performance for data sets that are not skewed, however for imbalanced sets the optimal separating hyper plane is not enough to achieve acceptable results. In this paper a novel method that improves the performance of SVM for skewed data sets is presented. The proposed method works by exciting the support vectors and displacing the separating hyper plane towards majority class. According to the results obtained in experiments with different skewed data sets, the method enhances not only the accuracy but also the sensitivity of SVM classifier on this kind of data sets.","Exposure to UV rays due to global warming can lead to sunburn and skin damage, ultimately resulting in skin cancer. Early prediction of this type of cancer is crucial. A detailed review in this paper explores various algorithms, including machine learning (ML) techniques as well as deep learning (DL) techniques. While deep learning strategies, particularly CNNs, are commonly employed for skin cancer identification and classification, there is also some usage of machine learning and hybrid approaches. These techniques have proven to be effective classifiers of skin lesions, offering promising results for early detection. The paper analyzes various researchers\u2019 reviews on skin cancer diagnosis to identify a suitable methodology for improving diagnostic accuracy. A publicly available dataset of dermoscopic images retrieved from the ISIC archive has been trained and evaluated. Performance analysis is done, considering metrics such as test and validation accuracy. The results indicate that the RF(random forest) algorithm outperforms other machine learning algorithms in both scenarios, with accuracies of 58.57% without augmentation and 87.32% with augmentation. MobileNetv2, ensemble of Dense Net and Inceptionv3 exhibit superior performance. During training without augmentation, MobileNetv2 achieves an accuracy of 88.81%, while the ensemble model achieves an accuracy of 88.80%. With augmentation techniques applied, the accuracies improved to 97.58% and 97.50%, respectively. Furthermore, experiment with a customized convolutional neural network (CNN) model was also conducted, varying the number of layers and applying various hyperparameter tuning methodologies. Suitable architectures, including a CNN with 7 layers and batch normalization, a CNN with 5 layers, and a CNN with 3 layers were identified. These models achieved accuracies of 77.92%, 97.72%, and 98.02% on the raw data and augmentation datasets, respectively. The experimental results suggest that these techniques hold promise for integration into clinical settings, and further research and validation are necessary. The results highlight the effectiveness of transfer learning models, in achieving high accuracy rates. The findings support the future adoption of these techniques in clinical practice, pending further research and validation.","Parkinson\u2019s disease (PD) is the second most common neurodegenerative disorder, as reported by the World Health Organization (WHO). In this paper, we propose a direct three-Class PD classification using two different modalities, namely, MRI and DTI. The three classes used for classification are PD, Scans Without Evidence of Dopamine Deficit (SWEDD) and Healthy Control (HC). We use white matter (WM) and gray matter (GM) from the MRI and fractional anisotropy (FA) and mean diffusivity (MD) from the DTI to achieve our goal. We train four separate CNNs on the above four types of data. At the decision level, the outputs of the four CNN models are fused with an optimal weighted average fusion technique. We achieve an accuracy of 95.53% for the direct three-class classification of PD, HC and SWEDD on the publicly available PPMI database. Extensive comparisons including a series of ablation studies clearly demonstrate the effectiveness of our proposed solution.","The greatest significant contributor to cancer-related morbidity and mortality worldwide is malignant lung tumors. Lung cancer frequency has been seen to be on the rise recently. Lung cancer histopathology diagnosis is a crucial part of the patient\u2019s treatment. The current study aims to demonstrate the efficiency of convolutional neural networks for the identification of squamous cell carcinoma and adenocarcinoma of the lung and colon by investigating the diagnosis of histopathology images. Five state-of-the-art pre-trained (ImageNet) convolutional neural network architectures, VGG-19, InceptionResNetV2, DenseNet201, EfficientNetB6, and MobileNetV2, are employed in this investigation to tri-categorize lung cancer images (normal, adenocarcinoma, and squamous cell carcinoma), together with colon cancer images (normal and adenocarcinoma). Regularization strategies have been applied to fine-tune the learning rate for improving accuracy. The LC25000 dataset has been used to validate the proposed method. EfficientNetB6, VGG19, InceptionResNetV2, DenseNet201, and MobileNetV2 accuracy on test data is reported to be 93.12, 98.00, 97.92, 99.12, and 99.32 percent respectively.","The traditional k-mean clustering algorithm has some drawbacks, such as the need to manually determine the initial K value in advance, and the value may not match the real data distribution, and is susceptible to noise, thus causing classification errors. In this paper, we take the lead in improving the contour coefficient solving code and the k-mean clustering algorithm, so that the two improved codes can cooperate with each other to improve the accuracy of the results of the algorithm.\nFirstly, we use variance comparison to sub-classify the dataset, aiming to find the initial clustering center of the dataset, use the k-means clustering algorithm to classify the dataset, and finally introduce the contour coefficient to evaluate the classification results. Finally, we apply this algorithm to an example of artifact classification and train the improved algorithm with a large amount of data, and the results demonstrate that the contour coefficient-k-mean clustering algorithm yields high accuracy in the classification results.","Given a large convolutional neural network (CNN) with hundreds of layers, when can the input data be correctly classified? How many layers does each image require? We propose an architecture with a mid-network classifier to classify certain images at earlier points in the model. When the network is very confident about an image, having high activations, then that individual image will be classified early. The number of computations and the average number of convolutions will be reduced if certain images can be classified earlier. In addition, the mid-network classification task is more difficult because fewer features have been extracted at earlier points in the network. Thus, the output and mid-network classifier will work together to correctly classify each image as fast as possible while preserving the accuracy. This proposed method has been implemented into well known computer vision architectures, like ResNet and GoogLeNet Inception. We have achieved large runtime improvements while limiting the accuracy degradation.","Multi-dimensional classification (MDC) assumes that each instance has multiple heterogeneous class spaces simultaneously, and each class variable describes the semantic information of instances from a specific dimension. Recent studies have proven that encoding heterogeneous class spaces into a special logical-label space and employing the label enhancement technique to learn latent real-number labels (i.e., label distributions) of instances is an effective strategy for MDC. However, the adopted label enhancement methods can result that data whose features are quite different to each other have similar label distributions. To tackle this problem, we propose a novel probability-based label enhancement approach for MDC. Specifically, manifold structures of the feature and label distribution spaces are transformed into two different probability distributions, and we expect them to be close. Subsequently, it makes label distributions of samples whose features have large differences be more differentiated. Moreover, the logical-label mapping and reconstruction terms are designed to preserve the intrinsic information from the logical-label space. Besides, an improved multi-output support vector regression is developed as the prediction model, where we introduce mean squared error to reduce the risk of model underfitting. Experimental results on ten benchmark datasets clearly validate the superiority of our method over state-of-the-art MDC baselines.","Real-world applications of artificial intelligence that can potentially harm human beings should be able to express uncertainty about the made predictions. Probabilistic deep learning (DL) methods (e.g., variational inference [VI], VI last layer [VI-LL], Monte-Carlo [MC] dropout, stochastic weight averaging - Gaussian [SWA-G], and deep ensembles) can produce a predictive uncertainty but require expensive MC sampling techniques. Therefore, we evaluated if the probabilistic DL methods are uncertain when making incorrect predictions for an open-source driver intention recognition dataset and if a surrogate DL model can reproduce the uncertainty estimates. We found that all probabilistic DL methods are significantly more uncertain when making incorrect predictions at test time, but there are still instances where the models are very certain but completely incorrect. The surrogate DL models trained on the MC dropout and VI uncertainty estimates were capable of reproducing a significantly higher uncertainty estimate when making incorrect predictions.","Federated learning (FL), a decentralized machine learning technique, enhances privacy by enabling multiple devices to collaboratively train a model without transferring data to a central server. FL is used in Human Activity Recognition (HAR) problems, where multiple users generating private wearable data share models with a server to learn a useful global model. However, FL may compromise data privacy through model information sharing during training. Moreover, it adheres to a one-size-fits-all approach toward data privacy, potentially neglecting varied user preferences in collaborative scenarios such as HAR. In response to these challenges, this paper presents a collaborative learning framework integrating differential privacy (DP) and FL, thus providing a tailored approach to privacy protection. While some existing works integrate DP and FL, they do not allow clients to have different privacy preferences. In this work, we introduce a framework that allows different clients to have different privacy preferences and hence more flexibility in terms of privacy. In our framework, DP adds individualized noise to individual clients\u2019 gradient updates for privacy. However, such noised updates can also be interpreted as an attack on the FL system. Defending against these attacks might result in excluding honest private clients altogether from training, posing a fairness concern. On the other hand, not having any defensive measures might allow malicious users to attack the system, posing a security issue. Thus, to address security and fairness, our framework incorporates a client selection strategy that protects the global model from malicious clients and provides fair model access to honest private clients. We have demonstrated the effectiveness of our system on a HAR dataset and provided insights into our framework\u2019s privacy, utility, and fairness.","Data-driven fault diagnosis approaches have attracted considerable attention in the past few years, and promising diagnostic performance has been achieved with sufficient monitoring data. However, in real industrial scenarios, individual users often struggle to collect enough labeled data. Meanwhile, direct data aggregation from multiple users is not always feasible due to data privacy concerns and conflicts of interest. To solve this issue, a novel federated contrastive prototype learning scheme is proposed for collaborative fault diagnosis of rotating machinery. The collaborative modeling between the central server and multiple clients is implemented to establish a global fault diagnostic model with data privacy. A contrastive prototype learning module is designed to align the prototypes of the same classes across different clients while separating them away from other class prototypes, thus effectively eliminating distribution discrepancies across clients and learning domain-invariant discriminative features. To remove the bias of the global model during federated communication, an unbiased prototype learning module is constructed, which aligns the class prototypes of different clients to the global prototype center and enhances the generalization ability of the proposed approach under unseen conditions. Experimental results on two self-built testbeds and a laboratory dataset demonstrate that the proposed approach is a potential solution for real-world fault diagnosis applications.","Lung cancer (LC) remains a leading cause of death worldwide. Early diagnosis is critical to protect innocent human lives. Computed tomography (CT) scans are one of the primary imaging modalities for lung cancer diagnosis. However, manual CT scan analysis is time-consuming and prone to errors/not accurate. Considering these shortcomings, computational methods especially machine learning and deep learning algorithms are leveraged as an alternative to accelerate the accurate detection of CT scans as cancerous, and non-cancerous. In the present article, we proposed a novel transfer learning-based predictor called, Lung-EffNet for lung cancer classification. Lung-EffNet is built based on the architecture of EfficientNet and further modified by adding top layers in the classification head of the model. Lung-EffNet is evaluated by utilizing five variants of EfficientNet i.e., B0\u2013B4. The experiments are conducted on the benchmark dataset \u201cIQ-OTH/NCCD\u201d for lung cancer patients grouped as benign, malignant, or normal based on the presence or absence of lung cancer. The class imbalance issue was handled through multiple data augmentation methods to overcome the biases. The developed model Lung-EffNet attained 99.10% of accuracy and a score of 0.97 to 0.99 of ROC on the test set. We compared the efficacy of the proposed fine-tuned pre-trained EfficientNet with other pre-trained CNN architectures. The predicted outcomes demonstrate that EfficientNetB1 based Lung-EffNet outperforms other CNNs in terms of both accuracy and efficiency. Moreover, it is faster and requires fewer parameters to train than other CNN based models, making it a good choice for large-scale deployment in clinical settings and a promising tool for automated lung cancer diagnosis from CT scan images.\nHighlights\n\u2022\nWe developed a novel transfer learning framework using EfficientNetB1 for lung cancer classification.\n\u2022\nWe solved the severe imbalance issue by using augmentation method to overcome the skewness of data.\n\u2022\nWe compared the novel designed model with other advanced methods in terms of execution time and computational complexity to demonstrate the performance of EfficientNet over other classification models.\n\u2022\nOur proposed model Lung-EffNet demonstrates superior performance in comparison to existing methods and targeting lung cancer from CT scan images.","Social and political polarization has become a dramatically intensifying force that is having a huge impact on political discourse, public policies and electoral outcomes in the 21st century. Twitter is a social media platform that mirrors to a large extent the sociological notion of public opinion, and has notably fueled these polarization dynamics worldwide. A proper understanding of how different issues become polarized in Twitter and their interrelationship is therefore crucial for the development of effective policies and governance strategies in our democracies. This paper introduces TwiSP, a framework for analyzing polarization on controversial topics in Twitter. TwiSP utilizes a combination of two cutting-edge machine learning techniques: stance detection for identifying attitudes and perspectives and BERTopic for topic modeling. The outcome of TwiSP is a visual tree-like representation of all tweets related to conflicting topics (rooted in a particular topic), contrasting their relationship using different colors to denote the degree of polarization. As a case study, we show how the TwiSP framework can be used for analyzing polarized issues in the context of the COVID-19 vaccine, exploring the resulting degree of polarization and the key topics driving it. The results reveal the diversity of opinions and the presence of highly polarized clusters in social media discussions. We contend that the TwiSP framework provides a novel and valuable tool for decision makers, helping them to recognize contentious issues behind the dynamics of polarization and ultimately identifying potential opportunities for bridging divides.","Imbalanced data classification is a challenging problem frequently encountered in many real-world applications. Traditional classification algorithms are generally designed to maximize overall accuracy; therefore, their effectiveness tends to be impeded by imbalanced data. Similar to other traditional classifiers, naive Bayes (NB) sometimes fails at predicting minority instances owing to its sensitivity to class distribution. To cope with this challenge, we proposed RankOptAUC NB (RNB), a novel attribute weighting method for the NB. In the proposed method, learning a weighted NB classifier was formulated as a nonlinear optimization problem with the objective of maximizing the area under the ROC (AUC). The optimization formulation enabled the RNB method to select important variables by simply adding a regularization term to the objective function. We also provided theoretical evidence that, based on the AUC metric, the proposed method improved the performance of a weighted NB classifier. The results of numerical experiments conducted using 30 real-world datasets proved that the proposed scheme successfully determined the optimal attribute weights for imbalanced data classification.\nHighlights\n\u2022\nA novel weighted naive Bayes (NB) for imbalanced data classification was proposed.\n\u2022\nLearning a weighted NB classifier was formulated as a nonlinear optimization problem.\n\u2022\nArea under ROC curve (AUC) was incorporated into the objective function.\n\u2022\nThe proposed method can select important attributes.","Research on machine activity recognition (MAR) is drawing more attention because MAR can provide productivity monitoring for efficiency optimization, better maintenance scheduling, product design improvement, and potential material savings. A particular challenge of MAR for human-operated machines is the overlap when transiting from one activity to another: during transitions, operators often perform two activities simultaneously, e.g., lifting the fork already while approaching a rack, so the exact time when one activity ends and another begins is uncertain. Machine learning models are often uncertain during such activity transitions, and we propose a novel ensemble-based method adapted to fuzzy transitions in a forklift MAR problem. Unlike traditional ensembles, where models in the ensemble are trained on different subsets of data, or with costs that force them to be diverse in their responses, our approach is to train a single model that predicts several activity labels, each under a different context. These individual predictions are not made by independent networks but are made using a structure that allows for sharing important features, i.e., a context ensemble. The results show that the gated recurrent unit network can provide medium or strong confident context ensembles for 95% of the cases in the test set, and the final forklift MAR result achieves accuracies of 97% for driving and 90% for load-handling activities. This study is the first to highlight the overlapping activity issue in MAR problems and to demonstrate that the recognition results can be significantly improved by designing a machine learning framework that addresses this issue.","In recent years, object detection has been widely used in various fields such as face detection, remote sensing image detection and pedestrian detection. Due to the complex environment in the actual scene, we need to fully obtain the feature information in the image to improve the accuracy of object detection. This paper proposes an object detection algorithm based on coordinate attention and contextual feature enhancement. We design a multi-scale attention feature pyramid network, which first uses multi-branch atrous convolution to capture multi-scale context information, and then fuses the coordinate attention mechanism to embed location information into channel attention, and finally uses a bidirectional feature pyramid structure to effectively fuse high-level features and low-level features. We also adopt the GIoU loss function to further improve the accuracy of object detection. The experimental results show that the proposed method has certain advantages compared with other detection algorithms in the PASCAL VOC datasets.","Federated learning (FL) is an emerging machine learning paradigm that allows multiple parties to train a shared model collaboratively in a privacy-preserving manner. Existing horizontal FL methods generally assume that the FL server and clients hold the same model structure. However, due to system heterogeneity and the need for personalization, enabling clients to hold models with diverse structures has become an important direction. Existing model-heterogeneous FL approaches often require publicly available datasets and incur high communication and/or computational costs, which limit their performances. To address these limitations, we propose a simple but effective Federated Global prediction Header (FedGH) approach. It is a communication and computation-efficient model-heterogeneous FL framework which trains a shared generalized global prediction header with representations extracted by heterogeneous extractors for clients' models at the FL server. The trained generalized global prediction header learns from different clients. The acquired global knowledge is then transferred to clients to substitute each client's local prediction header. We derive the non-convex convergence rate of FedGH. Extensive experiments on two real-world datasets demonstrate that FedGH achieves significantly more advantageous performance in both model-homogeneous and -heterogeneous FL scenarios compared to seven state-of-the-art personalized FL models, beating the best-performing baseline by up to 8.87% (for model-homogeneous FL) and 1.83% (for model-heterogeneous FL) in terms of average test accuracy, while saving up to 85.53% of communication overhead.","Ensemble methods and conventional base class learners have effectively been applied in the realm of educational data mining to ameliorate the accuracy and consistency in prediction. Primarily in the contemporary study, researchers conducted empirical results on pedagogical real dataset acquired from University of Kashmir, using miscellaneous base classifiers viz. j48, random forest and random tree, to predict the performance of students. However, in the later phase, the pedagogical dataset was subjected to more proficient version of stacking viz. stackingC, with the principle objective to ameliorate the performance of students. Furthermore, the dataset was deployed with filtering procedures to corroborate any improvement in results, after the application of techniques such as synthetic minority oversampling technique (SMOTE) and spread sub-sampling method. Moreover, in case of ensemble stackingC, hybridization of predicted output was carried out with three base classifier vis-a- vis j48, random forest and random tree, and the classifier achieved paramount accuracy of 95.65% in predicting the actual class of students. The findings have by and large noticeably corroborated that the stackingC classifier, attained significant prediction accuracy of 95.96% when undergone through undersampling (spread sub-sampling) and 96.11% using oversampling (SMOTE). As a subject of corollary, it calls upon the researchers to broaden the canvas of literature by employing the analogous methods to uncover the diverse patterns hidden in academic datasets.","The predictive performance of machine learning models tends to deteriorate in the presence of class imbalance. Multiple strategies have been proposed to address this issue. A popular strategy consists of oversampling the minority class. Classic approaches such as SMOTE utilize techniques like nearest neighbor search and linear interpolation, which can pose difficulties when dealing with datasets that have a large number of dimensions and intricate data distributions. As a way to create synthetic examples in the minority class, Generative Adversarial Networks (GANs) have been suggested as an alternative technique due to their ability to simulate complex data distributions. However, most GAN-based oversampling methods tend to ignore data uncertainty. In this paper, we propose a novel GAN-based oversampling method using evidence theory. An auxiliary evidential classifier is incorporated in the GAN architecture in order to guide the training process of the generative model. The objective is to push GAN to generate minority objects at the borderline of the minority class, near difficult-to-classify objects. Through extensive analysis, we demonstrate that the proposed approach provides better performance, compared to other popular methods.","Individuals and businesses are frequently seen engaging in a fraud scheme, which results in the loss of funds, rights, and assets. This paper aims to provide an empirical analysis and study of a supervised learning technique, decision trees (DT), on a credit card transaction dataset as a benchmark. The proposed approach can be employed to reduce FPs and FNs through supervised machine learning (ML) technique. The fraud detection system also uses historical data to construct a training set and then analyses it to identify fraudulent activity. In this study, suspicious activity is detected using the decision tree classifier. The obtained results showed that FPs and FNs in an online transaction or activity can be reduced to a large extent using DT classification. This method achieved a promising result in terms of performance measures such as precision (99.7%), accuracy (92.25%), recall (81.49%), and F1_score (86.47%) respectively. As a result, the use of ML classifiers can reduce FPs and FNs, increasing customer satisfaction in an online transaction.","Automatic modulation classification (AMC) plays a vital role in modern communication systems, which can support wireless communication systems with limited spectrum resource. This paper proposes an AMC method, which integrates gated recurrent unit (GRU) and convolutional neural network (CNN) to utilize the complementary input features of received signals for spatiotemporal feature extraction and classification. Different from other state-of-the-art (SoA) frameworks, the proposed AMC classifier, named as fusion GRU deep learning neural network (FGDNN), aggregates firstly temporal features with GRUs and then extracts spatial features with CNNs. The GRUs can store temporal dynamic features, and facilitate to capture the characteristics of correlation and dependence among input features. The method is tested extensively with comparisons in order to verify its effectiveness. Experiment results show that the recognition rates of our method outperform other deep learning frameworks.","Deep learning-based approaches for three-dimensional (3D) grid understanding and processing tasks have been extensively studied in recent years. Despite the great success in various scenarios, the existing approaches fail to effectively utilize the velocity information in the flow field, resulting in the actual requirements of post-processing tasks being difficult to meet by the extracted features. To fully integrate structural information in the 3D grid and velocity information, this paper constructs a flow-field-aware network (FFANet) for 3D grid classification and segmentation tasks. The main innovations include: (i) using the self-attention mechanism to build a multi-scale feature learning network to learn the distribution feature of the velocity field and structure feature of different scales in the 3D flow field grid, respectively, for generating a global feature with more discriminative representation information; (ii) constructing a fine-grained semantic learning network based on a co-attention mechanism to adaptively learn the weight matrix between the above two features to enhance the effective semantic utilization of the global feature; (iii) according to the practical requirements of post-processing in numerical simulation, we designed two downstream tasks: 1) surface grid identification task and 2) feature edge extraction task. The experimental results show that the accuracy (Acc) and intersection-over-union (IoU) performance of the FFANet compared favourably to the 3D mesh data analysis approaches.","In this paper, we introduce STEER to adapt learned semantic type extraction approaches to a new, unseen data lake. STEER provides a data programming framework for semantic labeling which is used to generate new labeled training data with minimal overhead. At its core, STEER comes with a novel training data generation procedure called Steered-Labeling that can generate high quality training data not only for non-numeric but also for numerical columns. With this generated training data STEER is able to fine-tune existing learned semantic type extraction models. We evaluate our approach on four different data lakes and show that we can significantly improve the performance of two different types of learned models across all data lakes.","Deep NLP models are correlation-based learning, which has a critical limitation of over-fitting over spurious features and shows poor generalization capability in the out-of-distribution (OOD) setting. Existing methods encourage the model to exploit causal features and exclude spurious correlations through Counterfactually Augmented Data (CAD) and feature regularization. However, those methods still face challenges due to the low quality of counterfactual generation and the high cost of annotation. This paper proposes an improved method for OOD generalization motivated by causal inference tools. Specifically, taking the topic of the text as the confounder of the input and the label, the model fits the causal correlation between the representations and the label through the backdoor adjustment to alleviate the exploitation of the spurious correlations. The proposed method is evaluated on the counterfactual adversarial test set (movie review text) and the challenging test set with synonym perturbation (financial news text) provided in the previous work. The experimental results show that this method improves the OOD generalization capability of the sentiment classification models in these two attacks while preserving the predictive ability, especially in the case of long text.","Supervised and unsupervised classification is crucial in many areas where different types of data sets are common, such as biology, medicine, or industry, among others. A key consideration is that some units are more typical of the group they belong to than others. For this reason, fuzzy classification approaches are necessary. In this paper, a fuzzy supervised classification method, which is based on the construction of prototypes, is proposed. The method obtains the prototypes from an objective function that includes label information and a distance-based depth function. It works with any distance and it can deal with data sets of a wide nature variety. It can further be applied to data sets where the use of Euclidean distance is not suitable and to high-dimensional data (data sets in which the number of features p is larger than the number of observations n, often written as p &gt; &gt; n). In addition, the model can also cope with unsupervised classification, thus becoming an interesting alternative to other fuzzy clustering methods. With synthetic data sets along with high-dimensional real biomedical and industrial data sets, we demonstrate the good performance of the supervised and unsupervised fuzzy proposed procedures.\nHighlights\n\u2022\nNew fuzzy classification methodology based on the construction of prototypes\n\u2022\nDistance-based, it overcomes the curse of dimensionality\n\u2022\nIt can be applied to a large spectrum of data, when the Euclidean distance is not suitable\n\u2022\nIt identifies K observations, selected between the deepest observations\n\u2022\nSupervised and unsupervised approaches integrated in the objective function","In this paper, we propose a new general classification algorithm based on natural neighboring granular spheres, which has good noise immunity and self-adaptability. The old particle sphere generation algorithm is based on purity, and it can have good noise immunity and classification accuracy when the purity threshold is properly selected. However, when the quality of the data is unknown, the selection of the purity threshold will become a difficult problem. The old granular ball generaotr only considers the purity. When the purity reaches the purity threshold, even if the sample points inside the sphere should be divided into two balls, they will not continue to split, which may lead to a large difference between the actual distribution of the generated spheres and the sample points, and cause a negative impact on the next algorithm based on the sphere calculation. To address this situation, this paper proposes to continue the splitting of such balls by applying the natural neighbor-based clustering algorithm: LORE, which does not need parameter k, and thus can provide an effective basis for the granular ball generator.","Information-theoretic measures have been commonly applied to evaluate the relevance and redundancy in multi-label feature selection. However, the current multi-label feature selection methods based on information-theoretic measures neglect the dynamic changes in the relevance of selected features and candidate features. Furthermore, they also do not fully consider the influence of label redundancy on the relevance of candidate features. In this paper, we first propose a new feature relevance term named Dynamic Correlation Change (DCC), which uses two conditional mutual information terms to evaluate the dynamic changes in the relevance of selected features and candidate features. We then introduce a new label redundancy term named Label Redundancy with Interaction Information (LRII), which more accurately quantifies the influence of label redundancy on the relevance of candidate features. On this basis, we design a new multi-label feature selection method, called Maximum Dynamic Correlation Change and Minimum Label Redundancy (MDCCMLR), by combining DCC and LRII. Finally, we conduct extensive experiments in order to verify the performance of our method by comparing it with some state-of-the-art multi-label feature selection methods based on information-theoretic measures in terms of six evaluation metrics. The experimental results show that the MDCCMLR method outperforms the other comparison methods on all six evaluation metrics.","Many existing image and text sentiment analysis methods only consider the interaction between image and text modalities, while ignoring the inconsistency and correlation of image and text data, to address this issue, an image and text aspect level multimodal sentiment analysis model using transformer and multi-layer attention interaction is proposed. Firstly, ResNet50 is used to extract image features, and RoBERTa-BiLSTM is used to extract text and aspect level features. Then, through the aspect direct interaction mechanism and deep attention interaction mechanism, multi-level fusion of aspect information and graphic information is carried out to remove text and images unrelated to the given aspect. The emotional representations of text data, image data, and aspect type sentiments are concatenated, fused, and fully connected. Finally, the designed sentiment classifier is used to achieve sentiment analysis in terms of images and texts. This effectively has improved the performance of sentiment discrimination in terms of graphics and text.","NAVTEX is a crucial marine safety information broadcasting system for ensuring the safe navigation of ships, which plays a significant role in ship safety. However, the current manual reading and subject classification of NAVTEX suffer from low efficiency and accuracy. To enhance the processing efficiency of maritime safety information (MSI) and promote information and communication, achieving automated MSI classification with high confidence in the accuracy of the results becomes imperative. In the context of machine learning, this study proposes an adaptive weight TFIDF method to address the aforementioned challenges. The primary objective is to optimize the weights of keywords with prominent classification features in NAVTEX. Experimental results demonstrate that the adaptive weight-based TFIDF algorithm significantly improves the classification outcomes for NAVTEX. By enhancing the accuracy and efficiency of MSI classification, this approach facilitates the automation of NAVTEX analysis and promotes the reliability of the generated classification results.","Machinery fault diagnosis based on deep learning methods is cost-effective to guarantee safety and reliability of mechanical systems. Due to the variability of machinery working condition and difficulty of data obtaining under different health states, it is desirable to enhance the generalization capability to unseen working conditions for the fault diagnosis models trained by available data sets under limited number of working conditions. Considering that labeling industrial data is also a laborious work, this paper proposes a novel semi-supervised domain generalization model, termed domain-invariant feature fusion networks (DIFFN) for intelligent fault diagnosis under unseen target working conditions. The main contributions are that, intra-domain-invariant features are considered to capture the intrinsic semantic information within the domain and are fused with inter-domain-invariant features to enhance the discrimination and generalization abilities in fault diagnosis. First, a domain-invariant representation learning method is established to learn the inter- and intra-domain-invariant features using two network branches and fuse them via a fusion module. Second, a mutual learning strategy is designed to enable the network branches and the fusion module to learn from each other, thereby improving the discrimination of the extracted features for accurate fault diagnosis. Lastly, a feature divergence maximization strategy is embedded between the two network branches to improve the generalization ability of the fault diagnosis model. Experiments on two bearing data sets demonstrate that the proposed model has better diagnostic accuracy and stability over state-of-the-art semi-supervised domain generalization methods, indicating its great potential for application in generalization fault diagnosis of machinery under unseen target working conditions.\nHighlights\n\u2022\nDIFFN is proposed to realize semi-supervised generalization fault diagnosis.\n\u2022\nInter- and intra-domain-invariant features are sufficiently exploited.\n\u2022\nA mutual learning strategy is designed to promote the discrimination of features.\n\u2022\nFeature divergence maximization strategy enhances the feature diversification.\n\u2022\nBearing generalization diagnosis experiments validate the superiority of DIFFN.","Infection with a virus can lead to a range of illnesses in humans, including cancer. When viruses infect a host, they may disrupt normal host function and cause deadly diseases. Understanding complicated viral illnesses requires novel viral genome prediction. Since many of the sequences in assembled contigs from human samples are not identical to known genomes, many assembled contigs are labeled \u201cunknown\u201d by conventional alignments. In this study, sequences from 19 metagenomic investigations were used to create the model proposed here, and these sequences were examined and classified using BLAST. We implemented k-mer counting and the bag-of-words technique using CountVectorizer. As far as we are aware, this work represents the first framework that combines natural language processing (NLP) along with traditional ML classification approaches on raw metagenomic contigs to automatically identify viruses in a variety of human biospecimens. The suggested models are general rather than specialized to a particular viral family. Since the proposed methodology is precise and simple, we may incorporate it into computer-aided diagnosis (CAD) systems to make day-to-day hospital activities easier. In the last stage, binary classification of deoxyribonucleic acid (DNA) with normal and viral genomes was performed using traditional ML classifiers. Using the KNN classifier, the suggested model achieved 98.6% classification accuracy along with 98.5% precision, 98.6% recall, 0.984 F1 score, 0.896 Matthews correlation coefficient, 0.895 kappa, 0.97 classification success index and detection rate of 98.6% for the prediction of viral genomes in DNA. Compared to previously developed ML techniques, the model achieved a significantly greater performance for viral genome prediction.","Objective. Wireless sensor networks, crucial for various applications, face growing security challenges due to the escalating complexity and diversity of attack behaviours. This paper presents an advanced intrusion detection algorithm, leveraging feature-weighted Naive Bayes (NB), to enhance network attack detection accuracy. Methodology. Initially, a feature weighting algorithm is introduced to assign context-based weights to different feature terms. Subsequently, the NB algorithm is enhanced by incorporating Jensen\u2013Shannon (JS) divergence, feature weighting, and inverse category frequency (ICF). Eventually, the improved NB algorithm is integrated into the intrusion detection model, and network event classification results are derived through a series of data processing steps applied to corresponding network traffic data. Results. The effectiveness of the proposed intrusion detection algorithm is evaluated through a comprehensive comparative analysis using the NSL-KDD dataset. Results demonstrate a significant enhancement in the detection accuracy of various attack types, including normal, denial of service (DoS), probe, remote-to-local (R2L), and user-to-root (U2R). Moreover, the proposed algorithm exhibits a lower false alarm rate compared to other algorithms. Conclusion. This paper introduces a wireless network intrusion algorithm that not only ensures improved detection accuracy and rate but also reduces the incidence of false detections. Addressing the evolving threat landscape faced by wireless sensor networks, this contribution represents a valuable advancement in intrusion detection technology.","Enduring stress can have negative impacts on human health and behavior. Widely used wearable devices are promising for assessing, monitoring and potentially alleviating high stress in daily life. Although numerous automatic stress recognition studies have been carried out in the laboratory environment with high accuracy, the performance of daily life studies is still far away from what the literature has in laboratory environments. Since the physiological signals obtained from these devices are time-series data, Recursive Neural Network (RNN) based classifiers promise better results than other machine learning methods. However, the performance of RNN-based classifiers has not been extensively evaluated (i.e., with several variants and different application techniques) for detecting daily life stress yet. They could be combined with CNN architectures, applied to raw data or handcrafted features. In this study, we created different RNN architecture variants and explored their performance for recognizing daily life stress to guide researchers in the field.","Transformers with long-range dependency and data specificity act as an effective means of classifying insect pests in agricultural engineering. Although many methods have been proposed to confine the range of self-attention within a local region to reduce the computation complexity, none of them can reduce the number of model parameters. Moreover, the self-attention mechanism usually causes query tokens to focus excessively on image patches, which limits the effective receptive field and the long-range dependence. To address these issues, this paper establishes a novel Dilated-Windows-based Vision Transformer with Efficient-Suppressive-self-attention (DWViT-ES) architecture, which includes efficient-self-attention (ESA), dilated window (DW), and suppressive-self-attention (SSA) as its core components. The ESA simplifies the successive linear Transformations to reduce the number of model parameters and computational costs. Meanwhile, the DW and SSA expand the effective receptive field of self-attention mechanism to prevent query tokens from focusing on similar and close regions, thereby preventing the loss of useful information. Finally, experiments show that the DWViT-ES only has 19.6 M parameters and 3.5G FLOPs (over 20% reductions vs. 19.6 M and 4.5G of Swin-T). Meanwhile, the DWViT-ES training from scratch has 71.6% top-1 accuracy on the IP102 dataset (2.4% absolute improvement of Swin-T); after fine-tuning on Imagenet-1K, the DWViT-ES achieves 76.0% and 78.7% top-1 accuracy on IP102 and CPB (0.1% and 0.9% absolute improvement of Swin-T), respectively. Meanwhile, practical deployment on a mobile-embedded device is presented, which validates the feasibility of the DWViT-ES.","Intention recognition of non-cooperative target is an important basis for battlefield command decision-making. Recent advances suggest recognizing target intention from a perspective of data-driven. However, existing data-driven models do not consider complementary information between features to enhance their robustness in battlefield environments. To solve the problem, this paper constructs a novel neural network fusion model with information classification processing and information fusion to achieve target intention recognition. The model first designs the cross-classification processing method according to attributes\u2019 correlations and variation characteristics. Then, an interactive feature-level fusion method is proposed to model the fine-grained correlations between attributes to discover salient features. Finally, a decision-level fusion method based on Dempster\u2013Shafer theory is proposed to fuse the complementary information among attributes. The experimental results show that the recognition accuracy of the proposed model can reach 89.63%, and it can be maintained above 75% under the conditions of severe attribute missing or noise interference. It is demonstrated that the proposed model has higher accuracy and robustness in battlefield incomplete information environments.\nHighlights\n\u2022\nAn artificial neural network model with information classification processing and information fusion is constructed for target intention recognition.\n\u2022\nAn interactive feature-level fusion method is proposed to model the fine-grained correlations between attributes to discover salient features.\n\u2022\nA decision-level fusion method based on Dempster\u2013Shafer theory is proposed to fuse the complementary information among attributes.\n\u2022\nExperiments demonstrate that the proposed model has higher accuracy and robustness in battlefield incomplete information environments.","Origin: Warts are produced and developed on the human body due to infection induced by Human Papillomavirus. The most influenced zone of warts are hands and feet particularly, which is bit irritating and difficult to recoup in later stages. The major challenge in treating warts is the diversity of treatment method applicable on different patients, so it becomes difficult to recognize specific treatment method to be adopted in order to treat this infection. Ramifications of machine learning techniques in the medical domain have become crucial nowadays for early disease detection and developing expert systems. Objective: This research work focuses on enhancing predictive accuracy of J48, which is a binary decision tree based classifier by adding attributes based on genetic programming. These genetically tuned attribute construction not only just upgrades the classification capabilities of J48 classifier but also additionally expand the information space, intending J48 for giving more exact predictions for wart treatment method identification. Method: For their experimental setup, authors have chosen immunotherapy and cryotherapy datasets from UCI machine learning repositories, which includes instances of patients responses against treated with immunotherapy and cryotherapy methods for both plantar and common warts. The investigation has been led with the help of WEKA tool, which is an open source for performing data mining operations. Finding: After experimentation, it is found after inclusion of attributes generated through genetic programming, the classification accuracy of J48 can be increased by a substantial amount with less error rate. The result shows significant performance improvements in classification accuracy of J48 by 82.22% to 96.66% and 93.33% to 98.88% for immunotherapy and cryotherapy datasets, implemented with J48 and J48+GA respectively.","Social media is awash with hateful content, much of which is often veiled with linguistic and topical diversity. The benchmark datasets used for hate speech detection do not account for such divagation as they are predominantly compiled using hate lexicons. However, capturing hate signals becomes challenging in neutrally-seeded malicious content. Thus, designing models and datasets that mimic the real-world variability of hate warrants further investigation.\nTo this end, we present GOTHate, a large-scale code-mixed crowdsourced dataset of around 51k posts for hate speech detection from Twitter. GOTHate is neutrally seeded, encompassing different languages and topics. We conduct detailed comparisons of GOTHate with the existing hate speech datasets, highlighting its novelty. We benchmark it with 10 recent baselines. Our extensive empirical and benchmarking experiments suggest that GOTHate is hard to classify in a text-only setup. Thus, we investigate how adding endogenous signals enhances the hate speech detection task. We augment GOTHate with the user's timeline information and ego network, bringing the overall data source closer to the real-world setup for understanding hateful content. Our proposed solution HEN-mBERT is a modular, multilingual, mixture-of-experts model that enriches the linguistic subspace with latent endogenous signals from history, topology, and exemplars. HEN-mBERT transcends the best baseline by 2.5% and 5% in overall macro-F1 and hate class F1, respectively. Inspired by our experiments, in partnership with Wipro AI, we are developing a semi-automated pipeline to detect hateful content as a part of their mission to tackle online harm.","Feature selection, as an important pre-processing technique, can efficiently mitigate the issue of \u201cthe curse of dimensionality\u201d by selecting discriminative features especially for multi-label learning, a discriminative feature subset can improve the classification accuracy. The existing feature selection methods for multi-label classification address the problem of label ambiguity by with logical labels. However, the significance of each label is often different in many practical applications. Using logical label to train the model may result in unsatisfactory performance due to not considering the importance of related labels with each sample. To address this issue, a novel multi-label feature selection algorithm is proposed with two-step: label enhancement and label correlations-based feature selection with label enhancement. In the step of label enhancement, a framework of label enhancement based on deep forest is utilized to transform the logical label to label distribution, which contains rich semantic information and then guides a more correct exploration of semantic correlations. In the step of feature selection, a novel multi-label feature selection algorithm is proposed based on label distribution data. Firstly, the samples are divided into multiple different clusters by using spectral clustering in the label space. Then, the label correlations can be reflected by multiple different clusters. Finally, the l 2 , 1-norm is used to construct an objective function to achieve multi-label feature selection. Experimental results demonstrate that competitiveness of the proposed algorithm over six state-of-the-art multi-label feature selection algorithms on eighteen benchmark datasets in terms of six widely accepted evaluation metrics.","This article presents a novel automatic classification method for garment fabric pattern images using the vanilla Reset. The study begins by collecting industry-standard garment fabric images, which are further subjected to preprocessing techniques such as cropping, rotation, and contrast enhancement. These steps contribute to an expanded garment fabric image dataset. The dataset is then divided into a validation set and a training set for conducting image classification experiments. Different ResNet frameworks are employed to analyze the datasets and compare the results. The findings demonstrate that the classification model based on ResNet-34, serving as the backbone network, achieves the highest accuracy of 91.8% in garment fabric pattern classification. This performance surpasses the accuracy achieved by alternative backbone networks, namely AlexNet, VGG16, and GoogleNet, by a substantial margin. The superiority of ResNet-34 as a backbone network is thus affirmed. The proposed method's effectiveness is validated by the significant improvement in classification accuracy achieved by ResNet-34 compared to other backbone networks. These results highlight the potential of ResNet-34 in garment fabric pattern classification tasks. By leveraging the strengths of the ResNet architecture, our approach offers a promising solution for automating the classification of garment fabric patterns, contributing to efficiency and accuracy in the fashion industry. Overall, this study establishes the value of employing the ResNet-34 backbone network for garment fabric pattern image classification, as it outperforms competing networks and achieves remarkable classification accuracy. Future research can build upon these findings to explore further advancements in automatic garment fabric pattern classification.","Traditional techniques for network traffic classification are no longer effective in handling the complexities of dynamic network environments. Moreover, deep learning methods, while powerful, demand substantial spatial and computational resources, resulting in increased latency and instability. In this paper, we propose an innovative approach to network traffic classification utilising an LSTM structure. This approach incorporates network pruning, knowledge refinement, and Generative Adversarial Networks (GAN) to reduce model size, accelerate training speed without compromising accuracy, and address challenges associated with unbalanced datasets in classification problems. Our methodology involves the pruning of unimportant filters from the teacher model, followed by retraining and knowledge distillation to generate the student model. Experimental show that the size of the pruned teacher model is only 25.69% of the original, resulting in a noteworthy 28.16% improvement in training speed. Additionally, the classification performance of various unbalanced traffic categories, such as VoIP and streaming, shows significant enhancement.","Immune repertoire classification, a typical multiple instance learning (MIL) problem, is a frontier research topic in computational biology that makes transformative contributions to new vaccines and immune therapies. However, the traditional instance-space MIL, directly assigning bag-level labels to instances, suffers from the massive amount of noisy labels and extremely low witness rate. In this work, we propose a noisy-label-learning formulation to solve the immune repertoire classification task. To remedy the inaccurate supervision of repertoire-level labels for a sequence-level classifier, we design a robust training strategy: The initial labels are smoothed to be asymmetric and are progressively corrected using the model's predictions throughout the training process. Furthermore, two models with the same architecture but different parameter initialization are co-trained simultaneously to remedy the known \"confirmation bias\" problem in the self-training-like schema. As a result, we obtain accurate sequence-level classification and, subsequently, repertoire-level classification. Experiments on the Cytomegalovirus (CMV) and Cancer datasets demonstrate our method's effectiveness and superior performance on sequence-level and repertoire-level tasks. Code available at https://github.com/TencentAILabHealthcare/NLL-IRC.","Methods to classify objects into two or more classes are at the core of various disciplines. When a set of objects with their true classes is available, a supervised classifier can be trained and employed to decide if, for example, a new patient has cancer or not. The choice of performance measure is critical in deciding which supervised method to use in any particular classification problem. Different measures can lead to very different choices, so the measure should match the objectives. Many performance measures have been developed, and one of them is the F-measure, the harmonic mean of precision and recall. Originally proposed in information retrieval, the F-measure has gained increasing interest in the context of classification. However, the rationale underlying this measure appears weak, and unlike other measures, it does not have a representational meaning. The use of the harmonic mean also has little theoretical justification. The F-measure also stresses one class, which seems inappropriate for general classification problems. We provide a history of the F-measure and its use in computational disciplines, describe its properties, and discuss criticism about the F-Measure. We conclude with alternatives to the F-measure, and recommendations of how to use it effectively.","Near infrared fluorescence optical imaging (NIR-FOI) is a relatively new imaging modality to diagnose arthritis in the hands. The acquired data has two spatial dimensions and one temporal dimension, which visualizes the time dependent distribution of an administered color agent. In accordance with previous work, we hypothesize that the distribution process allows a joint-wise classification into inflammatory affected and unaffected.\nIn this work, we present the first approach to objectively classify hand joint NIR-FOI image stacks by designing, training, and testing a neural network. Previously presented model architectures for spatio-temporal classification do not yield satisfying results when trained on NIR-FOI data. A recall value of 0.812 of the over- and a recall value of 0.652 of the underrepresented class is achieved, the model\u2019s robustness tested against small variations and its attention visualized in activation maps.\nEven though these results leave room for further improvement, they also indicate, that the model architecture can capture the latent features of the data. We are confident, that more available data will lead to a robust classification model and can support medical doctors in using NIR-FOI as a diagnostic tool for PsA.","The Human Mobility Signature Identification (HuMID) problem aims at determining whether the incoming trajectories were generated by a claimed agent from the historical movement trajectories of a set of individual human agents such as pedestrians and taxi drivers. The HuMID problem is significant, and its solutions have a wide range of real-world applications, such as criminal identification for police departments, risk assessment for auto insurance providers, driver verification in ride-sharing services, and so on. Though Deep neural networks (DNN) based HuMID models on spatial-temporal mobility fingerprint similarity demonstrate remarkable performance in effectively identifying human agents' mobility signatures, it is vulnerable to adversarial attacks as other DNN-based models. Therefore, in this paper, we propose a Spatial-Temporal iterative Fast Gradient Sign Method with L0 regularization - ST-iFGSM - to detect the vulnerability and enhance the robustness of HuMID models. Extensive experiments with real-world taxi trajectory data demonstrate the efficiency and effectiveness of our ST-iFGSM algorithm. We tested our method on both the ST-SiameseNet and an LSTM-based HuMID classification model. It shows that ST-iFGSM can generate successful attacks to fool the HuMID models with only a few steps of attack in a small portion of the trajectories. The generated attacks can be used as augmented data to update and improve the HuMID model accuracy significantly from 47.36% to 76.18% on testing samples after the attack(86.25% on the original testing samples).","Accurate integration of high-dimensional single-cell sequencing datasets is important for the construction of cell atlases and for the discovery of biomarkers. Because the performance of integration methods varies in different scenarios and on different datasets, it is important to provide end users with an automated system for the benchmarking and selection of the best integration among several alternatives. Here, we present a system that uses an ensemble of auditors, trained by supervised machine learning, which quantifies residual variability of integrated data and automatically selects the integration with the smallest difference between observed and expected batch effects. A rigorous and systematic validation was performed using 6 popular integration methods and 52 benchmark datasets. Algorithmic and data biases were uncovered and shortcomings of existing validation metrics were examined. Our results demonstrate the utility, validity, flexibility and consistency of the proposed approach.","Most of the existing techniques for solving data imbalance problems are geared towards binary classification problems, hence a novel strategy capable of natively handling multi-class classification problems is required. Existing implementations mainly employ a one-versus-rest approach to support multi-class problems and this generalisation hinders its effectiveness in datasets with multiple minority classes. On the contrary, a one-versus-one approach avoids such generalisation and provides finer control over the balancing strategy. In this paper, we propose a novel SCALA algorithm capable of handling imbalanced data with multiple minority class labels with a multi-class output. We introduce a user-defined set of scaling factors which are then integrated with a one-versus-one balancing strategy. Our results show that SCALA demonstrated a significant improvement compared to ADASYN and SMOTE in model performance metrics used to validate balancing techniques. SCALA can balance these datasets without allowing minority classes to overshadow other minority classes. This preserves the information needed by the training algorithm to distinguish between the classes to a high precision.","In this paper we summarize the contributions of participants to the fifth Sussex-Huawei Locomotion-Transportation (SHL) Recognition Challenge organized at the HASCA Workshop of UbiComp/ISWC 2023. The goal of this machine learning/data science challenge is to recognize eight locomotion and transportation activities (Still, Walk, Run, Bike, Bus, Car, Train, Subway) from the motion (accelerometer, gyroscope, magnetometer) and GPS (GPS location, GPS reception) sensor data of a smartphone in a user-independent manner. The training data of a \u201ctrain\u201d user is available from smartphones placed at four body positions (Hand, Torso, Bag and Hips). The testing data originates from \u201ctest\u201d users with a smartphone placed at one, but unknown, body position. We introduce the dataset used in the challenge and the protocol of the competition. We present a meta-analysis of the contributions from 15 submissions, their approaches, the software tools used, computational cost and the achieved results. The challenge evaluates the recognition performance by comparing predicted to ground-truth labels at every 10 milliseconds, but puts no constraints on the maximum decision window length. Overall, five submissions achieved F1 scores above 90%, three between 80% and 90%, two between 70% and 80%, three between 50% and 70%, and two below 50%. While the task this year is facing the technical challenges of sensor unavailability, irregular sampling, and sensor diversity, the overall performance based on GPS and motion sensors is better than previous years (e.g. the best performance reported in SHL 2020, 2021 and 2023 are 88.5%, 75.4% and 96.0%, respectively). This is possibly due to the complementary between the GPS and motion sensors and also the removal of constraints on the decision window length. Finally, we present a baseline implementation to help understand the contribution of each sensor modality to the recognition task.","Micro-expressions are rapid and subtle facial movements that can reflect the most real emotional state hidden in the human heart. Classifying different micro-expressions is still challenging because of their short duration and low intensity. This paper proposes new neural network models, Simplified SE-DenseNet-cc and SE-ResNet-cc, incorporating Eulerian video magnification (EVM) to enlarge micro-expression movements. Important features can be selectively enhanced, and unimportant features can be compressed using SE-block. The experimental results show that our proposed methods perform better than most of the algorithms in CASME-II and SMIC.","With the recent surge of interest in machine learning, Positive and Unlabeled learning (PU learning) has also attracted much attention of scholars. A key bottleneck for addressing PU classification is the absence of training negative data, and thus many popular approaches belonging to the \u201ctwo-step\u201d strategy have been proposed. However, almost none of the existing two-step methods can thoroughly learn the feature information of samples, which makes the extracted negative samples unreliable and easily leads to undesirable results. Therefore, in this paper, we propose a two-phase projective dictionary pair learning (TPDPL) method for PU learning. The first phase of TPDPL determines reliable negatives by exploiting the reconstruction residuals and the second phase trains the DPL-based classifier with the extracted reliable negative and original positive samples to perform classification. Our experimental results demonstrate that the TPDPL approach can achieve highly competitive classification performance when compared with conventional and state-of-the-art PU learning algorithms. More importantly, due to the special dictionary pair learning framework, the computational complexity of TPDPL is extraordinarily low.","The destruction of archaeological sites and the loss of archaeological landscapes remains a global concern as populations and urban areas continue to expand. Archaeological sites are not only significant to local communities, national identities, and modern tourist economies but also provide critical knowledge of past sociocultural interactions, settlement patterns, human-environment relationships, and risk mitigation strategies. While archaeological landscapes and site destruction have remained outside of traditional land use land cover change (LULCC) studies, they are a form of urban and agricultural land use. By conceptualizing archaeological site destruction within land change science, this study provides an innovative approach for assessing \u201cwhat's left\u201d of historically surveyed archaeological landscapes. Using a Random Forest algorithm and Landsat satellite data, this study quantifies archaeological site destruction attributed to LULCC in Peru's lower Moche Valley between 1985 and 2020. More than 400 archaeological sites previously recorded during the Chan Chan-Moche Valley Project (CCMVP, 1969\u20131974) are analyzed. Results indicate that less than a quarter of the original CCMVP sites remain on the landscape. The primary drivers of LULCC in the lower Moche Valley include population growth, migration, and government policies, while secondary drivers include heritage values. Positioning archaeological survey data within land change science and integrating machine learning techniques can benefit historic survey reassessments globally and provides significant knowledge of archaeological site destruction and the socioeconomic conditions that underly dynamic landscape changes.","In this paper, we present a new approach for hyperspectral image classification. The pixels\u2019 spectra are grouped into clusters in an unsupervised manner using an improved version of plane based clustering. Since the pixels containing the same substances are linearly correlated, the proposed plane-based clustering can effectively group the data points. Plane-based clustering is a more appropriate choice than point based clustering schemes for grouping the datasets which are distributed around hyperplanes instead of hyperspheres. Then, Kernel Principal Component Analysis (KPCA) is applied to each cluster individually to obtain multiple kernel vectors for each data point. Applying non-linear kernels, can greatly increase the discrimination power of the acquired features. The feature vectors are extracted by a weighted linear combination of the kernel components obtained from each cluster. We compute optimal weights using the cluster hyperplane parameters. Since the whole procedure is performed in an unsupervised manner, the proposed approach can enhance the generalization power of the extracted features. Then, morphological attribute filters are applied to the feature maps to effectively utilize spatial relations. Hence, the acquired compact feature vectors include both spectral and spatial information. SVM is used for classification. The experiments performed on three well-known hyperspectral datasets reveal the effectiveness of the proposed feature extraction approach.","Dynamic early exiting has been proven to improve the inference speed of the pre-trained language model like BERT. However, all samples must go through all consecutive layers before early exiting and more complex samples usually go through more layers, which still exists redundant computation. In this paper, we propose a novel dynamic early exiting combined with layer skipping for BERT inference named SmartBERT, which adds a skipping gate and an exiting operator into each layer of BERT. SmartBERT can adaptively skip some layers and adaptively choose whether to exit. Besides, we propose cross-layer contrastive learning and combine it into our training phases to boost the intermediate layers and classifiers which would be beneficial for early exiting. To keep the consistent usage of skipping gates between training and inference phases, we propose a hard weight mechanism during training phase. We conduct experiments on eight classification datasets of the GLUE benchmark. Experimental results show that SmartBERT achieves 2-3\u00d7 computation reduction with minimal accuracy drops compared with BERT and our method outperforms previous methods in both efficiency and accuracy. Moreover, in some complex datasets like RTE and WNLI, we prove that the early exiting based on entropy hardly works, and the skipping mechanism is essential for reducing computation. Our codes are available at: https://github.com/HuBoren99/SmartBert.","It is common to observe significant heterogeneity in clustered data across scientific fields. Cluster-wise conditional distributions are widely used to explore variations and relationships within and among clusters. This paper aims to capture such heterogeneity by employing cluster-wise finite mixture models. To address the heterogeneity among clusters, we introduce latent group structure and incorporate heterogeneous mixing proportions across different groups, accommodating the diverse characteristics observed in the data. The specific number of groups and their membership are unknown. To identify the latent group structure, we employ concave penalty functions to the pairwise differences of the preliminary consistent estimators for the mixing proportions. This approach enables the automatic division of clusters into finite subgroups. Theoretical results demonstrate that as the number of clusters and cluster sizes tend to infinity, the true latent group structure can be recovered with probability close to one, and the post-classification estimators exhibit oracle efficiency. We support our proposed approach\u2019s performance and applicability through extensive simulations and analysis of basic consumption expenditure among urban households in China.","Plant diseases are a threat to the food supply as they reduce the yield, and reduce the quality of fruits and grains. Hence, early identification and classification of plant diseases are essential. This paper aims to classify mango plant leaves into healthy and diseased using convolutional neural networks (CNNs). The performance comparison of CNN architectures, AlexNet, VGG-16 and ResNet-50 for mango plant disease classification is provided. These models are trained using the Mendeley dataset, validation accuracies are found and compared with and without the use of transfer learning models. AlexNet (25 layers, 6.2 million parameters) produces a testing accuracy of 94.54% and consumes less training time. ResNet-50 (117 layers, 23 million parameters) and VGG-16 (16 layers, 138 million parameters) have given testing accuracies of 98.56% and 98.26% respectively. Therefore, based on the accuracies achieved and complexity, this paper recommends AlexNet followed by ResNet-50 and VGG-16 for plant leaf disease classification.","Predicting the secondary structure of proteins is a challenging task. A large variety approaches exist that include observation using equipment\u2019s and theoretical evaluation, in which the optimal structure is determined. The secondary structure determines 3D tertiary structure of protein, on which features and functionalities of protein depend. This paper use classification technique, Random Forest to build a model which is able to determine structure of unknown proteins. The dataset included the amide frequencies of proteins whose structure is known. Machine learning model is developed that can predict the structure of protein that still need to be exploited. The accuracy of the model is determined using ROC curve. The results confirm the performance of the model constructed using amides dataset.","Traditional SVM algorithms for multi-class (k &gt; 2 classes) classification tasks include \u201cone-against-one\u201d, \u201cone-against-rest\u201d, and \u201cone-against-one-against-rest\u201d, which build k(k\u22121)/2 or k classifiers for space partitioning and classification decision. However, they may cause a variety of problems, such as an imbalanced problem, a high temporal complexity, and trouble establishing the decision boundary. In this study, we use the notion of minimizing structural risks (SRM) to recognize k classes by designing only one optimization problem, which we call M3HS-SVM. The M3HS-SVM offers numerous benefits. In summary, the following points should be emphasized: (1) Rather than dividing the space with hyper-planes, M3HS-SVM describes the structural characteristics of various classes of data and trains the hyper-sphere classifier of each class based on the data distribution. (2) M3HS-SVM inherits all of the advantages of classical binary SVM, such as the maximization spirit, the use of kernel techniques to solve nonlinear separable problems, and excellent generalization ability. (3) In the dual problem, we develop an SMO algorithm to effectively reduce the complexity of time and space. We eventually validate the preceding statement with comprehensive experiments. The experiment findings show that our method outperforms other mainstream methods in terms of computing time and classification performance on synthetic datasets, UCI datasets, and NDC datasets.","The application of Train of EMU failures Detection System (TEDS) ensures the running safety of EMU. In order to reduce the manual workload and meet the requirements of fine classification monitoring, we researched the automatic classification technology, designed and implemented the corresponding methods, established the TEDS classification chart of all EMU trains at headquarters, and put forward the automatic calculation operation algorithm using multi-source data. Designed the generation scheme of local chart at the monitoring center, the system application function of automatic dispatching is developed, and the classification monitoring based on train running diagram was realized. The application shows that the method proposed in this paper have reduced the manual workload of work effectively, and the capability of abnormal detection has been enhanced, laid the technical foundation for the effective operation monitoring of EMU.","With the development of artificial intelligence technology and edge computing technology, deep learning-based automatic modulation classification (AI-based AMC) deployed at edge devices using centralised or distributed learning methods for optimisation has emerged in recent years, and has made great progress in the recognition accuracy and recognisable range of wireless signals. However, the lack of sufficient explanation of these models leads to low accuracy and training efficiency of model training, and their applications and further improvements are limited. Researchers have started to propose interpretable methods for technical analysis of deep learning-based AMC. In this paper, based on the research and application development of interpretable methods in recent years, we review the applicable methods and existing research challenges of interpretable automatic modulation classification. And an interpretable AI-based automatic modulation classification framework is proposed to map the interpretability of automatic modulation classification results by obtaining the contribution of wireless signal features to deep learning network training. Experimental results show that the proposed method possesses the ability to explore the classification mechanism of non-transparent auto-modulated classification networks and has the potential to help edge devices train networks with lower energy consumption and higher accuracy.","This paper proposes a novel approach for classifier ensemble by employing the concepts of multi-criteria decision-making (MCDM) and aggregation operators. In this framework, a heterogeneous ensemble process has been incorporated where we consider varied set of classifiers to train the model. Each considered classifier is trained on the training data and a score correspondent to it is generated by utilizing the MCDM process. Subsequently, during the training phase, the priority is generated among the classifiers. For the testing phase, these prioritized classifiers are combined using prioritized aggregation operator. The priority order determined during the training phase is used to ensemble the classifiers during the testing phase. The proposed method is tested on UCI benchmark datasets and outperforms existing state-of-the-art methods.","Voice signals are the essential input source for applications based on human and computer interaction technology. Gender identification through voice signals is one of the most challenging tasks. For voice signal based analysis, deep learning algorithms provide an alternative to traditional and conventional algorithms for classification. To identify the gender through voice signals of female, male and \u2018first-time\u2019 transgender, the deep learning algorithm is used to improve the robustness of the identification model with the Mel Frequency Cepstrum Coefficients (MFCC) as a feature of the voice signals. This article presents the identification accuracy of gender with the help of recorded live voice signals. The voice samples of the third gender are recorded in the Hindi language. These Hindi language voice samples of transgender are very low resources and are unavailable at any recognized sources. The simulation results do not depend on the duration of the signals and are text independent. The recurrent neural network \u2013 Bidirectional Long Short-term Memory (RNN \u2013 BiLSTM) algorithm has been simulated on the recorded voice signals. The simulation outcome is compared with the earlier reported results in the literature. The gender-wise average accuracy of the proposed model is achieved as 91.44%, 94.94%, and 96.11% for males, females, and transgender, respectively, using voice signals. The identification accuracy of transgender is high in comparison to other genders. On the other hand, the average accuracy of the proposed model is obtained as 94.16%.","Machine learning applications in remote sensing often require a labour-intensive feature engineering step, if only a small number of samples is available and transfer learning is not applicable. Here, we are introducing the concept of Spatial Variation Sequences, which allows to apply methodologies from automated time-series feature engineering to remote sensing applications of static images. The presented example application detects swimming pools from four-channel satellite images with an\nF\n1\n-score of 0.95, by generating spatial variation sequences from a modified swimming pool index. The automated feature engineering approach reduced the dimensionality of the classification problem by 99.7%. A more traditional approach using transfer learning on pre-trained Convolutional Neural Networks (CNN) was evaluated in parallel for comparison. The CNN approach boasted a higher performance of\nF\n1\n-score of 0.98 but required the use of pre-trained weights. The comparable performance of the FE and CNN approach demonstrates that time-series feature extraction is a valuable alternative to traditional remote sensing methods in the presence of data scarcity or the need of significant dimensionality reduction.","This paper proposes a real-time voice activity detection (VAD) system that utilizes a compressed convolutional neural network (CNN) model. On general-purpose computers, the system is capable of accurately classifying the presence of speech in audio with low latency. Whereas, when implemented on small devices, the system is showing higher latency, which is presumably an indication of high-load computations in the preprocessing steps. The results of the evaluation indicate that the proposed VAD system is an improvement over the existing solutions, in terms of reducing the model size and improving the level of accuracy among different evaluation metrics. Furthermore, the proposed VAD system offers an extension of the applicability by training the CNN model on a different and more diverse data set. Moreover, the proposed architecture is capable of being compressed to approximately one-eleventh of the size, facilitating eventual deployment on small devices. In contrast to existing closed VAD solutions, the entire pipeline of the proposed VAD system is developed in Python and made available as open source, ensuring the verifiability and accessibility of the work.","Natural Language Processing (NLP) is presently among the hottest scientific fields with an enormous growth rate of the relevant research. Sentiment analysis is a popular NLP problem that aims at the automatic identification of the polarity in user reviews, tweets, blog posts, comments, forum discussions and so on. Unfortunately, the natural sparseness of text, along with its intimate high dimensionality renders the direct application of machine/deep learning models problematic. For this reason, the relevant literature contains a wealth of state-of-the-art dimensionality reduction methods that confront these issues. In this paper, we conduct an experimental study on the effects of dimensionality reduction in the area of sentiment classification. More specifically, we consider multiple feature selection and feature extraction techniques and we investigate their impact on the effectiveness and the efficiency of seven state-of-the-art classifiers. The experimental evaluation includes accuracy and execution time measurements on four benchmark datasets with various degrees of reduction aggressiveness. The results indicate that, in most cases, dimensionality reduction has indeed a beneficial impact on the running times, whereas the accuracy sacrifices are usually small. However, we also indicate several exceptions where this observation is not valid. These exceptions are appropriately highlighted and discussed.","The task of assigning internationally accepted commodity codes (aka HS codes) to traded goods is a critical function of customs offices. Like court decisions made by judges, this task follows the doctrine of precedent and can be nontrivial even for experienced officers. Together with the Korea Customs Service (KCS), we propose a first-ever explainable decision supporting model that suggests the most likely subheadings (i.e., the first six digits) of the HS code. The model also provides reasoning for its suggestion in the form of a document that is interpretable by customs officers. We evaluated the model using 5,000 cases that recently received a classification request. The results showed that the top-3 suggestions made by our model had an accuracy of 93.9% when classifying 925 challenging subheadings. A user study with 32 customs experts further confirmed that our algorithmic suggestions accompanied by explainable reasonings, can substantially reduce the time and effort taken by customs officers for classification reviews.","The deep learning techniques have been shown to make a traffic objects classification system for V2V communications to ensure traffic safety and traffic flow prediction. The robust classifier on the base of MLP and PointNet are explored to recognize the traffic objects from lidar point clouds. The features of a lidar sensor, the lidar point cloud coordinate system and its complex properties for creation a smart traffic object detection and recognition model are described. The best configuration of PointNet architecture with hyperparameters are shown, which is more efficient and robust with respect to input perturbation and corruption of lidar point clouds.","Past research has demonstrated that the explicit use of protected attributes in machine learning can improve both performance and fairness. Many machine learning algorithms, however, cannot directly process categorical attributes, such as country of birth or ethnicity. Because protected attributes frequently are categorical, they must be encoded as features that can be input to a chosen machine learning algorithm, e.g. support vector machines, gradient boosting decision trees or linear models. Thereby, encoding methods influence how and what the machine learning algorithm will learn, affecting model performance and fairness. This work compares the accuracy and fairness implications of the two most well-known encoding methods: one-hot encoding and target encoding. We distinguish between two types of induced bias that may arise from these encoding methods and may lead to unfair models. The first type, irreducible bias, is due to direct group category discrimination and the second type, reducible bias, is due to the large variance in statistically underrepresented groups. We investigate the interaction between categorical encodings and target encoding regularization methods that reduce unfairness. Furthermore, we consider the problem of intersectional unfairness that may arise when machine learning best practices improve performance measures by encoding several categorical attributes into a high-cardinality feature.","Due to the enormous amount of user-generated content being generated on the web, labeling such data is a time-consuming and expensive endeavor. As a result, we have limited annotated data and the vast majority of data are unlabeled. Analysis reveals that extracting (external) knowledge from unlabeled data and integrating it with knowledge extracted from labeled data is a beneficial task for text information processing, in particular text classification. In this paper, we present a hybrid approach for classifying sentiments that employs external knowledge, which is categorized as either general-purpose sentiment knowledge or domain-related knowledge. General-purpose sentiment knowledge is extracted from sentiment lexicons, whereas domain-related knowledge is extracted from unlabeled data from the same or related domains. Similar domains for a given domain are identified based on their similarity score in terms of overlapping features. The proposed approach utilizes both forms of external knowledge and combines them with logistic regression to train an improved classification model. The classification model uses the conventional gradient descent algorithm for optimization, and its convergence analysis indicates that it is convex and converges to the global optimum. The proposed approach is empirically evaluated and compared to three baselines and one state-of-the-art method using standard performance evaluation metrics on a multi-domain sentiment dataset. The experiment results are encouraging, demonstrating that the proposed approach considerably outperforms the baseline approaches and outperforms the state-of-the-art approach by up to 2% in terms of both f-score and accuracy.\nHighlights\n\u2022\nA hybrid approach for document-level sentiment classification that makes use of external knowledge.\n\u2022\nA domain-specific knowledge extraction approach from unlabeled text documents.\n\u2022\nA detailed convergence analysis of the proposed optimization model used in the proposed approach.","Weighting strategy prevails in machine learning. For example, a common approach in robust machine learning is to exert low weights on samples which are likely to be noisy or quite hard. This study summarizes another less-explored strategy, namely, perturbation. Various incarnations of perturbation have been utilized but it has not been explicitly revealed. Learning with perturbation is called perturbation learning and a systematic taxonomy is constructed for it in this study. In our taxonomy, learning with perturbation is divided on the basis of the perturbation targets, directions, inference manners, and granularity levels. Many existing learning algorithms including some classical ones can be understood with the constructed taxonomy. Alternatively, these algorithms share the same component, namely, perturbation in their procedures. Furthermore, a family of new learning algorithms can be obtained by varying existing learning algorithms with our taxonomy. Specifically, three concrete new learning algorithms are proposed for robust machine learning. Extensive experiments on image classification and text sentiment analysis verify the effectiveness of the three new algorithms. Learning with perturbation can also be used in other various learning scenarios, such as imbalanced learning, clustering, regression, and so on.","For training and testing enhancer-promoter interaction (EPI) classifiers, the question on which non-positive EPIs are selected as negative instances must be answered. Most previous methods use the dataset of the EPI classifier TargetFinder where negative EP pairs are sampled from non-positive EP pairs. Consequently, over 92% of EPIs in the TargetFinder-positive and negative sets of cell line GM12878 have a 2-fold or greater positive/negative class imbalance of promoter occurrences between the positive and negative EP pairs. This situation negatively impacts the predictability of EPI classifiers trained using the datasets.\nThus, we first proposed the condition that the negative EPIs should satisfy. Second, we devised a method called CBOEP (class balanced occurrences of enhancers and promoters), to generate negative EPI sets that approximately fulfil this condition for a given positive EPI set. CBOEP solves the finding problem by reducing it to the maximum-flow problem. Third, we applied the generated negative EPI sets to existing EPI classifiers, TransEPI and TargetFinder. The negative datasets lead to higher prediction performance than the existing negative EPI datasets. The source code is available at https://github.com/maruyama-lab-design/CBOEP.","Insect pests have always been a global agricultural problem because the severity and extent of their occurrence threaten crop yield. Recognizing them early can help farmers have efficient measures to handle them, which can help mitigate negative impacts from insect pests. However, insect pest recognition still relies heavily on experts, which is expensive and time-consuming. With the power of Deep Learning, we propose two methods to solve this task in this paper. First, we proposed a method that uses models pre-trained on the ImageNet dataset, including ResNet-50, EfficientNet-B4, and VisionTransformer-B16, respectively. We also change the structure of these models by adding a Dropout layer before the output layer of these pre-trained models to avoid overfitting. Second, we apply hierarchical learning for this task. In the latter approach, we first use the baseline model to create a confusion matrix. Through this matrix, we cluster classes that the baseline model misses to each other because of the similar appearance across classes into bigger classes, and we consider them as sub-datasets. Then, we build each model for each sub-dataset using the identical backbones as the baseline methods with the hope that it helps the method classify better in these classes. We do experiments to evaluate the performance of methods on the IP102 dataset. From experiments, our proposed method, which uses VisionTransformer-B16 backbone combined with hierarchical learning, gets the best accuracy of 74.50% on the IP102 dataset. When ensemble 3 above models and combine with hierarchical learning, we get the best accuracy of 76.24% on this dataset.","We propose a self-attention Vision Transformer (ViT) model tailored for breast cancer histology image classification. The proposed architecture uses a stack of transformer layers, with each layer consisting of a multi-head self-attention mechanism and a position-wise feed-forward network, and it is trained with different strategies and configurations, including pretraining, resize dimension, data augmentation, patch overlap, and patch size, to investigate their impact on performance on the histology image classification task. Experimental results show that pretraining on ImageNet and using geometric and color data augmentation techniques significantly improve the model\u2019s accuracy on the task. Additionally, a patch size of 16 \n\u00d7\n 16 and no patch overlap were found to be optimal for this task. These findings provide valuable insights for the design of future ViT-based models for similar image classification tasks.","Recent research has revealed that deep neural networks often take dataset biases as a shortcut to make decisions rather than understand tasks, leading to failures in real-world applications. In this study, we focus on the spurious correlation between word features and labels that models learn from the biased data distribution of training data. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased word as biased example. Our analysis shows that biased examples are easier for models to learn, while at the time of prediction, biased words make a significantly higher contribution to the models' predictions, and models tend to assign predicted labels over-relying on the spurious correlation between words and labels. To mitigate models' over-reliance on the shortcut (i.e. spurious correlation), we propose a training strategy Less-Learn-Shortcut (LLS): our strategy quantifies the biased degree of the biased examples and downweights them accordingly. Experimental results on Question Matching, Natural Language Inference and Sentiment Analysis tasks show that LLS is a task-agnostic strategy and can improve the model performance on adversarial data while maintaining good performance on in-domain data.","Bibliographic references in scholarly documents are integral to discourse in humanities disciplines. While prior work has focused on reference extraction and parsing from these documents, little research has investigated the classification of footnotes containing bibliographic citations and author commentary using supervised machine learning methodologies. Using an historiographic dataset drawn from the JSTOR humanities archive, we train and compare the performance of a suite of single and hybrid machine learning classifiers on a novel, previously unexplored reference classification task in archival document analysis. Moreover, as a part of this analysis, we investigate the feasibility of using the grammar of these scholarly footnotes as training features for our machine learning models. In our work we compare the performance of traditional features previously used in reference mining and these novel, grammatical features inspired by natural language processing techniques. Our work demonstrates the superiority of hybrid models for classification of scholarly footnotes containing historiographic bibliographic references, the transferability of features from reference extraction to this research problem, and the viability of training machine learning models for this task utilizing novel, grammatical feature sets.","One of the main challenges in the industry is having trained and efficient operators in manufacturing lines. Smart adaptive guidance systems are developed that offer assistance to the operator during assembly. Depending on the operator\u2019s level of execution, the system should be able to serve a different guidance response. This paper investigates the assessment and classification of the operator\u2019s functional state using observed task execution times. Five different classifiers are studied for operator functional state classification on task execution time series. The experiments are based on an industry case and the ground truth is provided by an expert rule-based system. Three classification scenarios are defined that segment the problem on the level of the task, the individual, or the team. Furthermore, the investigation includes the evaluation of four distinct window-size configurations. The examination of how these scenarios and window-sizes influence the studied dataset across diverse classifiers reveals that achieving enhanced accuracy necessitates a larger input dimension. In this context, Convolutional Neural Networks predominantly exhibit superior performance compared to alternative classifiers. Careful attention needs to be paid to performance over classes and skills, but results confirm the validity of the approach for data-driven operator functional state classification.","Sentiment analysis is a technique that analyzes the attitudes and emotions of people towards some product, service etc. Sentiment analysis of some product or service can be beneficial in predicting future scope of it. However, manually analyzing a large number of documents in a limited time can be a tedious and challenging task. Hence, several attempts have been made in the literature to solve this problem and several sentiment analysis techniques have been proposed. However, these approaches do not consider or do not give much weighted to\u2018emoticons\u2019 present in the sentence. Emotions are very popular these days and have become an integral part of written communication. Hence, in this paper, we propose a novel algorithm, based on \u2018emoticon score learning\u2019 for identifying sentiment of a given sentence. We test the proposed algorithm on 1000 tweets. Experimental results show that the proposed algorithm is effective in sentiment classification and give accuracy of 91.1%. Additionally, the proposed algorithm is able to detect sentences consisting of both positive and negative sentiments.","Multi-metric learning is important for improving performance of learners. For complex data, multi metric learning algorithms need intensive research. Moreover, the existing multi-metric learning methods may lead to the distance not being comparable. To solve these shortcomings and characterize better complexity data, we propose a novel multi-metric learning framework, where each class is divided into several clusters, and then a local metric and two concentric hypers-pheres are trained jointly in a cluster, such that the samples of the same cluster distribute within one hypersphere, and the classification margin are as large as possible simultaneously. This will leads to intra-class compactness and inter-class dispersion. During the test phase, the relative distance in learned metric space is designed to make classification decisions. A new example is classified to the class of its closest hyper-sphere center. This ensures that the comparison of distances is meaningful and avoids effectively the limitation of k-nearest neighbors (kNN) classifiers. Moreover,some important properties the proposed algorithm are analyzed theoretically. Further, an alternating iterative algorithm is developed to solve the problem. Numerical experiments are carried out on different scales and types datasets. Experiment results confirm the feasibility and effectiveness of the proposed method.","The alternative accumulated improvement curve stochastic order is a criterion for the comparison of the performance of classifiers that predict binary responses. An explicit optimal classifier for this criterion is obtained. That optimal classifier has the largest ROC and CAP curves and indexes, that is, it is also optimal for the criteria based on the comparison of such curves and indexes. An application of the results to the search of the best classifier to predict clients of a bank which will make a transaction in the future is developed.\nHighlights\n\u2022\nOptimal classifier for the alternative accumulated improvement curve stochastic order.\n\u2022\nThat classifier has the largest ROC and CAP curves and indexes.\n\u2022\nApplication to a problem of a bank to predict clients which will make a transaction.\n\u2022\nThe method based on the optimal classifier shows the best performance.","Real-world data usually obeys a long-tailed distribution, where a few classes have higher number of samples compared to the other classes. Recent studies have been proposed to alleviate the extreme data imbalance from different perspectives. In this paper, we experimentally find that due to the easily confusing visual features between some head- and tail classes, the cross-entropy model is prone to misclassify tail samples to similar head classes. Therefore, to alleviate the influence of the confusion on model performance and improve the classification of tail classes, we propose a Similarity Window Reweighting and Margin (SWRM) algorithm, where the SWRM consists of Similarity Window Reweighting (SWR) and Similarity Window Margin (SWM) algorithms. For the confusable head- and tail classes, SWR assigns larger weights to tail classes and smaller weights to head classes. Therefore, the model can enlarge the importance of tail classes and effectively improve their classification. Moreover, SWR considers the difference in label frequency and the impact of category similarity simultaneously, so that the weight coefficients are more reasonable and efficacious. SWM generates adaptive margins that are proportional to the ratio of the classifier\u2019s weight norm, thus promoting the learning of tail classifier with small weight norm. Our SWRM effectively eliminates the confusion between head- and tail classes and alleviates the misclassification issues. Extensive experiments on three long-tailed datasets, i.e., CIFAR100-LT, ImageNet-LT and Places-LT, verify our proposed method\u2019s effectiveness and superiority over comparative methods.","Events are the core element of information in descriptive corpus. Many progresses have been made in Event Detection (ED) to detection and extraction of key events information from massive unstructured texts, However, it is still a challenge to detect event information from data with unavoidable noisy labels. A robust Joint-training Graph Convolution Networks (JT-GCN) model is proposed to meet the challenge of ED tasks with noisy labels in this paper. Specifically, we first employ two Graph Convolution Networks with Edge Enhancement (EE-GCN) to make predictions simultaneously. A joint loss combining the detection loss and the contrast loss from two networks is then calculated for training. Meanwhile, a small-loss selection mechanism is introduced to mitigate the impact of mislabeled samples in networks training process. These two networks gradually reach an agreement on the ED tasks as joint-training progresses. Corrupted data with label noise are generated from the benchmark dataset ACE2005. Experiments on ED tasks has been conducted with symmetry label noise on different level. The experimental results show that the proposed model is robust to the impact of label noise and superior to present models for ED tasks.","Examples from living systems at various levels of the biological hierarchy and also from natural food products show that ultra-weak photon emission (UPE) has potential applications in the rating of vital functions and quality testing. In this study, the UPE of chicken eggs has been tested regarding the possibility of egg quality verification. The UPE from intact eggs and separated egg parts were subjected to supervised and unsupervised classification methods according to different housing types. The results of unsupervised egg grouping substantially agreed with the types of hen rearing. The Cohen\u2019s Kappa test score for the K-means method was up to K = 0 . 63. Supervised Support Vector Machine (SVM) classifier with radial kernel function achieved a relatively high accuracy (AC), up to 88%, also confirmed by the value of the K-statistics up to 0.81. This study shows that the best result of egg types classification can be obtained using UPE emission data from all egg parts.\nHighlights\n\u2022\nBiophoton emission of egg components can be used as a measure of the egg quality.\n\u2022\nOrganic housing type eggs are characterised by the highest levels of photon emission.\n\u2022\nUltra-weak photon emission of egg components allows classification of egg types.","Nowadays, many classification algorithms have been applied to various industries to help them work out their problems met in real-life scenarios. However, in many binary classification tasks, samples in the minority class only make up a small part of all instances, which leads to the datasets we get usually suffer from high imbalance ratio. Existing models sometimes treat minority classes as noise or ignore them as outliers encountering data skewing. In order to solve this problem, we propose a bagging ensemble learning framework A S E (Anomaly Scoring Based Ensemble Learning). This framework has a scoring system based on anomaly detection algorithms which can guide the resampling strategy by divided samples in the majority class into subspaces. Then specific number of instances will be under-sampled from each subspace to construct subsets by combining with the minority class. And we calculate the weights of base classifiers trained by the subsets according to the classification result of the anomaly detection model and the statistics of the subspaces. Experiments have been conducted which show that our ensemble learning model can dramatically improve the performance of base classifiers and is more efficient than other existing methods under a wide range of imbalance ratio, data scale and data dimension. A S E can be combined with various classifiers and every part of our framework has been proved to be reasonable and necessary.\nHighlights\n\u2022\nIntroduce a scoring system based on anomaly detection to the resampling strategy.\n\u2022\nThe proposed weighting functions are intuitive and easy to understand.\n\u2022\nPropose an efficient ensemble learning framework.\n\u2022\nExcellent performance on different real-world imbalanced classification tasks.","Microscopy analysis of sputum images for bacilli screening is a common method used for both diagnosis and therapy monitoring of tuberculosis (TB). Nonetheless, it is a challenging procedure, since sputum examination is time-consuming and needs highly competent personnel to provide accurate results which are important for clinical decision-making. In addition, manual fluorescence microscopy examination of sputum samples for tuberculosis diagnosis and treatment monitoring is a subjective operation. In this work, we automate the process of examining fields of view (FOVs) of TB bacteria in order to determine the lipid content, and bacterial length and width. We propose a modified version of the UNet model to rapidly localise potential bacteria inside a FOV. We introduce a novel method that uses Fourier descriptors to exclude contours that do not belong to the class of bacteria, hence minimising the amount of false positives. Finally, we propose a new feature as a means of extracting a representation fed into a support vector multi-regressor in order to estimate the length and width of each bacterium. Using a real-world data corpus, the proposed method i) outperformed previous methods, and ii) estimated the cell length and width with a root mean square error of less than 0.01%.","Breast cancer is a major cause of concern on a global scale due to its high incidence rate. It is one of the leading causes of death for women, if left untreated. Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is increasingly being used in the evaluation of breast cancer. Prior studies neglected to take into account breast cancer characteristics and features that might be helpful for distinguishing the four molecular subtypes of breast cancer. The use of breast DCE-MRI to identify the molecular subtypes is now the focus of research in breast cancer analysis. It offers breast cancer patients a better chance for an early and effective treatment plan. A manually annotated dataset of 1359 DCE-MRI images was used in this study, with 70% used for training and the remaining for testing. Twelve deep features were extracted from this dataset. The dataset was initially preprocessed through placing the ROIs by a radiologist experienced in breast MRI interpretation, then deep features are extracted using the proposed convolutional neural network (CNN). Finally, the deep features extracted are classified into molecular subtypes of breast cancer using the support vector machine (SVM). The effectiveness of the predictive model was assessed using accuracy and area under curve (AUC) measures. The test was performed on unseen held-out data. The maximum achieved accuracy and AUC were 99.78% and 100% respectively, with substantially a low complexity rate.","Mixup is an efficient data augmentation technique, which improves generalization by interpolating random examples. While numerous approaches have been developed for Mixup in the Euclidean and in the hyperbolic space, they do not fully use the intrinsic properties of the examples, i.e., they manually set the geometry (Euclidean or hyperbolic) based on the overall dataset, which may be sub-optimal since each example may require a different geometry. We propose DynaMix, a framework that automatically selects an example-specific geometry and performs Mixup between the different geometries to improve training dynamics and generalization. Through extensive experiments in image and text modalities we show that DynaMix outperforms state-of-the-art methods over six downstream applications. We find that DynaMix is more useful in low-resource and semi-supervised settings likely because it displays a probabilistic view of the geometry.","Multi-label learning (MLL) usually requires assigning multiple relevant labels to each instance. While a fully supervised MLL dataset needs a large amount of labeling effort, using complementary labels can help alleviate this burden. However, current approaches to learning from complementary labels are mainly designed for multi-class learning and assume that each instance has a single relevant label. This means that these approaches cannot be easily applied to MLL when only complementary labels are provided, where the number of relevant labels is unknown and can vary across instances. In this paper, we first propose the unbiased risk estimator for the multi-labeled complementary label learning (MLCLL) problem. We also provide an estimation error bound to ensure the convergence of the empirical risk estimator. In some cases, the unbiased estimator may give unbounded gradients for certain loss functions and result in overfitting. To mitigate this problem, we improve the risk estimator by minimizing a proper loss function, which has been shown to improve gradient updates. Our experimental results demonstrate the effectiveness of the proposed approach on various datasets.","Highlights\n\u2022\nPresent an overview of ASC methods covering earlier works and recent advances.\n\u2022\nReview core techniques including data processing, feature acquisition, and modeling.\n\u2022\nSummarize available resources for ASC and analyze ASC tasks in DCASE challenges.\n\u2022\nDiscuss limitations and open challenges of current ASC algorithms.\n\u2022\nProvide suggestions for future research.\nAbstract\nAcoustic scene classification (ASC) has gained significant interest recently due to its diverse applications. Various audio signal processing and machine learning methods have been proposed for ASC. The volume and scope of ASC publications covering theories, algorithms, and applications have also been expanded. However, no recent comprehensive surveys exist to collect and organize the knowledge, impeding the ability of researchers and its applications. To fill this gap, we present an up-to-date overview of ASC methods, covering earlier works and recent advances. In this work, we first define a general framework for ASC, starting with a historical review of previous research in the ASC field. Then, we review core techniques for ASC that have achieved good performance. Focus on machine learning based ASC systems, this work summarizes and groups the existing techniques in terms of data processing, feature acquisition, and modeling. Furthermore, we provide a summary of the available resources for ASC research and analyze ASC tasks in Detection and Classification of Acoustic Scenes and Events (DCASE) challenges. Finally, we discuss limitations of the current ASC algorithms and open challenges to possible future developments toward practical applications of ASC systems.","In this study, the authors combined the research on loose particle signal and component signal identification with the research on loose particle material identification for the first time, providing comprehensive and reliable loose particle detection results. Based on this, a signal detection and material identification method for loose particles inside sealed relays based on fusion classification model is proposed. Due to the limitations of technical means and confidentiality management, the authors made a real sealed relay sample, and took it as the research object. Through the steps of data acquisition, signal processing, feature engineering, and model training, the dedicated component identification feature library and material identification feature library was constructed, respectively, the component identification model and material identification model based on parameter-optimized SVM with linear kernel and XGBoost was trained, respectively. For the seal relay to be tested, through the steps of data acquisition, signal processing and feature engineering, the data set to be tested was created. The component identification model was used to identify component signals with loose particle signals, and the material identification model was used to identify the materials of loose particles. The majority voting process was used to convert the classification results into identification results, resulting in loose particle detection and material identification results. In addition, the general procedure steps of the proposed method for physical testing were given, and the identification accuracy for device-level loose particle detection was newly proposed. The loose particle testing event containing thirty-seven identification tasks shows that, the achieved identification accuracy was 97.30%, and 92.16% of the average classification accuracy was achieved by the component identification model, 80.41% of the average classification accuracy was achieved by the material identification model. This effectively demonstrates the feasibility and practicality of the proposed method in this paper. It is an important supplement to the loose particle detection research, and provides references for signal detection in similar fields.\nHighlights\n\u2022\nFirst combine the loose particle signal detection and material identification study.\n\u2022\nFirst construct the dedicated feature library and perform feature optimization.\n\u2022\nTrain the optimal component identification model and material identification model.\n\u2022\nNewly add majority voting steps to obtain the identification results.\n\u2022\nNewly propose the identification accuracy for device-level loose particle detection.","The aim of this research is to evaluate the performance of a classification model on nonlinear data. The study utilizes accuracy, precision, sensitivity, and specificity metrics based on data from e-commerce X sellers. The classification model is developed using the Support Vector Machine (SVM) approach, employing different kernel functions such as linear, polynomial, and Radial Basis Function (RBF). By comparing the performance scores of each model, the best model is determined. The results indicate that the SVM model with a linear kernel outperforms the others, demonstrating the highest performance scores. This approach is applied to predict the status of sellers on e-commerce X.","This paper presents a novel study on soil image classification, leveraging the synergistic potential of transfer learning and convolutional neural networks (CNNs). The proposed approach combines the strengths of the MobileNetV2 architecture with a customized CNN model for accurate and efficient soil type recognition. The pre-trained MobileNetV2 is used to capture generic features before fine-tuning it with a dedicated soil image dataset comprising four distinct classes: red, clay, black, and yellow soils. To enhance the model\u2019s capacity for discerning intricate soil textures, a specially designed CNN architecture is incorporated. The model\u2019s performance is rigorously evaluated on a dataset of 108 images, each sized at 256\u2009\u00d7\u2009256 pixels, achieving an exceptional accuracy rate of 100% on the test dataset. The promising results demonstrate the efficacy of the proposed methodology in soil image classification tasks, offering potential applications in precision agriculture, environmental monitoring, and land management. While these findings showcase remarkable accuracy, further investigations are recommended to assess the model\u2019s generalization across diverse environmental conditions and an expanded range of soil image datasets.","Insider threats refer to cyber-attacks originating from within an organization that can cause significant damage, such as intellectual property theft, sabotage, and sensitive data exposure. Traditional cybersecurity strategies tend to focus on external threats, leaving organizations vulnerable to insider attacks. In this paper, we propose an approach for insider threat classification with various classification models. Aggregated numerical features are generated using the access patterns of the employees of the organization. We used the CERT dataset for training and testing. The proposed method is evaluated with classification models like Logistic Regression, Decision Tree, Random Forest, and Xgboost. The experimental results of the model's performance, measured using evaluation metrics such as accuracy, recall, precision, and F1-Score, demonstrated improved accuracy and performance compared to existing works in terms of high recall, precision, and F1-Score values, and effectively outperformed pre-trained CNN models.","A world of healthcare possibilities has been opened with the development of the Internet of Medical Things and related machine learning, deep learning, and artificial intelligence approaches. It has a broad range of uses: when linked to the Internet, common medical equipment and sensors may gather important data; deep learning and artificial intelligence algorithms use this data to understand symptoms and patterns and allow remote healthcare. There are a large number of people affected by thyroid disorders across the world. The ultrasound-based thyroid nodule detection using traditional methods increased the burden on the expertise. Therefore, alternate methods are required to overcome this problem. In order to facilitate early thyroid disorder detection, this research aims to offer an IoT-based ensemble learning framework. In the proposed ensemble model, three pre-trained models DeiT, Mixer-MLP and Swin Transformer, are used for feature extraction. The mRMR technique is used for relevant feature selection. A total of 24 machine learning models have been trained, and weighted average ensemble learning is employed using the Improved Jaya optimization algorithm and Coronavirus Herd Immunity optimization algorithm. The ensemble model with the improved Jaya optimization algorithm achieved excellent results. The best value for accuracy, precision, sensitivity, specificity, F2-score and ROC-AUC score are 92.83%, 87.76%, 97.66%, 88.89%, 0.9551 and 0.9357, respectively. The main focus of this research is to increase the specificity. A poor value of specificity can lead to a high false positive rate. This situation can increase anxiety and emotionally weaken the patient. The proposed ensemble model with the Improved Jaya optimization algorithm outperformed state-of-the-art techniques and can assist medical experts.","Traditional federated classification methods, even those designed for non-IID clients, assume that each client annotates its local data with respect to the same universal class set. In this paper, we focus on a more general yet practical setting, non-identical client class sets, where clients focus on their own (different or even non-overlapping) class sets and seek a global model that works for the union of these classes. If one views classification as finding the best match between representations produced by data/label encoder, such heterogeneity in client class sets poses a new significant challenge-local encoders at different clients may operate in different and even independent latent spaces, making it hard to aggregate at the server. We propose a novel framework, FedAlign1, to align the latent spaces across clients from both label and data perspectives. From a label perspective, we leverage the expressive natural language class names as a common ground for label encoders to anchor class representations and guide the data encoder learning across clients. From a data perspective, during local training, we regard the global class representations as anchors and leverage the data points that are close/far enough to the anchors of locally-unaware classes to align the data encoders across clients. Our theoretical analysis of the generalization performance and extensive experiments on four real-world datasets of different tasks confirm that FedAlign outperforms various state-of-the-art (non-IID) federated classification methods.","Imbalanced data distribution is a common feature in real-world datasets. For imbalanced data, the imbalanced characteristics of the classes have two negative effects on classification results, one of which is that the minority class is highly likely masked by the majority class so as to weaken the ability of the classifiers to identify the minority class. Another effect is that irrelevant attributes hidden in imbalanced data can create much noise to interfere the classifiers, thereby leading to that the classifiers could mistakenly treat noise as the minority classes. In this scenario, the performance of the classifiers is rapidly declined and the classifiers obtain incorrect classification results. To address this issue, this paper proposed a conformal transformation twin-hypersphere with fuzzy. The critical thought is that using conformal transformation to explore the regions containing minority classes, by so doing, minority classes can be more likely to be noticed by the classifier. Using the proposed fuzzy function assesses the contributions of points to the hypersphere training, through evaluating the contributions, noise can be determined, thereby increasing the ability of the classifier to noise resistance. Results on the synthetic and real datasets show that the proposed method outperforms the competitors in classification accuracy and noise resistance. Results also imply that the proposed method does not exhibit exponential calculation time, meaning that the method is suitable for the classification of large-scale imbalanced datasets. We demonstrate that conformal transformation can assist those non-linear kernels to find those hard-to-observe regions containing minority classes, thereby strengthening the adaptability of the classifiers to imbalanced data following complex distributions. Moreover, the non-linear kernels using conformal transformation can adapt to the situation where different sub-regions in sample space require different nonlinearities.","In this article, we investigate the effects on authorship identification tasks (including authorship verification, closed-set authorship attribution, and closed-set and open-set same-author verification) of a fundamental shift in how to conceive the vectorial representations of documents that are given as input to a supervised learner. In \u201cclassic\u201d authorship analysis, a feature vector represents a document, the value of a feature represents (an increasing function of) the relative frequency of the feature in the document, and the class label represents the author of the document. We instead investigate the situation in which a feature vector represents an unordered pair of documents, the value of a feature represents the absolute difference in the relative frequencies (or increasing functions thereof) of the feature in the two documents, and the class label indicates whether the two documents are from the same author or not. This latter (learner-independent) type of representation has been occasionally used before, but has never been studied systematically. We argue that it is advantageous, and that, in some cases (e.g., authorship verification), it provides a much larger quantity of information to the training process than the standard representation. The experiments that we carry out on several publicly available datasets (among which one that we here make available for the first time) show that feature vectors representing pairs of documents (that we here call Diff-Vectors) bring about systematic improvements in the effectiveness of authorship identification tasks, and especially so when training data are scarce (as it is often the case in real-life authorship identification scenarios). Our experiments tackle same-author verification, authorship verification, and closed-set authorship attribution; while DVs are naturally geared for solving the 1st, we also provide two novel methods for solving the 2nd and 3rd that use a solver for the 1st as a building block. The code to reproduce our experiments is open-source and available online.1","The growing availability of time series data has increased the usage of classifiers for this data type. Unfortunately, state-of-the-art time series classifiers are black-box models and, therefore, not usable in critical domains such as healthcare or finance, where explainability can be a crucial requirement. This paper presents a framework to explain the predictions of any black-box classifier for univariate and multivariate time series. The provided explanation is composed of three parts. First, a saliency map highlighting the most important parts of the time series for the classification. Second, an instance-based explanation exemplifies the black-box\u2019s decision by providing a set of prototypical and counterfactual time series. Third, a factual and counterfactual rule-based explanation, revealing the reasons for the classification through logical conditions based on subsequences that must, or must not, be contained in the time series. Experiments and benchmarks show that the proposed method provides faithful, meaningful, stable, and interpretable explanations.","Time series imaging technique: Gramian Angular Field (GAF), and a deep stacked Autoencoder (SAE) are employed to develop a multi-class classifier for the classification and authentication of water samples of bottled water brands: Aquafina (AF), Bisleri (BS), Kingfisher (KF), Oasis (OS), Dolphin (DL) and McDowell (MD) that are attainable in Indian market. The electronic tongue is an artificial taste sensor that is used in the present wok to taste the mineral water samples and subsequently produce one-dimensional current waveforms (CWFs). GAF is used to transform the 1D CWFs into images that are used to train the deep SAE based classifier. The trained classifier is tested on the test GAF images belonging to the water samples of six unknown mineral water brands. Results show that the classifier exhibits satisfactory performance with high classification rate of 93.9%.","Predicting students\u2019 academic performance is a critical research area, yet imbalanced educational datasets, characterized by unequal academic-level representation, present challenges for classifiers. While prior research has addressed the imbalance in binary-class datasets, this study focuses on multi-class datasets. A comparison of ten resampling methods (SMOTE, Adasyn, Distance SMOTE, BorderLineSMOTE, KmeansSMOTE, SVMSMOTE, LN SMOTE, MWSMOTE, Safe Level SMOTE, and SMOTETomek) is conducted alongside nine classification models: K-Nearest Neighbors (KNN), Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Support Vector Machine (SVM), Logistic Regression (LR), Extra Tree (ET), Random Forest (RT), Extreme Gradient Boosting (XGB), and Ada Boost (AdaB). Following a rigorous evaluation, including hyperparameter tuning and 10 fold cross-validations, KNN with SmoteTomek attains the highest accuracy of 83.7%, as demonstrated through an ablation study. These results emphasize SMOTETomek\u2019s effectiveness in mitigating class imbalance in educational datasets and highlight KNN\u2019s potential as an educational data mining classifier.","To evaluate the robustness of non-classifier models, we propose probabilistic local equivalence, based on the notion of randomized smoothing, as a way to quantitatively evaluate the robustness of an arbitrary function. For a given function\nf\n, probabilistic local equivalence evaluates whether, when sampling a normally-distributed point\nx\n\u2032\nin a neighborhood of a point\nx\n, there is a probability\n&gt;\n0.5\nthat\nf\n(\nx\n\u2032\n)\nis equivalent to\nf\n(\nx\n)\n, according to a user-defined notion of equivalence. We use probabilistic local equivalence to evaluate the effect of data augmentation methods for improving robustness, including adversarial training, on a model\u2019s performance. We also use probabilistic local equivalence to evaluate the effect on robustness of model architecture, number of parameters, pre-training, quantization, and other model properties.","Class imbalance problem commonly exists in multi-label classification (MLC) tasks. It has non-negligible impacts on the classifier performance and has drawn extensive attention in recent years. Borderline oversampling has been widely used in single-label learning as a competitive technique in dealing with class imbalance. Nevertheless, the borderline samples in multi-label data sets (MLDs) have not been studied. Hence, this paper deeply discussed the borderline samples in MLDs and found they have different neighboring relationships with class borders, which makes their roles different in the classifier training. For that, they are divided into two types named the self-borderline samples and the cross-borderline samples. Further, a novel MLDs resampling approach called Multi-Label Borderline Oversampling Technique (MLBOTE) is proposed for multi-label imbalanced learning. MLBOTE identifies three types of seed samples, including interior, self-borderline, and cross-borderline samples, and different oversampling mechanisms are designed for them, respectively. Meanwhile, it regards not only the minority classes but also the classes suffering from one-vs-rest imbalance as those in need of oversampling. Experiments on eight data sets with nine MLC algorithms and three base classifiers are carried out to compare MLBOTE with some state-of-art MLDs resampling techniques. The results show MLBOTE outperforms other methods in various scenarios.\nHighlights\n\u2022\nA new borderline oversampling technique for multi-label imbalanced learning.\n\u2022\nDefining self-borderline and cross-borderline samples in multi-label data sets.\n\u2022\nHandling one-vs-rest imbalance in multi-label imbalanced learning.\n\u2022\nPerforming competitively in the experiments with C4.5, RBF kernel SVM and linear SVM.","Breast cancer (BC) is the most common cancer amongst women that threatens the health of women, initial diagnosis of BC becomes essential. Though there were several means to diagnose BC, the standard way is pathological analysis. Precise diagnosis of BC necessitates experienced histopathologists and needs more effort and time for completing this task. Recently, machine learning (ML) was successfully implemented in text classification, image recognition, and object recognition. With the emergence of computer aided diagnoses (CAD) technology, ML was effectively implemented for BC diagnosis. Histopathological image classification depends on deep learning (DL), particularly convolution neural network (CNN), which frequently needs a large amount of labelled training models, whereas the labelled data was hard to obtain. This study develops an Aquila Optimizer(AO) with Hybrid ResNet-DenseNet Enabled Breast Cancer Classification on Histopathological Images (AOHRD-BC2HI). The proposed AOHRD-BC2HI technique inspects the histopathological images for the diagnosis of breast cancer. To accomplish this, the presented AOHRD-BC2HI technique uses hybridization of Resnet with Densenet (HRD) model for feature extraction. Moreover, the HRD method can be enforced for feature extracting procedure in which the DenseNet (feature value memory by concatenation) and ResNet (refinement of feature value by addition) were interpreted. For BC detection and classification, the DSAE model is utilized. The AO algorithm is exploited to improve the detection performance of DSAE model. The experimental validation of the presented AOHRD-BC2HI approach is tested using benchmark dataset and the results are investigated under distinct measures.Also the proposed model achieved the accuracy of 96%. The comparative result reports the improved performance of the presented AOHRD-BC2HI technique over other recent methods.","Unexploded ordnance (UXO) dumped in water reservoirs pose a serious environmental and human safety hazard. Various ways of economically solving this problem are being sought. One of them is the use of machine learning methods for the automatic classification of dangerous objects based on the recorded signals. The paper presents the preliminary results on the use of machine learning methods applied to raw magnetometry data generated in a virtual environment based on the concept of a digital twin. This introduces a different approach to a standard approach, which is based on the inverse problem, where the signals are mapped to the magnetic dipole model. Conducted research points out that the highest performance can be obtained with neural networks, and a direct classification based on the raw signals allows to achieve accuracy of up to 93% when no remanent magnetization is present.","This paper describes the classification of facial expressions using EEG data. The entire procedure aims at controlling an electric wheelchair with a Brain Computer Interface (BCI) headset. The goal is to help the people who are suffering from locked-in syndrome to move or to pass the necessary signals. The headset consists of the electroencephalogram (EEG) cap comprising 16 electrodes attached to the amplifier out of which 14 electrodes are used for data acquisition while two are used as reference and ground. The EEG cap is placed on the head of the subject and various expressions (blink, eyebrows raise, smile, etc.) are performed on the subject. Muscle activities due to facial expressions can be observed from the recorded EEG signals. Expressions are classified and necessary signals are generated. The features are extracted using the wavelet packet transform processing method and classified primarily using Support Vector Machine (SVM).","The feature selection problem has become a key undertaking within machine learning. For classification problems, it is known to reduce the computational complexity of parameter estimation, but it also adds an important contribution to the explainability aspects of the results. An evolution strategy for feature selection is proposed in this paper. Feature weights are evolved with decision trees that use the Nash equilibrium concept to split node data. Trees are maintained until the variation in probabilities induced by feature weights stagnates. Predictions are made based on the information provided by all the trees. Numerical experiments illustrate the performance of the approach compared to other classification methods.","Latent Dirichlet allocation model (LDA) has been widely used in topic modeling. Recent works have shown the effectiveness of integrating neural network mechanisms with this generative model for learning text representation. However, one of the significant setbacks of LDA is that it is based on a Dirichlet prior that has a restrictive covariance structure. All its variables are considered to be negatively correlated, which makes the model restrictive. In a practical sense, topics can be positively or negatively correlated. To address this problem, we proposed a generalized Dirichlet variational autoencoder (GD-VAE) for topic modeling. The Generalized Dirichlet (GD) distribution has a more general covariance structure than the Dirichlet distribution because it takes into account both positively and negatively correlated topics in the corpus. Our proposed model leverages rejection sampling variational inference using a reparameterization trick for effective training. GD-VAE compares favorably to recent works on topic models on several benchmark corpora. Experiments show that accounting for topics\u2019 positive and negative correlations results in better performance. We further validate the superiority of our proposed framework on two image data sets. GD-VAE demonstrates its significance as an integral part of a classification architecture. For reproducibility and further research purposes, code for this work can be found at https://github.com/hormone03/GD-VAE.\nHighlights\n\u2022\nWe propose GD-VAE to capture correlations and learn complex distributions.\n\u2022\nWe show that capturing all correlations leads to improved performance in GD-VAE.\n\u2022\nWe address training instability by introducing a weighted objective function.\n\u2022\nThe comprehensive experiments show that GD-VAE outperformed state-of-the-art models.\n\u2022\nWe demonstrate the effectiveness of GD-VAE on data augmentation with image data sets.","The pre-trained model based on the Transformer architecture is currently the most widely used model in the field of Natural Language Processing (NLP), and feature fusion technology is the process of aggregating features from different sources to form an augmented feature representation that contains more information. In multi-modal or multi-branch NLP models, feature fusion is a commonly used technique, but for models with only a single feature source, feature fusion technology can be difficult to apply. Therefore, this paper proposes a new probabilistic-controlled late fusion encoder-decoder architecture, called the Feature Fusion Gate (FFG), based on both feature fusion technology and Mixup technology to aggregate the feature representations from the last two layers of the NLP pre-trained model to better capture semantic information in samples. During the aggregation process, FFG utilizes controlled noise as a regularization technique to help the model achieve better generalization performance. Experimental results on eight NLP benchmark datasets show that FFG outperforms three other baseline methods and consistently achieves significant performance improvements across DistilBERT, BERT and RoBERTa.","Sign Language Recognition (SLR) is a challenging task that aims to bridge the communication gap between the deaf and hearing communities. In recent years, deep learning-based approaches have shown promising results in SLR. However, the lack of interpretability remains a significant challenge. In this paper, we seek to understand which hand and pose MediaPipe Landmarks are deemed the most important for prediction as estimated by a Transformer model. We propose to embed a learnable array of parameters into the model that performs an element-wise multiplication of the inputs. This learned array highlights the most informative input features that contributed to solve the recognition task. Resulting in a human-interpretable vector that lets us interpret the model predictions. We evaluate our approach on public datasets called WLASL100 (SRL) and IPNHand (gesture recognition). We believe that the insights gained in this way could be exploited for the development of more efficient SLR pipelines.","This paper presents our solution for the Requests Sub-challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge. Drawing upon the framework of self-supervised learning, we put forth an automated data augmentation technique for audio classification, accompanied by a multi-channel fusion strategy aimed at enhancing overall performance. Specifically, to tackle the issue of imbalanced classes in complaint classification, we propose an audio data augmentation method that generates appropriate augmentation strategies for the challenge dataset. Furthermore, recognizing the distinctive characteristics of the dual-channel HC-C dataset, we individually evaluate the classification performance of the left channel, right channel, channel difference, and channel sum, subsequently selecting the optimal integration approach. Our approach yields a significant improvement in performance when compared to the competitive baselines, particularly in the context of the complaint task. Moreover, our method demonstrates noteworthy cross-task transferability.","In this research project, we used the financial texts published by the Federal Open Market Committee (FOMC), known as the FOMC Minutes, for sentiment analysis. The pre-trained FinBERT model, a state-of-the-art transformer-based model trained for NLP tasks in finance, was utilized for that. The focus of this research has been on improving the predictive performance of complex financial sentences, as our problem analysis has shown that such sentences pose a significant challenge to existing models. To accomplish this objective the original FinBERT model was fine-tuned for domain-specific sentiment analysis. A strategy, referred to as Sentiment Focus (SF) was utilized to reduce the complexity of sentences, making them more amenable to accurate sentiment predictions.\nTo evaluate the efficacy of our method, we curated a manually labeled test dataset comprising 1375 entries. The results demonstrated an overall improvement of in accuracy when using SF-enhanced fine-tuned FinBERT over the original FinBERT model. In cases of complex sentences containing conjunctions like but, while, and though with contradicting sentiments, our fine-tuned model outperformed the original FinBERT by a margin of .","Highlights\n\u2022\nA novel classification model via Siamese network for fentanyl analogs was proposed;\n\u2022\nSiamese network and spectral library searching were combined;\n\u2022\nThe proposed model can achieve relatively high classification accuracy;\n\u2022\nProblem of small sample classification of fentanyl analogs was resolved effectively.\nAbstract\nFentanyl and its analogs, as emerging psychotropic drugs, have led to a sharp increasing fatality due to their abuse in recent years. It is difficult to identify their differences due to the diversified molecular structures and small sample characteristics. This paper proposed a novel deep classification model based on Siamese network and mass spectral library searching to classify fentanyl analogs accurately. After embedding the query mass spectrum and reference spectrum into a low-dimensional space, the best matched spectrum is obtained by calculating their similarity, so as to determine the category of the query analogue. Three experiments were performed to verify the classification performance of the proposed model on two open datasets of fentanyl analogs. Compared with two spectral library searching methods of simple match factor (sMF) and hybrid match factor (hMF), four machine learning methods of linear discriminant analysis (LDA), support vector machine (SVM), random forest (RF) and Adaboost, and two deep learning methods of deep clustering and contrastive learning, the proposed model can achieve the highest classification accuracy of 96.13%, 95.83% and 94.17%, respectively.","Covid-19 is a serious disease caused by the Sars-CoV-2 virus that has been first reported in China at late 2019 and has rapidly spread around the world. As the virus affects mostly the lungs, chest X-rays are one of the safest and most accessible ways of diagnosing the infection. In this paper, we propose the use of an approach for detecting Covid-19 in chest X-ray images through the extraction and classification of local and global percolation-based features. The method was applied in two datasets: one containing 2,002 segmented samples split into two classes (Covid-19 and Healthy); and another containing 1,125 non-segmented samples split into three classes (Covid-19, Healthy and Pneumonia). The 48 obtained percolation features were given as input to six different classifiers and then AUC and accuracy values were evaluated. We employed the 10-fold cross-validation method and evaluated the lesion sub-types with binary and multiclass classification using the Hermite Polynomial classifier, which had never been employed in this context. This classifier provided the best overall results when compared to other five machine learning algorithms. These results based in the association of percolation features and Hermite polynomial can contribute to the detection of the lesions by supporting specialists in clinical practices.","To maintain development consciousness, simplify project coordination, and prevent misinterpretation, communication is essential for software development teams. Instant private messaging, group chats, and sharing code are just a few of the capabilities that chat rooms provide to assist and meet the communication demands of software development teams. All of this is capacitated to happen in real-time. Consequently, chat rooms have gained popularity among developers. Gitter is one of these platforms that has gained popularity, and the conversations it contains may be a treasure trove of data for academics researching open-source software systems. This research made use of the GitterCom dataset, The largest collection of Gitter developer messages that have been carefully labelled and curated and perform multi-label classification for the \u2019Purpose\u2019 category in the dataset. An extensive empirical analysis is performed on 6 feature selection techniques, 14 machine learning classifiers, and BERT transformer layer architecture with layer-by-layer comparison. Consequently, we achieve proficient results through our research pipeline involving Extra Trees Classifier and Random Forest classifiers with AUC (OvR) median performance of 0.94 and 0.92 respectively. Furthermore, The research proposed research pipeline could be utilized for generic multi-label text classification on software developer forum text data.","Mangoes are a common agricultural product in Asia that are sold to other nations. Exported mangoes must meet the standards of different countries, mangoes are classified into different groups for export. A method segmentation for an automatic mango classification system is proposed in this study. The KNN model is applied to segment the mangoes, however, there are many different varieties of mangoes so segmentation is also difficult. Therefore, a self-training model is introduced to increase the accuracy of the KNN model and one can adapt to many mango species. The mangoes are rated by deducting penalty points for failing to meet the requirements that have been established. The system achieved more than 98.7% accuracy for segmentation and 96.67% for the whole classification system.","Data irregularities, such as small disjuncts, class skew and imbalance, and outliers significantly affect the performance of classifiers. In this paper, we focus on identifying small disjuncts, which hitherto, has been addressed mainly by rule-based or inductive algorithms. Small disjuncts have been identified as distribution-based irregularities which provide significant learning, although they cover a subset of examples in the training set, which may be considered as being rare. Such samples are more error-prone than large disjuncts. Eliminating small disjuncts by removal or pruning is seen to affect the learning of the classifier adversely. Widely used non-rule-based learning algorithms like SVM, kNN, Logistic Regression, and Neural networks perform poorly in the presence of small disjuncts in the dataset. In this paper, a novel Sequential Ellipsoidal Partitioning method is proposed to identify small disjuncts in the dataset. This method is a supervised classifier that iteratively partitions the dataset into Minimum Volume Ellipsoids that contain points of the same label; this is performed based on the idea of Reduced Convex Hulls. By allowing an ellipsoid that contains points of one label to contain a few points of the other, such small disjuncts may be identified. As we discuss, the proposed technique is agnostic of underlying data distributions and is applicable as a supervised classifier when the datasets are highly skewed and imbalanced even. We demonstrate the performance of the approach using a few publicly available datasets.","Uploading research articles to a database can be a complex process with multiple HTML fields. The complexity of this process makes users less efficient and productive. This study explored the use of the Multilayer Perceptron (MLP) algorithm using language-independent features (count and Boolean features) to create a multi-class text classifier that can classify 10 research article components (e.g., title, authors, abstract, etc.). The text classifier was developed to pave the way for a streamlined manual data entry process for uploading research articles to a database by implementing a single textarea in favor of using multiple HTML fields. The text samples were obtained from multiple sources using web scraping technology, consolidated, cleaned, and standardized. The 12 language-independent features were generated based on the textual formats of sample texts (e.g., count of capitalized letters, digits, punctuation, checking the existence of a URL pattern, etc.). Recursive feature elimination with cross validation (RFECV) was used to determine the optimal number of input features. The hyperparameter values of the model were determined through the grid search technique. A trial-and-error process was conducted to determine the number of hidden layers. The model achieved 95%, 94%, and 95% scores for micro, macro, and weighted average f1-scores, respectively. The model performed well in classifying research article components. However, it is sensitive to textual format (e.g., lower or upper case, punctuation used, etc.). For subsequent research in this area, this study recommends investigating the use of both language-dependent and language-independent features to address the limitations of the current model.","Skip Abstract Section\nAbstract\nIn a complex classification task, samples are represented by various types of multimodal features, including structured data, text, images, video, audio, etc. These data are usually high dimensionally, large-sized, structurally complex, and semantically inconsistent. The representation, translation, alignment, fusion and co-learning of multimodal data are core technical challenges to traditional classification tasks. Kernel functions are applied in dealing with multimodal data for extracting some nonlinear information. However, they cannot consider the aspects of complex structures and uncertain semantics in a multimodal classification task. Fuzzy granular computing emerges as a powerful vehicle to handle the structured and uncertain multimodal data. In this paper, we propose a framework of multimodal classification based on kernel functions and fuzzy granular computing. First, a fuzzy granulation based on kernel functions is introduced to extract nonlinear features for the multimodal classification. Then, a model of multimodal fuzzy classification including fuzzy granular representation, fusion and learning for multimodal data is constructed. Finally, we design an efficient fuzzy granular classification algorithm for big multimodal data based on the proposed model. Experimental results demonstrate the effectiveness of our proposed model and its corresponding algorithm.\nSkip Graphical abstract Section\nGraphical abstract","Medical imaging classification is an area that has taken relevance in recent years due to the capability to support the medical specialist at the time of diagnosis. However, there are different instruments to obtain images from the body, and each body organ is captured differently due to its chemical composition. In this way, there are some difficulties in working with different imaging modalities. Firstly, using different functions or methods to extract features from the images is necessary. Secondly, the classification performance depends on the relevant features extracted from the images, and thirdly, it is necessary to find the classifier that performs with the minimum error. Following the concept of Auto-Machine Learning (AutoML), where the feature engineering and the hyperparameter tuning of the classifier are done automatically, this work proposes an automated approach for feature extraction and image classification based on Genetic Programming. The approach modifies the functions and their parameters and the hyperparameters for the classifier. The results show that the approach can deal with different imaging modalities, demonstrating that feature extraction is necessary to increase the classification performance. For X-ray images, it achieves a classification accuracy of 0.99, and for computerized tomography, it achieves an accuracy of 0.96. On the other hand, the solutions given by the approach are easily reproducible and easy to interpret.","Parkinson\u2019s disease is one of the most common neurodegenerative chronic diseases which can affect the patient\u2019s quality of life by creating several motor and non-motor impairments. The freezing of gait is one such motor impairment which can cause the inability to move forward despite the intention to walk. The identification of the freezing-of-gait events using sensor technology and machine-learning algorithms can result in an improvement in the quality of life and can decrease the risk of fall in Parkinson\u2019s patients. Our study focuses on a systematic performance evaluation of machine learning algorithms for developing a good fit and generalized model. In this work, we train time-domain and frequency-domain-transform-based features on fully connected artificial and deep neural network algorithm for classifying the events of freezing of gait in patients by using accelerometer data. We evaluate these algorithms for hyperparameters such as batch size, optimizer type, and window sizes in a step-wise process. We identify an optimal combination of parameters according to the accuracy and model fit optimality metrics, for artificial and deep neural network to classify freezing of gait events in Parkinson\u2019s patients. We were able to achieve classification accuracy of - with Adam optimizer, batch sizes (BS) of 256 and 8 and epochs of 60 and 40 for ANN and DNN respectively.","Highlights\n\u2022\nComprehensive wheat lodging analysis in terms of ratio, location, and angle was conducted.\n\u2022\nAuto crop plot dataset generation method was developed.\n\u2022\nImbalanced data challenge was addressed by changing the conventional loss function.\n\u2022\nEfficientNet-B7 produced exceptional performance in identifying and categorizing wheat lodging.\n\u2022\nLRCN gave a high performance for the classification of concatenated dataset.\nAbstract\nCrop lodging in agricultural fields is one of the major factors that limit cereal crop yields. Wheat, the most popular cereal crop in most countries, is also affected by this phenomenon, which may result in a significant decrease in both yield and quality. Therefore, addressing wheat lodging is crucial for producers. This study aims to detect and identify wheat lodging through aerial images and classify its severity based on ratio, angle and location of the lodging. To achieve this goal, a multi-task approach was proposed involving three phases. First, automatic dataset generation methodology was conducted on orthomosaic imagery of three dates. Next, a comprehensive assessment of wheat lodging (ratio, angle and location) was performed, which has received little research attention. Third, applying and improving selected classification models for classifying image datasets was conducted. Combining convolutional neural networks and temporal sequences in a single model provided an opportunity to use spatiotemporal information extracted from the wheat image datasets. Time dependency and individual dates were both considered in the classification task. The limited number of data and imbalanced classes challenges, resulting from real field conditions data collection, were overcome by applying a new loss function to the classifier models. The overall accuracy of wheat lodging classification reached over 91% in these two states using the proposed approach. Based on this research, wheat lodging was detected more accurately by the proposed models despite the small and imbalanced dataset. The developed methodology paves the way for comprehensive and automatic wheat lodging detection, and the methodology can be adapted for similar crops that suffer lodging issues with suitable modifications.","We explore solutions for text classification applied to online cooking recipes, in a multitask, multilingual approach. The main objective is designing a solution that ensures high accuracy on the prediction tasks from, but not constrained to, 6 European Languages, considering also the cross-lingual transferability. The challenges of the problem are structured on two main dimensions: (1) data driven - such as imbalance and noise in the training data, and (2) solution driven - such as multilingualism, or the need to easily extend the model to new languages. We propose a solution focused on the XLM-R architecture, fine-tuned jointly on all tasks. We apply self-supervised domain adaptation via additional pre-training and analyze the enhancements produced by performing a 0-shot evaluation for underrepresented languages. Compared to basic language modeling solutions, we obtained an increase of 1.32% and 2.42%, respectively for the two most difficult classification tasks. In the 0-shot context, the absolute improvements are of 16.71% and 7.83% respectively, on underrepresented languages.","The selection of the optimum machine learning technique is a crucial step to detect faults efficiently in the predictive maintenance (PdM) area. Because the performance of the machine learning algorithm changes with respect to a data set, which has different characteristics, including feature number, data size and nonlinearity. The paper considers the problem of detecting faults observed in an autonomous electric drive without using any sensor information. More importantly, we aim to show the opportunities and explore the limitations of machine learning techniques in fault detection. Accordingly, the advantages and disadvantages of different types of machine learning methods including logistic regression, support vector machine, decision tree, navie Bayes, gradient boosting etc. for condition monitoring are discussed with an emphasis given to an autonomous electric drive train. Experimental comparison of machine learning algorithms suggests that the boosting methods yield promising performance in fault classification. The results are supported by statistical analysis.","Transformer-based pre-trained Language Models (PLMs) have emerged as the foundations for the current state-of-the-art algorithms in most natural language processing tasks, in particular when applied to context rich data such as sentences or paragraphs. However, their impact on the tasks defined in terms of abstract individual word properties, not necessary tied to their specific use in a particular sentence, has been inadequately explored, which is a notable research gap. Addressing this gap is crucial for advancing our understanding of natural language processing. To fill this void, we concentrate on classification of semantic relations: given a pair of concepts (words or word sequences) the aim is to identify the semantic label to describe their relationship. E.g. in the case of the pair green/colour, \u201cis a\u201d is a suitable relation while \u201cpart of\u201d, \u201cproperty of\u201d, and \u201copposite of\u201d are not suitable. This classification is independent of a particular sentence in which these concepts might have been used. We are first to incorporate a language model into both existing approaches to this task, namely path-based and distribution-based methods. Our transformer-based approaches exhibit significant improvements over the state-of-the-art and come remarkably close to achieving human-level performance on rigorous benchmarks. We are also first to provide evidence that the standard datasets over-state the performance due to the effect of \u201clexical memorisation.\u201d We reduce this effect by applying lexical separation. On the new benchmark datasets, the algorithmic performance remains significantly below human-level, highlighting that the task of semantic relation classification is still unresolved, particularly for language models of the sizes commonly used at the time of our study. We also identify additional challenges that PLM-based approaches face and conduct extensive ablation studies and other experiments to investigate the sensitivity of our findings to specific modelling and implementation choices. Furthermore, we examine the specific relations that pose greater challenges and discuss the trade-offs between accuracy and processing time.","Fault detection and classification is an important part of assessing the structural and system health status. The classification and detection of faults and faulty units is mostly done with statistical methods. After the data are measured and collected, the use of statistical software is necessary. Currently, many statistical software packages are being developed for the R programming language, as a result of R implementation being open source and free to use. This paper focuses on the rebmix R package, which concentrates on mixture model estimation. Mixture models, in particular Gaussian mixture models, are the main driver for many practical applications, such as clustering and classification. Hence, in this paper, we have expanded the rebmix for the estimation of the Gaussian mixtures. The results acquired on three different fault classification datasets were promising. Additionally, the process of obtaining those results is shown in detail, giving the researchers in the fault classification field useful resources for their research.\nHighlights\n\u2022\nREBMIX algorithm is derived for Gaussian mixture model estimation.\n\u2022\nMain methods and classes of the corresponding R package rebmix are described.\n\u2022\nThree different datasets for fault detection and classification are processed.\n\u2022\nThe R package rebmix has achieved better results than other popular R packages.","From the perspective of a dialog system, the identification of the intention behind the segments in a dialog is important, as it provides cues regarding the information present in the segments and how they should be interpreted. The ISO 24617-2 standard for dialog act annotation defines a hierarchically organized set of general-purpose communicative functions that correspond to different intentions that are relevant in the context of a dialog. In this paper, we explore the automatic recognition of these functions. To do so, we propose to adapt existing approaches to dialog act recognition, so that they can deal with the hierarchical classification problem. More specifically, we propose the use of an end-to-end hierarchical network with cascading outputs and maximum a posteriori path estimation to predict the communicative function at each level of the hierarchy, preserve the dependencies between the functions in the path, and decide at which level to stop. Additionally, we rely on transfer learning processes to address the data scarcity problem. Our experiments on the Dialog-Bank show that this approach outperforms both flat and hierarchical approaches based on multiple classifiers and that each of its components plays an important role in the recognition of general-purpose communicative functions.","Weeds are a significant threat to agricultural production. Weed classification systems based on image analysis have offered innovative solutions to agricultural problems, with convolutional neural networks (CNNs) playing a pivotal role in this task. However, CNNs are limited in their ability to capture global relationships in images due to their localized convolutional operation. Vision Transformers (ViT) and Pyramid Vision Transformers (PVT) have emerged as viable solutions to overcome this limitation. Our study aims to determine the effectiveness of CNN, PVT, and ViT in classifying weeds in image datasets. We also examine if combining these methods in an ensemble can enhance classification performance. Our tests were conducted on significant agricultural datasets, including DeepWeeds and CottonWeedID15. The results indicate that a maximum of 3 methods in an ensemble, with only 15 epochs in training, can achieve high accuracy rates of up to 99.17%. This study demonstrates that high accuracies can be achieved with ease of implementation and only a few epochs.","Aspect-based sentiment classification is an important task in natural language processing research, and in response to the fact that most studies at this stage ignore the influence of contextual semantic information on the sentiment polarity of aspect words, our model proposed in this paper combines local aspect word feature extraction and global contextual semantic information extraction based on Bi-directional Long Short-Term Memory (BiLSTM), and after a multi-headed attention mechanism to enhance the local aspect word sentiment representation. Comparative experiments were conducted on the restaurant and laptop datasets of the SEMEVAL2014 evaluation task. The experimental results show that the model proposed in this paper achieves good classification results in the aspect-level sentiment analysis task of text reviews. The method provides a new idea for ABSA task development.","Fine-grained image classification is a challenging task due to the small inter-class variance, the large intra-class difference, and the small training data. Traditional methods typically rely on large-scale training samples with annotated part annotations, making them costly and severely limiting their application area. In this paper, we propose an effective and weakly supervised fine-grained classification framework. In this framework, a discriminative class-specific spectral feature is learned by intra-class spectral coupling and inter-class spectral decoupling under the weak supervision of image-level category labels, and then the new input images are classified based on the learned class-specific spectral feature. Different from existing strong supervised methods, the proposed technique creatively combines weak supervision of the image-level category labels with unsupervised spectral graph decomposition, not relying on large-scale training samples with dense part annotations, which are heavily labor-consuming. The performance of the proposed methods has been verified on four kinds of typical datasets: the JAFFE dataset, the Yale database, the UCI-CMU face database, and the neural foramina dataset. The satisfactory classification results have been achieved by the proposed method in expression recognition on the JAFFE dataset (with a mean accuracy of 95.31%), face recognition on the Yale database (with a mean accuracy of 98.79%), object recognition on the UCI-CMU face database (with a mean accuracy of 96.96%), and disease grading on the neural foramina dataset (with a mean accuracy of 92.09%). Compared with most state-of-the-art methods, the proposed method has superior classification performance in the small data set.\nHighlights\n\u2022\nFully mine and exploit the discriminative potentials of region correlations for fine-grained image classification in weak supervision.\n\u2022\nSpectral graph captures the internal region structure to ensure the image\u2019s comparison in a natural part-based fashion.\n\u2022\nIntra-class spectral synchronization aligns the spectral representations of with-class images to enhance intra-class similarity.","Handwritten character recognition is a significant image classification task. We present a model that is the first of it\u2019s kind as it is the first ever deep learning model designed to classify all basic and compound Bangla handwritten characters along with all Bangla numerals under the same filters. In this work, we propose a new architecture that can potentially ensure the network to learn sufficient number of filters with fewer parameters and time complexity. Furthermore, we also devised a technique to select a specific portion of the network that has almost the same learning capability as the entire network. Moreover, we demonstrated how this technique can enhance classification accuracy while making the neural network unbiased in terms of view point. Our proposed model is also a demonstration of managing variable amount of filters without adding the load on number of parameters required. Through the coarse of this work we came up with a image classifier that can classify all meaningful Bangla handwritten characters and numerals of different shapes. Consequently, we have achieved an accuracy rate of 97.21%. The paper provides conclusive results as well as adequate proof behind all the methodologies presented.","Time series classification is a supervised task in the field of temporal data mining. Time series naturally tend to be highly dimensional, requiring the use of reduction techniques such as discretization. eMODiTS is a data-driven method for symbolically discretizing time series, which determines the best scheme by modifying the number of time (word segments) and values (alphabet) cuts, generating a unique alphabet set for every word segment. However, due to the high computational cost required, a surrogate model is incorporated to minimize this cost, using the K-Nearest Neighbors approach for regression and Dynamic Time Warping (DTW) as the similarity measure. Results suggest that the surrogate model effectively estimates the objective functions\u2019 values similarly to the original ones, leading to similar classification rates. It is validated with the statistical test where there is no significant statistical difference between the surrogate and original models. The surrogate model produces modified acceptance index (\nd\nj\n) values regarding predicting ability, indicating that the predictive performance is on average. On the other hand, the Mean Squared Error (MSE) consistently stays below 0.15, demonstrating that even when surrogate models cannot estimate the same values as the original model, the similarity of the values remains clear.","Text sentiment analysis is an important task in natural language processing (NLP), which aims to determine people's emotional tendency towards a certain topic or event by analyzing the language and emotion in the text. Aiming at the traditional emotion classification model can't fully capture the semantic information implied in short text comments, a two-channel emotion classification model based on CNN and BiLSTMl is proposed.Dynamic allocation weights introduced since the attention mechanism, build fusion BiLSTM and CNN's dual channel neural network architecture, and extract the bureau of emotional characteristics and emotional characteristics as global pay attention to the input feature fusion layer, through your emotions full text feature fusion module integration characteristic information and emotional polarity to break..Compared to the experimental results show that the model of emotion classification performance of the optimum Transformer model, this model (CNN-BiLSTM-AFF) on a public data set senti_weibo_100k accuracy, F1 value, the recall rate of 1.034%, 1.265% and 1.045% respectively.","Multi-label learning has attracted a great deal of research interests as it has a wide range of real-world applications. Although many multi-label learning methods have been proposed, very few of them have addressed the problem of class imbalance distribution in multi-label data. Moreover, most of the existing class imbalance multi-label learning algorithms only focus on solving the class imbalance problem, without taking into account the correlations among labels. To address these issues simultaneously, we propose to combine the well-known ensemble of classifier chain (ECC) algorithm with various binary-class imbalance learning techniques such as sampling, cost-sensitive learning, and threshold moving. This approach creates a new algorithm family called ECC++, designed specifically for class imbalance multi-label learning. ECC is already an excellent ensemble high-order binary relevance multi-label learning algorithm that is well-suited to exploiting correlations among labels. Combining it with binary-class imbalance learning techniques enables each link in a classifier chain (CC) to overcome the negative effect of skewed data distribution. ECC++ is a dynamic algorithm family that can be extended arbitrarily by applying any new binary-class imbalance learning techniques. To demonstrate the effectiveness and superiority of the proposed ECC++ algorithm family, we developed several ECC++ family members using some popular binary-class imbalance learning techniques. We then compared them with several state-of-the-art class imbalance multi-label learning algorithms on twelve benchmark and four real-world multi-label datasets. Our experimental results showed the effectiveness and superiority of the proposed ECC++ algorithm family over existing class imbalance multi-label learning algorithms. In conclusion, the proposed ECC++ algorithm family combines the strengths of the well-established ECC algorithm and binary-class imbalance learning techniques, resulting in a superior methodology for class imbalance multi-label learning.","In multi-label classification, it is critical to capitalize on complicated data structures and semantic relationships. Metric learning serves as an effective strategy to provide a better measurement of distances between examples. Existing works on metric learning for multi-label classification mainly learn one single global metric that characterizes latent semantic similarity between multi-label instances. However, such single-semantics metric exploitation approaches can not capture the intrinsic properties of multi-label data possessed of rich semantics. In this paper, the first attempt towards multi-semantics metric learning for multilabel classification is investigated. Specifically, the proposed LIMIC approach simultaneously learns one global and multiple label-specific local metrics by exploiting label-specific side information. The global metric is learned to capture the commonality across all the labels and label-specific local metrics characterize the individuality of each semantic space. The combination of global metric and label-specific local metrics is utilized to construct latent semantic space for each label, in which similar intra-class instances are pushed closer and interclass instances are pulled apart. Furthermore, a metric-based label correlation regularization is constructed to maintain similarity between correlated label spaces. Extensive experiments on benchmark multi-label data sets validate the superiority of our proposed approach in learning effective distance metrics for multi-label classification.","Graph representation learning (GRL) is a powerful tool for graph analysis, which has gained massive attention from both academia and industry due to its superior performance in various real-world applications. However, the majority of existing works for GRL are dedicated to node-based tasks and thus focus on producing node representations. Despite such methods can be used to derive edge representations by regarding edges as nodes, they suffer from sub-par result utility in practical edge-wise applications, such as financial fraud detection and review spam combating, due to neglecting the unique properties of edges and their inherent drawbacks. Moreover, to our knowledge, there is a paucity of research devoted to edge representation learning. These methods either require high computational costs in sampling random walks or yield severely compromised representation quality because of falling short of capturing high-order information between edges. To address these challenges, we present TER and AER, which generate high-quality edge representation vectors based on the graph structure surrounding edges and edge attributes, respectively. In particular, TER can accurately encode high-order proximities of edges into low-dimensional vectors in a practically efficient and theoretically sound way, while AER augments edge attributes through a carefully-designed feature aggregation scheme. Our extensive experimental study demonstrates that the combined edge representations of TER and AER can achieve significantly superior performance in terms of edge classification on 8 real-life datasets, while being up to one order of magnitude faster than 16 baselines on large graphs.","Federated learning (FL) has recently been applied to skin lesion analysis, but the challenges of huge communication requirements and non-independent and identical distributions have not been fully addressed. The former problem arises from model parameter transfer between the server and clients, and the latter problem is due to differences in imaging protocols and operational customs. To reduce communication costs, dataset distillation methods have been adopted to distill thousands of real images into a few synthetic images (1 image per class) in each local client, which are then used to train a global model in the server. However, these methods often overlook the possible inter-client distribution drifts, limiting the performance of the global model. In this paper, we propose a generalizable dataset distillation-based federated learning (GDD-FL) framework to achieve communication-efficient federated skin lesion classification. Our framework includes the generalization dataset distillation (GDD) method, which explicitly models image features of the dataset into an uncertain Gaussian distribution and learns to produce synthetic images with features close to this distribution. The uncertainty in the mean and variance of the distribution enables the synthetic images to obtain diverse semantics and mitigate distribution drifts. Based on the GDD method, we further develop a communication-efficient FL framework that only needs to transmit a few synthesized images once for training a global model. We evaluate our approach on a large skin lesion classification dataset and compare it with existing dataset distillation methods and several powerful baselines. Our results show that our model consistently outperforms them, particularly in comparison to the classical FL method. All resources can be found at https://github.com/jcwang123/GDD-FL.","In multi-label classification, the expansion of output dimension seriously interferes learning performance, and even fails to build a joint prediction model. In order to restrain the proliferation of multi-label classifier\u2019s hypothesis space, the current works focus on the application of global positive label correlation. However, the \u201cblack or white\u201d mechanism ignore other possible forms of label correlation, such as negative or neutral correlation. By introducing the doctrine of the mean, three-way decision (3WD) theory provides a solution for in-depth research on local label correlation, and aims to handle the uncertainty of multi-label learning tasks. In this paper, a novel learning algorithm for multi-label joint classification, namely ML-3WD, is proposed by considering the 3WD label correlation from the perspective of samples. According to the weights of different features on any label, the comprehensive loss of each sample to three action strategies can be measured. Obviously, the 3WD rules for any label variable in multi-label output space is obtained. By aggregating the cutting thresholds between different labels, the division principles of 3WD label correlation are further established. Given any multi-label sample, the local fuzzy membership to co-occurrence or mutual state for label pair is examined based on kernelized fuzzy rough sets. The 3WD local label relevance of each sample is confirmed, that is, positive, negative or neutral. The global application strategy for multi-label classification is utilized to avoid over-fitting induced by local mining strategy. Based on the integral mean of the distribution of 3WD local label relevance in multi-label sample space, two different versions of empirical label relevance are constructed. By constraining the relative position between sub-separation hyperplanes, the 3WD label correlation distribution-based model for multi-label joint classification is designed. The experiment results on fifteen real world multi-label datasets reflect that our algorithm achieves good classification ability and versatility. The impact of core parameters on learning performance is also dissected.\nHighlights\n\u2022\nThe doctrine of the mean in three-way decision theory, which accords with human behavior cognition, inspires us to enrich the \u201dblack or white\u201d mining mechanism on label correlation. By adding buffer processing to the determined correlation, three possible forms for label correlation are first considered, they are positive, negative or neutral. A multi-label classification algorithm is designed according to 3WD label correlation from the perspective of samples, where global empirical label relevance is explicitly applied to restrict the sub-separation hyperplanes of different labels.","A fit person who is health conscious always considers weighing what they eat and takes the calories on the food they eat. There is a certain number of calories per day that helps bodybuilders or people who want to stay fit. Taking in considerations of eating Fruits to have the calories, macros and nutrients they need. This study presents fruit calorie estimation using CNN or Convolutional Neural Network, the program was able to detect all the fruits with recognition accuracy of 70% and the percentage difference calorie estimation for each fruit are as follows: apple has 30.58%, banana garnered 21.15%, grapes garnered 44.07% and orange has 32.20%.","Counterfactually-Augmented Data (CAD) \u2013 minimal editing of sentences to flip the corresponding labels \u2013 has the potential to improve the Out-Of-Distribution (OOD) generalization capability of language models, as CAD induces language models to exploit domain-independent causal features and exclude spurious correlations. However, the empirical results of CAD\u2019s OOD generalization are not as efficient as anticipated.In this study, we attribute the inefficiency to the myopia phenomenon caused by CAD: language models only focus on causal features that are edited in the augmentation operation and exclude other non-edited causal features. Therefore, the potential of CAD is not fully exploited. To address this issue, we analyze the myopia phenomenon in feature space from the perspective of Fisher\u2019s Linear Discriminant, then we introduce two additional constraints based on CAD\u2019s structural properties (dataset-level and sentence-level) to help language models extract more complete causal features in CAD, thereby mitigating the myopia phenomenon and improving OOD generalization capability. We evaluate our method on two tasks: Sentiment Analysis and Natural Language Inference, and the experimental results demonstrate that our method could unlock the potential of CAD and improve the OOD generalization performance of language models by 1.0% to 5.9%.\nHighlights\n\u2022\nExclusion of non-edited causal features causes CAD inefficiency in OOD generalization.\n\u2022\nThis inefficiency is analyzed in feature space by Fisher\u2019s linear discriminant.\n\u2022\nTwo constraints based on CAD structural properties help to extract causal features.\n\u2022\nCAD\u2019s potential for OOD generalization is unlocked.","Diffuse large B-cell lymphoma (DLBCL) is an aggressive and most common type of non-Hodgkin lymphoma. The two major molecular subtypes of DLBCL, i.e. germinal center B-cell-like (GCB) and activated B-cell-like (ABC) types of DLBCL, have different clinical outcomes when treated with combined therapy R-CHOP. Cell-of-origin (COO) is a published prognostic method. Up to now, this classification requires either complex gene expression analysis or multiple immunohistochemistry (IHC) stains requiring expert scoring and assessment. In this paper, we aim to develop an effective and tissue-saving COO classification method based on H&amp;E stained whole slide images (WSIs). Specifically, we develop a new approach named Cellular Features Based Interpretable Network (CellFiNet), by leveraging both interpretable cellular features derived from image tiles and attention based multi-instance learning (AMIL) framework to train a WSI classification model. In comparison with the conventional AMIL approach based on image embeddings derived from convolutional neural networks (CNNs), the proposed approach achieved comparable classification accuracy, while being favorable in terms of explainability, as the model behavior can be interpreted through both attention scores and biologically relevant feature importances at whole slide as well as image tile levels.","In recent years, the prevalence of obesity and its related co-morbidities have been increasing significantly. Therefore, it is an important challenge to pursue an early prediction of obesity risk that could help in reducing the pace of obesity rise when appropriate interventions are placed, accordingly. The prediction and classification of obesity depend on different factors such as body mass index (BMI) and lifestyle aspects, including eating habits. By focusing on these lifestyles and eating habit factors, we can develop a more holistic approach to weight management and prevention of obesity. The aim of this paper is to propose a machine-learning model that can classify weight levels using lifestyle variables without relying on BMI which enables us to investigate how lifestyle factors affect different levels of weight categorization. Although BMI is the most widely used estimation of obesity, there are other factors that can contribute to gaining weight such as lifestyle factors. The accuracy of our lifestyle-based model reached 75% excluding weight, height, and family history. Our model could serve as a starting point for using an interpretable machine learning model to better understand the effect of lifestyle factors on obesity levels.","Highlights\n\u2022\nA novel non-parallel bounded support matrix machine (NPBSMM) is proposed.\n\u2022\nA constraint norm group (CNG) is constructed, which can suppress negative influence of outliers and enhance robustness.\n\u2022\nThe dual problem of NPBSMM avoids the calculation of matrix inversion.\n\u2022\nMulti-rank left and right projection matrices are employed to realize a better ability of data fitting.\nAbstract\nAt present, the excellent performance of support vector machine (SVM) has made it successfully applied in many fields. However, when SVM is used for two-dimensional matrix data classification, vectorization of these data easily leads to dimension curse and the loss of structural information. Moreover, SVM is sensitive to outliers, which causes the hyperplane to move towards outliers. Therefore, this paper proposes a novel classification method for data in matrix-form, named non-parallel bounded support matrix machine (NPBSMM). In NPBSMM, a constraint norm group (CNG) is constructed and applied to objective function, which can not only suppress the negative impact of outliers on the model, but also make NPBSMM has better sparsity. By constructing CNG, the operation of matrix inversion in dual problem of traditional classification methods is avoided, so NPBSMM is more suitable for solving large-scale data problems. Further, to extract structure information of matrix for modeling, multi-rank left and right projection matrices are employed to establish objective function, which makes NPBSMM has a better ability of data fitting. Experiments performed on three roller bearing fault datasets show that the proposed NPBSMM method has powerful performance and robustness as compared with other typical classification methods.","Emotion classification from text is the process of identifying and classifying emotions expressed in textual data. Emotions can be feelings such as anger, joy, suspense, sadness and neutral. Developing a machine learning model to identify emotions in a low-resourced language with a limited set of linguistic resources and annotated corpora is a challenge. This research proposes a Deep Learning Emotion Classification Framework to identify and classify emotions in low-resourced languages such as Hindi. The proposed framework combines a classification model and a low resource optimization technique in a novel way. An annotated corpus of Hindi short stories consisting of 20,304 sentences is used to train the models for predicting five categories of emotions: anger, joy, suspense, sadness, and neutral talk. To resolve the class imbalance in the dataset SMOTE technique is applied. The optimal classification model is selected through experimentation that compares machine learning models and pre-trained models. Machine learning and deep learning models are SVM, Logistic Regression, Random Forest, CNN, BiLSTM, and CNN+BiLSTM. The pre-trained models, mBERT, IndicBERT, and a hybrid model, mBERT+BiLSTM. The models are evaluated based on macro average recall, macro average precision, and macro average F1 score. Results demonstrate that the hybrid model mBERT+BiLSTM out perform other models with a test accuracy of 57%.","Text classification first needs to convert the text into embedding vectors. Considering that static word embedding models such as Word2vec do not consider the position information of word and the difference of its role in different documents, while dynamic word embedding models such as Bert consume a large amount of time. An improved word embedding model based on pre-trained Word2vec is proposed, which achieves better classification accuracy and much lower classification time than Bert. At first, the concept of Term Document Frequency (TDF) is proposed on the basis of TF-IDF, and the TF-IDF-TDF of each word in different documents is calculated. Then, The positional encoding is added. Finally, in order to reduce the misleading of words with low importance, a filter is designed to set the embedding vector with low importance to zero. Considering that the sequence length that the deep learning model can handle is limited, and the text sequence exceeding the Maximum Sequence Length (MSL) set by the deep learning model will be directly truncated and discarded, an adaptive segmentation model is proposed, which can set different segmentation strategies for different texts according to the length of the text and the MSL. In order to maintain the continuity of adjacent text after segmentation, an adjacent-segment-vector-attended co-attention network is designed. In addition, the multi-channel convolution and the capsule network are designed to further extract deep hidden features. Multiple comparative experiment results show that the proposed model achieves the best Accuracy and Micro-F1 on five long text baseline datasets and six short text baseline datasets. In addition, when the MSL is not set too large compared with the document length in the dataset, the classification results of the proposed model are not affected by it.\nHighlights\n\u2022\nAn pre-trained Word2vec based embedding model is proposed.\n\u2022\nAn adaptive segmented text classification model is proposed.\n\u2022\nAn adjacent-segment-vector-attended co-attention network is designed.\n\u2022\nThe multi-channel convolution and capsule network are used to extract deep hidden features.","Facial Micro-Expression (ME) is one of the pre-dominating non-verbal clues to demystify the true emotional states that people try to conceal cautiously. But emotion recognition from spontaneous ME images limits the high accuracy due to short duration and low intensity, lack of sufficient samples and consistencies among publicly available ME datasets. In this study, we have proposed two highly effective, lightweight, and generalized single-channel DLRRF-MER, and multi-channel DLH-3C-FUSION fusion models inspired by deep dense convolutional models and texture-based feature descriptors Local Binary Pattern (LBP) and Histogram of Oriented Gradients (HOG) to recognize ME from apex frame by constructing a composite dataset from five publicly available ME datasets CASME, CASMEII, CAS(ME)2, SAMM and MMEW. Pre-training has been done on a new composition of five facial macro expressions datasets CK+, MUGFE, OuluCasia, SFEW, and RAF-DB. The proposed models are fine-tuned on the target ME dataset rigorously with Stratified 5-Fold and 10-Fold, Leave-One-Subject-Out, and Leave-One-Dataset-Out(LODO) cross-validations(CV). In all evaluations, our proposed algorithms show remarkable improvement in effectiveness which surpasses the state-of-the-art accuracies and results in higher generalization capacity.","Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on public datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using standard commercial hardware. Moreover, large-spread ensembles are more robust than traditional ensembles against evasion attacks, at the cost of an acceptable loss of accuracy in the non-adversarial setting.","The aim of ordinal classification is to predict the ordered labels of the output from a set of observed inputs. Interval-valued data refers to data in the form of intervals. For the first time, interval-valued data and interval-valued functional data are considered as inputs in an ordinal classification problem. Six ordinal classifiers for interval data and interval-valued functional data are proposed. Three of them are parametric, one of them is based on ordinal binary decompositions and the other two are based on ordered logistic regression. The other three methods are based on the use of distances between interval data and kernels on interval data. One of the methods uses the weighted k-nearest-neighbor technique for ordinal classification. Another method considers kernel principal component analysis plus an ordinal classifier. And the sixth method, which is the method that performs best, uses a kernel-induced ordinal random forest. They are compared with na\u00efve approaches in an extensive experimental study with synthetic and original real data sets, about human global development, and weather data. The results show that considering ordering and interval-valued information improves the accuracy. The source code and data sets are available at https://github.com/aleixalcacer/OCFIVD.\nHighlights\n\u2022\nSix ordinal classifiers for interval data-valued data are proposed.\n\u2022\nOrdinal methods for interval-valued functional data are also proposed.\n\u2022\nConsidering ordering and interval-valued information improves the accuracy.\n\u2022\nA kernel-induced ordinal random forest performs best.","Action recognition has become a prerequisite approach to fluent Human-Robot Interaction (HRI) due to a high degree of movement flexibility. With the improvements in machine learning algorithms, robots are gradually transitioning into more human-populated areas. However, HRI systems demand the need for robots to possess enough cognition. The action recognition algorithms require massive training datasets, structural information of objects in the environment, and less expensive models in terms of computational complexity. In addition, many such algorithms are trained on datasets derived from daily activities. The algorithms trained on non-industrial datasets may have an unfavorable impact on implementing models and validating actions in an industrial context. This study proposed a lightweight deep learning model for classifying low-level actions in an assembly setting. The model is based on optical flow feature elicitation and mobilenetV2-SSD action classification and is trained and assessed on an actual industrial activities\u2019 dataset. The experimental outcomes show that the presented method is futuristic and does not require extensive preprocessing; therefore, it can be promising in terms of the feasibility of action recognition for mutual performance monitoring in real-world HRI applications. The test result shows 80% accuracy for low-level RGB action classes. The study's primary objective is to generate experimental results that may be used as a reference for future HRI algorithms based on the InHard dataset.","Highlights\n\u2022\nA novel framework named graph auxiliary augmentation learning (GAU) is proposed, which co-trains the primary task together with a fine-grained auxiliary classification through a multi-task GNN.\n\u2022\nIt alleviates the sensitivity of the model to the pseudo-label quality and reduces the model degradation due to the accumulative error of the pseudo-labels.\n\u2022\nThe fine-grained auxiliary classification task helps to learn better node representations from a different view, thereby boosting the performance of the primary task.\n\u2022\nIt is architecture-agnostic so that it can be applied to any variant of GNN. Experiments show that it can achieve superior performance on different architectures when compared with other state-of-the-art methods.\nAbstract\nNode classification has become an important research topic in recent years. Since there are always a few training samples, researchers improve the performance by properly leveraging the predictions of unlabeled nodes during training. However, suffering from the model degradation resulted from the accumulative error of pseudo-labels, there is limited improvement. In this paper we present fine-grained Graph Auxiliary aUgmentation (GAU). It trains the primary task together with an automatically created auxiliary task which is a fine-grained node classification task. And an auxiliary augmentation strategy is designed to enlarge the labeled set for the auxiliary task by utilizing the pseudo-labels of the primary task. Comprehensive experiments show that GAU alleviates the sensitivity of the model to the pseudo-label quality, so more unlabeled nodes can participate in the training. From the perspective of co-training, the fine-grained auxiliary task which is trained by much more unlabeled nodes helps to learn better node representations from a different view, thereby boosting the final performance. Extensive experiments verify the superior performance of the GAU on different GNN architectures when compared with other state-of-the-art approaches.","Accurate transformer fault diagnosis is crucial for maintaining the power system stability. Due the complex operation condition of the transformer, its faults are with the characteristic of multi-class faults, class-imbalance, and limited diagnosis data of availability. Additionally, some fault samples are only with overheating or discharge labels when collected, it is a challenge that how to how to use these samples. To address these issues, in this paper, a novel transformer fault diagnosis method based on a hybrid model of Res-Variational-Auto-Encoder (ResVAE) and ensemble learning (EL) model is proposed. Through a self-strengthening strategy, fault characteristics are extracted category-by-category by using a residual convolutional neural network, and low dimensional characteristics are mapped into characteristic fusion samples by VAE. Based on this strategy, an offline pre-training model is built based on ResVAE and EL. The hybrid model can obtain more information from offline source domain, enabling the EL to diagnose multiple fault types as well as undetermined faults. Considering 11 categories of imbalanced classification scenarios with limited sample sizes, the comparison is made between eight expansion and six diagnosis algorithms. The results show that the offline pre-training EL model increased the diagnostic accuracy up to 11.224% compared with tradition ratios method. The ResVAE-EL model achieves the highest diagnostic accuracy of 91.011%, which is 10.112% higher than that of the single offline pre-training model.","This paper presents a data pre-processing algorithm to tackle class imbalance in classification problems by undersampling the majority class. It relies on a formalism termed Presumably Correct Decision Sets aimed at isolating easy (presumably correct) and difficult (presumably incorrect) instances in a classification problem. The former are instances with neighbors that largely share their class label, while the latter have neighbors that mostly belong to a different decision class. The proposed algorithm replaces the presumably correct instances belonging to the majority decision class with prototypes, and it operates under the assumption that removing these instances does not change the boundaries of the decision space. Note that this strategy opposes other methods that remove pairs of instances from different classes that are each other\u2019s closest neighbors. We argue that the training and test data should have similar distribution and complexity and that making the decision classes more separable in the training data would only increase the risks of overfitting. The experiments show that our method improves the generalization capabilities of a baseline classifier, while outperforming other undersampling algorithms reported in the literature.","Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized in part by difficulties in verbal and nonverbal social communication. Evidence indicates that autistic people, compared to neurotypical peers, exhibit differences in head movements, a key form of nonverbal communication. Despite the crucial role of head movements in social communication, research on this nonverbal cue is relatively scarce compared to other forms of nonverbal communication, such as facial expressions and gestures. There is a need for scalable, reliable, and accurate instruments for measuring head movements directly within the context of social interactions. In this study, we used computer vision and machine learning to examine the head movement patterns of neurotypical and autistic individuals during naturalistic, face\u2013to\u2013face conversations, at both the individual (monadic) and interpersonal (dyadic) levels. Our model predicts diagnostic status using dyadic head movement data with an accuracy of , highlighting the value of head movement as a marker of social communication. The monadic data pipeline had lower accuracy () compared to the dyadic approach, emphasizing the importance of studying back-and-forth social communication cues within a true social context. The proposed classifier is not intended for diagnostic purposes, and future research should replicate our findings in larger, more representative samples.","Under real-world conditions, faulty samples of key components (e.g., bearings and cutting tools, etc.) are typically limited and sparse. Additionally, their historical data is characterized by time-series and imbalance characteristics. In other words, the training samples are not only limited and noisy, but also exhibit both within-class and between-class imbalance. These factors present significant challenges in the realm of fault monitoring modeling. To tackle these challenges, this paper presents an innovative fault diagnosis method rooted in the extended NI-MWMOTE and LS-SVM. NI-MWMOTE stands as an advanced noise-immunity majority weighted minority oversampling technique, originally introduced in our prior research, and it has exhibited exceptional competitiveness in noisy imbalanced benchmark datasets. It champions an adaptive noise processing strategy leveraging the distribution characteristics of noisy imbalanced data and the essence of machine learning. Specifically, it employs Euclidean distance and neighbor density to differentiate between spurious noise and true noise, and it determines the optimal processing strategy based on misclassification error and iteration. Furthermore, it employs unsupervised aggregative hierarchical clustering, misclassification error, and majority-weighted minority oversampling in a collaborative manner to address both within-class and between-class imbalanced problems. The primary contribution of our paper lies in the context of the monitoring scenario mentioned above. We have expanded the hyper-parameter range of NI-MWMOTE, corrected and optimized its built-in noise function to enhance the interpretability of the model, and successfully applied it in conjunction with LS-SVM to this particular setting. Notably, this marks the pioneering endeavor within our established knowledge sphere into the domain of tool wear state monitoring. The results suggest that, when compared to 11 well-known algorithms, our framework demonstrates significant competitiveness in real-world scenarios characterized under data-limited and noise-imbalanced scenarios for bearings and cutting tools fault diagnosis. This establishes a solid theoretical and practical foundation for similar scenarios.","Pneumonia is an important threat to human health, and different types of pneumonia have different treatment options, so the prediction and classification of pneumonia are important health issues. In this paper, chest X-ray images are used as data, and the final ensemble model can achieve excellent performance on these two tasks. In addition, this paper introduces the InceptionNeXt model to pneumonia prediction and classification problems for the first time, and finds that different model convolution kernels and perception fields may be more suitable for different medical image research tasks.","Agriculture is an important sector in India, and about 58% of the Indian population depends on it. This is why it is paramount it remains profitable and provides a high yield. One of the problems that lead to reduced productivity is the selection of the wrong crop. For maximum productivity, every crop needs specific environmental conditions like soil quality, water, etc. In our work, we have used various Machine learning techniques and based on their comparative analysis adopted the best model to predict the most suitable crop for a particular soil sample based on parameters like Nitrogen, Potassium, Phosphorus, ph. level, rainfall, temperature, and humidity. The dataset is pre-processed and optimized using pre-processing techniques. We have reviewed existing algorithms such as Decision Trees, Naive Bayes, Support Vector Machine (SVM), K Nearest Neighbor (KNN), and Random Forest to predict the most suitable crop and found Naive Bayes Classifier to be the best model, based on performance metrics of precision, recall, accuracy and F1 score.","Braille character recognition(BCR) is a basic step in building and designing any Braille assistive technology. Each Braille character is represented by a 2 \u00d7 3 matrix of raised dots (called a cell), which can be read by touch. This study introduces a generalized recognition approach based on an ensemble of transfer learning models for BCR. The study experiments are performed on two benchmark English Braille datasets (handwritten Braille \u2013 Omniglot (HBO), and Braille character (BC)), and a new dataset of Arabic Braille characters collected by our group called Arabic Braille (AB). First, we investigate the performance of 17- transfer learning models on the three datasets. Then, we build three ensemble approaches based on majority voting from the most effective two, three, and four models in each dataset. The experimental results reveal that the ensemble of DarkNet-53, GoogleNet, SqueezeNet, and DenseNet-201 is a more generalizable ensemble approach for BCR. It achieves a higher F1 score and lesser generalization error ( E t e s t ) value than each individual transfer learning model. The F1 scores of the introduced ensemble reached 89.42%, 99.58%, and 97.11% on the HBO, BC, and AB datasets, respectively, with E t e s t values of 10.47%, 0.43%, and 3.23%. While the F1 scores of the DarkNet-53 which is the most effective single model on the three datasets are 87.54%, 99.14%, and 94.73, with E t e s t values of 12.79%, 0.85%, and 5.31%, respectively.","Recent research has shown that artificial intelligence (AI) models can exhibit bias in performance when trained using data that are imbalanced by protected attribute(s). Most work to date has focused on deep learning models, but classical AI techniques that make use of hand-crafted features may also be susceptible to such bias. In this paper we investigate the potential for race bias in random forest (RF) models trained using radiomics features. Our application is prediction of tumour molecular subtype from dynamic contrast enhanced magnetic resonance imaging (DCE-MRI) of breast cancer patients. Our results show that radiomics features derived from DCE-MRI data do contain race-identifiable information, and that RF models can be trained to predict White and Black race from these data with 60\u201370% accuracy, depending on the subset of features used. Furthermore, RF models trained to predict tumour molecular subtype using race-imbalanced data seem to produce biased behaviour, exhibiting better performance on test data from the race on which they were trained.","Joint intent detection and slot filling, which is also termed as joint NLU (Natural Language Understanding) is invaluable for smart voice assistants. Recent advancements in this area have been heavily focusing on improving accuracy using various techniques. Explainability is undoubtedly an important aspect for deep learning-based models including joint NLU models. Without explainability, their decisions are opaque to the outside world and hence, have tendency to lack user trust. Therefore to bridge this gap, we transform the full joint NLU model to be 'inherently' explainable at granular levels without compromising on accuracy. Further, as we enable the full joint NLU model explainable, we show that our extension can be successfully used in other general classification tasks. We demonstrate this using sentiment analysis and named entity recognition.","Constrained clustering is a semi-supervised task that employs a limited amount of labelled data, formulated as constraints, to incorporate domain-specific knowledge and to significantly improve clustering accuracy. Previous work has considered exact optimization formulations that can guarantee optimal clustering while satisfying all constraints, however these approaches lack interpretability. Recently, decision trees have been used to produce inherently interpretable clustering solutions, however existing approaches do not support clustering constraints and do not provide strong theoretical guarantees on solution quality. In thiswork, we present a novel SAT-based framework for interpretable clustering that supports clustering constraints and that also provides strong theoretical guarantees on solution quality. We also present new insight into the trade-off between interpretability and satisfaction of such user-provided constraints. Our framework is the first approach for interpretable and constrained clustering. Experiments with a range of real-world and synthetic datasets demonstrate that our approach can produce high-quality and interpretable constrained clustering solutions.","Finding the right business partner to drive innovation or acquire technology transfer is a labor and time-intensive process. To simplify this process, there is a need for improved methods of automated matchmaking that can quickly identify the best potential collaboration partners. This paper presents a novel approach for semi-automated business matchmaking between companies and research institutes, that is applied to a first case study. For this purpose, we compare two transformer-based text classification models and evaluate how dataset quality affects few-shot learning performance. Flair's TARS classifier performed very well in our use case, requiring only 40 examples per class to achieve an F1 score of about 90%. This is already very close to the Hugging Face standard text classifier, which achieved an F1 score of 92% with much more annotation effort. The results show that few-shot learning models like TARS can achieve accurate results even with few training samples compared to regular transformer-based language models. Our novel approach allows the time-consuming and labor-intensive task of manual partner matchmaking to be significantly reduced.","The burner combustion tuning is a complex problem that has been studied through flame monitoring and characterization. It has been observed that the flame electromagnetic spectrum and flickering contain specific flame information in combustion processes. This information is helpful for combustion stoichiometry tuning on burners. This paper described a method for selecting the best flame feature subset that can be computed from the scanner signal, in order to get the flame index and induce combustion stoichiometry on burners under specific combustion conditions. We propose a method for selecting a reduced subset with only the useful flame features for flame index classification. To extract the most relevant flame features we use a feature subset selection (FSS) algorithm and to determine the combustion state in burners, five flame indices were defined that represent the most common flame states in oil fuel-fired boilers. FSS includes complete, sequential, and random searches in order to eliminate redundant and noisy flame features to decrease the flame feature set dimension. A probabilistic neural network (PNN) algorithm was implemented for flame feature clustering. Signals from the actual flame scanner system and relevant variables from the boiler data acquisition system were used by the algorithms to calculate the burner flame index. A set of parametric tests was done in a heavy oil-fired boiler under well-known flame and index conditions to train and test the flame classifier. The results showed that only the four more relevant features are enough to classify flames with a good performance (92.3% accuracy), which is useful for burner combustion monitoring and optimization.\nHighlights\n\u2022\nA new approach to defining/selecting critical features in the combustion process.\n\u2022\nA new approach to classifying flames in industrial heavy oil-fired boilers.\n\u2022\nThe proposed algorithms are tested &amp; evaluated in a real industrial process.\n\u2022\nThe overall methodology ensures that the combustion process guarantees safety.","Node classification is an important task in many fields, e.g., predicting entity types in knowledge graphs, classifying papers in citation graphs, or classifying nodes in social networks. In many cases, it is crucial to explain why certain predictions are made. Towards this end, concept learning has been proposed as a means of interpretable node classification: given positive and negative examples in a knowledge base, concepts in description logics are learned that serve as classification models. However, state-of-the-art concept learners, including EvoLearner and CELOE exhibit long runtimes. In this paper, we propose to accelerate concept learning with graph sampling techniques. We experiment with seven techniques and tailor them to the setting of concept learning. In our experiments, we achieve a reduction in training size by over 90% while maintaining a high predictive performance.","We propose a joint model that performs instance-level feature selection and classification. For a given case, the joint model first skims the full feature vector, decides which features are relevant for that case, and makes a classification decision using only the selected features, resulting in compact, interpretable, and case-specific classification decisions. Because the selected features depend on the case at hand, we refer to this approach as context-aware feature selection and classification. The model can be trained on instances that are annotated by experts with both class labels and instance-level feature selections, so it can select instance-level features that humans would use. Experiments on several datasets demonstrate that the proposed model outperforms eight baselines on a combined classification and feature selection measure, and is able to better emulate the ground-truth instance-level feature selections. The supplementary materials are available at https://github.com/IIT-ML/IJCAI23-CFSC.","Lambani is an under-resourced Indo-Aryan language spoken by a nomadic tribe known as the \u2018Banjara people\u2019 across central and southern India. Due to its contact with several major languages of India, Lambani has been influenced both linguistically as well as culturally. One of the major influences has been observed in its phonemic inventory. This paper is a preliminary investigation into the acoustic characteristics of vowels of the language. The paper analyses spectral and temporal features of six Lambani vowels, viz. [inline-graphic not available: see fulltext] spoken in the Bagalkot district of Karnataka. The results obtained throw light on the distinctiveness of this variety. The paper then uses spectral and temporal features to explore both machine learning and deep learning approaches to classify Lambani vowel perceptual space. Results show that Fully Connected Dense Layer achieves better accuracy in classifying Lambani vowels.","A progressive neurodegenerative disease affecting motor neurons, Amyotrophic Lateral Sclerosis (ALS) requires early diagnosis as quickly as possible. For such situations, surface electromyography (S-EMG) is widely used as a non-invasive diagnostic tool to measure muscles' activity through electrodes placed on the skin's surface. Artificial intelligence (AI) approaches can be employed to analyze captured signals and distinguish abnormal patterns. However, previous work focused primarily on spatial information. It does not consider temporal information, effectively capturing the dynamic nature of muscle activity and identifying subtle abnormalities that might indicate ALS. Therefore, we fill the gap in this study by proposing a combination of CNN, Long-Short-Term Memory Networks (LSTM), and attention mechanisms to exploit temporal information in EMG signals. Stability assessment using K-fold cross-validation ensures reliable model performance. Our results demonstrate that combining spatial and temporal information can enhance performance and acquire 98.15% and 98.45% for CNN and LSTM, and CNN, LSTM, and Attention combination. In addition, our proposed model remains stable compared to previous work.","As the importance of machine learning tools for decision support continues to grow, interpretability has emerged as a key factor. Rule-based classification algorithms, such as decision trees and rule induction, enable high local interpretability by providing transparent reasoning rules in an IF-THEN format. In this context, it is essential to provide concise and clear rules and conditions to achieve high local interpretability. This study proposes a novel Concise Algorithm, designed to effectively remove irrelevant conditions from classification rules. We present a framework incorporating the Concise Algorithm, which employs the One-Sided-Maximum decision tree algorithm for rule generation, followed by the application of the Concise Algorithm to remove irrelevant conditions. This proposed framework produces a rule-based classification model that exhibits an enhanced predictive performance-interpretability trade-off compared to benchmark methods (CART, Ripper, CN2, and modified One-Sided-Maximum), as demonstrated by empirical tests conducted on 19 UCI datasets. A case study focusing on the breast-cancer-wisconsin dataset provides a comprehensive analysis of the rule and condition generation processes.","In multi-label learning, each instance is associated with a set of labels. To improve the accuracy and efficiency of multi-label learning tasks, label correlations have been explored. However, existing conventional algorithms obtain label correlation directly from the raw label space, ignoring the significance of the label to the instance. In this study, a novel feature selection method was proposed to select a more relevant and compact feature subset by considering the label distribution and inter-label correlations. First, the concept of label distribution was defined to reflect the significance of each label. Second, a new algorithm for mining association rules was designed to obtain the correlation between labels by improving the existing association rules algorithm. Thus, a new information system was designed by combining the label distribution and correlation between labels. Subsequently, a novel feature selection algorithm was designed in this information system which can effectively remove irrelevant and redundant features in the feature space. Finally, the experimental results demonstrated that the proposed algorithm effectively improves the classification performance and perform better than some state-of-the-art methods.","Improving the fairness of machine learning models is a nuanced task that requires decision makers to reason about multiple, conflicting criteria. The majority of fair machine learning methods transform the error-fairness trade-off into a single objective problem with a parameter controlling the relative importance of error versus fairness. We propose instead to directly optimize the error-fairness tradeoff by using multi-objective optimization. We present a flexible framework for defining the fair machine learning task as a weighted classification problem with multiple cost functions. This framework is agnostic to the underlying prediction model as well as the metrics. We use multiobjective optimization to define the sample weights used in model training for a given machine learner, and adapt the weights to optimize multiple metrics of fairness and accuracy across a set of tasks. To reduce the number of optimized parameters, and to constrain their complexity with respect to population subgroups, we propose a novel meta-model approach that learns to map protected attributes to sample weights, rather than optimizing those weights directly. On a set of real-world problems, this approach outperforms current state-of-the-art methods by finding solution sets with preferable error/fairness trade-offs.","Event detection (ED) aims to identify events of interest described in the text. With the current explosive growth of text data on the internet, ED is increasingly practical and has gained many researchers\u2019 attention. The existing works usually design ED as a token-level multi-class classification task. In this setting, given a sentence, ED models\u2019 prediction for each token is relatively independent and thus cannot fully utilize sentence-level information and the association relations between multiple events in this sentence. To handle these situations, this paper proposes a multi-task learning based event detection model, which introduces an event type oriented text classification as an auxiliary task to improve the model\u2019s understanding of sentence-level information. In addition, this model utilizes a Conditional Random Field (CRF) to explore the correlations between various event types and constrain the model\u2019s output space. Experimental comparisons with state-of-the-art baselines on DuEE dataset demonstrate the model\u2019s effectiveness.","Leveraging unlabeled examples is a crucial issue for boosting performances in semi-supervised learning. In this work, we introduce the SAMOSA framework based on semantic augmentation for mixing semantic components from labeled examples and non semantic characteristics from unlabeled data. Our approach is based on a novel reconstruction module that can be grafted onto most state of the art networks. The proposed approach leans on two main aspects: an architectural component optimized to disentangle semantic and auxiliary non semantic representations using an unsupervised loss, and a semantic augmentation scheme that leverages this disentangling module to generate artificially labeled examples preserving known class information while controlling auxiliary variations. We demonstrate the ability of our method to improve the performance of models trained according to standard semi-supervised procedures Mean Teacher (Tarvainen and Valpola, 2017) MixMatch (Berthelot et al., 2019) and FixMatch (Sohn et al., 2020).\nHighlights\n\u2022\nSAMOSA regularizes classifiers through reconstruction in semi-supervised learning.\n\u2022\nOur Auto-encoder separates semantic and non-semantic information.\n\u2022\nNon-semantic information is isolated thanks to an asymmetrical decoder architecture.\n\u2022\nThe asymmetrical decoder allows for a novel semantic reconstruction regularizer.\n\u2022\nMixing samples\u2019 semantic and non-semantic contents yields a novel data augmentation.","Aspect-based sentiment analysis (ABSA) is a subtask of sentiment classification, and the difficulty is how to capture the sentiment aspect and sentiment polarity pairs in a sentence. Early studies applied serialization models with attention mechanisms to mine sentiment information. These models are simple and effective, but cannot accurately capture sentiment pairs when encountering complex sentences. Recently, scholars have applied dependency information to construct various graph neural networks for the ABSA task. Compared with serialized models, these structured models demonstrate the graph neural network is powerful in capturing information, and further illustrates the syntactic information is effective for sentiment analysis. However, these syntactic models are usually influenced by syntactic parsers, especially for complex sentences. Hence, this paper builds a Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis (LSOIT). Specifically, inducing knowledge-aware opinion induction trees for each aspect word applied by reinforcement learning and attention mechanisms that integrate the lexicon knowledge (i.e. sememe knowledge) and syntax knowledge (i.e. phrase structures, and dependency relationships). Finally, we establish graph neural networks on knowledge-aware opinion induction tree for ABSA. Experimental results on four benchmarking datasets (i.e., Rest14, Laptop14, Twitter and MAMS) demonstrate that LSOIT significantly improves 2.21%, 0.47%, and 0.18% on Rest14, Laptop14, and MAMS comparing with state-of-the-art models, respectively. Ablation Study and Case Study manifest that external knowledge is useful, especially for datasets with standardized grammar rules.\nHighlights\n\u2022\nLexicon and Syntax Enhanced Opinion Induction Tree is proposed.\n\u2022\nUsing reinforcement learning and attention mechanism builds opinion induction trees.\n\u2022\nKnowledge enhanced opinion induction tree is presented.\n\u2022\nGCNs is constructed based on knowledge opinion induction tree for ABSA.","Canonical Correlation Analysis (CCA) has been widely used in Steady-State Visually Evoked Potential (SSVEP) analysis, but there are still challenges in this research area, specifically regarding data quality and insufficiency. In contrast to most previous studies that primarily concentrate on the development of spatial or spectral templates for SSVEP data, this paper proposes a novel temporal filtering method based on a reinforcement learning (RL) algorithm for CCA on SSVEP data. The proposed method leverages RL to automatically and precisely detect and filter low-quality segments in the SSVEP data, thereby improving the accuracy of CCA. Additionally, the proposed RL-based Temporal Filtering is algorithm-independent and compatible with various CCA algorithms. The RL-based Temporal Filtering is evaluated using a wearable dataset consisting of 102 subjects. The experimental results demonstrate significant advancements in CCA accuracy, particularly when combined with the extended CCA (ECCA) algorithm. In addition to performance enhancement, the RL-based Temporal Filtering method provides visualizable filters, which can ensure the transparency of the filtering process and the reliability of the obtained results. By addressing data quality and insufficiency concerns, this novel RL-based Temporal Filtering approach demonstrates promise in advancing SSVEP analysis for various applications.","In the classification of benign and malignant breast tumors, in addition to the extraction of features, the selection of classifier is also an important factor affecting the accuracy of classification. At present, the ensemble classifier has limitations of local optimization and weak scalability in the integration process, which affect the accuracy and stability of classification. In this study, an ensemble classifier based on adaptive weighted ensemble is proposed to classify benign and malignant breast tumors. First, the original ultrasonic RF signal is preprocessed by down-sampling, dilation, and adaptive decomposition. Then, based on the intrinsic modal function obtained by decomposition, the ring region of interest (ROI) containing the tissue surrounding the tumor is determined. Next, texture features are extracted based on ring ROIs. Weighted k-nearest neighbors (KNN), bagged trees, and Gaussian Naive Bayes (NB) are integrated by bagging method, and each classifier is adaptively weighted based on genetic algorithms during the integration process. Finally, benign and malignant breast tumors are classified by an ensemble classifier based on adaptive weights. Experiments based on the Open Access Series of Breast Ultrasound Data database show that the classification accuracy of the proposed adaptive weight-based ensemble classifier is 90%, which is improved by 10.77%, 8.43%, 1.12% and 5.88% compared with the weighted KNN, bagged trees and Gaussian NB alone, and voting-based ensemble classifier. The conclusion is that the proposed ensemble classifier based on adaptive weighting can effectively improve the classification accuracy of breast tumors, which is helpful for the diagnosis of clinical breast tumors.","In this paper, a novel knowledge distillation (KD)-based pedestrian attribute recognition (PAR) model is developed, where a multi-label mixed feature learning network (MMFL-Net) is designed and adopted as the student model. In particular, by applying the grouped depth-wise separable convolution, re-parameterization and coordinate attention mechanism, not only the multi-scale receptive field information is sufficiently fused and spatially dependent robust features are extracted, the model complexity is also effectively kept acceptable. To alleviate the imbalance of category samples, an attribute weight parameter is proposed and considered when calculating the multi-label loss. Moreover, the Jensen\u2013Shannon (JS) divergence-based KD scheme can facilitate the learning of MMFL-Net from the teacher model, which benefits strong fitting ability of the deep feature correlations so as to realize a highly generalized model. The proposed KD-PAR is comprehensively evaluated through many of experiments, and experimental results show the effectiveness and superiority of the proposed model as compared with other advanced MLL-based methods and state-of-the-art PAR models, which efficiently achieves the balance between accuracy and complexity. When facing the complex scenes such as blurry background, similar object interference, and target occlusion, the proposed KD-PAR can even present satisfactory recognition results with strong robustness, thereby providing a feasible and practical solution to the PAR tasks.\nHighlights\n\u2022\nThe proposed KD-PAR can achieve multi-label mixed feature learning for PAR tasks.\n\u2022\nThe JS-based divergence KD scheme is beneficial for learning generalized features.\n\u2022\nAttribute weight can alleviate performance degradation caused by imbalanced samples.\n\u2022\nStructural re-parameterization refines feature presentation with less complexity.","The prevalence of skin cancer, specifically melanoma, constitutes a significant global health concern, thus giving rise to intricate detection challenges that demand immediate attention and comprehensive solutions. In this study, we investigate the application of deep learning models for melanoma detection. Five pre-trained models, including VGG-16, ResNet50, InceptionV3, DenseNet-121, and Xception, are evaluated through a series of experiments. The models undergo the same training process with transfer learning, freezing all layers and modifying the classification layer. The experiments reveal that ResNet50 consistently outperforms the other models, demonstrating superior accuracy, precision, recall, and F1 score. Notably, ResNet50 exhibits exceptional accuracy and F1 score, achieving around 93% in both. This study sheds light on the potential use of deep learning in enhancing melanoma diagnosis and underscores the need for robust and accurate classification systems for early detection and effective treatment of skin cancer.","Multi-label Aspect Category Detection (MACD) is essential for aspect-based sentiment analysis, which aims to identify multiple aspect categories in a given sentence. Few-shot MACD is critical due to the scarcity of labeled data. However, MACD is a high-noise task, and existing methods fail to address it with only two or three training samples per class, which limits the application in practice. To solve above issues, we propose a group of Few-shot Sample-set Operations (FSO) to solve noisy MACD in fewer sample scenarios by identifying the semantic contents of samples. Learning interactions among intersection, subtraction, and union networks, the FSO imitates arithmetic operations on samples to distinguish relevant and irrelevant aspect contents. Eliminating the negative effect caused by noises, the FSO extracts discriminative prototypes and customizes a dedicated query vector for each class. Besides, we develop a multilabel architecture, which integrates with score-wise loss and multi-label loss to optimize the FSO for multilabel prediction, avoiding complex threshold training or selection. Experiments show that our method achieves considerable performance. Significantly, it improves by 11.01% at most and an average of 8.59% Macro-F in fewer sample scenarios.","In this work, we propose DocLangID, a transfer learning approach to identify the language of unlabeled historical documents. We achieve this by first leveraging labeled data from a different but related domain of historical documents. Secondly, we implement a distance-based few-shot learning approach to adapt a convolutional neural network to new languages of the unlabeled dataset. By introducing small amounts of manually labeled examples from the set of unlabeled images, our feature extractor develops a better adaptability towards new and different data distributions of historical documents. We show that such a model can be effectively fine-tuned for the unlabeled set of images by only reusing the same few-shot examples. We showcase our work across 10 languages that mostly use the Latin script. Our experiments on historical documents demonstrate that our combined approach improves the language identification performance, achieving 74% recognition accuracy on the four unseen languages of the unlabeled dataset.","In microseismic monitoring, various types of vibration events are often collected. Realizing the automatic identification of microseismic events in many suspected events is the basis of monitoring timeliness. However, due to the different sampling methods of microseismic data provided by different products, the data often contains different waveform sizes and sampling frequencies. This makes it difficult for existing approaches to be widely used in different projects without data preprocessing. In this paper, we propose the Universal Automatic Classification Network (UACNet), a deep learning approach that automatically identifies microseismic data in engineering without preprocessing. The UACNet model includes multiple convolution layers, adaptive average pooling layers, fully connected layers, and UAC blocks. UAC block is a residual structure with multiple convolutional layers and reset and update gates. The adaptive average pooling layer unifies the input size, and the UAC block functions as a feature extraction network to mine sufficient features from data. We test the proposed UACNet on engineering data and compare it with existing common and advanced methods. As a result, UACNet passed the ablation study, and the classification accuracy of UACNet is 95.62%, which is higher than 89.14% of CNN, 91.24% of ResNet, 91.04% of CapsNet, and 86.16% of RTFN, respectively. Moreover, the influence of waveform size, sampling rate, signal-to-noise ratios, and amplitude on the accuracy of UACNet is analyzed. The results show that UACNet can overcome the influence of these factors and truly realize automatic real-time classification of microseismic signals without preprocessing.","The heart, as the main organ of our human body, plays an important role in pumping blood through our body. Early prevention and prediction of cardiovascular disease (CVD) can save more lives, especially for ordinary people. Hence, this study proposes a voting ensemble-based prediction model for the risk of CVD in ordinary people. We first integrate 2 years of data from the Korea National Health and Nutrition Examination Survey (KNHANES) and then extract the experimental data. Thereafter, the extracted data is preprocessed with missing value imputation and data normalization. A filter-based feature selection approach is also applied to select the efficient attributes for the experiment, then split the data into training (80%) data and test (20%) data. Thenceforth, we use two kinds of hybrid data sampling techniques such as synthetic minority oversampling techniques (SMOTE) plus Tomek Links (SMOTETomek) and SMOTE plus Edited Nearest Neighbors (SMOTEENN) to solve the imbalance issue in the training data. Next, the voting ensemble-based prediction model is designed based on different machine learning algorithms such as logistic regression, support vector machine, and AdaBoost on the balanced training data with selected features and complete features. Lastly, the proposed model is evaluated on the test data and compared with other popularly used machine learning-based models. In the experimental results, the proposed voting ensemble-based prediction model with the SMOTEENN technique on selected features by using the filter-based feature selection approach achieved the best performance with the accuracy of 0.8102, recall 0.8102, g-mean 0.8102, and AUC 0.8102, respectively for the risk of CVD in ordinary people and outperformed other machine learning-based prediction models.","Human behavior recognition is one of the most important research directions in the field of computer vision, and it plays an important role in the fields of rehabilitative medicine, auxiliary security, and scene entertainment. To address the shortcomings of traditional HAR recognition methods with tedious feature extraction and severe overfitting, we propose a human behavior recognition model based on XGBoost and feature simplification methods with a limited data set. The model uses the XGBoost algorithm to classify the collected sensor data to recognize human behaviors. In addition, to improve the efficiency and accuracy of the model, we also propose a feature simplification method to reduce the computational complexity and the risk of model overfitting by reducing the number of features. Experimental results show that the model has high accuracy and computational efficiency and can be applied to different human behavior recognition scenarios.\nCCS Concepts: Computing methodologies\u223cMachine learning\u223cMachine learning approaches","The K-nearest neighbor interpolation method was used to fill in missing data of five indicators of coronary heart disease, diabetes, total cholesterol, triglycerides, and albumin;, and the SMOTE algorithm was used to balance the number of variable indicators. The Relief-F algorithm was used to remove 18 variable indicators and retain 42 variable indicators. LASSO and ridge regression algorithms were used to remove eight variable indicators and retain 52 variable indicators; The prediction accuracy, recall, and AUC values of the linear kernel support vector machine model filtered using Relief-F and LASSO features are high, and the prediction results are optimal; The test result of random forest screened by Relief-F and LASSO features is better than that of the support vector machine model. It is concluded that the random forest model screened by Relief-F features is better as a prediction of lung cancer typing. The research results provide theoretical data support for predicting lung cancer classification using machine learning methods.","State-of-the-art weakly supervised text classification methods, while significantly reduced the required human supervision, still requires the supervision to cover all the classes of interest. This is never easy to meet in practice when human explore new, large corpora without complete pictures. In this paper, we work on a novel yet important problem of weakly supervised open-world text classification, where supervision is only needed for a few examples from a few known classes and the machine should handle both known and unknown classes in test time. General open-world classification has been studied mostly using image classification; however, existing methods typically assume the availability of sufficient known-class supervision and strong unknown-class prior knowledge (e.g., the number and/or data distribution). We propose a novel framework \u00f8ur that lifts those strong assumptions. Specifically, it follows an iterative process of (a) clustering text to new classes, (b) mining and ranking indicative words for each class, and (c) merging redundant classes by using the overlapped indicative words as a bridge. Extensive experiments on 7 popular text classification datasets demonstrate that \u00f8ur outperforms strong baselines consistently with a large margin, attaining 23.33% greater average absolute macro-F1 over existing approaches across all datasets. Such competent accuracy illuminates the practical potential of further reducing human effort for text classification.","Planktons are the building blocks of marine food webs and key indicators of ocean health. Monitoring of plankton populations help study the biological diversity of microbial eukaryotes. Recent years have witnessed the wide usage of digital holographic microscopes (DHM) for in situ detection of underwater microplanktons. Holography has an edge over other imaging techniques due to its unique ability to provide a 3D hologram of the microplankton without disturbing its orientations. In this paper, a novel network architecture with 5.29 GFLOPs is developed for the classification of microplanktons in digital holographic images. The proposed method achieved a class-wise F1-scores above\n80\n%\nat a lower computational cost. The proposal provided competitive performance with respect to six baseline network architectures. This technique has the potential to be appealing for future applications of in situ classification of microplanktons.","Recently, solving ordinal classification problems using machine learning and deep learning techniques has acquired important attention. There are many real-world problems in different areas of knowledge where a categorical variable needs to be predicted, and the existing categories follow an order associated with the nature of the problem: e.g. medical diagnosis with different states of a disease, or industrial quality assessment with different levels of quality. In these problems, it is quite common that the final label for each sample is determined by a group of experts with different opinions, and all opinions are usually summarised in a single crisp label by means of a given statistic (e.g. the median or the mode). Applying standard ordinal classifiers to these crisp labels could result in overfitting, as the labelling information is considered as totally certain. In this work, we propose a unimodal regularisation approach based on soft labelling, i.e. the ordinal information is used to introduce the inherent uncertainty of the label fusion. Specifically, said regularisation is based on using triangular distributions to simulate the aforementioned fusion of the expert opinions, where a parameter is used to decide the amount of probability that is assigned to the target category and the adjacent ones (according to the ordinal scale). The strategy could be applied to the loss function used by any ordinal classification learning algorithm, but we focus on deep learning in this paper. The proposal is compared to a baseline approach for nominal classification tasks and other state-of-the-art unimodal regularisation methods, and the experimental validation includes six benchmark datasets and five performance metrics. The results along with the statistical analysis show that the proposed methodology significantly outperforms the rest of the methods.\nHighlights\n\u2022\nUnimodal regularised loss function based on triangular distributions.\n\u2022\nApplication to different CNN models and ordinal benchmark datasets.\n\u2022\nComparison with other regularisation methods based on different distributions.\n\u2022\nImprovement of state-of-the-art classification performance regarding different metrics.","Railway switches are critical components in the rail system. Operation and maintenance tasks are essential to ensure proper functioning and avoid any failure that can cause delays, reducing operational safety. Data from condition monitoring systems requires advanced analysis tools. This paper presents the analysis of power output data of railway switches. A novel approach is proposed based on statistical analysis techniques combined with Machine Learning techniques to classify power curves by analyzing different sections of the power curves. These curves are studied statistically to classify them into normal and non-normal curves. Then, a dataset is generated with normal and non-normal labelled curves. Shapelets and k-Nearest Neighbour classification algorithms are applied to these data with good results (accuracy, sensitivity and specificity above 88% in each case). As a further analysis, a second dataset with the sectioned curves is done to detect non-normal curves without analyzing the complete curve. For this case study, k-Nearest Neighbour algorithm is able to classify with higher accuracy on the last section of the curve.","Few-Shot Class-Incremental Learning (FSCIL) is to learn novel classes with few data points incrementally, without forgetting old classes. It is very hard to capture the underlying patterns and traits of the few-shot classes. To meet the challenges, we propose a Self-supervised Contrastive Feature Refinement (SCFR) framework which tackles the FSCIL issue from three aspects. Firstly, we employ a self-supervised learning framework to make the network to learn richer representations and promote feature refinement. Meanwhile, we design virtual classes to improve the models robustness and generalization during training process. To prevent catastrophic forgetting, we attach Gaussian Noise to encountered prototypes to recall the distribution of known classes and maintain stability in the embedding space. SCFR offers a systematic solution which can effectively mitigate the issues of catastrophic forgetting and over-fitting. Experiments on widely recognized datasets, including CUB200, miniImageNet and CIFAR100, show remarkable performance than other mainstream works.","The findings on open-set recognition (OSR) show that models trained on classification datasets are capable of detecting unknown classes not encountered during the training process. Specifically, after trainig, the learned representations of known classes dissociate from the representations of the unknown class, facilitating OSR. In this paper, we investigate this emergent phenomenon by examining the relationship between the Jacobian norm of representations and the inter/intra-class learning dynamics. We provide a theoretical analysis, demonstrating that intra-class learning reduces the Jacobian norm for known class samples, while inter-class learning increases the Jacobian norm for unknown samples, even in the absence of direct exposure to any unknown sample. Overall, the discrepancy in the Jacobian norm between the known and unknown classes enables OSR. Based on this insight, which highlights the pivotal role of inter-class learning, we devise a marginal one-vs-rest (m-OvR) loss function that promotes strong inter-class separation. To further improve OSR performance, we integrate the m-OvR loss with additional strategies that maximize the Jacobian norm disparity. We present comprehensive experimental results that support our theoretical observations and demonstrate the efficacy of our proposed OSR approach.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThe underlying principle of OSR is demystified by the Jacobian norm of representation.\n\u2022\nA marginal one-vs-rest loss function is devised for effective OSR.","Meta-learning excels in few-shot learning by extracting shared knowledge from the observed tasks. However, it needs the tasks to adhere to the i.i.d. constraint, which is challenging to achieve due to complex task relationships between data content. Current methods that create tasks in a one-dimensional structure and use meta-learning to learn all tasks flatly struggle with extracting shared knowledge from tasks with overlapping concepts. To address this issue, we propose further constructing tasks from the same environment into hyper-tasks. Since the distributions of hyper-tasks and tasks in a hyper-task can both be approximated as i.i.d. due to further summarization, the meta-learning algorithm can capture shared knowledge more efficiently. Based on the hyper-task, we propose a hierarchical meta-learning paradigm to meta-learn the meta-learning algorithm. The paradigm builds a customized meta-learner for each hyper-task, which makes meta-learners more flexible and expressive. We apply the paradigm to three classic meta-learning algorithms and conduct extensive experiments on public datasets, which confirm the superiority of hierarchical meta-learning in the few-shot learning setting. The code is released at https://github.com/tuantuange/H-meta-learning.","To lessen damages from landslides, the key challenge is to predict the events precisely and accurately. The objective of this study is to assess landslide susceptibility in the study area. To achieve this objective, a detailed landslide inventory has been prepared based on imagery data and frequent field visits of 153 rock slides and 44 debris slides. Nine landslide factors were prepared initially and their relationships with each other and with the type of landslide was analysed. Information gain ratio measure is used to eliminate triggering factors with least score. Train_test_split method was used to classify the dataset into training and testing groups. Decision tree classification model of machine learning was applied for landslide susceptibility model (LSM). The performance was evaluated using classification report and receiver operating characteristic (ROC) curve. Results obtained have proven that the decision tree classification model performed well with good accuracy in forecasting landslide susceptibility.","The metric-based learning framework has been widely used in data-scarce few-shot visual classification. However, the current loss function limits the effectiveness of metric learning. One issue is that the nearest neighbor classification technique used greatly narrows the value range of similarity between the query and class prototypes, which limits the guiding ability of the loss function. The other issue is that the episode-based training setting randomizes the class combination in each iteration, which reduces the perception of the traditional softmax losses for effective learning from episodes with various data distributions.To solve these problems, we first review some variants of the softmax loss from a unified perspective, and then propose a novel Dynamically-Scaled Softmax Loss (DSSL). By adding a probability regulator (for scaling probabilities) and a loss regulator (for scaling losses), the loss function can adaptively adjust the prediction distribution and the training weights of the samples, which forces the model to focus on more informative samples. Finally, we found the proposed DSSL strategy for few-shot classifiers can achieve competitive results on four generic benchmarks and a fine-grained benchmark, demonstrating the effectiveness of improving the distinguishability (for base classes) and generalizability (for novel classes) of the learned feature space.\nHighlights\n\u2022\nThe deep connections between some known losses were established and revealed.\n\u2022\nThe new framework are suitable for small sample scenarios with intuitive motivation.\n\u2022\nDetailed implementation was conducted on sufficient datasets with good result.","In the recommendation systems, there are multiple business domains to meet the diverse interests and needs of users, and the click-through rate(CTR) of each domain can be quite different, which leads to the demand for CTR prediction modeling for different business domains. The industry solution is to use domain-specific models or transfer learning techniques for each domain. The disadvantage of the former is that the data from other domains is not utilized by a single domain model, while the latter leverage all the data from different domains, but the fine-tuned model of transfer learning may trap the model in a local optimum of the source domain, making it difficult to fit the target domain. Meanwhile, significant differences in data quantity and feature schemas between different domains, known as domain shift, may lead to negative transfer in the process of transferring. To overcome these challenges, we propose the Collaborative Cross-Domain Transfer Learning Framework (CCTL). CCTL evaluates the information gain of the source domain on the target domain using a symmetric companion network and adjusts the information transfer weight of each source domain sample using the information flow network. This approach enables full utilization of other domain data while avoiding negative migration. Additionally, a representation enhancement network is used as an auxiliary task to preserve domain-specific features. Comprehensive experiments on both public and real-world industrial datasets, CCTL achieved SOTA score on offline metrics. At the same time, the CCTL algorithm has been deployed in Meituan, bringing 4.37% CTR and 5.43% GMV lift, which is significant to the business.","\u201cUnknown unknowns\u201d are instances predicted models assign incorrect labels with high confidence, greatly reducing the generalization ability of models. In practical applications, unknown unknowns may lead to significant decision-making mistakes and reduce the application value of models. As unknown unknowns are agnostic to models, it is extremely difficult to figure out why models would make highly confident but incorrect predictions. In this paper, based on identification of unknown unknowns, we investigate the interpretability of unknown unknowns arising from convolutional neural network models in image classification tasks by interpretable methods. We employ visualization methods to interpret prediction results on unknown unknowns, further understand predictive models and analyze the predictive basis of unknown unknowns. We focus the application scenario of interpretability of unknown unknowns on a clothes category recognition task (dress vs shorts) in e-commerce platforms, and observe some patterns of models making wrong classifications that lead to unknown unknowns, which indicates that a CNN model that lacks of common sense can make mistakes even for a large dataset. Besides, we observe some interesting phenomena: certain correct predictions of instances are unreliable due to wrongly identified features by CNNs.","Customer churn prediction is an essential strategy for companies, especially in telecommunications. Such industries face the challenge that customers frequently switch operators. Due to the higher cost of acquiring new customers compared to retaining existing ones, companies put considerable effort into keeping their current customers. Improving service quality and identifying the point at which customers are likely to terminate their engagement with the company are crucial in retaining customers. Customer Churn Prediction aims to predict potential customer churn by building an effective predictive model. However, the model\u2019s performance is sensitive to unnecessary and irrelevant features. Feature selection is used to eliminate irrelevant features while emphasizing significant ones. This study suggests utilizing a feature selection method to identify significant features and enhance the accuracy of the customer churn prediction model. We propose employing a recently developed evolutionary computation method known as the gravitational search algorithm (GSA) for the feature selection approaches. We elaborate on GSA and the SVM as the classifier to find the optimum features and to improve the prediction accuracy. Our method produced higher precision and AUC scores than the baseline model (without feature selection).","Uncertainty measures exhibit algebraic and informational perspectives, and the two-view measure integration facilitates feature selections in classification learning. According to neighborhood decision systems (NDSs), two basic algorithms of feature selections (called JE-FS and DE-FS) already exist by using joint and decisional entropies, respectively, but they have advancement space for informationally fusing algebraic measures. In this paper on NDSs, three-way fusion measures are systematically constructed by combining three-way algebraic and informational measures, and thus three-level feature selections are hierarchically investigated by using corresponding monotonic and nonmonotonic measures and strategies. At first, the accuracy, granularity, and composite granularity-accuracy constitute three-way algebraic measures, while the joint, conditional, and decisional entropies (JE, CE, DE) formulate three-way informational measures. Then, three-way algebraic and informational measures are combined via normalization and multiplication, so three-way fusion measures based on JE, CE, DE are established. These new measures acquire granulation monotonicity and nonmonotonicity. Furthermore by relevant measures and monotonicity/nonmonotonicity, three-level feature selections (with null, single, and double fusion levels) related to JE, CE, DE are proposed, and corresponding heuristic algorithms are designed by monotonic and nonmonotonic principles. 4 \u00d7 3 = 12 selection algorithms comprehensively emerge, and they extend and improve current JE-FS and DE-FS. Finally by data experiments, related uncertainty measures and granulation properties are validated, and all 12 selection algorithms are compared in classification learning. As a result, new algorithms outperform JE-FS and DE-FS for classification performance, and the algorithmic improvements accord with the fusion-hierarchical deepening and entropy-systematic development of uncertainty measures.\nHighlights\n\u2022\nThree-way algebraic and informational measures induce three-way fusion measures.\n\u2022\nThree-way fusion measures acquire granulation monotonicity and nonmonotonicity.\n\u2022\nThree-level feature selections offer 4 \u00d7 3 = 12 monotonic/nonmonotonic algorithms.\n\u2022\nExtended heuristic algorithms improve 2 current algorithms on classification effects.","Accurate classification of Acute Myeloid Leukemia (AML) subtypes is crucial for clinical decision-making and patient care. In this study, we investigate the potential presence of age and sex bias in AML subtype classification using Multiple Instance Learning (MIL) architectures. To that end, we train multiple MIL models using different levels of sex imbalance in the training set and excluding certain age groups. To assess the sex bias, we evaluate the performance of the models on male and female test sets. For age bias, models are tested against underrepresented age groups in the training data. We find a significant effect of sex and age bias on the performance of the model for AML subtype classification. Specifically, we observe that females are more likely to be affected by sex imbalance dataset and certain age groups, such as patients with 72 to 86 years of age with the RUNX1::RUNX1T1 genetic subtype, are significantly affected by an age bias present in the training data. Ensuring inclusivity in the training data is thus essential for generating reliable and equitable outcomes in AML genetic subtype classification, ultimately benefiting diverse patient populations.","Data classification is the most common task in machine learning, and feature selection is the key step in the classification task. Common feature selection methods mainly analyze the maximum correlation and minimum redundancy between feature factors and tags while ignoring the impact of the number of key features, which will inevitably lead to waste in subsequent classification training. To solve this problem, a feature selection algorithm (SSMI) based on the combination of sinusoidal sequences and mutual information is proposed. First, the mutual information between each feature and tag is calculated, and the interference information in high-dimensional data is removed according to the mutual information value. Second, a sine function is constructed, and sine ordering is carried out according to the mutual information value and feature mean value between different categories of the same feature. By adjusting the period and phase value of the sequence, the feature set with the largest difference is found, and the subset of key features is obtained. Finally, three machine learning classifiers (KNN, RF, SVM) are used to classify key feature subsets, and several feature selection algorithms (JMI, mRMR, CMIM, SFS, etc.) are compared to verify the advantages and disadvantages of different algorithms. Compared with other feature selection methods, the SSMI algorithm obtains the least number of key features, with an average reduction of 15 features. The average classification accuracy has been improved by 3% on the KNN classifier. On the HBV and SDHR datasets, the SSMI algorithm achieved classification accuracy of 81.26% and 83.12%, with sensitivity and specificity results of 76.28%, 87.39% and 68.14%, 86.11%, respectively. This shows that the SSMI algorithm can achieve higher classification accuracy with a smaller feature subset.","We investigate the generalization properties of a self-training algorithm with halfspaces. The approach learns a list of halfspaces iteratively from labeled and unlabeled training data, in which each iteration consists of two steps: exploration and pruning. In the exploration phase, the halfspace is found sequentially by maximizing the unsigned-margin among unlabeled examples and then assigning pseudo-labels to those that have a distance higher than the current threshold. These pseudo-labels are allegedly corrupted by noise. The training set is then augmented with noisy pseudolabeled examples, and a new classifier is trained. This process is repeated until no more unlabeled examples remain for pseudo-labeling. In the pruning phase, pseudo-labeled samples that have a distance to the last halfspace greater than the associated unsigned-margin are then discarded. We prove that the misclassification error of the resulting sequence of classifiers is bounded and show that the resulting semi-supervised approach never degrades performance compared to the classifier learned using only the initial labeled training set. Experiments carried out on a variety of benchmarks demonstrate the efficiency of the proposed approach compared to state-of-the-art methods.","This paper proposes a multi-task model for the classification and grasp detection of surgical tools so that the tasks such as handing, collection (from the surgeon or other person), disinfection, sorting, and assembling of surgical tools can be automatized with the help of a robotic system, which will in-turn allow health-care workers to spend their time on other complex tasks. The multi-task model uses a feature extractor and the extracted features are processed further to produce the output corresponding to both tasks. To train the model, we have prepared a custom dataset consisting of 800 images with 8 different classes taken from two publicly available datasets namely the HOSPI-Tools Dataset and the Surgical Image dataset. The model was trained using transfer learning in two phases with three different pre-trained feature extractors namely: MobileNetV3-Large, Inception-v3, and EfficientNetV2-S. We have achieved the best results with EfficientNetV2-S as a feature extractor and the results are classification accuracy\u201499.75%, localization accuracy\u201490.375%, and detection accuracy\u201490.25%.","Unsupervised Domain Adaptation (UDA) is an ideal transfer learning method, which can use labeled source data to improve the classification performance of unlabeled target data. At present, the UDA methods for Time Series Classification (TSC) only use time-domain data or frequency-domain data as the input, and ignore fusing them, resulting in insufficient feature extraction and inaccurate source-target distribution alignment. Therefore, we propose an unsupervised Multimodal Domain Adversarial Network (MDAN) for TSC tasks. Specifically, we adopt two feature extractors for the time-domain and frequency-domain feature representations, and employ-three classifiers to perform TSC of source data for training the two feature extractors; Then, we fuse the time-domain and frequency-domain feature representations of source and target data, respectively, input them into the unified domain discriminator for unsupervised multimodal domain adversarial learning, and combine the proposed Time-Frequency-domain Joint Maximum Mean Discrepancy (TF-JMMD) to accurately align the source-target distributions; Finally, we select CNN or ResNet18 as the feature extractors to carry out comprehensive experiments, and the results demonstrate the SOTA performance of MDAN.","Evaluating speaker emotion in conversations is crucial for various applications requiring human-computer interaction. However, co-occurrences of multiple emotional states (e.g. 'anger' and 'frustration' may occur together or one may influence the occurrence of the other) and their dynamic evolution may vary dramatically due to the speaker's internal (e.g., influence of their personalized socio-cultural-educational and demographic backgrounds) and external contexts. Thus far, the previous focus has been on evaluating only the dominant emotion observed in a speaker at a given time, which is susceptible to producing misleading classification decisions for difficult multi-labels during testing. In this work, we present Self-supervised Multi- Label Peer Collaborative Distillation (SeMuL-PCD) Learning via an efficient Multimodal Transformer Network, in which complementary feedback from multiple mode-specific peer networks (e.g.transcript, audio, visual) are distilled into a single mode-ensembled fusion network for estimating multiple emotions simultaneously. The proposed Multimodal Distillation Loss calibrates the fusion network by minimizing the Kullback-Leibler divergence with the peer networks. Additionally, each peer network is conditioned using a self-supervised contrastive objective to improve the generalization across diverse socio-demographic speaker backgrounds. By enabling peer collaborative learning that allows each network to independently learn their mode-specific discriminative patterns,SeMUL-PCD is effective across different conversation environments. In particular, the model not only outperforms the current state-of-the-art models on several large-scale public datasets (e.g., MOSEI, EmoReact and ElderReact), but with around 17% improved weighted F1-score in the cross-dataset experimental settings. The model also demonstrates an impressive generalization ability across age and demography-diverse populations.","In this paper the first results of the process of extracting survival patterns in diagnosed women with invasive cervical cancer with classification techniques from data reported in population-based cancer registry of the municipality of Pasto (Colombia) for a time period of 10 years are presented. The generated knowledge will allow to understand the different socioeconomic and clinical factors affecting the survival of this population group. This knowledge will support effective decision making of government agencies and private health sector in relation to the approach of public policies and prevention programs designed to detect new cases of women with this disease early.","Haze classification plays a crucial role in air quality and visibility assessment. In contrast to traditional image classification, haze classification requires the classifier to capture the characteristics of different levels of haze. However, existing methods primarily focus on feature extraction while neglecting the interference of background information. To address this issue, this paper proposes a hard attention infused network (HAINet) for haze classification, consisting of an unsupervised segmentation module (USM) and a hybrid information fusion module (HIF). The USM is used to extract haze area information in an unsupervised manner, generating various forms of haze images. The HIA selects different various forms of haze images, as a hard attention mechanism, to reduce the impact of background and improve classification performance. We conduct experiments on two datasets, Hazel-level and Haze-Wild, in terms of performance comparison, ablation study, and case studies. The results show that our method effectively reduces the impact of background noise in haze images and consistently improves the classification performance.","Hierarchical text classification aims to assign text to multiple labels in a label set stored in a tree structure. The current algorithms mainly introduce the priori information of the label hierarchy, but the implicit correlation between labels in the hierarchy is rarely applied. At the same time, we also found that the inherent class imbalance of chain labels will also lead to poor classification effects of lower-level labels through a large number of studies. Therefore, a label structure enhanced hierarchy aware global model (LSE-HiAGM) is proposed. Firstly, the common density coefficient of labels is defined to measure the importance of a pair of labels in the hierarchical structure. Secondly, the common density coefficient is used as the weight of the label to update the topological structure features, so that the label can be linked with all labels globally. Finally, the topological structure feature, text features, and label hierarchical features are fused to make full use of all features to improve the embedding quality of low-level labels. In addition, to alleviate the class imbalance problem, a new loss function is used to constrain the model training. The probability of the label being sampled relative to all the labels of the sample is taken as the weight of the loss function. Therefore, a small penalty is imposed on the upper label and a large penalty on the lower label. A large number of experiments on datasets such as RCV1, WOS and NYT show that LSE-HiAGM performs better than the baseline models in hierarchical text classification.","MERS-CoV, which belongs to the beta-coronaviruses together with SARS-CoV-2, although it has received relatively less attention by the COVID-19 pandemic, there is a sufficient possibility of new MERS-CoV lineages and variants. Previous studies have discussed the possibility of frequent recombination of MERS-CoV. We thus present a highly accurate method for the phylogenetic analysis and classification of MERS-CoV including recombinant sequences. We collected the sequences of S protein from MERS-CoV and divided them into five phylogenetic groups, of which recombinant sequences were divided into seven types. Physicochemical properties of amino acids were then calculated from the S protein sequences, and the results were used for the random forest model, Na\u00efve Bayes classification, and k-nearest neighbor method. We also constructed several feature subsets based on the ranked amino acid properties and applied them to the random forest model. In each dataset, the amino acid physicochemical properties were ranked differently. Using this information, classification of MERS-CoV based on machine learning algorithms showed that the random forest model had the best accuracy and area under the curve compared with the k-nearest neighbor and Na\u00efve Bayes classification methods. Several feature subsets were constructed using the correlation feature selection algorithm and applied to the random forest model. Overall, the performance of the classifier was improved compared to that when using all features. Coronaviruses including MERS-CoV continue to evolve into new forms through recombination or mutation. We thus present a method to increase the accuracy of their classification using additional information of the viral protein sequence, and confirm that a subunit consisting of optimal prominent features can improve the performance of the classifier by removing the unnecessary characteristic information.","Cautious classifiers are designed to make indeterminate decisions when the uncertainty on the input data or the model output is too high, so as to reduce the risk of making wrong decisions. In this paper, we propose two cautious decision-making procedures, by aggregating trees providing probability intervals constructed via the imprecise Dirichlet model. The trees are aggregated in the belief functions framework, by maximizing the lower expected discounted utility, so as to achieve a good compromise between model accuracy and determinacy. They can be regarded as generalizations of the two classical aggregation strategies for tree ensembles, i.e., averaging and voting. The efficiency and performance of the proposed procedures are tested on random forests and illustrated on three UCI datasets.","One of the difficult problems in agriculture is predicting the crop production. At the international, regional, and crop level, it is crucial to make decisions on this. In Most of the cases, agricultural, land, climatic, atmospheric, and other characteristics are used to forecast crop production. ML is a crucial decision-support model for estimating agricultural yields, enabling choices about which crops to cultivate and what to do while they are in the growing season. Numerous ML and DL algorithms have been applied to support studies on agricultural yield prediction. In this paper, a new crop yield prediction model is proposed which includes preprocessing, feature extraction and yield prediction phase. In preprocessing, data cleaning will takes place. Higher order statistical feature, information gain and improved entropy based features are extracted in feature extraction phase. The prediction is done by the hybrid model that combines Bi-GRU model and Maxout classifiers. To enhance the performance of this hybrid classifier, a new Self Adaptive Archimedes Optimization Algorithm (SAAOA) is introduced for training the weight parameters optimally. Finally the overall performance is evaluated and the better result is determined.","To improve the classification accuracy of hand movements from sEMG signals, this paper puts forward a unified hand gesture classification framework which exploits the potentials of variational mode decomposition (VMD) and multi-class support vector machine (SVM). Acquiring the sEMG signals from 25 intact subjects for ten functional activities in real-time, we implement a non-recursive adaptive decomposition technique to sEMG signals and perform power spectral analysis to identify the dominant narrow-band intrinsic mode functions (IMFs) that contain prominent biomarkers. Subsequently, to compute the optimal feature vectors from a set of entropy measures, this work investigates the performance of two techniques namely minimum redundancy and maximum relevance (MRMR) technique and kernel principal component analysis (kPCA). After extracting the optimal set of entropy features, the proposed approach implements a multi-class SVM based on one-vs-one (OVO) strategy to classify the hand gestures. The performance of the multi-class SVM compared with those of the K-nearest neighbor (KNN) and na\u00efve bayes (NB) classifiers highlight that multi-class SVM offers superior performance with an average classification accuracy of 99.98%. Moreover, for statistical analysis of the experimental results, this work performs Friedman test to analyze the significance of the SVM, KNN and NB classifier performances. Finally, the performance comparison of the proposed approach with those of the state-of-the-art techniques highlights the superiority of the proposed framework to improve the hand gesture classification accuracy.\nHighlights\n\u2022\nVMD augmented multi-class SVM framework is presented for gesture recognition.\n\u2022\nOptimal entropy measures from decomposed IMFs are extracted through kPCA technique.\n\u2022\nA maximum classification accuracy of 99.98% is achieved using multi-class SVM.\n\u2022\nStatistical analysis of ML classifier models is performed using Friedman test.","Smart speaker voice assistants (VAs) such as Amazon Echo and Google Home have been widely adopted due to their seamless integration with smart home devices and the Internet of Things (IoT) technologies. These VA services raise privacy concerns, especially due to their access to our speech. This work considers one such use case: the unaccountable and unauthorized surveillance of a user's emotion via speech emotion recognition (SER). This paper presents DARE-GP, a solution that creates additive noise to mask users' emotional information while preserving the transcription-relevant portions of their speech. DARE-GP does this by using a constrained genetic programming approach to learn the spectral frequency traits that depict target users' emotional content, and then generating a universal adversarial audio perturbation that provides this privacy protection. Unlike existing works, DARE-GP provides: a) real-time protection of previously unheard utterances, b) against previously unseen black-box SER classifiers, c) while protecting speech transcription, and d) does so in a realistic, acoustic environment. Further, this evasion is robust against defenses employed by a knowledgeable adversary. The evaluations in this work culminate with acoustic evaluations against two off-the-shelf commercial smart speakers using a small-form-factor (raspberry pi) integrated with a wake-word system to evaluate the efficacy of its real-world, real-time deployment.","In the realm of ChatGPT's language capabilities, exploring Arabic Sentiment Analysis emerges as a crucial research focus. This study centers on ChatGPT, a popular machine learning model engaging in dialogues with users, garnering attention for its exceptional performance and widespread impact, particularly in the Arab world. The objective is to assess people's opinions about ChatGPT, categorizing them as positive or negative. Despite abundant research in English, there is a notable gap in Arabic studies. We assembled a dataset from Twitter, comprising 2,247 tweets, classified by Arabic language specialists. Employing various machine learning algorithms, including Support Vector Machine (SVM), Logistic Regression (LR), Random Forest (RF), and Naive Bayes (NB), we implemented hyperparameter optimization techniques such as Bayesian optimization, Grid Search, and random search to select the best hyperparameters which contribute to achieve the best performance. Through training and testing, performance enhancements were observed with optimization algorithms. SVM exhibited superior performance, achieving 90% accuracy, 88% precision, 95% recall, and 91% F1 score with Grid Search. These findings contribute valuable insights into ChatGPT's impact in the Arab world, offering a comprehensive understanding of sentiment analysis through machine learning methodologies.","Plant pathogens in maize create a severe impact that directly affects agricultural productivity. The foliar disease affects maize growth, where diagnosing and controlling them becomes challenging for farmers. Automatic and early detection of such conditions will aid in the prevention of yield loss by providing appropriate treatment. Leaf textures play a significant role in plant disease recognition, and analyzing them makes the task faster and more efficient. With the computer vision approach, we fused an image processing technique called Gabor filtering as a core pipeline for extracting textural features effectively. This paper proposes an enhanced Convolutional Neural Network (CNN) with Gabor filters called GF-CNN for maize disease classification. Several experiments have been conducted with both machine learning classifiers and CNN and a comparison study was made with the existing approaches. Furthermore, the analysis of the proposed method on maize Plant Village datasets shows that GF-CNN outperforms other existing models with improved accuracy of 99.25%. We also experimented by limiting training samples and attained a significant improvement. Thus, exploring Gabor\u2019s textural patterns for recognizing crop disease can increase the robustness of the classification model.","In this study, we propose a new method called 'multi-label mapping' (MLM) for solving multi-class classification problems by mapping them into multi-label problems. The MLM method frequently selects different combinations of base classes, merges the classes, and assigns a new label to each class. Six standard datasets are selected from the UCI machine learning repository to evaluate the proposed method. Experimental results demonstrate that the MLM method reduces 50% to 96.66% of the number of required SVM classifiers and 25.76% to 72.27% of the training-testing time in comparison with the OVA and OVO methods. It also yields a better performance in terms of accuracy, precision, recall, and overfitting. Due to the need for a very low number of the SVM binary classifiers, a low training-testing time, and an acceptable prediction error, the presented method is a potential candidate for use in pattern recognition applications and multi-class classification problems.","Breast cancer characterization remains a significant and challenging issue in contemporary medicine. Accurately distinguishing between malignant and benign breast lesions is crucial for effective diagnosis and treatment. The anatomical structure of malignant breast ultrasound images is more chaotic than that of benign images due to disease pathologies. However, texture-based analysis alone often fails to identify the extent of chaoticness in malignant breast ultrasound images due to their vague appearance with normal echo patterns, leading to missed diagnoses and increased mortality rates. To address this issue, we proposed an angular feature-based multilevel breast cancer classification framework mBCCf that aims to improve the accuracy and efficiency of classification. The proposed framework mimics the radiologist interpretation procedure by identifying the chaoticness on the periphery of the breast lesion in a breast ultrasound image (level-1). If the lesion contains an acute angle in any part of the periphery, it can be characterized as malignant or otherwise benign. However, solely relying on level-1 analysis may result in misclassification, especially when benign lesions exhibit echo patterns that resemble malignant ones. To overcome this limitation and to make the proposed system highly sensitive, advanced texture-based analysis (using combined shape, texture, and angular features) is performed (level-2). Finally, the performance of the proposed system is evaluated using a cross-dataset (consisting of 1293 breast ultrasound images) and compared with the different individual feature extraction techniques. Encouragingly, our system demonstrated an accuracy of 96.99% for classifying malignant and benign tumors, which is also validated using statistical analysis. The implications of our research lie in its potential to significantly improve breast cancer diagnosis by providing a reliable, efficient, and sensitive tool for radiologists.","Homicide involving multiple victims has a significant negative effect on society. Criminal profiling consists of determining the traits of an unknown offender based on those of the crime and the victims, with a view to their identification. To provide the most likely profile of the perpetrator of a multi-victim homicide, we propose a predictive model of supervised machine learning based on a Bayesian Network. Conventional classifiers can generate the perpetrator\u2019s profile according to the traits of each of the victims of the same homicide, but the profiles may differ from one another. To address this issue, we consider the Multi-Instance (MI) learning framework, in which the victims of the same incident form a bag, and each bag is associated with a unique label for each of the perpetrator\u2019s features. We introduce the unanimity MI assumption in this domain, and accordingly allocate a label to the bag based on the labels and probabilities the Bayesian Network has assigned its instances, using a combination rule from those of the ensemble of classifiers. We apply this methodology to the Federal Bureau of Investigation (FBI) homicide database to compare three combination rules empirically in the validation process, as well as theoretically, using the one that ultimately proves to be the best to build the final model, which is then applied in some illustrative examples to achieve the criminal profile.\nHighlights\n\u2022\nPredictive model of Machine Learning based on Bayesian Networks.\n\u2022\nUseful for criminal profiling of multi-victim homicides.\n\u2022\nMulti-Instance learning using combination rules of the ensembles of classifiers.\n\u2022\nApplication to the FBI homicide dataset.","In scenarios with long-tailed distributions, the model's ability to identify tail classes is limited due to the under-representation of tail samples. Class rebalancing, information augmentation, and other techniques have been proposed to facilitate models to learn the potential distribution of tail classes. The disadvantage is that these methods generally pursue models with balanced class accuracy on the data manifold, while ignoring the ability of the model to resist interference. By constructing noisy data manifold, we found that the robustness of models trained on unbalanced data has a long-tail phenomenon. That is, even if the class accuracy is balanced on the data domain, it still has bias on the noisy data manifold. However, existing methods cannot effectively mitigate the above phenomenon, which makes the model vulnerable in long-tailed scenarios. In this work, we propose an Orthogonal Uncertainty Representation (hOUR) of feature embedding and an end-to-end training strategy to improve the long-tail phenomenon of model robustness. As a general enhancement tool, OUR has excellent compatibility with other methods and does not require additional data generation, ensuring fast and efficient training. Comprehensive evaluations on long-tailed datasets show that our method significantly improves the long-tail phenomenon of robustness, bringing consistent performance gains to other long-tailed learning methods.","The original K-nearest neighbour (KNN) algorithm was meant to classify homogeneous complete data, that is, data with only numerical features whose values exist completely. Thus, it faces problems when used with heterogeneous incomplete (HI) data, which has also categorical features and is plagued with missing values. Many solutions have been proposed over the years but most have pitfalls. For example, some solve heterogeneity by converting categorical features into numerical ones, inflicting structural damage. Others solve incompleteness by imputation or elimination, causing semantic disturbance. Almost all use the same K for all query objects, leading to misclassification. In the present work, we introduce KNNHI, a KNN-based algorithm for HI data classification that avoids all these pitfalls. Leveraging rough set theory, KNNHI preserves both categorical and numerical features, leaves missing values untouched and uses a different K for each query. The end result is an accurate classifier, as demonstrated by extensive experimentation on nine datasets mostly from the University of California Irvine repository, using a 10-fold cross-validation technique. We show that KNNHI outperforms six recently published KNN-based algorithms, in terms of precision, recall, accuracy and F-Score. In addition to its function as a mighty classifier, KNNHI can also serve as a K calculator, helping KNN-based algorithms that use a single K value for all queries that find the best such value. Sure enough, we show how four such algorithms improve their performance using the K obtained by KNNHI. Finally, KNNHI exhibits impressive resilience to the degree of incompleteness, degree of heterogeneity and the metric used to measure distance.","Accurate liver cancer classification is essential, as it substantially influences the selection of effective treatment strategies and impacts patient prognosis. Convolutional neural network (CNN) classifiers typically require extensive labeled datasets for training to attain decent performance. However, the process of obtaining labeled data through manual labeling is time-consuming, potentially biased, and costly when applied to large datasets. This study utilizes the Simple Siamese (SimSiam) contrastive self-supervised learning approach to enhance the classification of liver tumours, especially considering the limited availability of labeled computed tomography (CT) scans of liver cancer. We integrate SimSiam with three baseline CNN-based classifiers - Inception, Xception, and ResNet152 - and pretrain them with two loss functions: mean squared error (MSE) and cosine similarity (COS). Our findings show consistent improvements for three classifiers compared to the baseline models. Specifically, the ResNet152 model exhibits the highest performance among the evaluated networks. With MSE and COS losses, the classification accuracy for ResNet152 improves by 1.27% and 2.53%, respectively. The classification accuracy of the Inception model improves by 3.95% and 5.26%. Similarly, Xception\u2019s validation accuracy demonstrates an increase of 2.60% with both loss functions, compared to the baseline models. We validate our pipeline via our multi-resolution in-house abdominal CT scans of primary and secondary liver cancers, including 155 patients with hepatocellular carcinoma, 198 patients with colorectal liver metastases, and 107 patients with intrahepatic cholangiocarcinoma. Source code available at: https://github.com/Ramtin-Mojtahedi/SimSiam-LiverCancer-CL.","The predict-then-optimize framework is fundamental in many practical settings: predict the unknown parameters of an optimization problem and then solve the problem using the predicted values of the parameters. A natural loss function in this environment is to consider the cost of the decisions induced by the predicted parameters in contrast to the prediction error of the parameters. This loss function is referred to as the smart predict-then-optimize (SPO) loss. In this work, we seek to provide bounds on how well the performance of a prediction model fit on training data generalizes out of sample in the context of the SPO loss. Because the SPO loss is nonconvex and non-Lipschitz, standard results for deriving generalization bounds do not apply. We first derive bounds based on the Natarajan dimension that, in the case of a polyhedral feasible region, scale at most logarithmically in the number of extreme points but, in the case of a general convex feasible region, have linear dependence on the decision dimension. By exploiting the structure of the SPO loss function and a key property of the feasible region, which we denote as the strength property, we can dramatically improve the dependence on the decision and feature dimensions. Our approach and analysis rely on placing a margin around problematic predictions that do not yield unique optimal solutions and then providing generalization bounds in the context of a modified margin SPO loss function that is Lipschitz continuous. Finally, we characterize the strength property and show that the modified SPO loss can be computed efficiently for both strongly convex bodies and polytopes with an explicit extreme point representation.\nFunding: O. El Balghiti thanks Rayens Capital for their support. A. N. Elmachtoub acknowledges the support of the National Science Foundation (NSF) [Grant CMMI-1763000]. P. Grigas acknowledges the support of NSF [Grants CCF-1755705 and CMMI-1762744]. A. Tewari acknowledges the support of the NSF [CAREER grant IIS-1452099] and a Sloan Research Fellowship.","The application of hyperspectral imaging with computer-aided technology has promising prospects, and achieving real-time, efficient, and non-destructive detection, especially for food and agricultural products, undoubtedly poses a great challenge. Hyperspectral data processing has many complications, such as large volume, high redundancy, and difficulty extracting useful features. Therefore, this study develops a lightweight end-to-end unified framework for deep neural networks with excellent generalization to conserve memory space and computation. To improve the classification accuracy and performance of the core model LSAC-net, we combine an attention mechanism based on the temporal convolution method with a complementary model-scaling technique. Experimental results on our own datasets for the production year of citri reticulate pericarpium, production origin of Pu\u2019er tea, and process mode of coffee beans show that our model outperforms several other state-of-the-art models.\nHighlights\n\u2022\nA valid approach for the assessment of agri-food products by hyperspectral images is proposed.\n\u2022\nThe network is an integration of convolution and self-attention.\n\u2022\nRobustness of the accuracy by efficient use of hyperspectral image data.\n\u2022\nAn equilibrium model performance achieved by the compound scaling strategy.","Ship classification based on machine learning (ML) has proven to be a significant underwater acoustic research direction. One of the critical challenges rests with how to embed domain signal knowledge into ML models to obtain suitable features that highly correlate with the classification and create better predictors. In this paper, a novel ML-based ship classification model, Hierarchical Underwater Acoustic Transformer (HUAT), is proposed to improve the classification performance. Firstly, the Detection of Envelope Modulation on Noise (DEMON) spectra of ship-radiated noise signals are estimated by cyclostationary analysis. The motivation for using a DEMON-based preprocessing scheme is that valuable propeller information can be revealed by exploiting the second-order cyclostationarity of ship-radiated noise signals. Secondly, the useful features of DEMON spectra are enhanced using a multi-head self-attention module, and the potential features of the Mel spectrograms are extracted employing a Convolutional Neural Network (CNN) module. The two kinds of features are fused to provide ship classification patterns. The challenge of feature learning in the deep classification model is reduced by leveraging domain-related classification knowledge. Finally, the Swin Transformer, based on shifted window self-attention mechanism, is used to learn high-level feature representations and conduct ship classification. Experimental results show that the HUAT model achieves excellent classification performance on ship-radiated noise datasets, ShipsEar and DeepShip. And its classification efficiency is better than the model based on traditional Transformer architecture. In addition, the proposed method provides technical support for the underwater intelligent system capable of automatically sensing sailing vessels and recognizing vessel types.\nHighlights\n\u2022\nThe Detection of Envelope Modulation on Noise (DEMON) spectra of ship-radiated noise signals are estimated by cyclostationary analysis.\n\u2022\nA novel feature fusion strategy is proposed for embedding domain signal knowledge into ML models to obtain suitable features highly correlated with the classification.\n\u2022\nThe valuable features of DEMON spectra and the Mel spectrogram of ship signals are extracted using two different feature extractors.\n\u2022\nThe Swin Transformer is used to learn high-level feature representations and conduct ship classification.","Long-tailed learning is attracting increasing attention due to the unbalanced distributions of real-world data. The aim is to train well-performing depth models. Traditional knowledge transfer methods for long-tailed learning are classified into feature-based horizontal knowledge transfer (HKT) and class-based vertical knowledge transfer (VKT). HKT transfers head-to-tail feature knowledge from different classes to improve classification performance when there are few tail classes. However, HKT easily leads to invalid transfer due to the deviation caused by the difference between the knowledge of head and tail classes. Fortunately, the class space has a multi-grained relationship and can form a multi-granularity knowledge graph (MGKG), which can be recast as coarse-grained and fine-grained losses to guide VKT. In this paper, we propose a hierarchical long-tailed classification method based on multi-granularity knowledge transfer (MGKT), which vertically transfers knowledge from coarse- to fine-grained classes. First, we exploit the semantic information of classes to construct an MGKG, which forms an affiliation of fine- and coarse-grained classes. Fine-grained knowledge can inherit coarse-grained knowledge to reduce transfer bias with the help of MGKG. We then propose a multi-scale feature fusion network, which aims to fully mine the rich information of the features to drive MGKT. Experiments show that the proposed model outperforms several state-of-the-art models in classifying long-tailed data. For example, our model performed 4.46% better than the next-best model on the SUN-LT dataset.\nHighlights\n\u2022\nWe propose a multi-scale feature fusion network about channel and spatial features.\n\u2022\nWe investigate a multi-granularity relationship of class space.\n\u2022\nWe explore a vertical transfer of coarse- to fine-grained knowledge.","According to the characteristics of complex feature information garbage classification application, a garbage classification method based on multi-source information fusion based on Bayesian network is proposed.In this method, the training sample data is preprocessed by La Pullaras smoothing method to solve the problem of zero prior probability in traditional Bayesian method and eliminate the influence of zero value prior probability on fusion results.Then, according to the decision information of the image sensor, combined with the multi-source heterogeneous characteristic information of other sensors of different types, the multi-source information fusion model is established by using the improved Bayesian parameter estimation algorithm.Bayesian networks are established and Bayesian classifiers are constructed to simplify the fusion results. Finally, the discriminant results are obtained by calculating the maximum posterior probability estimate.Through comparative experiments, the average discrimination accuracy of the improved data fusion method for complex feature information garbage samples is increased from 89.5% to 98.5%, which proves that the method can fully integrate multi-source heterogeneous feature information, reduce the high fuzziness of the discrimination process of hazardous waste and recyclable waste, so as to obtain more accurate classification results.This has important theoretical significance and practical value for the classification of complex garbage in daily life.","As the latest representative of GNSS positioning technology, the PPP-RTK method, which is able to achieve centimeter-level positioning using a single receiver, has been recognized as a preferred alternative for emerging applications such as self-drive cars and unmanned ariel vehicles. Nevertheless, the performance of PPP-RTK faces serious challenges in urban environments due to the severe impact of multipath and non-line-of-sight (NLOS) reception. Presently, machine learning-based signal classification methods are increasingly prevalent, which have great potential to serve for detecting NLOS signals by leveraging a wide range of features and parameters. In this contribution, a novel NLOS signal detection method based on the machine learning algorithm is developed, aiming to improve the kinematic positioning performance of PPP-RTK in urban areas. A multilayer perceptron (MLP)-based signal classifier is proposed where the signal strength, satellite elevation and pseudorange consistency are considered as input and then mapped to the signal type labeled by the fish-eye camera. Furthermore, a new stochastic model derived from both the classification results and the prediction confidence is also developed and employed in PPP-RTK processing. Several vehicular experiments are conducted in diverse urban areas to verify the effectiveness of the proposed method. Results indicate that the proposed method outperforms the traditional PPP-RTK with the 3D positioning accuracy improved by 36.7\u201342.3%. Besides, the horizontal positioning availability within 0.1 m and 1 m is improved from 34.9% to 76.3% and 69.5% to 92.1%, respectively. In partly blocked areas, the proposed method is capable of providing continuous centimeter-level positions in both horizontal and vertical directions. Particularly, in urban canyon, the vertical positioning accuracy is dramatically improved by 80.3% with NLOS signals effectively mitigated.","Consumer preference prediction aims to predict consumers\u2019 future purchases based on their historical behavior-level data. Using machine learning algorithms, the prediction results provide evidence to conduct commercial activities and further improve consumer experiences. However, missing values and imbalanced class problems of consumer behavioral data always make machine learning algorithms ineffective. While several methods have been proposed to address missing data or imbalanced class problems, few works have considered the relationships among missing mechanisms, imputation algorithms, imbalanced class methods, and the effectiveness of classification algorithms that use impute data. In this study, we aim to propose an adaptive process for selecting the optimal combination of amputation, imputation, imbalance treatment, and classification based on classification performance. Our research extends the literature by showing significant interaction effects between 1) the amputation mechanism and imputation algorithms, 2) imputation and imbalance treatments, and 3) imbalance treatments and classification algorithms. Using three consumer behavioral datasets from the UCI Machine Learning Repository, we empirically show that, among different classification methods, the overall performance of Random Forest is better than that of Logit, SVM, or Decision Tree. Moreover, Logit, as the most widely used classification method, suffers most from imbalance issues in real-world datasets. Furthermore, Metacost is always the best imbalance treatment for different imputation techniques or missing value mechanisms.","We present a novel algorithm for learning a union of convex separators (UCS) to separate a class from another using decision boundaries, each of which is a convex separator. A convex separator is defined by a collection of hyperplanes that separate one class from another class using an intersection of half-spaces. A union of convex separators can be thought of as an ensemble of such convex separators that collectively separate all points of one class from the other. In this work, we put forth the notion of separability using a UCS previously known in earlier works as min-max separability, provide a gradient-based algorithm for learning UCS, and assess it against popular classifiers using recent datasets of interest.","Handwritten Chinese character recognition has achieved high accuracy using deep neural networks (DNNs), but the structural recognition (which offers structural interpretation, e.g., stroke and radical composition) is still a challenge. Existing DNNs treat character image as a whole and perform classification end-to-end without perception of the structure. They need a large amount of training samples to guarantee high generalization accuracy. In this paper, we propose a method for structural recognition of handwritten Chinese characters based on a modified part capsule auto-encoder (PCAE), which explicitly considers the hierarchical part-whole relationship of characters, and leverages extracted structural information for character recognition. Our PCAE is improved based on stacked capsule auto-encoder (SCAE) so as to better extract strokes and perform classification. By the modified PCAE, the character image is firstly decomposed into primitives (stroke segments), with their shape and pose information decoupled. The transformed primitives are aggregated into higher-level parts (strokes) guided by prior knowledge extracted from writing rules. This process enhances interpretability and improves the discrimination ability of features. Experimental results on a large dataset demonstrate the effectiveness of our method in both Chinese character recognition and stroke extraction tasks.","Deep forest models offer a promising alternative to traditional deep neural networks by demanding fewer training samples and hyperparameters. However, existing deep forest fault diagnosis models encounter persistent challenges such as insufficient representation of multi-grained spatial information and redundancy of cascaded forest features. To address the above challenges, an enhanced deep forest method called random multi-grained fusion cascade forest (rgfc-Forest) is presented for fault diagnosis of electromechanical systems with limited training samples. First, a random multi-grained scanning module is designed to improve feature information learning. Subsequently, a feature fusion cascade forest module is constructed to improve the representativeness of features in multi-grained scanning and cascade forest delivery while ensuring data diversity. Finally, a decision tree self-growth strategy is combined to refine the classification capability of the high-level forest. To evaluate the effectiveness of our proposed method, we applied it to experimental data related to motor system and gearbox faults. Our results demonstrate significant improvements over existing methods: With just 20 samples per class, our method achieved an average accuracy of 84.41% for motor System Diagnosis. Similarly, for the gearbox system, we attained an impressive accuracy of up to 92.72% with the same limited dataset. These outcomes underscore the superior feature representation and fault classification capabilities of our approach compared to both benchmark deep forest models and mainstream deep learning methods when confronted with small training datasets.","Once a crisis arises, people use social media platforms (such as Twitter) to communicate real-time updates. This data is incredibly helpful to disaster relief and response organisations and may offer rapid notifications for prioritising requests. Text mining and machine learning algorithms can scan enormous amounts of unstructured data created by social media outlets like Twitter to recognise disaster-related content based on keywords and phrases. One of the difficulties that algorithms may confront is determining whether the tweet content discusses actual disasters or uses these keywords as metaphors. As a result, this research aims to apply natural language processing (NLP) and classification models to discriminate between authentic and bogus disaster tweets. This dataset from the Kaggle website includes tweets about genuine disasters and fictional disasters. Four machine learning classifier methods were used: KNN, SVM, XGBoostand, and Naive Bayes. KNN offers the highest accuracy.","The family orientation process in Cuban Schools for children with Affective \u2013 Behavioral Maladies (SABM) involves clustering and classification of mixed type data with non-symmetric similarity functions. To improve this process, this paper includes some novel characteristics in clustering and prototype selection. The proposed approach uses a hierarchical clustering based on compact sets, making it suitable for dealing with non-symmetric similarity functions, as well as with mixed and incomplete data. The proposal obtains very good results on the SABM data, and over repository databases. In addition, the proposed clustering method is able to detect the true partitions of data and it was significantly better with respect to others according to external validity indexes. In prototype selection, the proposal obtains a highly reduced prototype set, while maintains the original classifier accuracy.","The task of annotating a data point with labels most relevant to it from a large universe of labels is referred to as Extreme Classification (XC). State-of-the-art XC methods have applications in ranking, recommendation, and tagging and mostly employ a combination architecture comprised of a deep encoder and a high-capacity classifier. These two components are often trained in a modular fashion to conserve compute. This paper shows that in XC settings where data paucity and semantic gap issues abound, this can lead to suboptimal encoder training which negatively affects the performance of the overall architecture. The paper then proposes a lightweight alternative DEXA that augments encoder training with auxiliary parameters. Incorporating DEXA into existing XC architectures requires minimal modifications and the method can scale to datasets with 40 million labels and offer predictions that are up to 6% and 15% more accurate than embeddings offered by existing deep XC methods on benchmark and proprietary datasets, respectively. The paper also analyzes DEXA theoretically and shows that it offers provably superior encoder training than existing Siamese training strategies in certain realizable settings. Code for DEXA is available at https://github.com/Extreme-classification/dexa.","Highlights\n\u2022\nNine supervised machine-learning models were trained and compared.\n\u2022\nA hyperspectral data collection platform was developed for field data collection.\n\u2022\nEffectiveness of MCC and F1 scores were compared for imbalanced dataset.\n\u2022\nQuadratic discriminant classifier with F1 score 0.95 &amp; MCC 0.85 was chosen.\nAbstract\nWeed infestation and their management are a critical production challenge in agricultural fields. Palmer amaranth has created management challenges because it has multiple emergence pattern and has evolved resistant to nine unique herbicide sites of action. Effective Palmer amaranth detection and positive identification in field conditions will help to improve Palmer amaranth control. A field-based hyperspectral imaging system was developed to record Palmer amaranth in soybean fields. The data were pre-processed applying Savitzky-Golay 2nd derivative, Multiplicative Scatter Correction, and Standard Normal Variate in a forward feed manner. Recursive feature elimination, SelectFromModel, sequential forward selection, and backward elimination were used to select significant wavebands from the available 224 bands. Later, supervised machine-learning models were generated to classify soybean and Palmer amaranth using the selected wavebands. Matthew\u2019s correlation coefficient (MCC), F1 score, precision, and recall were considered as the most significant parameters to evaluate the models\u2019 performance. The highest result was obtained by quadratic discriminant analysis with a prediction accuracy of 93.95%, a precision of 90.30%, a recall of 90.29%, an F1 score of 0.95, and an MCC score of 0.85. The findings of this study showed that the combination of hyperspectral imaging and machine-learning is a potential technique for real-time weed detection in the open field condition.","For the machine learning-based prediction of the conversion from mild cognitive impairment to Alzheimer\u2019s disease, the collection of sufficient data to train a model is required, which involves a lot of time and expense. When data is not enough, combining public and in-house data may be appropriate by applying domain adaptation that alleviates inter-site heterogeneity. Existing methods simultaneously transform in-house and public data to represent them into a common feature space, and then train a classifier using labels in public data. However, this procedure causes the time- and cost-consuming re-training of classifier whenever in-house data changes, and also inheres the risk of information loss in public data. Motivated by this, we propose a method that only transforms in-house data while preserving public data, namely one-way domain adaptation. The proposed method represents in-house data similar with public data by matching the data distribution and the connectivity between brain regions with mean vectors and covariance matrices, respectively. Then, the pre-trained classifier in public data is applied to predict AD conversion for in-house data. The experiments, which use the Australian Imaging Biomarkers and Lifestyle Study of Aging and the Open Access Series of Imaging Studies as the in-house data and the Alzheimer's Disease Neuroimaging Initiative as the public data, show the effectiveness and efficiency of the proposed method, improving prediction performance about 34.8% on average without labels in the in-house datasets.","Classifying architectural structures is an important and challenging task that requires expertise. Convolutional Neural Networks (CNN), which are a type of deep learning (DL) approach, have shown successful results in computer vision applications when combined with transfer learning. In this study, we utilized CNN based models to classify regional houses from Anatolia and Balkans based on their architectural styles with various pretrained models using transfer learning. We prepared a dataset using various sources and employed data augmentation and mixup techniques to solve the limited data availability problem for certain regional houses to improve the classification performance. Our study resulted in a classifier that successfully distinguishes 15 architectural classes from Anatolia and Balkans. We explain our predictions using grad-cam methodology.","Over the past two decades, matrix-based or bilinear discriminant analysis (BLDA) methods have received much attention. However, it has been reported that the traditional vector-based regularized LDA (RLDA) is still quite competitive and could outperform BLDA on some benchmark datasets. A central question is whether the superiority of the vector-based RLDA would always hold for general matrix data, or is there any type of matrix data on which BLDA would perform better than RLDA? Actually, the reported comparisons are found to suffer from two limitations: (i) the comparisons are only limited to image data, and (ii) regularized RLDA is compared with non-regularized BLDA. In this paper, we break the two limitations and investigate the central question on another type of matrix data, namely multivariate time series (MTS) data. We propose a new two-parameter regularized BLDA (RBLDA) for MTS data classification. To choose the two parameters, we develop an efficient model selection algorithm. The newly proposed RBLDA enables us to perform a fair comparison between vector-based RLDA and matrix-based RBLDA. Experiments on a number of real MTS data sets are conducted to compare RBLDA with RLDA and evaluate the proposed algorithm. The results reveal that the superiority of the vector-based RLDA does not always hold for general matrix data, and RBLDA outperforms RLDA on MTS data. Moreover, the proposed model selection algorithm is efficient, and RBLDA can produce better visualization of MTS data than RLDA.\nHighlights\n\u2022\nA new regularized BLDA (RBLDA) is proposed for multivariate time series (MTS) classification.\n\u2022\nAn efficient model selection algorithm is developed for the proposed RBLDA.\n\u2022\nEmpirical results show that the proposed RBLDA generally performs better than RLDA on MTS data.\n\u2022\nRBLDA can produce better visualization of MTS data than RLDA.","Skip Abstract Section\nAbstract\nNetwork slicing (Ns) is a key enabling technology to support the concurrent provisioning of better quality of service (QoS) in 5G networks. These services have become essential for a telecom service provider (SP) to offer better QoS and QoE (quality of experience). The QoS parameters are used to estimate the performance of the network, and QoE determines user satisfaction with the network services. The main challenges faced by the service provider are to select the appropriate slice for each service and accurately classify these services on a timely basis to satisfy the Service level agreement (SLA) while improving the QoS and QoE. To overcome this issue, machine learning (ML) is a good solution. In this paper, we have proposed a 5G-KPQI (5G-key performance and quality indicator) model that considers the 5G service-based dataset for the 5G services classification. Next, we used feature selection (FS) methods to rank and select the best feature subset, which increases the performance of ML models and also reduces the training time required by the models. We subsequently considered various ML models to classify the services. Results demonstrate that the 5G-KPQI model ranks the features using Relief-F and mrMR methods and also reduces the training time of the model, hence improving classification performance measured by precision, accuracy, F1-score, recall, MCC, and time. The evaluation of the key approach outperforms in high classification accuracy and less training time using decision tree (DT) and random forest (RF).","Predicting human mobility holds significant practical value, with applications ranging from enhancing disaster risk planning to simulating epidemic spread. In this paper, we present the GeoFormer, a decoder-only transformer model adapted from the GPT architecture to forecast human mobility. Our proposed model is rigorously tested in the context of the HuMob Challenge 2023---a competition designed to evaluate the performance of prediction models on standardized datasets to predict human mobility. The challenge leverages two datasets encompassing urban-scale data of 25,000 and 100,000 individuals over a longitudinal period of 75 days. Geo-Former stands out as a top performer in the competition, securing a place in the top-3 ranking. Its success is underscored by performing well on both performance metrics chosen for the competition---the GEO-BLEU and the Dynamic Time Warping (DTW) measures. The performance of the GeoFormer on the HuMob Challenge 2023 underscores its potential to make substantial contributions to the field of human mobility prediction, with far-reaching implications for disaster preparedness, epidemic control, and beyond.","Mobile application (App) reviews which are provided by users through different App stores are considered as a rich information source for developers to inform about bugs, new feature requests, performance issues, etc. These feedbacks help developers improve the quality of their apps which in turn will significantly impact the user experience and the App\u2019s overall ratings. Popular Apps receive a high number of user reviews daily which makes their manual analysis a very tedious and time-consuming task. Automating the classification of user reviews will save developers time and help them better prioritize the issues that need to be handled. Since an App review is text data in which a user may report more than one issue, we propose a multi-label text classification model which uses neural language models. These models have shown high performance in various natural language processing problems. Experimental results confirm that neural language models outperform frequency-based methods in the context of App reviews classification. In fact, with RoBERTa, we could achieve a 0.87 average F1-score and a 0.16 hamming loss performances.","The ability to detect out-of-distribution (OOD) inputs is essential for safely deploying machine learning models in an open world. Most existing research on OOD detection, and more generally uncertainty quantification, has focused on multi-class classification. However, for many information retrieval (IR) applications, the classification of documents or images is by nature not multi-class but multi-label. This paper presents a pure theoretical analysis of the under-explored problem of OOD detection in multi-label classification using deep neural networks. First, we examine main existing approaches such as MSP (proposed in ICLR-2017) and MaxLogit (proposed in ICML-2022), and summarize them as different combinations of label-wise scoring and aggregation functions. Some existing methods are shown to be equivalent. Then, we prove that JointEnergy (proposed in NeurIPS-2021) is indeed the optimal probabilistic solution when the class labels are conditionally independent with each other for any given data sample. This provides a more rigorous explanation for the effectiveness of JointEnergy than the original joint-likelihood interpretation, and also reveals its reliance upon the assumption of label independence rather than the exploitation of label relationships as previously thought. Finally, we discuss potential future research directions in this area.","Recognizing plant species and disease is essential to practical applications, such as keeping biodiversity and obtaining a desired crop yield. This study aims to extend the recognition from known to unknown classes in the context of plants, termed Plant-relevant Open-Set Recognition (POSR). In this task, a trained model is required to either classify an input image into one of the known classes or an unknown class, even if the model is only trained with the images of known classes. To achieve this task, we propose a method to obtain a high-performance classifier with compact feature distributions for known classes. To have a high-performance classifier, a ViT model pre-trained in the PlantCLEF2022 dataset is transferred, following an observation that a plant-related source dataset is more beneficial to plant species and disease recognition than other commonly used datasets, such as ImageNet. To have compact feature distributions, we adopt additive margin Softmax loss (AM-Softmax) which brings the distance smaller between the features of the same known class and hence gives more spaces for the unknown class. Extensive experimental results suggest that our method outperforms current algorithms. To be more specific, our method obtains AUROC 93.685 and OSCR 93.256 on average on four public datasets, with an average accuracy of 99.295 on closed-set classification. We believe that our study will contribute to the community and, to fuel the field, our codes will be public https://github.com/xml94/POSR. .\nHighlights\n\u2022\nA plant-relevant versatile recognition, PVR, is explicitly proposed from a unified perspective for real-world applications.\n\u2022\nPVR is instantiated as POSR to perform known and unknown class recognition on plant species and disease.\n\u2022\nTo achieve POSR, a ViT model pre-trained in the PlantCLEF2022 dataset and AM-Softmax are leveraged.\n\u2022\nExtensive experiments are executed with non-trivial analysis, which suggests that the proposed method surpasses the current methods with clear margins.","As one of the major threats to the healthy development of various online platforms, fraud has become increasingly committed in the form of gangs since collusive fraudulent activities are much easier to obtain illicit benefits with lower exposure risk. To detect fraudsters in a gang, spatio-temporal graph neural network models have been widely applied to detect both temporal and spatial collusive patterns. However, a closer peek into real-world records of fraudsters can reveal that fraud gangs usually conduct community-level camouflage, specified by two types, i.e., temporal and spatial camouflage. Such camouflage can disguise gangs as benign communities by concealing collusive patterns and thus deceiving many existing graph neural network models. In the meantime, many existing graph neural network models suffer from the challenge of extreme sample imbalance caused by rare fraudsters hidden among massive users. To handle all these challenges, in this paper, we propose a generative adversarial network framework, named Adversarial Camouflage Detector, to detect fraudsters. Concretely, this ACD framework consists of four modules, in charge of community division, camouflage identification, fraudster detection, and camouflage generation, respectively. The first three modules form up a discriminator that uses spatio-temporal graph neural networks as the foundation model and enhance fraudster detection by amplifying the gangs' collusive patterns through automatically identifying and removing camouflage. Meanwhile, the camouflage generation module plays as the generator role that generates fraudsters samples by competing against the discriminator to alleviate the challenge of sample imbalance and increase the model robustness. The experimental result shows that our proposed method outperforms other methods on real-world datasets.","Label distribution learning (LDL) is a new machine learning paradigm for solving label ambiguity. Since it is difficult to directly obtain label distributions, many studies are focusing on how to recover label distributions from logical labels, dubbed label enhancement (LE). Existing LE methods estimate label distributions by simply building a mapping relationship between features and label distributions under the supervision of logical labels. They typically overlook the fact that both features and logical labels are descriptions of the instance from different views. Therefore, we propose a novel method called Contrastive Label Enhancement (ConLE) which integrates features and logical labels into the unified projection space to generate high-level features by contrastive learning strategy. In this approach, features and logical labels belonging to the same sample are pulled closer, while those of different samples are projected farther away from each other in the projection space. Subsequently, we leverage the obtained high-level features to gain label distributions through a well-designed training strategy that considers the consistency of label attributes. Extensive experiments on LDL benchmark datasets demonstrate the effectiveness and superiority of our method.","Significant work has been done on learning regular expressions from a set of data values. Depending on the domain, this approach can be very successful. However, significant time is required to learn these expressions and the resulting expressions can become either very complex or inaccurate in the presence of dirty data. The alternative of manually writing regular expressions becomes unattractive when faced with a large number of values that must be matched.\nAs an alternative, we propose learning from a large corpus of manually authored, but uncurated regular expressions mined from a public repository. The advantage of this approach is that we are able to extract salient features from a set of strings with limited overhead to feature engineering. Since the set of regular expressions covers a wide range of application domains, we expect them to be widely applicable.\nTo demonstrate the potential effectiveness of our approach, we train a model using the extracted corpus of regular expressions for the class of semantic type classification. While our approach yields results that are overall inferior to the state-of-the-art, our feature extraction code is an order of magnitude smaller, and our model outperforms a popular existing approach on some classes. We also demonstrate the possibility of using uncurated regular expressions for unsupervised learning.","This paper presents a LIghtweight Domain Adaptive Cell Segmentation (LIDACS) framework that achieves state-of-the-art results (0.9505 mIoU) in instance segmentation on the SegPC-21 challenge dataset featured in ISBI 2021, while being significantly parameter efficient than the existing methods. LIDACS is a hierarchical multi-stage approach that utilizes prior domain-specific information to perform statistical and empirical analysis. It also employs task-specific augmentations and improved transfer learning via shared representation to enable better data representation. LIDACS also applies a novel cell structure-based contrastive augmentation paired with cell cloning, increasing annotation density and promoting better stain color in-variance. Effectively, LIDACS is a lightweight architecture, efficient for practical deployment, that provides optimal generalization.","The sequential three-way decision (S3WD) model, which merges three-way decisions and granular computing, is increasingly crucial in classification. The risk attitude to the decision process and result costs affects the decisive actions in the S3WD model. Furthermore, decision conflict arises when there is a discrepancy between coarse-grained and fine-grained definite decision-making for the same object, which can potentially impact decision accuracy. However, current studies show incomplete risk preference research and a lack of decision correction strategies to address decision conflict. To address the limitation, four sequential three-way classifiers (S3WCs) are proposed. First, three prominent distance functions are employed to compute similarity classes for condition probability estimation. Second, optimistic, pessimistic, and weighted compromise sequential three-way classifiers are established to reflect the risk preference for the two types of costs. Third, four precision differences in the S3WCs are defined from local and global perspectives. An S3WC with decision correction is presented to improve precision by judging precision differences in adjacent granularity levels and the entire granular structure. Finally, a series of experiments are conducted to thoroughly analyze the characteristics and applications of these S3WCs. The superior classification performance of the proposed models on diverse datasets is demonstrated.\nHighlights\n\u2022\nThree prominent distance functions are adopted to construct similarity classes for condition probability estimation.\n\u2022\nThree kinds of sequential three-way classifiers considering risk preference are proposed.\n\u2022\nLocal and global classification precision differences are defined to detect the classification precision changing status.\n\u2022\nThe sequential three-way classifier with a decision correction strategy is presented to improve the classification precision.","Visual recognition methods assume models will be evaluated on the same class distribution as training data, but real-world data is often heavily class-imbalanced. To address this, the essential idea is to provide discriminative fitting abilities for classes with different sample sizes, i.e., the model achieves better generalization on less frequent classes, while maintaining high classification ability on the recurring classes. In this work, we propose to unify representation learning and classification learning with robust margin adjustment, which enforces a suitable margin in logit space and regularizes the distribution of embeddings. This procedure reduces representation bias in the feature space and reduces classification bias in the logit space at the same time. We further augment the under-represented tail classes on the feature level via re-balanced sampling from the robust prototype, calibrated with the knowledge from well-represented head classes and adaptive embedding uncertainty estimation. We conduct extensive experiments on a common long-tailed benchmark CIFAR100-LT. Experimental results demonstrate the advantage of the proposed AMDRG for the long-tailed recognition problem.","In this paper, we propose a generalization of classical Rough Sets, the Nearest Neighborhood Rough Sets, by modifying the indiscernible relation without using any similarity threshold. We also combine these Rough Sets with Compact Sets, to obtain a prototype selection algorithm for Nearest Prototype Classification of mixed and incomplete data as well as arbitrarily dissimilarity functions. We introduce a set of rules to a priori predict the performance of the proposed prototype selection algorithm. Numerical experiments over repository databases show the high quality performance of the method proposed in this paper according to classifier accuracy and object reduction.","The rapid development of the Internet has led to a geometric expansion of text information resources online. Among them, corpus, as the basic data source of natural language processing based on statistical language model, its construction and application have become a hot issue in current language processing research. After consulting a large number of relevant literature and materials, it was found that many researchers have provided new ideas for multi label corpus text classification methods. However, this article was adding its own understanding and taking this as the direction and basis. In the introduction, the research significance of text classification was introduced, and then academic research and analysis were carried out on the two key sentences of corpus text classification and natural language processing in multi tag corpus text classification. This article then utilized an algorithm model to provide a theoretical basis for the study of multi label corpus text classification methods; At the end of the article, a simulation comparative experiment would be conducted, and the experiment would be summarized and discussed; In the Enterprise L corpus, the difference in recall rates before and after the use of Entrance 1 was 5.5%, the difference in recall rates before and after the use of Entrance 2 was 7.8%, the difference in recall rates before and after the use of Entrance 3 was 3.3%, and the difference in recall rates before and after the use of Entrance 4 was 4.5%. At the same time, with the continuous research of natural language processing and machine learning, the research on text classification methods of multi tag corpus is also facing new opportunities and challenges.","Ensemble classifiers have been investigated by many in the artificial intelligence and machine learning community. Majority voting and weighted majority voting are two commonly used combination schemes in ensemble learning. However, understanding of them is incomplete at best, with some properties even misunderstood. In this paper, we present a group of properties of these two schemes formally under a geometric framework. Two key factors, every component base classifier\u2019s performance and dissimilarity between each pair of component classifiers are evaluated by the same metric\u2014the Euclidean distance. Consequently, ensembling becomes a deterministic problem and the performance of an ensemble can be calculated directly by a formula. We prove several theorems of interest and explain their implications for ensembles. In particular, we compare and contrast the effect of the number of component classifiers on these two types of ensemble schemes. Some important properties of both combination schemes are discussed. And a method to calculate the optimal weights for the weighted majority voting is presented. Empirical investigation is conducted to verify the theoretical results. We believe that the results from this paper are very useful for us to understand the fundamental properties of these two combination schemes and the principles of ensemble classifiers in general. The results are also helpful for us to investigate some issues in ensemble classifiers, such as ensemble performance prediction, diversity, ensemble pruning, and others.","A classification model for predicting the main activity of bitcoin addresses based on their balances is proposed. Since the balances are functions of time, methods from functional data analysis are applied; more specifically, the features of the proposed classification model are the functional principal components of the data. Classifying bitcoin addresses is a relevant problem for two main reasons: to understand the composition of the bitcoin market, and to identify addresses used for illicit activities. Although other bitcoin classifiers have been proposed, they focus primarily on network analysis rather than curve behavior. The proposed approach, on the other hand, does not require any network information for prediction. Furthermore, functional features have the advantage of being straightforward to build, unlike expert-built features. Results show improvement when combining functional features with scalar features, and similar accuracy for the models using those features separately, which points to the functional model being a good alternative when domain-specific knowledge is not available.","Automated machine learning (AutoML) has allowed for many innovations in biomedical data science; however, most AutoML approaches do not support image or text data. To rectify this, we implemented four feature extractors in the Tree-based Pipeline Optimization Tool (TPOT) to make TPOT with Feature Extraction (TPOT-FE), an automated machine learning system that uses genetic programming (GP) to create ideal pipelines for a classification or regression task. These feature extractors enable TPOT-FE to build pipelines that can analyze non-tabular data, including text and images, which are increasingly common biomedical big data modalities that can contain rich quantities of information. We evaluate this approach on six image datasets and four text datasets, including three biomedical datasets, and show that TPOT-FE is able to consistently construct and optimize classification pipelines on all of the datasets.","Using convolutional neural networks for 360\u00b0 images can induce sub-optimal performance due to distortions entailed by a planar projection. The distortion gets deteriorated when a rotation is applied to the 360\u00b0 image. Thus, many researches based on convolutions attempt to reduce the distortions to learn accurate representation. In contrast, we leverage the transformer architecture to solve image classification problems for 360\u00b0 images. Using the proposed transformer for 360\u00b0 images has two advantages. First, our method does not require the erroneous planar projection process by sampling pixels from the sphere surface. Second, our sampling method based on regular polyhedrons makes low rotation equivariance errors, because specific rotations can be reduced to permutations of faces. In experiments, we validate our network on two aspects, as follows. First, we show that using a transformer with highly uniform sampling methods can help reduce the distortion. Second, we demonstrate that the transformer architecture can achieve rotation equivariance on specific rotations. We compare our method to other state-of-the-art algorithms using the SPH-MNIST, SPH-CIFAR, and SUN360 datasets and show that our method is competitive with other methods.","With the exponential increase of interdisciplinary research, identifying accurate disciplines of scientific documents has become increasingly important in various research management tasks. Interdisciplinary classification, which classifies documents into multiple disciplines, is essential for multidisciplinary research development. Due to the scarcity of labeled multidiscipline data, existing scientific document classification methods can't solve the interdisciplinary issue. Most of them also have the problem of explainability with curtly providing classification results. This study proposes an explainable transfer-learning-based classification method for interdisciplinary documents. First, we trained a single-discipline classification model using existing labeled single-discipline documents. Then, we transfer the knowledge learned from single-discipline classification to interdisciplinary classification to address the scarcity of labeled interdisciplinary data. We also added discipline co-occurrence information into our proposed model. Finally, we obtained our final model by training the transferred model with interdisciplinary data. In addition, keyword-based explanations for classifying texts are provided by employing layer-wise relevance propagation. Experiments on real-life NSFC data show the effectiveness of the proposed method, which can promote interdisciplinary development by constructing an efficient and fair classification for interdisciplinary review systems.","We presented the Pyramid Swin Transformer, a versatile and efficient architecture tailored for object detection and image classification. This time we applied it to a wider range of tasks, such as object detection, image classification, semantic segmentation, and video recognition tasks. Our architecture adeptly captures local and global contextual information by employing more shift window operations and integrating diverse window sizes. The Pyramid Swin Transformer for Multi-task is structured in four stages, each consisting of layers with varying window sizes, facilitating a robust hierarchical representation. Different numbers of layers with distinct windows and window sizes are utilized at the same scale. Our architecture has been extensively evaluated on multiple benchmarks, including achieving 85.4% top-1 accuracy on ImageNet for image classification, 51.6\nA\nP\nbox\nwith Mask R-CNN and 54.3\nA\nP\nbox\nwith Cascade Mask R-CNN on COCO for object detection, 49.0 mIoU on ADE20K for semantic segmentation, and 83.4% top-1 accuracy on Kinetics-400 for video recognition. The Pyramid Swin Transformer for Multi-task outperforms state-of-the-art models in all tasks, demonstrating its effectiveness, adaptability, and scalability across various vision tasks. This breakthrough in multi-task learning architecture opens the door to new research and applications in the field.","Much of Earth's charismatic megafauna is endangered by human activities, particularly the rhino, which is at risk of extinction due to the poaching crisis in Africa. Monitoring rhinos' movement is crucial to their protection but has unfortunately proven difficult because rhinos are elusive. Therefore, instead of tracking rhinos, we propose the novel approach of mapping communal defecation sites, called middens, which give information about rhinos' spatial behavior valuable to antipoaching, management, and reintroduction efforts. This paper provides the first-ever mapping of rhino midden locations by building classifiers to detect them using remotely sensed thermal, RGB, and LiDAR imagery in passive and active learning settings. As existing active learning methods perform poorly due to the extreme class imbalance in our dataset, we design MultimodAL, an active learning system employing a ranking technique and multimodality to achieve competitive performance with passive learning models with 94% fewer labels. Our methods could therefore save over 76 hours in labeling time when used on a similarly-sized dataset. Unexpectedly, our midden map reveals that rhino middens are not randomly distributed throughout the landscape; rather, they are clustered. Consequently, rangers should be targeted at areas with high midden densities to strengthen anti-poaching efforts, in line with UN Target 15.7.","Clothing classification serves as a fundamental task for clothing retrieval, clothing recommendation, etc. In this task, there are two inherent challenges: suppressing complex backgrounds outside the clothing region and disentangling the feature entanglement of shape-similar clothing samples. These challenges arise from insufficient attention to key distinctions of clothing, which hinders the accuracy of clothing classification. Also, the high computational resource requirement of some complex and large-scale models also decreases the inference efficiency. To tackle these challenges, we propose a new COntext-driven Clothing ClassIfication network (COCCI), which improves inference accuracy while reducing model complexity. First, we design a self-adaptive attention fusion (SAAF) module to enhance category-exclusive clothing features and prevent misclassification by suppressing ineffective features with confused image contexts. Second, we propose a novel multi-scale feature aggregation (MSFA) module to establish spatial context correlations by using multi-scale clothing features. This helps disentangle feature entanglement among shape-similar clothing samples. Finally, we introduce knowledge distillation to extract reliable teacher knowledge from complex datasets, which helps student models learn clothing features with rich representation information, thereby improving generalization while reducing model complexity. In comparison to state-of-the-art networks trained with one single model, our method achieves SOTA performance on the widely-used clothing classification benchmark.","This paper introduces a binary classification network that utilizes the Informer Encoder to classify ping pong actions as either correct or incorrect. The dataset used in this study comprises 949 action videos capturing two fundamental ping pong stroke actions performed by athletes, including both correct and incorrect actions. The average frame count for each action is 38.62. Temporal skeletal data is extracted from the videos using a 2D pose estimation model, and a fully connected layer is employed to perform binary classification on the temporal skeletal data. During training and testing, the extracted skeletal data is segmented into temporal sequences of 39 frames for training and evaluation. On the test set, the Informer Encoder-based model achieves 100% accuracy, while the MLP-based model reaches 94%.","Applications involving Extreme Multi-Label Classification (XMLC) face several practical challenges with respect to scale, model size and prediction latency, while maintaining satisfactory predictive accuracy. In this paper, we propose a Multi-Label Factorization Machine (MLFM) model, which addresses some of the challenges in XMLC problems. We use behavioral ad targeting as a case study to illustrate the benefits of the MLFM model. Predicting user qualifications for targeting segments plays a major role in both personalization and real-time bidding. Considering the large number of segments and the prediction time requirements of real-world production systems, building scalable models is often difficult and computationally burdensome. To cope with these challenges, we (1) reformulate the problem of assigning users to segments as a multi-label classification (XMLC) problem, and (2) leverage the benefits of the conventional FM model and generalize its capacity to joint prediction across a large number of targeting segments. We have shown that the MLFM model is both effective and computationally efficient compared to several baseline models on publicly available datasets in addition to the targeting use case.","Decision tree algorithm, because of its strong interpretability and high algorithm efficiency, is widely used in the field of pattern recognition and classification. When the number of data samples is small and there is uncertainty in the data, it is difficult for the traditional decision tree algorithm to fully mine the effective information in the data. In this paper, we use the Dempster\u2013Shafer framework to model data uncertainty and propose a hierarchical interval estimation method to improve decision tree algorithms. The proposed method constructs intervals through two methods of attribute boundary and mean square error estimation, which not only utilizes the characteristics of intervals to model the inaccuracy of data, but also constrains intervals from two aspects, narrowing the representation range of available information. By comparing with the classic decision tree algorithm and the decision tree algorithm based on single interval estimation, the proposed method can perform classification tasks robustly and accurately in different types of data under seven data sets.\nHighlights\n\u2022\nWe propose an evidential decision tree based on a reliability-based BPA generation method and hierarchical interval estimation.\n\u2022\nThe proposed method greatly reduces the influence of the labels of uncertain data on the classification accuracy of the decision tree and strengthens the robustness of the algorithm.\n\u2022\nComparison with fifteen different decision trees, the accuracy of our proposed method on seven datasets is higher than other methods especially in the face of with uncertain attributes and labels.","Ensemble methods are advanced learning algorithm proposed for generating base classifiers and accumulating them all together to derive a new classifier which is expected to perform better than the constituent classifier. This study proposes a novel ensemble technique where a base learning classifier is trained repeatedly by using different weightings over the training samples or examples, and the process is governed by the conceptualization of evolutionary processes and the aggregation operators. We utilize the evolutionary technique that can efficiently search a large weighing space for enriching suitable weights (chromosome) to the training samples. For finding an appropriate weighting, the crossover and mutation processes are applied on the weighting space to get the optimized set of weights which is accomplished through different generations. The considered base learning classifier is trained over the training examples along with their respective weightings by utilizing a learning algorithm, and for the finite number of generations, the weights are evolved and optimized through the evolutionary process. All the classifiers obtained in different generations of the evolutionary process are utilized for efficiently building the final ensemble. The set of classifiers obtained in different generations are combined together by utilizing the concept of priority-based averaging aggregation operator by availing priority to different generations. The classifier ensemble is done with two forms of operators: one without priority degree and the other with the priority degree. The proposed classifier ensemble algorithm is tested over the UCI benchmark dataset. The results obtained through the experimental process are more accurate, consistent, and reliable while comparing to other state-of-the-art methods, which ensures the efficacy of the proposed algorithm.","This paper presents an empirical analysis of theperformance of popular convolutional neural networks (CNNs) for identifying objects in real time video feeds. The most popular convolution neural networks for object detection and object category classification from images are Alex Nets, GoogLeNet, and ResNet50. A variety of image data sets are available to test the performance of different types of CNN\u2019s. The commonly found benchmark datasets for evaluating the performance of a convolutional neural network are anImageNet dataset, and CIFAR10, CIFAR100, and MNIST image data sets. This study focuses on analyzing the performance of three popular networks: Alex Net, GoogLeNet, and ResNet50. We have taken three most popular data sets ImageNet, CIFAR10, and CIFAR100 for our study, since, testing the performance of a network on a single data set does not reveal its true capability and limitations. It must be noted that videos are not used as a training dataset, they are used as testing datasets. Our analysis shows that GoogLeNet and ResNet50 are able to recognize objects with better precision compared to Alex Net. Moreover, theperformance of trained CNN\u2019s vary substantially across different categories of objects and we, therefore, will discuss the possible reasons for this.","Spectrogram zeros, originated by the destructive interference between the components of a signal in the time\u2013frequency plane, have proven to be a relevant feature to describe the time-varying frequency structure of a signal. In this work, we first introduce a classification of the spectrogram zeros in three classes that depend on the nature of the components that interfere to produce them. Then, we describe an algorithm to classify these points in an unsupervised way, based on the analysis of the stability of their location with respect to additive noise. Finally, potential uses of the classification of zeros of the spectrogram for signal detection and denoising are investigated, and compared with other methods on both synthetic and real-world signals.\nHighlights\n\u2022\nSpectrogram zeros can be classified in three kinds.\n\u2022\nAn unsupervised, noise-assisted method to classify spectrogram zeros is introduced.\n\u2022\nThe classification helped to overcome limitations of previous zero-based methods.\n\u2022\nOur approaches for signal detection and denoising are effective in low SNR cases.","Breast cancer became the major source of mortality between women. The accessibility of healthcare datasets and data analysis promote the researchers to apply study in extracting unknown pattern from healthcare datasets. The intention of this study is to design a prediction system that can predict the incidence of the breast cancer at early stage by analyzing smallest set of attributes that has been selected from the clinical dataset. Wisconsin breast cancer dataset (WBCD) have been used to conduct the proposed experiment. The potential of the proposed method is obtained using classification accuracy which was obtained by comparing actual to predicted values. The outcome confirms that the maximum classification accuracy (99.28%) is achieved for this study.","Data-driven bearing fault diagnosis methods have become increasingly crucial for the health management of rotating machinery equipment. However, in actual industrial scenarios, the scarcity of labeled data presents a challenge. To alleviate this problem, many transfer learning methods have been proposed. Some domain adaptation methods use models trained on source domain to generate pseudo labels for target domain data, which are further employed to refine models. Domain shift issues may cause noise in the pseudo labels, thereby compromising the stability of the model. To address this issue, we propose a Hierarchical Pseudo Label Domain Adversarial Network. In this method, we divide pseudo labels into three levels and use different training approach for diverse levels of samples. Compared with the traditional threshold filtering methods that focus on high-confidence samples, our method can effectively exploit the positive information of a great quantity of medium-confidence samples and mitigate the negative impact of mislabeling. Our proposed method achieves higher prediction accuracy compared with the-state-of-the-art domain adaptation methods in harsh environments.","The deep forest model, a random forest (RF) ensemble approach and an alternative to Deep Neural Network (DNN), has performance highly competitive to DNN in many classification tasks. However, deep forest model may encounter overfitting and characteristic dispersion issues as processing small-scale, class-imbalance or high-dimension data. Therefore, this paper proposes a Weighted Cascade Deep Forest framework, called WCDForest. In WCDForest, an equal multi-grained scanning module is used to scan each feature equally. Meanwhile, this framework adopts a class vector weighting module to emphasis the performance of each forest and each sliding window by weight. Furthermore, this study proposes a feature enhancement module to reduce the information loss in the first few cascade layers to improve the classification accuracy. Subsequently, systematic comparison experiments on 18 widely used public datasets demonstrate that the proposed model outperforms the state-of-the-art model. In particular, WCDForest improves the accuracy, precision, recall and F1-score by an average of 5.47%,7.04%,8.23% and 8.94%,respectively.","This study addresses challenges in land use and cover identification using remote sensing (RS) imagery, focusing on the Uppal region. By leveraging deep learning models, particularly an optimized ResNext-50 architecture, we aim to enhance efficiency and accuracy in classifying land features. Our approach integrates Landsat-8 and hyper-spectral satellite data, utilizing preprocessing techniques like dark subtraction, stacking, merging, and spectral enhancement. Principal Component Analysis (PCA) is applied to streamline high-dimensional feature sets obtained from pre-processed spectral data. We further employ hybrid NSCT-FDCT fusion for integrating Landsat-8 and hyperspectral images. The resulting fused image is fed into our classification process, utilizing the modified ResNext50 (Deep Learning Architecture) model with Reptile Search Optimization for weight link optimization. Notably, our proposed method achieves impressive outcomes: 97% accuracy, 96% sensitivity, 99% specificity, 3% error, 97% precision, and a 95% Matthew Correlation Coefficient. This demonstrates the efficacy of our approach in predicting diverse land covers within the Uppal region, showcasing the potential of Landsat-8 and Hyper-spectral data for accurate land use and cover identification.","Existing class incremental learning methods typically employ knowledge distillation to minimize discrepancies in model outputs. However, these methods are restricted by the mismatch between quondam knowledge and new data. To alleviate these issues, we introduce semantic alignment decouples the classification and distillation in different semantic spaces. The unmatched new data is regarded as out-of-distribution data on the old class distribution, and the corresponding pseudo-labels are attached to the new data using the original network. Intuitively, the pseudo-labels could be consistently preserved in the old semantic space. Moreover, we develop auxiliary self-supervised classifiers to learn more generalized representation, enabling a better stability-plastic trade-off. Furthermore, self-distillation is employed to refine self-supervised knowledge from auxiliary classifiers. Extensive experiments demonstrate that our method achieves the best performance on CIFAR100, ImageNet100, ImageNet, CUB200, and Stanford-Dogs120 datasets. Notably, our method outperforms existing methods by a substantial margin when only one old exemplar is stored per class, i.e., 11.34% and 21.46% improvement on CIFAR100 of 5 phases and 10 phases, respectively.","Bees play an important role as pollinating agents, contributing to the reproduction of many plant species around the world. Brazil is the home for different species of stingless bees, with around 200 registered species out of the more than 500 species classified worldwide. Each species constructs the entrance to its colony in an unique but similar way among colonies of the same species. In this work, we proposed a new dataset created in collaboration with stingless beekeepers from Brazil for the exploration of stingless bee species classification. The dataset consists of 158 samples distributed unequally among the 13 species: Boca de Sapo, Bor\u00e1, Bugia, Ira\u00ed, Japur\u00e1, Jata\u00ed, Lambe Olhos, Mandaguari, Mirim Droryana, Mirim Pregui\u00e7a, Mo\u00e7a Branca, Manda\u00e7aia, and Tubuna. The results presented in this work were obtained using deep learning models (i.e. CNN architectures) such as VGG and DenseNet, which are commonly used for image classification task in different application domains. Pre-trained models from ImageNet were used, along with transfer learning techniques, and due to the small size of the dataset, data augmentation techniques were applied, resulting in an expanded dataset of 1,106 samples. The experimental results demonstrated that the DenseNet model achieved the best results, reaching an accuracy of\n95\n%\n. The dataset created will be also made available as a contribution of these work. As far as we know, the stingless bee species identification task based on the colony entrance is addressed for the first time in this work.","Fake news is a major challenge in social media, particularly in the health domain where it can lead to severe consequences for both individuals and society as a whole. To contribute to combating this problem, we present a novel solution for improving the accuracy of detecting fake health news, utilizing a fine-tuned BERT model that integrates both user- and content-related socio-contextual information. Specifically, this information is combined with the textual content itself to form a socio-contextual input sequence for the BERT model. By fine-tuning such a model with respect to the health misinformation detection task, the resulting classifier can accurately predict the category to which each piece of content belongs, i.e., either \u201creal health news\u201d or \u201cfake health news\u201d. We validate our solution through a series of experiments conducted on distinct publicly available datasets constituted by health-related tweets. These results illustrate the superiority of the proposed solution compared to the standard BERT baseline model and other advanced models. Indeed, they show that the integration of socio-contextual information in the detection process positively contributes to increasing the overall accuracy of the fake health news detection task. The study also suggests, in a preliminary way, how such information could be used for the explainability of the model itself.","The QRS complex is the significant wave of electrocardiogram (ECG) and occurs during ventricular depolarization. If the synchronization problem (i.e., depolarization) occurs between endocardial cardiomyocytes and outer layers, then abnormal morphological changes in QRS complex take place which is possible in case of arrhythmia and ischemia. The proposed approach describes time domain measures of such alterations (i.e., the ratio of average rise &amp; fall amplitude and interval) of QRS complex along with the frequency domain feature i.e., peak frequency and power of mean QRS complexes. An improvised Difference Operation Method (DOM) (Yeh Yun-Chi et al., 2008) is implemented with added features like preprocessing techniques (e.g., baseline drifts and noise cancellation). The proposed methodology is evaluated with the standard databases, i.e., FANTASIA (healthy subjects), MIT-BIH Arrhythmia database (MITDB), and European ST-T database (EDB) respectively. Linear Discriminant Analysis (LDA) and decision tree are carried out for classification healthy, arrhythmic and ischemic subjects incorporating the time-frequency domain characteristics. The Naive Bayes\u2019 Classifiers also implemented where these two classes, i.e., ischemia and arrhythmia are visually distinguished by convergently spreading in different areas. Real-time hardware validation of this approach has also executed. The future scope of this approach is to be validated with ischemia-induced arrhythmia subjects for precise identification and classification.","Machine Learning (ML) and feature extraction techniques have shown a great potential in medical imaging field. This work presents an effective approach for the identification and classification of thyroid nodules. In the proposed model, various features are extracted using Grey Level Co-occurrence Matrix (GLCM), Local Binary Pattern (LBP) and intensity-based matrix. These features are fed to various ML classifiers like K-Nearest Neighbour (KNN), Decision-Tree (DT), Artificial Neural Network (ANN), Na\u00efve Bayes, Extreme Gradient Boosting (XGBoost), Random Forest (RF), Linear Regression (LR) and Support Vector Machine (SVM). From the result analysis, it can be observed that proposed Model-4 has performed better in comparison with the rest of seven proposed models with the reported literature. An improvement of 4% to 5% is seen in performance evaluation of model in comparison with reported literature.","Neural architecture search (NAS), which automates the design of neural network (NN) architectures for scientific datasets, requires significant computational resources and time \u2014 often on the order of days or weeks of GPU hours and training time. We design the Analytics for Neural Network (A4NN) workflow, a composable workflow that significantly reduces the time and resources required to design accurate and efficient NN architectures. We introduce a parametric fitness prediction strategy and distribute training across multiple accelerators to decrease the aggregated NN training time. A4NN rigorously record neural architecture histories, model states, and metadata to reproduce the search for near-optimal NNs. We demonstrate A4NN\u2019s ability to reduce training time and resource consumption on a dataset generated by an X-ray Free Electron Laser (XFEL) experiment simulation. When deploying A4NN, we decrease training time by up to 37% and epochs required by up to 38%.","Multi-instance learning (MIL), as a special version of classification, focuses on labeled sets (bags) consisting of unlabeled instances and has drawn accumulative attention due to its significant importance in practical applications. However, most existing MIL methods just utilize partial information (bags or instances) of MIL data to construct the kernel function, resulting in deteriorated classification performance of MIL. In this paper, we propose a Double Similarities weighted Multi-Instance Learning (DSMIL) kernel framework, which utilizes the similarities of Bag-to-Bag (B2B) and Instance-to-Bag (I2B). In the proposed kernel framework, the similarities of B2B and I2B could be derived from the prototypes distance of inter-bag and similarity matrix of intra-bag, respectively, based on the affinity propagation (AP) clustering of the bag. Meanwhile, we give theoretical proof of the validity of the designed kernel function. Experimental results on benchmark and semi-synthetic datasets show that our proposed method obtains competitive classification performance and achieves robustness to parameters and noise.\nHighlights\n\u2022\nA double similarities weighted MIL kernel is proposed and proved as a valid kernel.\n\u2022\nThe DSMIL integrates the similarities of B2B and I2B into the kernel function.\n\u2022\nThe DSMIL obtains competitive results on benchmark datasets and newsgroups dataset.","Detection of diseases in plants at an early stage is crucial to achieving high yields, preserving crop quality, and effective disease management. Existing research focuses mostly on leaf disease detection, despite the fact that disease may develop everywhere on the plant. We developed a new dataset using the PlantVillage dataset and other online sources. We used Convolutional Neural Network (CNN) architectures, Alexnet and MobileNet to analyze and evaluate the performance of the models on the new dataset (i.e., consists of over 50,000 images). The models were trained on the new dataset for 100 epochs. MobileNet outperformed the other two models, attaining 99.69% training accuracy, 94.37% validation accuracy, 96% average precision, 96% recall, and an F1-score. The MobileNet model predicted diseases that affect portions of the plant other than the leaf better. This work demonstrates detecting plant disease and provides a feasible technique for enhancing crop management.","Cervical cancer (CC) is one of the most prevalent malignancies affecting women globally, with a particularly notable impact and high mortality in regions with limited economic resources. This underscores the imperative for the expeditious development of techniques that facilitate timely and precise detection, thereby augmenting treatment efficacy, enhancing survival rates, and mitigating the burden of healthcare expenditure. The intricacies of cervical cancer detection are inherently aligned with the challenges of fine-grained visual classification. This study focuses on the integration of bilinear pooling within convolutional neural networks (CNNs) and addresses the problem of the computational complexity of bilinear features with the fortification of the bilinear CNN with a random projection paradigm (RP-BCNN). The aim is the simultaneous achievement of improved classification precision and streamlined processing temporalities. The proposed methodology entails the introduction of a dyadic feature extraction protocol in which the input cellular image is subjected to twin feature extraction modalities. The feature maps obtained from this process undergo element-wise multiplication via an outer-product operation, thereby engendering composite feature representations. Subsequently, a judiciously designed random projection procedure is invoked to reduce dimensionality, yielding a more succinct yet informative image descriptor. Empirical evaluations of the introduced model predicted on the RP-BCNN framework yielded commendable outcomes. Notably, an accuracy of 0.9983 was achieved for the dual-label classification scenarios, and an accuracy of 0.9530 was realized in the context of multiclass classification encompassing seven distinct labels. The proposed model achieves an optimal equilibrium between classification accuracy and processing efficiency, thus constituting a potent instrument for the classification of cervical cancer. Further, it holds promise for the refinement of diagnostic accuracy, thereby providing a vantage point for embracing sophisticated techniques in the realm of medical image analysis.","Siamese Neural Networks (SNN) are known to perform well in resource-constrained scenarios where computation and data availability are limited. They utilise the similarity space of a given dataset to extract distinguishing features between dissimilar data samples. Such features have also been utilised for classification tasks. Though several works on enhancing the accuracies and inference times using such similarity spaces have been reported, there is still scope for investigations that can yield more efficient strategies. The Biological Immune System (BIS) is known for employing such a transformation to recognise and contain antigenic attacks. Concepts from a BIS can thus, aid in boosting the classification performance of SNNs. This paper summarizes such an attempt made in our work \"Immuno-Inspired Augmentation of Siamese Neural Network for Multi-class Classification\" [8] presented at IVCNZ 2022, first published in Lecture Notes in Computer Science, 2023, vol 13836, pages 486--500 by Springer. A novel SNN-based multi-class classification method augmented with an immuno-inspired approach that allows an SNN to plug class-specific characteristics into its architecture is presented herein. The empirical analyses and results conducted on three benchmark datasets, clearly indicate that this method delivers higher accuracies and lower inference times when compared to recent SNN-based multi-class classification techniques.","Classification of Indonesian crops is a critical task in developing farming and getting more understanding of agriculture. However, there is no clear task in classifying types of crops in Indonesia. Transfer learning has been used successfully in a variety of image classification applications. Thus, in this paper, we collected images of Indonesian crops from the internet randomly and proposed a classification by using transfer learning of deep learning with four pre-trained models: EffficientNet- B0, ResNet18, VGG19, and AlexNet. In the experiment, augmentation techniques such as random horizontal flip, random vertical flip, and random affine were utilized to prevent the network from overfitting. The result found that EfficientNet-B0 outperformed other models with an accuracy of 82.55. Then, the model struggled to distinguish between crops in the same family. According to the results, although transfer learning can work well to classify images of Indonesian agricultural crops, some improvements are still required to address existing issues.","Hyperspectral image(HSI) classification is a crucial topic within remote sensing. Recently, deep self-supervised learning methods have gained widespread use in HSI classification, effectively addressing the scarcity of labeled samples issue. In particular, masked image modeling and contrastive learning have achieved commendable performance in the field of self-supervised learning. Therefore, to better investigate the association and synergy between the two self-supervised learning methods, we propose a novel hybrid self-supervised learning framework (HSL) for HSI classification that conforms to the properties of hyperspectral data. The HSL exploits the efficacy of masked image modeling and contrastive learning, and combines masked image reconstruction and instance contrastive learning to improve performance. The HSL specifically employs an asymmetric encoder-decoder two-branch structure. The structure adopts the Vision Transformer as the backbone network to efficiently extract spatial spectral information. Experiments on two commonly used HSI datasets demonstrate that this pre-training task results in better modeling of the feature relationships between shallow and deep layers and achieves superior performance.","As a fundamental part of natural language processing, text classification is the backbone of tasks and applications such as machine translation and classification. Among the text classification tasks of all languages, the one for Chinese appears to be one of the most challenging due to the complex structures and expressions within the nature of Chinese. Researchers generally require a significant amount of data for model training and tuning, while most of the time, that desired amount of data cannot be fulfilled and satisfied. Given the circumstances, we propose an effective data enhancement technique to lower the demand for data. The central principle is as follows: Randomize the acquired word vectors and tokens from tokenizing the text based on a certain density level (i.e., every group contains five words), then use the randomized results as data input. During the above process, a considerable number of data variations would be generated, easing the demand for data. From the experiments, we tested our theory on multiple Chinese natural language processing datasets and received signs of improvements in model performance across all the datasets used, thus proving the validity of the previously mentioned method.","Real-world industrial scenarios pose a challenging task known as few-shot class-incremental learning (FSCIL), which aims to recognize new classes using a few samples while not forgetting the old classes. Despite the recent advance of FSCIL, most existing methods rely on a single metric for making incremental relation predictions, which is unilateral and lacks stability. In this paper, we remedy this issue from two aspects. Specifically, to make convincing relation predictions, we first propose a relation complementation strategy that aggregates different metric models to investigate the comprehensive relation of classifier weights and test features. Then, to make the proposed strategy well fit the incremental scenarios, we design a pseudo incremental relation complementation learning scheme that constructs the learning tasks by mimicking the data setting in real incremental sessions. Taken together, our proposed method dubbed Relation Complementation Network (RCN) achieves the state-of-the-art performance on miniImageNet, CIFAR100 and CUB200. Our code is available at https://github.com/YeZiLaiXi/KT-RCN.git.","Learning from Label Proportions (LLP) is a machine learning problem where the training data are composed of bags of instances, and only the class label proportions for each bag are given. In some domains, we can directly obtain label distributions; for example, one can use census statistics and social media user information grouped by location to build a classifier for user demographics. However, label proportions are unavailable in many domains, such as product review sites. The solution is to modify the model fit on data from where label proportion are available domains (the source domain) to apply to a domain where the label distributions are not available (target domain). Such problems can be regarded as the unsupervised domain adaptation problems in an LLP setting. The goal of this paper is to introduce domain adaptation methods to the original LLP solutions such that the proposed model can classify instances from a new domain. We propose a model combining domain-adversarial neural network (DANN) and label regularization, which can be fit on the source-domain bags and predict labels for target-domain instances. This approach requires only label proportions in the source domain. Our experiments on both synthetic tasks and sentiment classification tasks indicate a noticeable improvement in accuracy as compared to using LLP without domain adaptation.","Credit risk assessment is a crucial element in credit risk management. With the extensive research on consumer credit risk assessment in recent decades, the abundance of literature on this topic can be overwhelming for researchers. Therefore, this article aims to provide a more systematic and comprehensive analysis from three perspectives: classification algorithms, data traits, and learning methods. Firstly, the state-of-the-art classification algorithms are categorized into traditional single classifiers, intelligent single classifiers, hybrid and ensemble multiple classifiers. Secondly, considering the diversity of data traits in the credit dataset, data traits are divided into external structure information traits, data quality traits, data quantity traits, and internal information traits. Data traits-driven modeling framework based on multiple classifiers is proposed for solving credit risk assessment. Thirdly, considering the differences in data modeling methods, learning methods are classified into data status, label status, and structure form. Furthermore, model interpretability, model bias, model multi-pattern, and model fairness are discussed. Finally, the limitations and future research directions are presented. This review article serves as a helpful guide for researchers and practitioners in the field of credit risk modeling and analysis.","Belief rule-based classification system (BRBCS) is a useful model to handle classification problems. In our previous work, a novel data-driven BRBCS with batch-by-batch observation, online learning and multi-weights (BRBCS-BOM) is proposed. It can powerfully obtain knowledge from data. However, in some applications of industrial engineering, it can be hard to obtain enough training samples. The knowledge contained in data is not enough to deal with the problem well. It is necessary to adopt expert-driven BRBCS as an important supplement (hybrid-driven). In this paper, a hybrid-driven BRBCS-BOM with expert intervention (HBRBCS-BOM/E2) is proposed. It adopts a modified inheriting-and-learning hybrid-driven mode. Generally, it inherits the belief rules generated from training samples and make a secondary optimization for these inherited belief rules based on learning from expert-driven BRBCS. Moreover, a novel mode of expert intervention is proposed, based on the reliability evaluation. It can diversely-and-precisely obtain some important online new training samples for enhancement of data-knowledge, making hybrid-driven model better. The related experiments on an industrial engineering classification problem, called abnormity recognition of synthetical balance of material and energy, have demonstrated that the proposed HBRBCS-BOM/E2 not only makes an effective improvement for data-driven BRBCS-BOM from above two ways, but also has a more advanced performance compared with other existing high-performance BRBCS.\nHighlights\n\u2022\nA hybrid-driven mode is proposed based on swapping the inheriting-and-learning.\n\u2022\nA mode of expert intervention is proposed based on the reliability evaluation.\n\u2022\nProposed model can handle the abnormity recognition in electrolytic cell well.","A classification system for hazardous materials in air traffic control was investigated using the Human Factors Analysis and Classification System (HFACS) framework and natural language processing to prevent hazardous situations in air traffic control. Based on the development of the HFACS standard, an air traffic control hazard classification system will be created. The dangerous data of the aviation safety management system is selected by dead bodies, classified and marked in 5 levels. TFIDF TextRank text classification method based on key content extraction and text classification model based on CNN and BERT model were used in the experiment to solve the problem of small samples, many labels and random samples in hazardous environment of air pollution control. The results show that the total cost of model training time and classification accuracy is the highest when the keywords are around 8. As the number of points increases, the time spent in dimensioning decreases and affects accuracy. When the number of points reaches about 93, the time spent in determining the size increases, but the accuracy of the allocation remains close to 0.7, but the increase in the value of time leads to a decrease in the total cost. It has been proven that extracting key content can solve text classification problems for small companies and contribute to further research in the development of security systems.","Accurate and timely crop classification results play a crucial role in providing data support for agricultural policy-making and crop yield estimation. However, the current development of crop classification faces a bottleneck in improving classification performance due to limited labeled samples and saturated classification algorithms. In this study, we propose a novel method to improve crop classification performance by leveraging unlabeled remote sensing data (URSD). Importantly, our method does not necessitate a large number of labeled samples or significant modifications to the classification algorithm. Instead, it relies on a unique self-supervised training approach and a substantial amount of URSD. Specifically, we develop a self-supervised classification framework based on a Multilayer Perceptron (MLP) and introduce a self-supervised training approach that takes into account both temporal and spectral factors. Additionally, we construct a historical sample classification model based on crop growth knowledge, emphasizing the correlation of local time series. We evaluate the proposed method using four study areas in China. The analysis of pre-training data types reveals that our method not only improves the classification performance of current year samples but also demonstrates noticeable improvement in classifying historical samples. The classification method analysis demonstrates the ability of our proposed self-supervised learning training approach to accumulate more prior knowledge. Overall, these results highlight the advantages of our method in terms of classification efficiency and performance improvement.","Extracellular action potentials (EAP) are one of the most important features in biological study. Many researchers have studied the classification of EAP by their differences in voltage and magnitude. However, most research ignored the fundamental origin of the EAP variation around the neurons in their classification and treated waveforms of different shapes as signals recorded from different neurons. In our research, we theoretically investigated the shapes of EAP by clustering the spatially-varied EAP around the neuron. We use an unsupervised machine-learning algorithm to classify all EAPs measured around the same neuron. To eliminate the influence of the non-characteristic part of the EAP curve, we also compared the classification results by eliminating the unchanged part at the front and end of the curve in the second group of our study. Our results illustrate the previously overlooked relationship between different shaped EAP and the biological structure of the neuron. The results show that EAP measured is closer to classical theory prediction in the axon while more eccentric, even with a shape similar to an intracellular action potential in the dendrite. Our research has important implications for further device design to record accurate electric signals and extracting biological related information from extracellular recordings.","The most malignant tumors of the central nervous system are adult-type diffuse gliomas. Historically, glioma subtype classification has been based on morphological features. However, since 2016, WHO recognizes that molecular evaluation is critical for subtyping. Among molecular markers, the mutation status of IDH1 and the codeletion of 1p/19q are crucial for the precise diagnosis of these malignancies. In pathology laboratories, however, manual screening for those markers is time-consuming and susceptible to error. To overcome these limitations, we propose a novel multimodal biomarker classification method that integrates image features derived from brain magnetic resonance imaging and histopathological exams. The proposed model consists of two branches, the first branch takes as input a multi-scale Hematoxylin and Eosin whole slide image, and the second branch uses the pre-segmented region of interest from the magnetic resonance imaging. Both branches are based on convolutional neural networks. After passing the exams by the two embedding branches, the output feature vectors are concatenated, and a multi-layer perceptron is used to classify the glioma biomarkers as a multi-class problem. In this work, several fusion strategies were studied, including a cascade model with mid-fusion; a mid-fusion model, a late fusion model, and a mid-context fusion model. The models were tested using a publicly available data set from The Cancer Genome Atlas. Our cross-validated classification models achieved an area under the curve of 0.874, 0.863, and 0.815 for the proposed multimodal, magnetic resonance imaging, and Hematoxylin and Eosin stain slide images respectively, indicating our multimodal model outperforms its unimodal counterparts and the state-of-the-art glioma biomarker classification methods.","Each year, millions of pilgrims come to Saudi Arabia to perform Hajj and Umrah. To help pilgrims with their difficulties and make plans to enhance the Hajj and Umrah services, this article offers a deep learning-based framework to categorize and analyze pilgrims\u2019 posts on social media networks X (formerly Twitter), Facebook and Instagram. We extracted Arabic posts related to Hajj/Umrah then tokenized and pre-processed the dataset to remove unnecessary parts such as punctuation. Posts are manually labeled into five classes: Health, Organization, Security, Services, and Worship. Labeled posts are collected to build a Long Short-Term Memory (LSTM) network classifier for deep learning. To increase the prediction accuracy, we customized the LSTM classification layer and used the sum of squares error (SSE) loss function instead of the default cross-entropy loss function. A rigorous simulation is run to assess the system\u2019s effectiveness. Every time a simulation round occurs, the trained network is tasked with identifying the classes of unlabeled posts (testing data). Similar tests are performed using the K-Nearest Neighbors (KNN) and Linear Discriminant Analysis (LDA) algorithms for comparative analysis. Accuracy, confusion matrix, precision, sensitivity, specificity, and F 1 score are used to quantify the system performance. The maximum mean accuracy of the proposed framework, KNN and LDA are 85.65%, 68.47%, and 59.06% respectively. The proposed framework needs to be integrated into a larger system called the Intelligent Pilgrim Service System (IPSS). We described the IPSS architecture, which comprises modules for data generation, data storage (on the cloud), and a control center. We described a hashtag mechanism as a part of the IPSS. This hashtag mechanism will provide both general and focused advice to millions of pilgrims related to their social media posts. We discussed scenarios of how the IPSS can enhance the Hajj and Umrah services.\nHighlights\n\u2022\nA tagged dataset of social media posts from X (formerly Twitter), Facebook, and Instagram related to Hajj and Umrah.\n\u2022\nA customized edge deep learning-based framework to classify social media posts.\n\u2022\nNine parameters to measure the performance of the system.\n\u2022\nAn architecture of the Intelligent Pilgrim Service System (IPSS) is provided.\n\u2022\nA novel hashtag mechanism is presented that provides on-time advice to pilgrims.","Highlights\n\u2022\nCalculating the KNN for each instance and leveraging instance correlation to expand the original feature space.\n\u2022\nUsing mutual information to measure feature redundancy and extracting high-quality feature subsets with low dimensions.\n\u2022\nDeveloping a multi-label learning approach that considers label correlation, instance correlation, and feature redundancy.\nAbstract\nMulti-label classification is a machine-learning task that simultaneously processes instances associated with multiple labels. Label-specific feature learning selects each label's most discriminative feature subset, effectively reducing the feature dimension and improving the classification performance. However, most methods only consider label correlation, ignoring the correlation between instances and feature redundancy. To solve this problem, a multi-label classification method based on instance correlation and feature redundancy is proposed. The proposed method merges instance correlation by updating the data set and removes redundant features by calculating mutual information. By jointly considering label correlation, instance correlation, and feature redundancy, our method promotes effective multi-label feature selection. The experimental results on ten data sets demonstrate the effectiveness of the proposed method.","Interpreting regulatory documents or building codes into computer-processable formats is essential for the intelligent design and construction of buildings and infrastructures. Although automated rule interpretation (ARI) methods have been investigated for years, most of them are highly dependent on the early and manual filtering of interpretable clauses from a building code. While few of them considered machine interpretability, which represents the potential to be transformed into a computer-processable format, from both clause- and document-level. Therefore, this research aims to propose a novel approach to automatically evaluate and enhance the machine interpretability of single clauses and building codes. First, a few categories are introduced to classify each clause in a building code considering the requirements for rule interpretation, and a dataset is developed for model training. Then, an efficient text classification model is developed based on a pretrained domain-specific language model and transfer learning techniques. Finally, a quantitative evaluation method is proposed to assess the overall interpretability of building codes. Experiments show that the proposed text classification algorithm outperforms the existing CNN- or RNN-based methods, by improving the F1-score from 72.16% to 93.60%. It is also illustrated that the proposed classification method can enhance downstream ARI methods with an improvement of 4%. Furthermore, analysis of more than 150 building codes in China showed that their average interpretability is only 34.40%, which implies that it is still difficult to fully transform an entire regulatory document into computer-processable formats. It is also argued that the interpretability of building codes should be further improved both from the human side (considering certain constraints when writing building codes) and the machine side (developing more powerful algorithms, tools, etc.).","The advancement in technology with multiple sensors embedded in smartphones results in the widespread of smartphones in the applications of human activity analysis and recognition. This promotes a variety of ambient assistive living applications, such as fitness tracking, fall detection, home automation system, healthcare monitoring etc. In this paper, a human activity recognition based on the amalgamation of statistical global features and local deep features is presented. The proposed model adopts temporal convolutional architecture to extract the long-range temporal patterns from the inertial activity signals captured by smartphones. To further enrich the information, statistical features are computed so that the global features of the time series data are encoded. Next, both global and local deep features are combined for classification. The proposed model is evaluated by using WISDM and UCI HAR datasets for user-dependent and independent protocols, respectively, to ensure its feasibility as user-dependent and independent HAR solutions. The obtained empirical results exhibit that the proposed model is outperforming the other existing deep learning models on both user-dependent and independent testing protocols.","This paper proposes a novel hybrid approach that combines a mixture of non-central Wishart distribution (MoNCW) model and a feed forward neural network (FFNN) to accurately estimate both the number and orientations of white matter fibers in biological tissues in brain. While the MoNCW model performs well in determining fiber orientations when the separation angle is greater than 50\u00b0, accurately clustering these orientations is still a significant challenge. To tackle this issue, the authors introduce a machine learning (ML) model that can precisely identify the number of fibers per voxel. The ML model is then integrated with the MoNCW model to improve the accuracy of fiber orientation estimation. The FFNN is trained using simulated datasets, which contain signal vectors for single, as well as two and three crossing fiber voxels, using a sequential model. The FFNN is particularly effective in solving classification problems, as it can process input data through multiple layers to produce output values that correspond to class labels. In this study, three classes are labelled as 1, 2, and 3, representing the number of fibers. By utilizing this hybrid approach, the accuracy of fiber number and orientation estimation in biological tissues is significantly improved, outperforming existing mixture models.","Efficiently classifying sheep breeds through image analysis is pivotal in modern animal husbandry, influencing critical management and breeding decisions. This study delves into automating this process by harnessing Convolutional Neural Networks (CNNs), with a particular focus on optimizing key hyperparameters\u2014the learning rate and dropout rate\u2014essential for refining model performance. Manual hyperparameter tuning is often time-consuming and demands expertise. To overcome this challenge, we introduce an innovative approach that utilises the Bat algorithm, a bio-inspired optimization technique. This algorithm mimics bat echolocation behaviors, skillfully navigating the complex hyperparameter search space to determine optimal values. By dynamically adjusting CNN hyperparameters, our research aims to boost classification accuracy while simplifying the tuning process. Empirical results highlight significant gains in classification accuracy and emphasizes the Bat algorithm's efficacy. The optimized CNN model, empowered by fine-tuned hyperparameters, demonstrates superior performance, promising practical applicability in real-world sheep breed classification scenarios. This study meticulously adjusts pulse rate and loudness, revealing an optimal combination of [0.001, 0.24404868], which substantially improves model performance. The findings emphasize the Bat algorithm's role in streamlining hyperparameter tuning and its potential impact on automated sheep breed classification.","Electroencephalogram (EEG) is a non-invasive technology with high temporal resolution, widely used in Brain-Computer Interfaces (BCIs) for mental workload (MWL) classification. However, numerous EEG channels in current devices can make them bulky, uncomfortable, and time-consuming to operate in real-life scenarios. A Riemannian geometry approach has gained attention for channel selection to address this issue. In particular, Riemannian geometry employs covariance matrices of EEG signals to identify the optimal set of EEG channels, given a specific covariance estimator and desired channel number. However, previous studies have not thoroughly assessed the limitations of various covariance estimators, which may influence the analysis results. In this study, we aim to investigate the impact of different covariance estimators, namely Empirical Covariance (EC), Shrunk Covariance (SC), Ledoit-Wolf (LW), and Oracle Approximating Shrinkage (OAS), along with the influence of channel numbers on the process of EEG channel selection. We also examine the performance of selected channels using diverse deep learning models, namely Stacked Gated Recurrent Unit (GRU), Bidirectional Gated Recurrent Unit (BGRU), and BGRU-GRU models, using a publicly available MWL EEG dataset. Our findings show that although no universally optimal channel number exists, employing as few as four channels can achieve an accuracy of 0.940 (\u00b10.036), enhancing practicality for real-world applications. In addition, we discover that the BGRU model, when combined with OAS covariance estimators and a 32-channel configuration, demonstrates superior performance in MWL classification tasks compared to other estimator combinations. Indeed, this study provides insights into the effectiveness of various covariance estimators and the optimal channel subsets for highly accurate MWL classification. These findings can potentially advance the development of EEG-based BCI applications.","Blood Pattern Analysis is a technique in forensic science that focuses on leftover bloodstains from the crime to recreate the event. However, the fluctuation in air resistance and drop deformity causes the calculations to deviate from the exact values. Therefore, machine learning models were constructed to overcome this limitation of calculations. A series of experiments was conducted by dropping porcine blood on paper across nine distinct heights: 20, 40, 60, 80, 100, 120, 140, 160, and 180 cm with four different drop volumes: 13, 16, 25, and 30 \u03bcL resulting in 36 classes. A simple simulation of a free-fall spherical object was also created to convert any drop height into impact velocity. Regarding both the empirical data and simulation, the correlation between the spreading factor and modified Reynold number, along with the number of spines and modified Weber number, were expressed as equations that can be used to determine drop height and drop volume. Concurrently, the same dataset used in physics calculations was used to train machine learning models that implement VGG-19 and XGBoost. For VGG-19, the inputs are images of bloodstains, while for XGBoost, the inputs are stain area, stain perimeter, and the number of spines. As a result, the accuracy for physics equations VGG-19 and XGBoost were 0.26, 0.56, and 0.49, respectively.","In this article we present the Amharic Speech Emotion Dataset (ASED), which covers four dialects (Gojjam, Wollo, Shewa, and Gonder) and five different emotions (neutral, fearful, happy, sad, and angry). We believe it is the first Speech Emotion Recognition (SER) dataset for the Amharic language. Sixty-five volunteer participants, all native speakers of Amharic, recorded 2,474 sound samples, 2 to 4 seconds in length. Eight judges (two for each dialect) assigned emotions to the samples with high agreement level (Fleiss kappa = 0.8). The resulting dataset is freely available for download. Next, we developed a four-layer variant of the well-known VGG model, which we call VGGb. Three experiments were then carried out using VGGb for SER, using ASED. First, we investigated which features work best for Amharic, FilterBank, Mel Spectrogram, or Mel-frequency Cepstral Coefficient (MFCC). This was done by training three VGGb SER models on ASED, using FilterBank, Mel Spectrogram, and MFCC features, respectively. Four forms of training were tried, standard cross-validation and three variants based on sentences, dialects, and speaker groups. Thus, a sentence used for training would not be used for testing, and the same for a dialect and speaker group. MFCC features were superior under all four training schemes. MFCC was therefore adopted for Experiment 2, where VGGb and three well-known existing models were compared on ASED: RESNet50, AlexNet, and LSTM. VGGb was found to have very good accuracy (90.73%) as well as the fastest training time. In Experiment 3, the performance of VGGb was compared when trained on two existing SER datasets\u2014RAVDESS (English) and EMO-DB (German)\u2014as well as on ASED (Amharic). Results are comparable across these languages, with ASED being the highest. This suggests that VGGb can be successfully applied to other languages. We hope that ASED will encourage researchers to explore the Amharic language and to experiment with other models for Amharic SER.","Vehicle classification holds significant importance in various domains such as infrastructure design and freight analysis. This study presents an innovative composite deep-learning framework for accurate vehicle classification. The framework exploits two distinct types of features extracted from vehicle images: (1) high-level encodings from state-of-the-art vision transformers (ViTs), and (2) localized vehicle wheel position features obtained through real-time object detection models. The former encapsulates global and semantic characteristics, while the latter focuses on specific wheel (axle) positions. Within this composite model paradigm, we evaluate and compare the efficacy of four ViT models: the original ViT, Cross ViT, Transformer-in-Transformer, and Swin Transformer. Similarly, we assess four object detection models for extracting wheel position features: two Faster R-CNN models (with ResNet-50 and MobileNetv3 backbones) and two YOLO models (YOLOv4 and YOLOR). The ViT encodings and wheel position features are then combined and channeled into a multi-layer perceptron classifier for precise vehicle classification. To enhance the ViT model's effectiveness, we employ a wheel masking strategy during its training, which acts as a regularizer, promoting robust and complementary encodings. Our experimental results reveal that introducing randomness by masking a single wheel significantly enhances the inference performance across all composite models. However, masking more wheels introduces excessive noise and causes performance degradation. Furthermore, initializing ViT encoders with pretrained weights through self-supervised methods leads to additional performance improvements. Notably, our best model achieves an impressive Top-1 classification accuracy of 96.7% when categorizing 13 vehicle classes as defined by the Federal Highway Administration. The results underscore the efficacy of the proposed composite architecture in achieving high precision in vehicle classification tasks.","Improper sorting of construction and demolition waste (CDW) leads to significant environmental and economic implications, including inefficient resource use and missed recycling opportunities. To address this, we developed a machine-learning-assisted procedure for recognizing CDW fragments using an RGB camera. Our approach uniquely leverages selected feature extraction, enhancing classification speed and accuracy. We employed three classifiers: convolutional neural network (CNN), gradient boosting (GB) decision trees, and multi-layer perception (MLP). Notably, our method\u2019s extraction of selected features for GB and MLP outperformed the traditional CNN in terms of speed and accuracy, especially for challenging samples with similar textures. Specifically, while convolution resulted in an overall accuracy of 85.9%, our innovative feature extraction approach yielded accuracies up to 92.3%. This study\u2019s findings have significant implications for the future of CDW management, offering a pathway for efficient and accurate waste sorting, fostering sustainable resource use, and reducing the environmental impact of CDW disposal. Supplementary materials, including datasets, codes, and models, are provided, promoting transparency and reproducibility.\nHighlights\n\u2022\nClassifiers were trained to recognize construction and demolition waste (CDW).\n\u2022\nCDW fragments were recognized from RGB images.\n\u2022\nFeatures were extracted for GB and MLP models; CNN employed convolution.\n\u2022\nGB and MLP outperformed CNN in terms of speed and accuracy.\n\u2022\nGB: 92.3% overall accuracy, MLP: 91.3%, and CNN: 85.9%.","Background: Breast cancer is one of the greatest health threats to women worldwide. Mammography is an effective and inexpensive tool for breast cancer early detection. Mammography-based breast cancer screening requires a lot of manpower from professional experts. Thus, computer-aided diagnosis tools, especially accurate classifiers which can distinguish the breast masses from the background tissues, are needed. However, since the sample size of publicly available mammography data sets is relatively small, the performance of the published breast mass identification models was not great, and the models were not well-embraced by clinical practice due to their low interpretability. Methods: In this work, using two independent and well-known mammography data sets, the CBIS-DDSM and the INbreast, we proposed a novel patch generation method for data augmentation and negative case generation. We implemented two successful deep learning models, the ResNet and the ViT, to classify the generated mass and non-mass patches. We also proposed to apply the patch-level model to the full-view mammogram screening in a sliding window manner and visualize/interpret the prediction results using a heatmap so that the clinic practice could potentially benefit from the well-trained model. Result: For the CBIS-DDSM dataset, we compared the performance of the ResNet and the ViT with and without data augmentation. The F1 score is 0.91, 0.86, 0.85, and 0.70, respectively. We also evaluated our models using other metrices such as accuracy, precision, recall, and ROC curve. The results show that the ResNet model outperforms the ViT model. And the data augmentation improves the overall performance of the models. The similar conclusions are further supported using the independent INbreast data. Furthermore, we also explored to use probability-based heatmaps to visualize the potential mass regions in mammogram images. Conclusion: The study shows that our patch-level data augmentation is effective in improving the classification performance of the deep learning models. The comparable performance on the CBIS-DDSM data and the independent INbreast data demonstrates the generalizability of our methods. The proposed heatmap visualization tool increases the interpretability of our results and could be a potential approach for clinic utilization.","Artificial intelligence (AI) technology has significant potential in Earth sciences, particularly in mineral identification for industrial exploration, geological mapping, and archaeological research. However, traditional methods are time-consuming, expensive, and complex. And existing mineral identification methods based on mineral photos face several critical challenges, including lack of consideration for natural image features captured in real environments, limitations of single-label classification which does not align with multi-mineral occurrences in nature, and growing computational complexity as the number of identifiable mineral labels increases. Therefore, this paper proposes an efficient mineral identification model based on multi-label image classification, focusing on natural environmental features. First, realistic feature datasets are created by simulating mineral photos in real environments. Then, the model uses the query-label (Query2Label) framework, with MaxViT-T (Multi-Axis Vision Transformer-Tiny) as the feature extraction network and the asymmetric loss function. Knowledge distillation is employed to improve identification accuracy while reducing computational complexity. The proposed model achieves an impressive average identification accuracy of 84.74% on a dataset of 495,756 mineral photos, surpassing existing models like ResNet-101, ML-GCN (Multi-Label Graph Convolutional Network), and SRN (Spatial Regularization Net). It maintains a lower parameter count and computational complexity. In the end, ablation experiments demonstrate the effectiveness of each optimization scheme.\nHighlights\n\u2022\nSelecting image noise and color shift methods for realistic mineral data simulation.\n\u2022\nProposing an enhanced two-stage image multi-Label identification model framework.\n\u2022\nApplying knowledge distillation for multi-label classification subtask decomposition.\n\u2022\nBeing with low computational complexity and high mineral identification accuracy.","Automated classification of skin lesions in dermoscopy images has the potential to significantly improve survival rates and reduce the risk of death for skin cancer patients. However, existing supervised learning models heavily depend on well-annotated dermoscopy training data, which is expensive and labor-intensive to obtain. This paper addresses this issue by proposing a semi-supervised framework called Noisy Consistent Pseudo Labeling (NCPL), which only utilizes less annotated images with many unlabeled raw data. The NCPL framework consists of two components: the Noisy-Consistent Sample Learning(NCSL) module to remove low-confidence images, and the Attentive Clustered Feature Integration (ACFI) module, incorporating an uncertainty-aware attention mechanism. Specifically, the NCSL module is introduced to filter and generate reliable pseudo-labels for unlabeled skin images, with excellent capability of removing noisy samples. Additionally, the ACFI module integrates high-dimensional representations of original lesion images in an attentive manner, assisted with the annotated data. By focusing the representative samples and removing noisy images, the NCPL approach performs outstanding experimental results, demonstrating the superiority of the NCPL framework in semi-supervised skin lesion classification task.","Text classification is a fundamental task for natural language processing, and adapting text classification models across domains has broad applications. Self-training generates pseudoexamples from the model's predictions and iteratively train on the pseudo-examples, i.e., mininizes the loss on the source domain and the Gibbs entropy on the target domain. However, Gibbs entropy is sensitive to prediction errors, and thus, self-training tends to fail when the domain shift is large. In this paper, we propose Meta-Tsallis Entropy minimization (MTEM), which applies meta-learning algorithm to optimize the instance adaptive Tsallis entropy on the target domain. To reduce the computation cost of MTEM, we propose an approximation technique to approximate the Second-order derivation involved in the meta-learning. To efficiently generate pseudo labels, we propose an annealing sampling mechanism for exploring the model's prediction probability. Theoretically, we prove the convergence of the meta-learning algorithm in MTEM and analyze the effectiveness of MTEM in achieving domain adaptation. Experimentally, MTEM improves the adaptation performance of BERT with an average of 4 percent on the benchmark dataset.","Malware is a serious threat to the modern Internet, as it is used to, e.g., sending spam or stealing bank login credentials. Typically, to communicate with the attacker, it utilizes popular network protocols such as the HyperText Transfer Protocol (HTTP). The network traffic characteristics related to this protocol can be used to detect malware and identify its family. The latter is a standard multi-class classification problem for which machine learning algorithms are utilized. However, existing methods cannot identify a real-world situation of encountering a new malware family, which was not known during their training phase. To address this issue, an Open Set Recognition (OSR) approach can be used, capable of a multi-class classification and identification of unknown class occurrence. In this paper, we apply OSR to the malware classification using HTTP requests and compare it with the existing solutions. In more detail, we analyze the classification performance of three OSR and two standard algorithms and their computation time. Additionally, we utilize two request representations: one based on Hfinger tool and the other relying on trigrams. The obtained experimental results allowed to select an optimal set of algorithms and HTTP request representations suitable for OSR scenarios.","This paper proposes a texture-based domain-specific data augmentation technique applicable when training on small datasets for deep learning classification tasks. Our method focuses on label-preservation to improve generalization and optimization robustness over data-dependent augmentation methods using textures. We generate a small perturbation in an image based on a randomly sampled texture image. The textures we use are naturally occurring and domain-independent of the training dataset: regular, near regular, irregular, near stochastic and stochastic classes. Our method uses the textures to apply sparse, patterned occlusion to images and a penalty regularization term during training to help ensure label preservation. We evaluate our method against the competitive soft-label Mixup and RICAP data augmentation methods with the ResNet-50 architecture using the unambiguous \u201cBird or Bicyle\u201d and Oxford-IIT-Pet datasets, as well as a random sampling of the Open Images dataset. We experimentally validate the importance of label-preservation and improved generalization by using out-of-distribution examples and show that our method improves over competitive methods.","Highlights\n\u2022\nWe enhanced off-the-shelf ASR with classifiers to score verbal fluency tasks.\n\u2022\nMany novel scores utilizing timings of words can be calculated automatically.\n\u2022\nWe achieved high AUCs for the identification of valid words.\n\u2022\nMost automated scores correlate strongly with manual scores.\nAbstract\nSkip Objective Section\nObjective\nTo compare verbal fluency scores derived from manual transcriptions to those obtained using automatic speech recognition enhanced with machine learning classifiers.\nSkip Methods Section\nMethods\nUsing Amazon Web Services, we automatically transcribed verbal fluency recordings from 1400 individuals who performed both animal and letter F verbal fluency tasks. We manually adjusted timings and contents of the automatic transcriptions to obtain \u201cgold standard\u201d transcriptions. To make automatic scoring possible, we trained machine learning classifiers to discern between valid and invalid utterances. We then calculated and compared verbal fluency scores from the manual and automatic transcriptions.\nSkip Results Section\nResults\nFor both animal and letter fluency tasks, we achieved good separation of valid versus invalid utterances. Verbal fluency scores calculated based on automatic transcriptions showed high correlation with those calculated after manual correction.\nSkip Conclusion Section\nConclusion\nMany techniques for scoring verbal fluency word lists require accurate transcriptions with word timings. We show that machine learning methods can be applied to improve off-the-shelf ASR for this purpose. These automatically derived scores may be satisfactory for some applications. Low correlations among some of the scores indicate the need for improvement in automatic speech recognition before a fully automatic approach can be reliably implemented.","Highlights\n\u2022\nHyperspectral images of 10,000 maize seeds from 20 varieties are collected.\n\u2022\nA self-supervised learning method for seed classification is proposed.\n\u2022\nThe proposed method performs well on the raw spectral data.\n\u2022\nSelf-supervised pre-trained model improves seed classification performance.\nAbstract\nRapid and non-destructive variety identification is essential for screening maize seeds for different end-uses such as food, feed, and breeding. Hyperspectral imaging (HSI) is one of the most commonly used techniques in such seed classification. Typically, after acquiring hyperspectral images of seeds, the spectral domain signals need to be preprocessed and a classifier need to be designed. The traditional method is to find a appropriate spectral preprocessing method through trial-and-error experiment, which is time-consuming, laborious and has high risk of misuse preprocessing. In view of this, this paper proposes a self-supervised learning method that includes pre-training and fine-tuning phases. In the pre-training phase, a model was trained on the unlabeled raw spectral data in an unsupervised manner to obtain general representations. In the fine-tuning phase, the pre-trained model was fine-tuned with the goal of the seed classification task and trained in a supervised manner on labeled spectral data. Experimental results showed that the proposed method did not rely on spectral preprocessing, and its performance was superior to other existing seed classification methods. In addition, the self-supervised pre-trained model significantly outperformed the non-pre-trained model in the downstream seed classification task, and obtained good generalization ability. Overall, this method combined with HSI for seed quality evaluation has broad application prospects.","As for the characteristics of the objects in the airtight package in the X-ray image, some prohibited items of the airtight package are difficult to be detected from the X-ray images with complex and overlapped backgrounds. In this article, the cooperative knowledge distillation method is used to enhance the prohibited items detection model in the X-ray image. To efficiently implement hard example mining, this article designs an Multi-task Classification Head (MCH) for teachers to provide prior knowledge of image-level and instance-level predictions. Different from the distillation method in which the students imitate the teacher, the algorithm in this article is implemented by the cooperation between teacher and student. In order to verify the effectiveness of this algorithm, a series of related experiments are carried out on PIDray and SIXray respectively. Experiments show that the algorithm improves the AP of State-of-the-Art dense object detectors (e.g., RetinaNet, ATSS, GFL, and TOOD) in SIXray by 1% \u223c 2%. Especially for prohibited items that are difficult to be found in X-ray images, the algorithm is more effective, and the dense object detectors can achieve a performance improvement of about AP of 2% on the Hidden subset of PIDray. The experiments demonstrate that the cooperative knowledge distillation algorithm proposed in this article can effectively enhance the performance of prohibited items detection, particularly showing more pronounced improvements in detecting hard examples.","Graph neural networks (GNNs) are increasingly used in critical human applications for predicting node labels in attributed graphs. Their ability to aggregate features from nodes' neighbors for accurate classification also has the capacity to exacerbate existing biases in data or to introduce new ones towards members from protected demographic groups. Thus, it is imperative to quantify how GNNs may be biased and to what extent their harmful effects may be mitigated. To this end, we propose two new GNN-agnostic interventions namely, (i) PFR-AX which decreases the separability between nodes in protected and non-protected groups, and (ii) PostProcess which updates model predictions based on a blackbox policy to minimize differences between error rates across demographic groups. Through a large set of experiments on four datasets, we frame the efficacies of our approaches (and three variants) in terms of their algorithmic fairness-accuracy tradeoff and bench- mark our results against three strong baseline interventions on three state-of-the-art GNN models. Our results show that no single intervention offers a universally optimal tradeoff, but PFR-AX and PostProcess provide granular control and improve model confidence when correctly predicting positive outcomes for nodes in protected groups.","Attention, one of the most important features of modern CNNs, has been shown to improve the performance of mammogram classification, but our understanding of why attention offers improvements is rather limited. In this paper, we present the first comprehensive comparison of different combinations of baseline models and attention methods at multiple resolutions for whole mammogram image classification of masses and calcifications. Our findings indicate that attention generally helps to improve the baseline model scores, but the benefits are variable depending on the resolution and abnormality type. Furthermore, we find that pooling and overall model architecture (i.e., combination of baseline and attention) significantly impact mammogram classification scores. Specifically, scores are generally improved by architectural features that allow the model to retain as much information as possible while still focusing on relevant features. We also find that attention improves the correlation between model performance and LayerCAM activation in the region of interest. Our work provides insightful information to help guide the future construction of attention-based models for mammogram classification.","The field of image classification faces significant challenges due to the scarcity of target samples, leading to model overfitting and difficult training. To address these issues, few-shot learning has emerged as a promising approach. However, current methods do not fully utilize the correlations among samples and external semantic information, resulting in poor recognition accuracy. To overcome these limitations, we propose a new few-shot classification method that incorporates both attributes and attention guided approach. The method leverages the attention mechanism to extract discriminative features from the images. By exploring regional correlations among samples, it assists in generating visual representations by utilizing predicted attribute features. As a result, accurate prototypes are generated. Extensive experiments were conducted on two attribute-labeled datasets, namely Caltech-UCSD Birds-200\u20132011(CUB) and SUN Attribute Database (SUN) Attribute Dataset. With the Resnet12 backbone, the method achieves remarkable accuracies of 79.95% and 89.34% for 1-shot and 5-shot, respectively, on the CUB dataset. Similarly, with the Conv4 backbone, the method achieves notable accuracies of 67.21% and 80.87% for 1-shot and 5-shot, respectively, on the SUN Attribute dataset. The achieved accuracies highlight the robustness and generalizability of our method, and show the capability of our method to accurately classify samples with limited training data, which is a significant advantage in real-world scenarios where labeled data are often scarce.","Automated credit risk assessment plays an important role in agricultural lending. However, credit risk assessment in the agricultural domain has unique challenges due to the impact of weather, pest outbreaks, commodities market dynamics, and other volatile forces that drive risk. Training a model to account for these factors requires immense data assets that are challenging to obtain. Indeed, even the best credit risk assessment models in this domain are trained using data from single-institutions that often focus on dedicated geographical regions, or singular commodities. Hence, most agricultural credit risk models exhibit poor out-of-domain performance. In this paper, we use a novel dataset describing nearly 100 thousand historical loans, sourced from 9 large agricultural lenders to train a Bayesian network model for loan delinquency classification. The proposed model exhibited improved calibration (relative improvement in Expected Calibration Error) in out-of-domain performance tests when compared to three state-of-the-art credit risk scoring approaches: Logistic regression (81 \u00b1 15% improvement), XGBoost (80 \u00b1 14% improvement), and an Artificial Neural Networks (7 \u00b1 2% improvement). We conclude that Bayesian networks provide better modeling of agricultural credit risk by combining (limited) data assets with expert domain knowledge. Our approach is likely to generalize to any credit risk assessment task where small sample sizes is of concern.","Nowadays, Multi-Label Feature Selection (MLFS) attracts more and more attention to tackle the high-dimensional problem in multi-label data. A key characteristic of existing gradient-based MLFS methods is that they typically consider two-way variable correlations between features and labels, including feature-feature and label-label correlations. However, two-way correlations are not sufficient to steer feature selection since such correlations vary given different additional variables in practical scenarios, which leads to the selected features with relatively-poor classification performance. Motivated by this, we capture three-way variable interactions including feature-feature-label and feature-label-label interactions to further characterize the fluctuating correlations in the context of another variable, and propose a new gradient-based MLFS approach incorporating the above three-way variable interactions into a global optimization objective. Specifically, based on information theory, we develop second-order regularization penalty terms to regard three-way interactions while jointly combining with the main loss term in regard to feature relevance. Then the objective function can be efficiently optimized via a block-coordinate gradient descent schema. Meanwhile, we provide a theoretical analysis demonstrating the effectiveness of the regularization terms in exploiting three-way interaction. In addition, experiments conducted on a series of benchmark data sets also verify the validity of the proposed method on multiple evaluation metrics.\nHighlights\n\u2022\nFirst gradient-based multi-label feature selection method tackling three-way interactions.\n\u2022\nModel three-way interactions via two regularization terms, whose effectiveness is shown in theory.\n\u2022\nOptimize objective via iterative coordinate descent for feature importance blocks.","During the several years of production of an animated movie, review meetings take place daily, where supervisors and directors generate text notes about fixes needed for the movie. These notes are manually assigned to artistic departments for them to fixed. Being manual, many notes are not properly assigned and are never fixed, lowering the quality of the final movie. This paper presents a proposal for automating the distribution of these notes using multi-label text classification techniques. The comparison of the results obtained by fine-tuning several transformer-based language models is presented. A highest mean accuracy of 0.776 is achieved assigning several departments to each of the review notes in the test set with a BERT Multilingual model. A mean accuracy of 0.762 was reached in just 10 epochs and 10 min of training on an RTX-3090 with a DistilBERT transformer model.","This paper applies Natural Language Processing (NLP) methods to analyze the exposure to trauma experienced by witnesses in international criminal tribunals when testifying in court. One major contribution of this study is the creation of a substantially extended version of the Genocide Transcript Corpus (GTC) that includes 52,845 text segments of transcripts from three different genocide tribunals. Based on this data, we first examine the prevalence of trauma-related content in witness statements. Second, we are implementing a binary classification algorithm to automatically detect potentially traumatic content. Therefore, in a preparatory step, an Active Learning (AL) approach is applied to establish the ideal size for the training data set. Subsequently, this data is used to train a transformer model. In this case, the two models BERTbase and HateBERT are used for both steps, allowing for a comparison of a base-level model with a model that has already been pre-trained on data more relevant in the context of harmful vocabulary. In a third step, the study employs an Explainable Artificial Intelligence (XAI) model to gain a deeper understanding of the reasoning behind the model's classifications. Our results suggest that both BERTbase and HateBERT perform comparatively well on this classification task, with no model clearly outperforming the other. The classification outcomes further suggest that a reduced data set size can achieve equally high performance metrics and might be a preferable choice in certain use cases. The results can be used to establish more trauma-informed legal procedures in genocide-related tribunals, including the identification of potentially re-traumatizing examination approaches at an early stage.\nWarning: Due to the overall purpose of the study, this paper contains descriptions of violent events in Section 4.1 (Examples 1 and 2) and in Figure 3 that may be distressing for some readers.","With the rapid development of higher education in China, more and more archives are managed by the archives of colleges and universities. Therefore, many colleges and universities have equipped archives management software to manage archives by computer. However, at present, the mainstream archives management software for colleges and universities does not have the function of automatic classification of archives. In order to reduce the workload of college archives staff, this paper explores a text automatic classification method suitable for college archives. Classification tree algorithm is a method of organizing and storing information. The classification tree is used to classify data into various categories, such as customers and products. It also provides an effective way to search for data using keywords or phrases. Classification tree is very useful in document processing, because it can help us find documents with similar characteristics, such as customers with similar requirements, products with similar functions, etc. The working principle of classification tree algorithm is to decompose the problem into smaller subproblems, and then solve one subproblem at a time until all problems are completely solved.","Glaciers play a critical role in the Earth\u2019s climate system, and accurate estimates of their behaviours are essential for understanding the impacts of climate change and informing policy decisions. One of the most important parameters for such a task is ice distribution, which is difficult to measure and predict using traditional physics-based models. In this study, we propose a deep learning approach to predict glacier thickness by learning directly from ice velocity and topography. Our approach overcomes the limitations of traditional physics-based models, such as computational cost and the need for expert knowledge to calibrate the models. In addition, deep learning models are flexible enough to explore the relevance of multimodality and multitasking to address the physical problem. Our results demonstrate the feasibility of quickly training a neural network model with sufficient training data and producing stable, high-quality ice thickness estimates. We highlight the importance of some specific input features suggested by geophysicists that have a positive impact on model stability.","Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don\u2019t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn\u2019t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame\u2019s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI are becoming an imperative.","This paper presents an automatic dialect identification in Ao using modulation-based approach. Ao is a low-resource, Tibeto-Burman tonal language spoken in Nagaland, a North-East state of India. This work aims to investigate dialect-specific characteristics to build a more robust DID system for classifying the three Ao dialects. In this direction, modulation-based representation is explored. Considering Ao is a tone language, the experiments were evaluated for 3 sec segment duration in order to capture the temporal information of the modulation spectrogram. In addition, the log Mel spectrogram is used as the feature for the baseline DID system. The proposed modulation spectrogram shows a significant performance of\n\u2248\n8\n%\nimprovement in accuracy over the baseline Ao DID system. Hence, the result indicates the effectiveness of modulation-based representation in automatically identifying the three dialects of Ao.","Parkinson\u2019s Disease is the second most prevalent neurodegenerative disorder, currently affecting as high as 3% of the global population. Research suggests that up to 80% of patients manifest phonatory symptoms as early signs of the disease. In this respect, various systems have been developed that identify high risk patients by analyzing their speech using recordings obtained from natural dialogues and reading tasks conducted in clinical settings. However, most of them are centralized models, where training and inference take place on a single machine, raising concerns about data privacy and scalability. To address these issues, the current study migrates an existing, state-of-the-art centralized approach to the concept of federated learning, where the model is trained in multiple independent sessions on different machines, each with its own dataset. Therefore, the main objective is to establish a proof of concept for federated learning in this domain, demonstrating its effectiveness and viability. Moreover, the study aims to overcome challenges associated with centralized machine learning models while promoting collaborative and privacy-preserving model training.","Image generation has seen huge leaps in the last few years. Less than 10 years ago we could not generate accurate images using deep learning at all, and now it is almost impossible for the average person to distinguish a real image from a generated one. In spite of the fact that image generation has some amazing use cases, it can also be used with ill intent. As an example, deepfakes have become more and more indistinguishable from real pictures and that poses a real threat to society. It is important for us to be vigilant and active against deepfakes, to ensure that the false information spread is kept under control. In this context, the need for good deepfake detectors feels more and more urgent. There is a constant battle between deepfake generators and deepfake detection algorithms, each one evolving at a rapid pace. But, there is a big problem with deepfake detectors: they can only be trained on so many data points and images generated by specific architectures. Therefore, while we can detect deepfakes on certain datasets with near 100% accuracy, it is sometimes very hard to generalize and catch all real-world instances. Our proposed solution is a way to augment deepfake detection datasets using deep learning architectures, such as Autoencoders or U-Net. We show that augmenting deepfake detection datasets using deep learning improves generalization to other datasets. We test our algorithm using multiple architectures, with experimental validation being carried out on state-of-the-art datasets like CelebDF and DFDC Preview. The framework we propose can give flexibility to any model, helping to generalize to unseen datasets and manipulations.","Online English teaching resources have recently surged, highlighting the exigency for efficient organization and categorization. This manuscript introduces an innovative strategy to classify university-level English teaching resources, employing a sophisticated density clustering algorithm. Initially, student discourse was mined within a teaching platform comment section, and in-depth textual analysis was conducted. Subsequently, the term frequency-inverse document frequency (TF\u2013IDF) feature extraction algorithm was enhanced, while emotive attributes were seamlessly integrated into the textual manifestation layer during the classification procedure. This enabled the distribution of topics and emotions to be acquired for each comment, facilitating subsequent analyses of emotion feature extraction and model training. An improved weight calculation was designed based on TF\u2013IDF to evaluate the importance of feature items for each corpus file. The simulation results demonstrate the proposed scheme's effectiveness. The algorithm facilitates faster scholarly access to educational resource information and effectively classifies data for high research adaptability.","Semi-supervised domain adaptation (SSDA) aims to bridge source and target domain distributions, with a small number of target labels available, achieving better classification performance than unsupervised domain adaptation (UDA). However, existing SSDA work fails to make full use of label information from both source and target domains for feature alignment across domains, resulting in label mismatch in the label space during model testing. This paper presents a novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE), to tackle this issue. Firstly, we introduce a cross-domain feature alignment strategy, Inter-domain Mixup, that incorporates label information into model adaptation. Specifically, we employ sample-level and manifold-level data mixing to generate compatible training samples. These newly established samples, combined with reliable and actual label information, display diversity and compatibility across domains, while such extra supervision thus facilitates cross-domain feature alignment and mitigates label mismatch. Additionally, we utilize Neighborhood Expansion to leverage high-confidence pseudo-labeled samples in the target domain, diversifying the label information of the target domain and thereby further increasing the performance of the adaptation model. Accordingly, the proposed approach outperforms existing state-of-the-art methods, achieving significant accuracy improvements on popular SSDA benchmarks, including DomainNet, Office-Home, and Office-31.\nHighlights\n\u2022\nA novel algorithm called IDMNE is proposed for semi-supervised domain adaptation.\n\u2022\nInter-Domain Mixup mitigates label mismatch during feature alignment in adaptation.\n\u2022\nNeighborhood Expansion diversifies target label information, curbs prediction uncertainty.\n\u2022\nIntegrated framework surpasses state-of-the-art on three SSDA benchmark datasets.","Leveraging the enormous amounts of real-world data collected through Internet of Things (IoT) technologies, human activity recognition (HAR) has become a crucial component of numerous human-centric applications, with the aim of enhancing the quality of human life. While the recent advancements in deep learning have significantly improved HAR, the process of labeling data continues to remain a significant challenge due to the substantial costs associated with human annotation for supervised model training. Active learning (AL) addresses this issue by strategically selecting informative samples for labeling during model training, thereby enhancing model performance. Although numerous approaches have been proposed for sample selection, which consider aspects of uncertainty and representation, the difficulties in estimating uncertainty and exploiting distribution of high-dimensional data still pose a major issue. Our proposed deep learning-based active learning algorithm, called Multiclass Autoencoder-based Active Learning (MAAL), learns latent representation leveraging the capacity of Deep Support Vector Data Description (Deep SVDD). With the multiclass autoencoder which learns the normal characteristics of each activity class in the latent space, MAAL provides an informative sample selection for model training by establishing a link between the HAR model and the selection model. We evaluate our proposed MAAL using two publicly available datasets. The performance results demonstrate the improvements across the overall active learning rounds, achieving enhancements up to 3.23% accuracy and 3.67% in the F 1 score. Furthermore, numerical results and analysis of sample selection are presented to validate the effectiveness of the proposed MAAL compared to the alternative comparison methods.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nWe present a deep learning-based active learning for an efficiently labeled dataset.\n\u2022\nThe proposed method extends the autoencoder with SVDD in a multiclass scheme.\n\u2022\nWe evaluate the proposed active learning method in the scenario of HAR applications.\n\u2022\nExperimental results show improvements in the performance of HAR with a smaller dataset.\n\u2022\nSelection of informative samples which is difficult for model to predict is validated.","Malignant brain tumors including parenchymal metastatic (MET) lesions, glioblastomas (GBM), and lymphomas (LYM) account for 29.7% of brain cancers. However, the characterization of these tumors from MRI imaging is difficult due to the similarity of their radiologically observed image features. Radiomics is the extraction of quantitative imaging features to characterize tumor intensity, shape, and texture. Applying machine learning over radiomic features could aid diagnostics by improving the classification of these common brain tumors. However, since the number of radiomic features is typically larger than the number of patients in the study, dimensionality reduction is needed to balance feature dimensionality and model complexity.\nAutoencoders are a form of unsupervised representation learning that can be used for dimensionality reduction. It is similar to PCA but uses a more complex and non-linear model to learn a compact latent space. In this work, we examine the effectiveness of autoencoders for dimensionality reduction on the radiomic feature space of multiparametric MRI images and the classification of malignant brain tumors: GBM, LYM, and MET. We further aim to address the class imbalances imposed by the rarity of lymphomas by examining different approaches to increase overall predictive performance through multiclass decomposition strategies.","Meta-learning has made tremendous progress in recent years and was demonstrated to be particularly suitable in low-resource settings where training data is very limited. However, meta-learning models still require large amounts of training tasks to achieve good generalisation. Since labelled training data may be sparse, self-supervision-based approaches are able to further improve performance on downstream tasks. Although no labelled data is necessary for this training, a large corpus of unlabelled text needs to be available. In this paper, we improve on recent advances in meta-learning for natural language models that allow training on a diverse set of training tasks for few-shot, low-resource target tasks. We introduce a way to generate new training data with the need for neither more supervised nor unsupervised datasets. We evaluate the method on a diverse set of NLP tasks and show that the model decreases in performance when trained on this data without further adjustments. Therefore, we introduce and evaluate two methods for regularising the training process and show that they not only improve performance when used in conjunction with the new training data but also improve average performance when training only on the original data, compared to the baseline.","Arrhythmia categorization is an exciting research in the early prevention and detection of cardiovascular illnesses, using Electrocardiogram (ECG). In the case of ECG signals, time series data are obtained by changing the time. This type of signal has the drawback of requiring repeated acquisition of comparison data with the same size as the registration data. Resolving the issue of inconsistent data size is accomplished by the use of an additional classifier-based adversarial neural networks. Adversarial data synthesis using Generative Adversarial Networks (GANs) and the generation of additional training examples solves the basic problem of insufficient data labelling. Recent studies have used the GAN architecture to create synthetic adversarial ECG signals in order to boost the amount of training data already available. The arrhythmia detection system, on the other hand, has a fragmented Convolution Neural Network (CNN) classification architecture. No flexible structural design has yet been suggested that can simultaneously discover and order abnormalities. An exceptional Prioritized Feature Subset Vector-Associated Generative Adversarial Network (PFSV-AGAN) is proposed in this research in order at a time produce ECG indications for multiple classes and sense heart-related problems. Furthermore, the model is based on class-specific ECG signals in order to generate realistic adversarial cases. This research presents a framework for ECG signal abnormality identification that has an unbalanced distribution among classes and achieves high accuracy in abnormalities categorization. After training on datasets, the classification model reliably identifies abnormalities in the proposed model. The proposed model when compared to the traditional model exhibits better performance levels.","Unmanned Aerial Systems (UAS), commonly known as drones, have revolutionized various industries with their diverse applications. As the demand for seamless and intuitive drone control grows, researchers are exploring innovative approaches to improve human-swarm interaction. This paper presents a novel method for operating a swarm of drones in real time using wearable technology and machine learning. Through the integration of motion capture data and classification algorithms, we strive to achieve an intuitive level of control that is accessible to users with varying skill levels. While the full realization of this approach remains a work in progress, our research lays the groundwork for future endeavors in this domain. In this paper, we discuss the limitations of existing control methods and present our methodology for data preprocessing, model training and testing, and result analysis. Our findings indicate the potential of this approach and open avenues for refining the interaction between humans and drone swarms.","Cardiac arrhythmia (CA) is an irregular rhythm that can cause an increase or decrease in heart rate. Electrocardiogram (ECG) is a noninvasive diagnostic technique widely used to identify CAs. The cardiologist analyzes these ECG signals for the accurate diagnosis and treatment of CA. However, diagnosing minute changes with the naked eye for longer ECG recordings is difficult and takes much time for the cardiologist to conclude the disease type. Therefore, developing an automated diagnostic tool for classifying CA from ECG recordings is essential. In this work, we propose a novel technique for effectively diagnosing CAs from the ECG signal. The proposed method optimizes the hyper-parameters of the tunable Q wavelet transform (TQWT) and random subspace of the stacked ensemble classifier using an enhanced Jaya optimization algorithm (EJOA) for CA classification. This optimized parameter of TQWT extracts features from ECG signals by decomposing them into high- and low-pass sub-band signals. Then, the low-dimensional features are extracted from the sub-band signal coefficients by applying principal component analysis (PCA). Finally, the optimized random subspace stacked ensemble classifier is trained with the optimal random subspace features of the principal components for subsequent classification of CAs. The trained random subspace stacked ensemble classifier was independently tested with inter-patient testing beats of the MIT-BIH arrhythmia and St Petersburg INCART 12-lead arrhythmia databases to diagnose different CA classes. The proposed method achieved an average accuracy of 98.30% and a sensitivity of 93.42% for the MIT-BIH database, an average accuracy of 96.60%, and a sensitivity of 80.2% for the INCART database. These performance measures demonstrate the proposed classifier\u2019s efficacy and are better than those reported in the existing literature.","This study introduces a novel model designed to classify macrocauses of violent crimes. The model\u2019s practical application is demonstrated through its integration into the framework of the Natal Smart City Initiative in Brazil. Utilizing the Design Science methodology, the study details the model\u2019s development, its subsequent implementation through a machine learning pipeline, and its assessment employing four prominent classification techniques: Decision Trees, Logistic Regression, Random Forest, and XGBoost. XGBoost performed exceptionally well, achieving an average accuracy of 0.961791, an F1-Score of 0.961410, and an AUC of ROC curve of 0.994732. Accurate classification of criminal macrocauses is crucial for developing effective public safety policies. The proposed model can provide public safety institutions and criminal analysts with a valuable tool for better understanding aspects related to violent crime analysis in their cities. This can streamline the analysis and management process and provide more accurate information for decision-making. This study also has important implications for the emerging field of smart cities. By providing a tool to assist in decision-making and planning public safety strategies, this work contributes to the development of innovative, data-based, and theory-based solutions to address urban challenges.\nHighlights\n\u2022\nWe propose a model for classifying criminal macrocauses to help criminal analysts.\n\u2022\nWe compared Decision Trees, Random Forest, Logistic Regression, and XGBoost.\n\u2022\nXGBoost obtained the best results (0.96 accuracies) after statistical analysis.\n\u2022\nUsing feature engineering techniques and the SMOTE-NC to handle unbalanced data.","Proteins play a vital role by booming out a number of activities within an organism to withstand its life. The field of Natural Language Processing has successfully adapted deep learning to get a better insight into the semantic nature of languages. In this paper, we propose semantic approaches based on deep learning to work with protein amino acid sequences and compare the performances of these approaches with traditional classifiers to predict their respective families. The Bidirectional Encoder Representations from Transformers (BERT) approach was tested over 103 protein families from UniProt consortium database. The results show the average prediction accuracy to 99.02%, testing accuracy to 97.70%, validation accuracy to 97.69%, Normalized Mutual Information (NMI) score on overall data to 98.45, on test data to 96.99, on validation data 96.93 with high weighted average F1 scores of 99.02 on overall data, 97.72 on test data and 97.70 on validation data, and high macro average F1 scores of 99.00 on overall data, 98.00 on test data and 98.00 on validation data. From the results, it is justified that our proposed approach is outperforming well when compared to the existing approaches.","Precise prediction of cancer survival is of paramount importance in aiding clinicians in formulating tailored treatment strategies. Such strategies have the potential to enhance the quality of life for individuals with cancer and lower the mortality rates associated with this disease. Recent research has underscored the significance of integrating data from various sources, including genomics and histopathologic images, as a pivotal step towards enhancing the accuracy of cancer survival prediction. Although these studies have achieved promising results, utilizing the consensus and complementarity of multimodal data for efficient learning of comprehensive multimodal representations poses an enormous challenge. In response to this challenge, we propose a Multimodal Disentangled Representation Learning (MMDR) method, aimed at acquiring modality-specific and shared representations, thus affording a comprehensive perspective of multimodal data. Empirical findings confirm that this approach yields notable enhancements in performance when compared to alternative methodologies.","The cultivation of desired grain varieties holds immense significance as about 67% of the world\u2019s population is associated with the agriculture sector. Unknowingly sowing the wrong variety of seeds may lead to a colossal waste of effort and money. Furthermore, the growing issue of rice grain adulteration in high-quality rice poses a threat to the trust of rice importers and exporters. While traditional methods are expensive, laborious, and error-prone, Computer Vision provides a good alternative that constitutes a current, advanced technology for image processing and data evaluation that holds tremendous promise and potential. In this research study, five varieties of rice grains including Jehlum Sr-1, Mushkibudji, Sr-2, and Sr-4 were collected from local grain and were used for research analysis. A computer vision system \u201cRiceNet\u201d contingent upon Deep Convolutional Neural Network (DCNN) framework has been designed for ameliorating the accuracy of identifying five unique groups of rice grain varieties. Deep Learning (DL) based pre-trained architectures including InceptionV3 and InceptionResNetV2 models were also adopted for classifying five specific groups of rice species. To optimize model parameters and alleviate back-propagation error during training, the Adam optimizer with a learning rate (lr) of 0.00003 has been employed to fine-tune the pre-trained InceptionV3 and ResNetInceptionV2 models. The proposed RiceNet architecture and pre-trained models were also compared with traditional ML approaches of HOG-SVM, SIFT-SVM, HOG-Logistic Regression(HOG-LR), SIFT-Logistic Regression(SIFT-LR), HOG-KNN, and SIFT-KNN for rice grain classification. With these experimentations at hand, it was observed that our proposed model \u201cRiceNet\u201d outperformed other approaches in similar computer vision tasks. The prediction accuracy outcome for the test dataset by HOG-SVM, SIFT-SVM, HOG-LR, SIFT-LR, HOG-KNN, and SIFT-KNN models were 66.0%, 65.33%, 62.67%, 65.0%, 54.0%, and 52.0% respectively. RiceNet, InceptionV3 and ResNetInceptionV2 have the best prediction accuracy of 94%, 84% and 81.333%. The remarkably high success rate of DCNN models makes them highly valuable and can be extended to endorse an integrated grain identification system that can operate in real-world situations.\nHighlights\n\u2022\nRice grain classification is crucial to ensure quality in the agricultural sector.\n\u2022\nDeep Convolutional Neural Network based RiceNet model achieved high accuracy of 94%.\n\u2022\nRiceNet outperforms ML traditional methods for rice grain identification.\n\u2022\nInceptionV3 and ResNetInceptionV2 achieved 84% and 81.333% prediction rates.","This paper addresses the missing modality problem in multimodal person classification, where an incomplete multimodal input with one modality missing is classified into predefined person classes. A multimodal cascaded framework with three deep learning models is proposed, where model parameters, outputs, and latent space learnt at a given step are transferred to the model in a subsequent step. The cascaded framework addresses the missing modality problem by, firstly, generating the complete multimodal data from the incomplete multimodal data in the feature space via a latent space. Subsequently, the generated and original multimodal features are effectively merged and embedded into a final latent space to estimate the person label. During the learning phase, the cascaded framework uses two novel latent loss functions, the missing modality joint loss, and latent prior loss to learn the different latent spaces. The missing modality joint loss ensures that the similar class latent data are close to each other, even if a modality is missing. In the cascaded framework, the latent prior loss learns the final latent space using a previously learnt latent space as a prior. The proposed framework is validated on the audio-visible RAVDESS and the visible-thermal Speaking Faces datasets. A detailed comparative analysis and an ablation analysis are performed, which demonstrate that the proposed framework enhances the robustness of person classification even under conditions of missing modalities, reporting an average of 21.75% increase and 25.73% increase over the baseline algorithms on the RAVDESS and Speaking Faces datasets.","Highlights\n\u2022\nA pretrained model on augmented data and fine-tuned by using AI and 3D contour features for assessing facial attractiveness is proposed.\n\u2022\nThe proposed model overcomes the subjective inconsistency and unreliability common to all traditional rating methods.\n\u2022\nThis model provides an accurate 3D information of full facial that is unavailable in previous studies using either 2D or 3D measurement.\n\u2022\n3D facial images and deep transfer learning have been firstly combined for evaluating the facial attractiveness in patients undergoing OGS.\n\u2022\nThe developed web browser\u2013based user interface contributes to effective doctor\u2013patient communication and decision-making.\nAbstract\nIn this paper, we investigate a new approach based on a combination of three-dimensional (3D) facial images and deep transfer learning (TL) with fine-grained image classification (FGIC) for quantitative evaluation of facial attractiveness. The 3D facial surface images of patients with and without filtering and the publicly available SCUT-FBP5500 dataset was used for transfer training and model pre-training, respectively. Experimental results show that a bilinear CNN model with a Gaussian filter freezing 80 % of the weights exhibit the strongest performance and lowest average error as a deep learning prediction model; the model was subsequently adopted for automatic assessment of facial attractiveness in clinical application. This is the first TL model with FGIC using 3D facial images for automatic quantitative evaluation of facial attractiveness in patients undergoing Orthognathic surgery (OGS). The developed web browser\u2013based user interface enables effective and rapid assessment, thus contributing to effective patient\u2013clinician communication and decision-making.","Interior style classification is an interesting problem which has potential applications both commercial and academic communities. This task aims to devise interior design styles automatically. Thus, interior designers will explore customers\u2019 tastes and then precisely provide suggestions for decor inspiration based on their preferences. Recently, Convolutional Neural Networks (CNNs) have been considered the de-facto standard in computer vision tasks. Therefore, several current works have tended to address interior style classification using CNN-based architectures. Moreover, transformer-based architectures and attention-based encoder\u2013decoder models have been proven successfully in computer vision and natural language processing tasks. Sequentially, more studies have been arguing the efficiency of combining CNN-based architectures and transformer-based architectures for normal image classification problems. In this project, we focus on finding an architecture network that is suitable for the interior style classification problem. We propose a robustness method to address interior style design classification, named ISC-DeIT. The proposed method is based on Data-efficient image transformer architectures and knowledge distillation, which can be trained on small datasets effectively. Especially, a proposed additional module is plugged to leverage learning feature representations for improving predictive accuracy. Experiments were carried out on a new curated dataset with five interior styles including Art-Decor, Hitech, Indochina, Industrial, and Scandinavian. Empirical results of ISC- DeiT indicated that the ability of prediction for interior style classification of the proposed method has been increased significantly, compared with other state-of-the-art methods.","Identifying client needs to provide optimal services is crucial in tourist destination management. The events held in tourist destinations may help to meet those needs and thus contribute to tourist satisfaction. As with product management, the creation of hierarchical catalogs to classify those events can aid event management. The events that can be found on the internet are listed in dispersed, heterogeneous sources, which makes direct classification a difficult, time-consuming task. The main aim of this work is to create a novel process for automatically classifying an eclectic variety of tourist events using a hierarchical taxonomy, which can be applied to support tourist destination management. Leveraging data science methods such as CRISP-DM, supervised machine learning, and natural language processing techniques, the automatic classification process proposed here allows the creation of a normalized catalog across very different geographical regions. Therefore, we can build catalogs with consistent filters, allowing users to find events regardless of the event categories assigned at source, if any. This is very valuable for companies that offer this kind of information across multiple regions, such as airlines, travel agencies or hotel chains. Ultimately, this tool has the potential to revolutionize the way companies and end users interact with tourist events information.\nGraphical Abstract\nDisplay Omitted\nHighlights\n\u2022\nComputational techniques are used to classify tourism destination events.\n\u2022\nA Large Language Model (BERT) is used to get vectorial representations of events.\n\u2022\nA method to automatically classify events is proposed to easy the adoption of standards.\n\u2022\nThere is great scope for extending this methodology to other applications.","Objective: The objective is to develop a predictive model utilizing Support Vector Machines (SVM) for the purpose of classifying the clinical stage of breast cancer.\nMaterials and Methods: Accurate determination of the clinical stage of breast cancer patients holds significant importance in selecting suitable treatment options and minimizing avoidable complications. In this study, we present the application of radiomics and SVM for breast cancer computed tomography (CT) to anticipate the preoperative clinical stage in breast cancer patients. The training dataset encompasses 166 cases obtained from the Affiliated Hospital of Xiangnan University, while the test dataset comprises 91 cases from Chenzhou Third People's Hospital. The integration of clinical parameters with radiomics exhibits the most superior diagnostic efficacy in forecasting the clinical stage of breast cancer. As part of the evaluation, various metrics were calculated, including the area under the curve (AUC), the accuracy (ACC), sensitivity (Sen), specificity (Spe), positive predictive value (PPV) and negative predictive value (NPV). To differentiate between the radiomics model, clinical data model, and fusion model, the Delong test was utilized. The precision of the prediction model was evaluated by generating a calibration curve using 1,000 bootstrap weight samples. Furthermore, the decision curve analysis (DCA) was conducted to assess the model's practicality.\nResults: The fusion model exhibits superior predictive performance compared to both the single radiomics model and clinical model. The fusion model's test sets of AUC, ACC, Sen, Spe, PPV, and NPV are 0.824, 0.780, 0.932, 0.652, 0.707, and 0.909, respectively.\nConclusion: The fusion model exhibits greater efficacy than both the single radiomics model and clinical model, and thus holds significant potential for facilitating the diagnosis of breast cancer stage and the development of individualized treatment plans.CCS","Surface electromyography (sEMG) signal is essential for accurately controlling prosthetic devices with numerous degrees of freedom in human-machine interfaces for robotics and assistive technologies. The controlling method of the upper-limb prosthesis device depends on electromyogram (EMG) pattern recognition, which requires the efficient blending of conventional signal processing and machine learning. This paper focuses on stacked ensemble models, one of the popular methods for reducing generalization error. The proposed work uses a dataset of sEMG signals from different upper-limb positions in subjects. The raw signals are transformed into correlated time-domain descriptors (cTDD) for feature extraction, which are then used to train the stacked ensemble framework. The framework includes four base classifiers (support vector machine (SVM), K-nearest neighbours (KNN), logistic regression (LR), and decision tree (DT)) and two meta-classifiers (random forest (RF) and multi-layer perceptrons (MLP). The performance of the meta-classifiers is evaluated on two test sets, showing superior classification accuracy compared to the basic classifiers. The proposed approach demonstrates the capability to accurately classify limb position invariant EMG signal classification for prosthetic device control.","Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose Crash-Former, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data, an image encoder to use map imagery data, a raw data encoder to utilize demographic information, a feature fusion module for aggregating the encoded features, and a classifier that accepts the aggregated data and makes predictions accordingly. Results from extensive real-world experiments in 10 major US cities show that CrashFormer outperforms state-of-the-art sequential and non-sequential models by 1.8% in F1-score on average when using \"sparse\" input data.","Automatic classifier accuracy evaluation (ACAEval) on unlabeled test sets is critical for unseen real-world environments. The use of dataset-level regression on synthesized meta-datasets (comprised of many sample sets) has shown promising results for ACAEval. However, the existing meta-dataset for ACAEval is created using simple image transformations such as rotation and background substitution, which can make it difficult to ensure a reasonable distribution shift between the sample set and the test set. When the distribution shift is large, it becomes challenging to estimate the classifier accuracy on the test set using those sample sets. To ensure more robust ACAEval, this paper attempts to customize a meta-dataset in which each sample set has a reasonable distribution shift to the test set. An intra-class cycle-consistent adversarial learning (ICAL) method is introduced to transfer the style of a labeled training set to the style of the test set, by jointly considering the domain shift issue, the label flipping issue (the semantic information may be changed after style transformation), and the diversity of multiple sample sets in the meta-dataset. Experiments validate that under the same experimental setup, our method outperforms the existing ACAEval methods by a good margin, and achieves state-of-the-art performance on several standard benchmark datasets, including digit classification and natural image classification.\nHighlights\n\u2022\nTwo authors named Yan Huang in pinyin, one PostDoc (1st author), the other an Associate Prof (3rd author).\n\u2022\nPaper on ACAEval for classifier accuracy. Uses meta-dataset technique for unlabeled real-world data.\n\u2022\nCustomized meta-dataset for ACAEval to address distribution shift between samples and test set.\n\u2022\nOur sample set considers label flip issue. Introduces random indicator and FD margin loss.\n\u2022\nExperiments demonstrate our ACAEval matches existing methods and surpasses dataset-level regression.","Brain tumors can be generated anywhere in the brain, with an extensive size range and morphology that makes it challenging to identify and classify. Classifying brain tumors is essential for developing personalized treatment plans. Different types of brain tumors have different responses to treatment, and an accurate classification can help medical professionals develop treatment plans tailored to each patient\u2019s needs. Therefore, this case study aimed to classify T1-weighted contrast-enhanced images of three types of tumors through various approaches, from shallow neural networks to fine-tuning deep neural networks trained. Comparing shallow and deep neural network approaches could help to understand the trade-offs between their performance, interoperability, interpretability, benefits, limitations, scopes, and overall, choosing the best method for a given problem.","Automatically classifying cough sounds is one of the most critical tasks for the diagnosis and treatment of respiratory diseases. However, collecting a huge amount of labeled cough dataset is challenging mainly due to high laborious expenses, data scarcity, and privacy concerns. In this work, our aim is to develop a framework that can effectively perform cough classification even in situations when enormous cough data is not available, while also addressing privacy concerns. Specifically, we formulate a new problem to tackle these challenges and adopt few-shot learning and federated learning to design a novel framework, termed F2LCough, for solving the newly formulated problem. We illustrate the superiority of our method compared with other approaches on COVID-19 Thermal Face &amp; Cough dataset, in which F2LCough achieves an average F1-Score of 86%. Our results show the feasibility of few-shot learning combined with federated learning to build a classification model of cough sounds. This new methodology is able to classify cough sounds in data-scarce situations and maintain privacy properties. The outcomes of this work can be a fundamental framework for building support systems for the detection and diagnosis of cough-related diseases.","One of the major difficulties in face recognition while comparing photographs of individuals of different ages is the influence of age progression on their facial features. As a person ages, the face undergoes many changes, such as geometrical changes, changes in facial hair, and the presence of glasses, among others. Although biometric markers like computed face feature vectors should ideally remain unchanged by such factors, face recognition becomes less reliable as the age range increases. Therefore, this investigation was carried out to examine how the use of Embedded Prototype Subspace Classifiers could improve face recognition accuracy when dealing with age-related variations using face feature vectors only.","This full-day tutorial introduces modern techniques for practical uncertainty quantification specifically in the context of multi-class and multi-label text classification. First, we explain the usefulness of estimating aleatoric uncertainty and epistemic uncertainty for text classification models. Then, we describe several state-of-the-art approaches to uncertainty quantification and analyze their scalability to big text data: Virtual Ensemble in GBDT, Bayesian Deep Learning (including Deep Ensemble, Monte-Carlo Dropout, Bayes by Backprop, and their generalization Epistemic Neural Networks), Evidential Deep Learning (including Prior Networks and Posterior Networks), as well as Distance Awareness (including Spectral-normalized Neural Gaussian Process and Deep Deterministic Uncertainty). Next, we talk about the latest advances in uncertainty quantification for pre-trained language models (including asking language models to express their uncertainty, interpreting uncertainties of text classifiers built on large-scale language models, uncertainty estimation in text generation, calibration of language models, and calibration for in-context learning). After that, we discuss typical application scenarios of uncertainty quantification in text classification (including in-domain calibration, cross-domain robustness, and novel class detection). Finally, we list popular performance metrics for the evaluation of uncertainty quantification effectiveness in text classification. Practical hands-on examples/exercises are provided to the attendees for them to experiment with different uncertainty quantification methods on a few real-world text classification datasets such as CLINC150.","The imbalanced dataset\u2019s existing classification methods have low prediction accuracy for the minority class because of the little information present. Using over- and under-sampling techniques, we can improve the minority\u2019s ability to forecast outcomes. However, the minority class\u2019s accuracy of prediction is negatively impacted by the two methods due to the loss of vital information or the addition of irrelevant details for classification. SVM kernels have great abilities to handle asymmetric data, but when we need to use SVM kernels alone or as part of the ensemble technique for an unbalanced dataset, we don\u2019t have a strong reason to choose which kernel to use, and also how a particular kernel will act depends a lot on the data set. In this paper, we present a framework in which several kernel SVM (Linear, Polynomial, Sigmoid, RBF) classifiers were utilized as the base learners and one of the kernels (say RBF kernel) as meta learner using the Stacking Ensembles technique, which shows that stacked generalization of SVM kernels gives similar results as best performing kernel for an imbalanced dataset of software change proneness, using AUC, ROC, MCC, and BAS as an evaluation matrix.","In many practical binary classification applications, such as financial fraud detection or medical diagnosis, it is crucial to optimize a model's performance on high-confidence samples whose scores are higher than a specific threshold, which is calculated by a given false positive rate according to practical requirements. However, the proportion of high-confidence samples is typically extremely small, especially in long-tailed datasets, which can lead to poor recall results and an alignment bias between realistic goals and loss. To address this challenge, we propose a novel loss reweighting framework called Momentum Threshold-Oriented Loss (MTOL) for binary classification tasks and propose two instantiated losses of it. Given a limited FPR range, MTOL aims to improve the recall of binary classification models at that FPR range by incorporating a batch memory queue and momentum estimation mechanisms. The MTOL adaptively estimates thresholds of FPR during the model training iterations and up-weights the loss of samples in the threshold range, with little consumption of storage and computation. Our experimental results on various datasets, including CIFAR-10, CIFAR-100, Tiny-ImageNet, demonstrate the significant effect of MTOL in improving the recall at low FPR especially in class imbalance settings. These results suggest that MTOL is a promising approach in scenarios where the model's performance in the low FPR range is of utmost importance.","In the era of digital information, ensuring the accuracy and reliability of information is crucial, making fact-checking a vital process. Currently, English fact-checking has thrived due to various language processing tools and ample datasets. However, the same cannot be said for Vietnamese fact-checking, which faces significant challenges due to the lack of such resources. To address these challenges, we propose a model for checking Vietnamese facts by synthesizing three popular technologies: Knowledge Graph (KG), Datalog, and KG-BERT. The KG serves as the foundation for the fact-checking process, containing a dataset of Vietnamese information. Datalog, a logical programming language, is used with inference rules to complete the knowledge within the Vietnamese KG. KG-BERT, a Deep Learning (DL) model, is then trained on this KG to rapidly and accurately classify information that needs fact-checking. Furthermore, to put Vietnamese complex sentences into the fact-checking model, we present a solution for extracting triples from these sentences. This approach also contributes significantly to the ease of constructing foundational datasets for the Vietnamese KG. To evaluate the model's performance, we create a Vietnamese dataset comprising 130,190 samples to populate the KG. Using Datalog, we enrich this graph with additional knowledge. The KG is then utilized to train the KG-BERT model, achieving an impressive accuracy of 95%. Our proposed solution shows great promise for fact-checking Vietnamese information and has the potential to contribute to the development of fact-checking tools and techniques for other languages. Overall, this research makes a significant contribution to the field of data science by providing an accurate solution for fact-checking information in Vietnamese language contexts.","As a fast and inexpensive machining method applicable for creating a wide range of shapes and producing large batches, sheet metal punching is widely used e.g., in automotive, aerospace, electronics, and construction industries. A significant downside of sheet metal punching is the punching tool wear in use. A worn punch tool may impact the quality of the end product by causing imperfections and reduce the efficiency of the manufacturing process through increased scrap and by slowing down the production. Effective monitoring of punching tool wear is therefore essential for an efficient and cost-effective production of high-quality parts. The monitoring can be based on acceleration measurement which produces large amounts of raw data, making edge processing ideal as only the indication of the tool condition needs to be sent forward for decision support. Classification models for tool wear identification were built and compared in this study. The models are based on measured acceleration data. Two different open-source methods for time series feature extraction, namely TSFEL and MiniRocket, were tested and the classification results based on them compared. All methods used for building the models are computationally light and therefore applicable for real-time data processing at the edge. According to the results the MiniRocket algorithm is suitable for the task and superior compared to the TSFEL method. The classification accuracies based on the MiniRocket features are at best over 96.5 % and at worst around 84 %, whereas the corresponding accuracies are between 35 and 56 % for TSFEL feature based models. The use of the MiniRocket algorithm in building a model for punch tool monitoring shows very promising results. However, the dataset used was very limited. Therefore, further investigation is required based on an ampler dataset.","Acute myocardial infarction (AMI) is the leading cause of hospital admissions and death all over the world and chest pain is the most common presenting complaint of AMI. Therefore, this paper proposes a machine learning (ML)-based prediction model for the in-hospital mortality in AMI patients with typical chest pain. To understand the principle of the black-box prediction model, a Shapley additive explanations (SHAP) method is applied to the ML-based prediction model. The experimental framework mainly includes three steps. First, we extract the experimental data from the Korea Acute Myocardial Infarction Registry National Institutes of Health (KAMIR-NIH), and then preprocess the selected data with missing value imputation, data normalization, and splitting. Thereafter, two kinds of data sampling methods such as synthetic minority oversampling techniques (SMOTE) and Adaptive Synthetic (ADASYN), are applied to handle the class imbalance problem on the experimental data. Second, different ML models such as decision tree, random forest, extreme gradient boosting (XGBoost), support vector machine, and logistic regression, are trained and evaluated on the preprocessed AMI patient data. Finally, the SHAP method is used to explain the best ML-based prediction model. The experimental results showed that the logistic regression with the ADASYN approach achieved the highest performance. Moreover, the SHAP technique enhanced the transparency of the ML model and can be a good reference for doctors to support their decisions in real life.","In recent times, deep neural networks achieved outstanding predictive performance on various classification and pattern recognition tasks. However, many real-world prediction problems have ordinal response variables, and this ordering information is ignored by conventional classification losses such as the multi-category cross-entropy. Ordinal regression methods for deep neural networks address this. One such method is the CORAL method, which is based on an earlier binary label extension framework and achieves rank consistency among its output layer tasks by imposing a weight-sharing constraint. However, while earlier experiments showed that CORAL\u2019s rank consistency is beneficial for performance, it is limited by a weight-sharing constraint in a neural network\u2019s fully connected output layer, which may restrict the expressiveness and capacity of a network trained using CORAL. We propose a new method for rank-consistent ordinal regression without this limitation. Our rank-consistent ordinal regression framework (CORN) achieves rank consistency by a novel training scheme. This training scheme uses conditional training sets to obtain the unconditional rank probabilities through applying the chain rule for conditional probability distributions. Experiments on various datasets demonstrate the efficacy of the proposed method to utilize the ordinal target information, and the absence of the weight-sharing restriction improves the performance substantially compared to the CORAL reference approach. Additionally, the suggested CORN method is not tied to any specific architecture and can be utilized with any deep neural network classifier to train it for ordinal regression tasks.","Dynamic functional connectivity network (DFCN) derived from resting-state functional magnetic resonance imaging (rs-fMRI), which characterizes the dynamic interaction between brain regions, has been applied to classification of brain diseases. However, existing studies usually focus on dynamic changes of low-order (i.e., pairwise) correlation of brain regions, thus neglecting their high-order dynamic information that could be important for brain disease diagnosis. Therefore, in this paper, we first propose a novel sparse learning based high-order DFCNs construction method, and then build a novel learning framework to extract high-level and high-order temporal features from the constructed high-order DFCNs for brain disease classification. The experimental results on 174 subjects from from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) demonstrate the effectiveness of our proposed method in comparison with state-of-the-art methods.","Highlights\n\u2022\nA two-stage framework to detect fraudulent transactions is proposed.\n\u2022\nThe framework incorporates a deep Autoencoder as a representation learning method.\n\u2022\nThe deep Autoencoder improves the performance of the Deep learning classifiers.\n\u2022\nThe results indicate the superiority of deep autoencoder over PCA.\nAbstract\nDue to the growth of e-commerce and online payment methods, the number of fraudulent transactions has increased. Financial institutions with online payment systems must utilize automatic fraud detection systems to reduce losses incurred due to fraudulent activities. The problem of fraud detection is often formulated as a binary classification model that can distinguish fraudulent transactions. Embedding the input data of the fraud dataset into a lower-dimensional representation is crucial to building robust and accurate fraud detection systems. This study proposes a two-stage framework to detect fraudulent transactions that incorporates a deep Autoencoder as a representation learning method, and supervised deep learning techniques. The experimental evaluations revealed that the proposed approach improves the performance of the employed deep learning-based classifiers. Specifically, the utilized deep learning classifiers trained on the transformed data set obtained by the deep Autoencoder significantly outperform their baseline classifiers trained on the original data in terms of all performance measures. Besides, models created using deep Autoencoder outperform those created using the principal component analysis (PCA)-obtained dataset as well as the existing models.","The three most important necessities for human life are food, shelter, and clothing. Young people who are technologically savvy have witnessed a significant scientific increase in the latter two areas. Despite this, farming is still regarded as a labor-intensive endeavour. Most farmers are uneducated and lack a scientific understanding of farming practices. Crop cultivation anywhere in the world is dependent on the climate, also known as seasons, and soil properties; however, increasing crop production is dependent on a variety of factors, most notably temperature. This work proposes a crop recommendation system to address the issue of increasing crop production. A vision of the perfect harvest before planting would be extremely beneficial to farmers and other stakeholders in making appropriate decisions about improving yields for local use, and it may inspire increased capacity and a wider range of product options for businesses. Precision agriculture is a modern farming strategy that advises farmers on the sorts of crops they should plant based on data collected through studies on soil features, soil types, and crop yields. This style of agriculture is also known as \"high-intensity agriculture\". Our system employed Machine Learning procedures to recommend the appropriate crops. This system then reduces the financial losses experienced by farmers because of establishing the ominous harvests. This problem is addressed in this paper by proposing a recommendation system using an ensemble model with majority voting and an accuracy of 99.4 percent.","The Healthcare Analytics(HcA) is a process in which clinical data is analyzed and patient\u2019s treatment is performed. The treatment depends on the analysis of clinical data accumulated from Electronic Health Records (EHRs), pharmaceutical and research and development cost and claims of patient. Lung cancer is the most common among cancer disease and the foremost reason for deaths in both men and women. In this research work EHRs are analyzed and the survivability rate is predicted for lung cancer. Researchers apply Machine Learning Techniques (MLT)for predicting the survivability rate so that chemotherapy can be provided for cancer affected people. MLTare well accepted by doctors and work well in diagnosing and predicting cancer. An ensemble of Support Vector Machine (SVM), Naive Bayes (NBs)and classification trees (C4.5) can be used to evaluate patterns that are risk factors for lung cancer study. The North Central Cancer Treatment Group (NCCTG) lung cancer data set along with new patient data is used for evaluating the performance of support SVM, NBs and C4.5. The comparison isbased on accuracy, Area Under the Curve(AUC), Receiver Operating Characteristic (ROC) and the resultshows that C4.5 performs better in predicting lung cancer with the increase in training data set.","Deciding the signal length is an important challenge for one-class time-series classification (OCTSC). This paper aims to develop an OCTSC algorithm that does not require model retraining for different signal lengths. For this purpose, a distance-based one-class time-series classification approach using local cluster balance (OCLCB) is proposed. OCLCB extracts feature vectors, namely, local cluster balance (LCB), from the clustering results of sliding windows. K-means clustering is applied to the sliding windows extracted from the training signal. Then, the local prototype (LP) is calculated as the average of the local cluster balance (LCB) in the training data. Unseen scores are computed as the distance metrics between LP and LCBs in the testing data. Since the sliding window size is independent of the entire signal size, OCLCB does not need to retrain the model. This aspect gives the benefit of reducing the parameter tuning costs. The source code is uploaded at https://github.com/ToshiHayashi/OCLCB.","Data classification is an important and challenging issue encountered in many practical applications. The classifier based on Evidential Reasoning Rule (ER Rule) can well handle the uncertainty in classification and obtain competitive accuracy. However, there are many parameters to be optimized, and the computation cost of the usually adopted optimization strategy is relatively high. This fact weakens the application advantage of ER Rule classifier. To address this challenge, an asynchronous optimization approach is proposed. In the original ER Rule classifier, feature referential values and evidence weights are optimized synchronously; while in the proposed method, these two types of parameters are optimized separately based on their essential impacts on the classification results. For the optimization of feature referential values, the objective function measures the quality of belief matrix, which is the critical strategy to improve the computational efficiency. Three types of feasible objective functions are constructed. After obtaining optimal referential values, evidence weights are optimized based on the actual classification effect, and the required iterations decrease. Various experiments on 14 publicly available datasets verify the computational efficiency and classification performance of the proposed method.\nHighlights\n\u2022\nThe low computational efficiency of ER Rule-based classifier is addressed by optimizing its parameters asynchronously.\n\u2022\nThe objective function of feature referential values optimization measures the quality of belief matrix.\n\u2022\nThe effectiveness of the proposed method is validated by theoretical analysis and various experiments.","Highlights\n\u2022\nA class imbalance metric to assess classifier performance considering imbalance distribution impacts.\n\u2022\nSensitive in comparison between classifier performances in different imbalance distribution statuses.\n\u2022\nAn Algorithm for prediction on ideal classifier performance with a fair distribution (1:1) using limited size of samples.\nAbstract\nClass imbalance is a common problem in many classification domains. This paper provides an evaluation index and one algorithm for this problem based on binary classification. The Model Performance Index (MPI) is proposed for assessing classifier performance as a new evaluation metric, considering class imbalance impacts. Based on MPI, we investigate algorithms to estimate ideal classifier performance with a fair distribution (1:1), referred to as the Ideal Model Performance Algorithm. Experimentally, compared with traditional metrics, MPI is more sensitive. Specifically, it can detect all types of changes in classifier performances, while others might remain at the same levels. Moreover, for the estimation of classifier performances, the algorithm reaches small differences between predictions and the values observed. Generally, for ideal performances, it achieved error rates of 0.060% - 1.3% for rare class in four experiments, showing a practical value on estimation and representation on the classifier performances.","In industrial settings, it is often necessary to achieve language-level accuracy targets. For example, Amazon business teams need to build multilingual product classifiers that operate accurately in all European languages. It is unacceptable for the accuracy of product classification to meet the target in one language (e.g, English), while falling below the target in other languages (e.g, Portuguese). To fix such issues, we propose Language Aware Active Learning for Multilingual Models (LAMM), an active learning strategy that enables a classifier to learn from a small amount of labeled data in a targeted manner to improve the accuracy of Low-resource languages (LRLs) with limited amounts of data for model training. Our empirical results on two open-source datasets and two proprietary product classification datasets demonstrate that LAMM is able to improve the LRL performance by 4%--11% when compared to strong baselines.","The trade-off between privacy and accuracy presents a challenge for current federated learning (FL) frameworks, hindering their progress from theory to application. The main issues with existing FL frameworks stem from a lack of interpretability and targeted privacy protections. To cope with these, we proposed Disentangled Federated Learning for Privacy (DFLP) which employes disentanglement, one of interpretability techniques, in private FL frameworks. Since sensitive properties are client-specific in nature, our main idea is to turn this feature into a tool that strikes the balance between data privacy and FL model performance, enabling the sensitive attributes to be private. DFLP disentangles the client-specific and class-invariant attributes to mask the sensitive attributes precisely. To our knowledge, this is the first work that successfully integrates disentanglement and the nature of sensitive attributes to achieve privacy protection while ensuring high FL model performance. Extensive experiments validate that disentanglement is an effective method for accuracy-aware privacy protection in FL frameworks.","Drug repurposing, which involves using already approved drugs for new clinical targets, represents a cost-effective alternative to the development of new drugs. In this study, we introduce an innovative computational strategy, which uses Non-negative Matrix Tri-Factorization (NMTF) to generate vector embeddings of given sizes for drugs and drug targets; vector embeddings are then employed to generate predictions for drug repurposing using conventional classifiers, like random forest, logistic regression, and multi-layer perceptron.\nOur approach leverages the NMTF method within a new approach to classification, named two-tower architecture, which is effective in solving complex tasks, such as the optimal prediction of targets for already approved drugs. This approach produces robust models, with AUROC reaching 0.90, which outperform traditional NMTF. We evaluate our method in the context of Parkinson\u2019s Disease; within the newly revealed drug-target predictions, we highlight compounds that exhibit potential in mitigating neurodegeneration, thereby revealing a potentially useful drug in relationships with a well-identified target.","This paper proposes a multi-domain sample classification method based on Baidu API's general object recognition function. we used three datasets in the experiment,including CIFAR-10, CIFAR-100, and Mini-ImageNet. For an unknown sample belonging to these three datasets, we first predict which domain it may belong to by using the output results of Baidu API, and then obtain the label of the sample by training a model on that domain. Compared with existing methods, our method reduces the number of high-performance models that need to be trained and reduces the computational difficulty. Experimental results show that our method is more convenient and accurate.","The fields of energy storage, photocatalysis, and sensors have undergone substantial technological advancements, which have led to the generation of vast amounts of data on electrochemical impedance (EIS). The interpretation of large amounts of EIS data is a challenging task since the analysis of EIS data requires multiple steps to get a suitable equivalent circuit. Recently, some progress has been made in the machine learning (ML) model for EIS classification. However, most of the ML models are performed as a \u201cblack box\u201d model, which provides only the classification result and lacks physical descriptor representation. Here, we apply variational autoencoders (VAE) to EIS data analysis, which includes classification, parameter prediction, and the visualization of physical descriptors. The VAE model performed well in the classification task, with an accuracy of 82.0%\u201392.4%. In the prediction task, VAE shows a high R-squared value on the Randles circuit. Additionally, the VAE model can map physical descriptors to the latent space, allowing the latent space to transform into a property space, which plays an important role in the optimization and exploration of novel materials research.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nAutomatically analyze the EIS spectrum.\n\u2022\nVAE model design for classification and regression.\n\u2022\nThe high accuracy classifier of the EIS circuit model with accuracy of 82.0%\u201392.4%.\n\u2022\nThe use of VAE model for the exploration and visualization of EIS dataset.","Network modeling has proven to be an efficient tool for many interdisciplinary areas, including social, biological, transportation, and various other complex real-world systems. In addition, cellular automata (CA) are a formalism that has received significant attention in recent decades as a model for investigating patterns in the dynamic spatio-temporal behavior of these systems, based on local rules. Some studies investigate the use of cellular automata to analyze the dynamic behavior of networks and refer to them as network automata (NA). Recently, it has been demonstrated that NA is effective for network classification, as it employs a Time-Evolution Pattern (TEP) for feature extraction. However, the TEPs investigated in previous studies consist of binary values (states) that do not capture the intrinsic details of the analyzed network. Therefore, in this work, we propose alternative sources of information that can be used as descriptors for the classification task, which we refer as Density Time-Evolution Pattern (D-TEP) and State Density Time-Evolution Pattern (SD-TEP). We examine the density of alive neighbors of each node, which is a continuous value, and compute feature vectors based on histograms of TEPs. Our results demonstrate significant improvement over previous studies on five synthetic network datasets, as well as seven real datasets. Our proposed method is not only a promising approach for pattern recognition in networks, but also shows considerable potential for other types of data that can be transformed into network.\nHighlights\n\u2022\nA Network Classification Method based on network automata is proposed.\n\u2022\nConway\u2019s life cellular automata are used as Network Automata model.\n\u2022\nTime Evolution Patterns Extracted from Network Automata represents the networks.\n\u2022\nResults on real-world and synthetic networks outperforms previous methods.","Inverse gravity moment (IGM) is a recent term weighting scheme in the text classification literature. The idea is that a distinguishing term should concentrate around preferably one or limited number of classes. IGM considers document frequencies of a term over all classes. However, it cannot handle the class imbalance problem. The natural distribution of documents in the text classification is frequently imbalanced. The classifier generally tend to bias toward majority classes, classes with many samples. Therefore, documents from minority classes might be ignored. In this study, we tackle the class imbalance problem in IGM and propose to use a factor called relative imbalance ratio (RIR). The aim of RIR coefficient is to scale document frequencies of the terms from minority classes in order to amplify the IGM score for the terms from the minority classes. Otherwise, those terms might be dwarfed due to the fact that majority classes have many more documents. Experimental results with three data sets, two of which are imbalanced, show that our proposed method manage to outperform the original IGM method as well as the improved IGM (IIGM) and seven other the state-of-the-art term weighting schemes (TF-ICF, TF-ICSDF, TF-RF, TF-PROB, TF-MONO, RE, AFE-MERT) in terms of f 1 - m a c r o results while not comprising f 1 - m i c r o.\nHighlights\n\u2022\nThe class imbalance in inverse gravity moment, IGM, term weighting scheme is studied.\n\u2022\nIGM-RIR, which integrates relative imbalance ratio, RIR, into IGM, is proposed.\n\u2022\nIGM-RIR promotes minority classes in the term weighting task.\n\u2022\nIGM-RIR generally manages to outperform both IGM and improved IGM (IIGM).\n\u2022\nIGM-RIR also outperform other state-of-the-art term weighting schemes.","The explosion of data which is happening now must be utilized to support decision making both in terms of business and other matters. Data which are becoming assets today needs to be analyzed and extracted in order to find valuable information. The results of data analysis can be used to make predictions, one of which is classification. For high dimensions data, we require preprocessing stage so that the model building process is not complex and the analysis is accurate. One of the preprocessing stages that need attention is feature selection. Feature selection is applied to reduce features without diminishing the accuracy and information in the data. Performing feature selection can also be done by using the association rule. Association rule refers to considering the association relationship between items and the frequency of items occurrence as features. However, the obstacle in implementing the association rule is when determining the minimum support value. Therefore, an adaptive support method is proposed to determine the minimum support value automatically based on the characteristics of the dataset. In this present study, a feature selection method using adaptive support is proposed. Based on the experimental results using 3 classifiers, the accuracy and F1-Score values for the feature selection method using adaptive support are higher compared to the Information gain method.","The Product Line Architecture (PLA) is one of the most important artifacts of a Software Product Line (SPL). PLA design can be formulated as an interactive optimization problem with many conflicting factors. Incorporating Decision Makers\u2019 (DM) preferences during the search process may help the algorithms find more adequate solutions for their profiles. Interactive approaches allow the DM to evaluate solutions, guiding the optimization according to their preferences. However, this brings up human fatigue problems caused by the excessive amount of interactions and solutions to evaluate. A common strategy to prevent this problem is limiting the number of interactions and solutions evaluated by the DM. Machine Learning (ML) models were also used to learn how to evaluate solutions according to the DM profile and replace them after some interactions. Feature selection performs an essential task as non-relevant and/or redundant features used to train the ML model can reduce the accuracy and comprehensibility of the hypotheses induced by ML algorithms. This work aims to select features of an ML model used to prevent human fatigue in an interactive search-based PLA design approach. We applied four selectors and through results we were able to reduce 30% of features, obtaining an accuracy of 99%.","Abstract. In the past decade, deep learning based methods have taken a dominant position in natural language processing (NLP). For almost all NLP tasks, deep learning based methods far surpassed traditional methods. Especially in the past five years, the development of deep learning methods has been particularly rapid. For example, the pre-training and fine-tuning paradigms represented by BERT have dominated the NLP field, while also driving the development of other fields such as computer vision. Nowadays pre-trained large language models (LLMs) such as GPT-3/ChatGPT further demonstrate the advantages of Transformer based deep learning methods, which can achieve good results across various problems without any specialized training. In spite of the remarkable success, their performances still underperform fine-tuned models in the task of text classification in some scenarios. Nevertheless, the LLMs are good generalist models. The goal we pursue is the deep learning methods with good generalization ability. In the case of limited computing resources and high performance requirements, the fine-tuned models remain the first choice. So how is the generalization ability of the fine-tuned models? In this paper, we explore the generalization of representative Chinese text classification methods based on deep learning. The experimental results indicate that Transformer based methods present good ability of generalization on two significant different Chinese datasets. In the current era of LLMs, this work can assist us in choosing more appropriate solutions for natural language processing tasks.","To tackle the challenge of ineffective sentiment prediction using current sentiment classification methods, this paper introduces a method social network text sentiment classification. The method leverages a bidirectional short and long-term memory model (AT-BiLSTM), specifically designed for a big data environment. First, a vectorized representation of text is realized by introducing a pre-trained BERT model, and the classification results are dynamically adjusted according to the semantic information of the words. Then, the BiLSTM combined with the attention mechanism performs aspect-level sentiment analysis, and the corresponding model AT-BiLSTM is formulated. Finally, the BERT model randomly selects input tags for information masking and pre-trains the proposed model. The proposed method was evaluated against three alternative methods using an identical dataset. The results show that the novel method achieved the highest accuracy, recall, and F1-score, reaching 93.72%, 93.91%, and 92.38%, respectively. Consequently, the proposed method demonstrates superior performance compared to the other three methods evaluated.","Skip Purpose Section\nPurpose\nOne of the significant problems in data stream classification is the concept drift phenomenon, which consists of the change in probabilistic characteristics of the classification task. Such changes in posterior probability destabilize the classification model performance, seriously degrading its quality. It is necessary to design appropriate strategies to counteract this phenomenon, allowing the classifier to adapt to the changing probabilistic characteristics. It is tough to propose such an approach with limited access to data labels. A human bias of high quality is usually costly, so to minimize the expenses related to this process, it is also necessary to propose learning strategies based on semi-supervised learning. Such strategies employ active learning methods indicating which of the incoming objects are valuable to be labeled for improving the classifier's performance.\nSkip Methods Section\nMethods\nThis paper proposes Active Weighted Aging Ensemble algorithm, a novel chunk-based method for non-stationary data stream classification. It employs a classifier ensemble approach and utilizes the changing ensemble lineup to react to concept drift appropriately. It also proposed a new active learning method, considering a limited budget that may be applied to any data stream classifier.\nSkip Results Section\nResults\nAWAE has been evaluated through computer experiments using real and synthetic data streams, confirming the proposed algorithm's high quality over state-of-the-art methods.\nSkip Conclusion Section\nConclusion\nThe research conducted on benchmark data streams confirmed the effectiveness of the proposed solution and highlighted its strengths in comparison with state-of-the-art methods. The estimated computational complexity is acceptable and comparable to the benchmark algorithms.\nHighlights\n\u2022\nThe proposal of a new chunk-base classifier ensemble for non-stationary data streams.\n\u2022\nNew weighting and decoying of base classifiers in the ensemble.\n\u2022\nNovel active learning method with limited labeling budget.\n\u2022\nExtensive experimental studies and comparison with SOTA methods.","One important aspect of human behavior understanding is the recognition and monitoring of daily activities. An accurate activity recognition system can improve the quality of life in many key areas. The multi-metric feature extraction and DeepForest classifier designed in this paper effectively had solved the problems of incomprehensive feature extraction and insufficient classifier accuracy.\nFirst, this paper extracts a total of 450 dimensional feature vectors using mean, variance, maximum, skewness, minimum, kurtosis, regression of independent variables and sample entropy as feature indicators, so that the features of the original vectors can be presented comprehensively. The dimensionality of the feature set is too large, so PCA is used to reduce the dimensionality of the high-dimensional feature vector. After studying the relationship between the dimensionality reduction and the cumulative contribution rate, it is concluded that the cumulative contribution rate reaches 90% when the dimensionality is 15, which can retain the original features better. Then DeepForest was used as the classifier, and the reduced-dimensional feature set was used as the sample set to divide the training set and test set by 3:1. The model was tested on the test set after training, and the classification accuracy of the test set was 98.202%. Six classifiers, GaussianNB, SVM, K-NN, XGBoost, RandomForest and DecisionTree, were selected as the control experimental group, of which only the RandomForest model reached 97%, while the rest of the control models did not achieve 95% effect, indicating that DeepForest was more accurate in classifying human activities.\nNext, the generalisation ability of the DeepForest classifier was assessed using Monte Carlo Cross Validation (MCCV), K-fold and its confusion matrix. The MCCV validation used 50% of the data as the training set and 30% of the data as the test set, and set the number of splits to 10, resulting in a mean accuracy of 98.227%. The size of K in the K-fold validation was determined to be 8 based on the number of people conducting the human activity experiment, and the final mean accuracy value obtained was 97.790%. The combined confusion matrix from the K-fold validation (which aggregates the confusion matrix for each classification result) was calculated, and the results showed that the highest accuracy reached 100% for A9 and A14 classifications, where A5 and A10, A15 and A10, A12 and A5 were more likely to be confused, with the highest error rate for A5 classification, which was 4.167%, and the rest of the activity classifications were better.","Advancements in the rapidly evolving specialization of deep learning have aided in improving several natural language understanding tasks. Sentiment and emotion classification models have improved, but when it comes to fine-grained sentiment analysis, these models can perform better. Human sentiment in natural language is generally an intricate combination of emotions, which can sometimes be indeterminate, neutral, or ambiguous. In the case of fine-grained sentiment analysis, the sentiments can be very similar to each other and interconnected, e.g., anger and fear. Most deep learning systems try to solve the problem of fine-grained sentiment analysis as a classification problem. However, fine-grained sentiments might combine similar emotions with one primary emotion. Trying to solve the problem as a classification task can result in better performance on benchmarks but does not ensure a better understanding and representation of language. The proposed work explores applying neutrosophy for fine-grained sentiment analysis using large language models. Neutrosophy identifies neutralities and employs membership functions (neutral, positive, negative) to quantify an instance into Single Valued Neutrosophic Sets (SVNS). This paper introduces Refined Emotion Neutrosophic Sets (RENS) for emotions (with four emotions) and Refined Ekman\u2019s Emotion Neutrosophic Sets (REENS) with seven emotions. In this paper, refined neutrosophic sets with membership functions are employed for each sentiment across a given taxonomy and assigned their values using the Neutrosophic Iterative Neural Clustering (NINC) algorithm proposed in this paper. It facilitates not only classifying sentiments but also quantifying the presence of each sentiment present in a given sample. It aids in better understanding and representation of samples across multiple sentiments, as in fine-grained sentiment analysis, experiments are performed on the GoEmotions dataset. The proposed approach performs on par with cross-entropy deep learning classifiers and is reproducible across different pre-trained language models.\nHighlights\n\u2022\nRefined neutrosophic sets for fine-grained sentiment analysis.\n\u2022\nUsing classification models as powerful feature learners.\n\u2022\nNeutrosophic iterative neural clustering for feature segregation.\n\u2022\nExperimental analysis using BERT, MPNet, RoBERTa, ELECTRA and XLNet.\n\u2022\nNeutrosophic logic for sentiment representation and quantification.","Multi-label learning deals with a kind of problem that the given samples areassociated with multiple labels simultaneously. Recently, multi-label learning has become a populartopic in the literatures of machine learning and has attracted lots of researches. In this paper, we propose a new multi-view multi-label learning method by considering the label correlation, which is called ELSMML. Based on the high-order strategy, we construct a crafted label correlation matrix to describe the relationships among labels. We further utilize multi-view learning and dimension reduction to exploit the high-level latent semantic label information and the latent feature information, so as to build a classifier in the low dimensional space. In addition, we apply manifold regularization terms to make the data samples in the low dimensional space have the same intrinsic structure as the original data. After that, we put forward the accelerated proximal gradient method to optimize the ELSMML model and obtain thepredictive classifier. Besides, we conduct convergence analysis and computational complexity analysis for ELSMML method. In the experiments, the ELSMML method can achieve better performance on the evaluation metrics compared with other baselines.","Artificial Intelligence (AI) classifier models based on Deep Neural Networks (DNN) have demonstrated superior performance in medical diagnostics. However, DNN models are regarded as \u201cblack boxes\u201d as they are not intrinsically interpretable and, thus, are reluctantly considered for deployment in healthcare and other safety-critical domains. In such domains explainability is considered a fundamental requisite to foster trust and acceptability of automatic decision-making processes based on data-driven machine learning models. To overcome this limitation, DNN models require additional and careful post-processing analysis and evaluation to generate suitable explainability of their predictions. This paper analyses a DNN model developed for predicting Alzheimer\u2019s Disease to generate and assess explainability analysis of the predictions based on feature importance scores computed using sensitivity analysis techniques. In this study, a high dimensional dataset was obtained from Magnetic Resonance Imaging of the brain for healthy subjects and for Alzheimer\u2019s Disease patients. The dataset was annotated with two labels, Alzheimer\u2019s Disease (AD) and Cognitively Normal (CN), which were used to build and test a DNN model for binary classification. Three Global Sensitivity Analysis (G-SA) methodologies (Sobol, Morris, and FAST) as well as the SHapley Additive exPlanations (SHAP) were used to compute feature importance scores. The results from these methods were evaluated for their usefulness to explain the classification behaviour of the DNN model. The feature importance scores from sensitivity analysis methods were assessed and combined based on similarity for robustness. The results indicated that features related to specific brain regions (e.g., the hippocampal sub-regions, the temporal horn of the lateral ventricle) can be considered very important in predicting Alzheimer\u2019s Disease. The findings are consistent with earlier results from the relevant specialised literature on Alzheimer\u2019s Disease. The proposed explainability approach can facilitate the adoption of black-box classifiers, such as DNN, in medical and other application domains.","Accurate classification of magnetic resonance imaging (MRI) images of brain tumors is crucial for early diagnosis and effective treatment in clinical studies. In these studies, many models supported by artificial intelligence (AI) have been proposed as assistant systems for experts. In particular, state-of-the-art deep learning (DL) models that have proven themselves in different fields have been effectively used in the classification of brain MRI images. However, the low accuracy of multiple classification of these images still leads researchers to conduct different studies in this field. Especially there is a need to develop models that achieve high accuracy on original images, and it is believed that this need can be met not only by DL models but also by classical machine learning (ML) algorithms. However, it is critical to choose the hyperparameters correctly for the hybrid use of ML algorithms with DL models. This study proposes a powerful new hybrid method to perform multiple classifications of brain tumors with high accuracy. This method also uses a novel convolutional neural network (CNN) model for feature extraction, and ML algorithms are used for feature classification. In addition, nine state-of-the-art CNN models are used for CNN performance comparison. The Bayesian optimization algorithm is used to obtain the optimal hyperparameter values of ML algorithms. The results obtained from the experimental studies show that the proposed hybrid model achieved 97.15% mean classification accuracy and 97% recall, precision, and F1-score values. Other hybrid models, including DarkNet19-SVM, DarkNet53-SVM, DenseNet201-SVM, EfficientNetB0-SVM, InceptionV3-SVM, NasNetMobile-SVM, ResNet50-SVM, ResNet101-SVM, and Xception-SVM, achieved mean classification accuracies of 95.01%, 95.58%, 96.87%, 97.01%, 95.3%, 95.01%, 96.3%, 95.87%, and 96.23%, respectively. Additionally, the proposed hybrid model exhibited remarkable time efficiency, accomplishing the classification process in a mere 67 min. Conversely, the model that exhibited the lowest time efficiency was the InceptionV3, with a processing time of 370 min. In terms of computational complexity, the EfficientNetB0 model is the most efficient. Despite the higher computational complexity of the proposed CNN model compared to some other models, it achieves the second-best classification accuracy. These results show that the proposed method performs better than previous studies on the same dataset. Especially in the classification problem, the optimized ML algorithms were superior to CNN classifiers. Finally, except for one, the proposed CNN model achieved better classification accuracies than the state-of-the-art CNN models.","The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the properties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embedding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97\u201398%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble model\u2019s results are examined in terms of recall, accuracy, and precision","Compositional zero-shot learning (CZSL) refers to recognizing unseen compositions of known visual primitives, which is an essential ability for artificial intelligence systems to learn and understand the world. While considerable progress has been made on existing benchmarks, we suspect whether popular CZSL methods can address the challenges of few-shot and few referential compositions, which is common when learning in real-world unseen environments. To this end, we study the challenging reference-limited compositional zero-shot learning (RL-CZSL) problem in this paper, i.e., given limited seen compositions that contain only a few samples as reference, unseen compositions of observed primitives should be identified. We propose a novel Meta Compositional Graph Learner (MetaCGL) that can efficiently learn the compositionality from insufficient referential information and generalize to unseen compositions. Besides, we build a benchmark with two new large-scale datasets that consist of natural images with diverse compositional labels, providing more realistic environments for RL-CZSL. Extensive experiments in the benchmarks show that our method achieves state-of-the-art performance in recognizing unseen compositions when reference is limited for compositional learning.","Current person re-identification (ReID) methods heavily rely on well-annotated training data, and their performance suffers from significant degradation in the presence of noisy labels that are ubiquitous in real-life scenes. The reason is that noisy labels not only affect the prediction results of the classifier, but also impede feature refinement, making it difficult to distinguish between different person features. To address these issues, we propose an Adaptive Self-correction Classification (ASC) loss and an Adaptive Margin Self-correction Triplet (AMSTri) loss. Specifically, ASC loss helps the network to produce better predictions by balancing annotations and prediction labels, and pays more attention to the minority samples with the help of a focusing factor. On the other hand, the AMSTri loss introduces an adaptive margin that varies with sample features to accommodate complex data variations, and utilizes predicted labels to generate reliable triples for feature refinement. We then present an end-to-end adaptive self-correction joint training framework incorporating ASC loss and AMSTri loss to achieve a robust ReID model. Our comprehensive experiments demonstrate that the proposed framework outperforms most existing counterparts.","Aspect category sentiment analysis (ACSA) excels at identifying the aspect categories and corresponding sentiments involved in a sentence, regardless of whether the aspect terms are explicitly mentioned or not. However, current methods tend to overinflate the original data, resulting in the introduction of unnecessary information, and fail to capture the inter-task relationship sufficiently. This paper presents a new method termed the prompt-based joint model (PBJM) to address these complications. PBJM treats the sentiment polarity prediction as binary classification and leverages a natural language prompt template, a concise sentence that guides the model to perform aspect category identification subtask and curtails the need for data augmentation. The two subtasks are jointly trained in pre-trained language models (PLMs) to capture their correlation. Further, the attention mechanism for aspect categories enables the model to concentrate selectively on significant features such as phrases and words during the predictions. In addition, the verbalizer employs a set of parameters to balance the weight of each label word while projecting between the label space and the label words space. Through experiments on four datasets, our model demonstrated remarkable performance in detecting category-sentiment pairs.","Forecasting retail sales often requires various number of products from different stores. Existing deep or machine learning techniques fall short of producing accurate classification results because of overfitting and two-class problem that affects the performance of evaluation parameters like precision, recall, accuracy and F-measure. Hence there is a need for an efficient prediction framework that addresses the existing problems. This work proposes an efficient framework for predicting retail sales using an ensemble DNN-BiLSTM framework. We suggest creating a base forecaster pool that includes both individual and pooled forecasting techniques for developing this ensemble approach to forecasting retail sales. Instead of focusing on finding the best individual technique, we suggest finding the optimal combination of forecasts. Classification Accuracy, Precision, Recall, and F-measure performance metrics of the experiment utilizing the proposed ensemble approach DNN\u2009+\u2009BiLSTM surpass the current DNN, CNN, and LSTM classifiers by 98.3%, 98.1%, 97.8%, and 97.94%, respectively.","Abstract\u2014 For areas with potential occurrence of blasting events, it is essential to distinguish them from natural earthquakes. An efficient processing method is needed to save manpower, especially under the current large amount of data records by seismic stations. We apply a SCOUTER algorithm to distinguish between the two types of events. The recognition precision of the trained model for natural earthquakes and blasts can reach 95% and 92.8%, respectively, and the recall can reach 93.4% and 94.6%, respectively. The testing results of data with different epicentral distances and SNR show that our method is stable, independent on regional waveform characteristics and insensitive to data of different SNR. The explanations for each classification at the final confidence also give us a profound enlightenment.","In recent years, the increasing use of online surveys for course evaluation in schools has led to an outpouring of evaluation texts. These texts, with their emotional polarity, can give schools the most direct feedback. Emotional analysis on course evaluation, therefore, has great implications. However, the not-so-rigid text grammar and rich text content pose a challenge for sentiment analysis in Chinese course evaluation. To solve this problem, this paper proposes a sentiment classification model BiLSTM-GCN-Att (BGAN). Here, BiLSTM is used to extract the features of the text and output the hidden state vector. Then, the deep biaffine attention mechanism is used to analyze the dependence of the text and generate a dependency matrix. Next, input the hidden state vector to the GCN. Finally, the softmax function is used as the output layer of the model to perform sentiment classification. The model proves effective and experimental results, showing that the BGAN achieved a maximum improvement of 11.02% and 14.47% in precision and F1-score respectively compared with the classical models.","While there have been extensive studies in the health assessment of the bearings using the vibration signal, most have focused on the constant operating conditions. The field, however, operates often under time-varying conditions as is the case of the automotive wheel bearing. In this study, a novel health indicator (HI) is proposed to address this problem based on the Isolation Forest algorithm, which was originally developed for anomaly detection. The method is advantageous in two aspects: the HI is not influenced by the type of operating conditions whether it is constant or time-varying. Only the data under normal condition are used to construct the HI without the need of run-to-failure data. The method is demonstrated by the three cases with different types of bearing and operating conditions ranging from constant to the highly variable conditions. As a result, monotonic trends are obtained for the HI in all cases, which may be useful for the prognostic monitoring. Furthermore, in comparison with the HI constructed by the run-to-failure data in the previous literature, it is found that the trends of HI agree reasonably well with each other, which supports the validity of the method.","A sequential learning framework for text categorization based on Meta-cognitive Neural Network (McNN) is presented in this paper. Initially text documents are pre-processed and represented in the form of Term Document Matrix (TDM). Since the TDM is of high dimension, to reduce it to lower dimension Regularized Locality Preserving Indexing (RLPI) is used. Further, to categorize the text document, Meta-cognitive Neural Network (McNN) classifier is employed. To measure the effectiveness of the proposed framework, various experiments are conducted on standard benchmark Reuters-21578 dataset and used leave one out cross validation technique to assess the performance. The proposed framework performance is investigated against two well known neural network based classifiers: MLP (Multi Layer Perceptron) and RBF-NN (Radial Basis Function-Neural Network). The experimental results reveals that the McNN classifier uses less number of training documents for learning and it has less true error rate than other two neural network classifiers.","Classifying ancient manuscripts based on their writing surfaces often becomes essential for palaeographic research, including writer identification, manuscript localization, date estimation, and, occasionally, forgery detection. Researchers continually perform corroborative tests to classify manuscripts based on physical materials. However, these tests, often performed on-site, require actual access to the manuscript objects. These procedures involve specific expertise in manuscript handling, a considerable amount of time, and cost. Additionally, any physical inspection can accidentally damage ancient manuscripts that already suffer degradation due to aging, natural corrosion, and damaging chemical treatments. Developing a technique to classify such documents using noninvasive techniques with only digital images can be extremely valuable and efficient. This study uses images from a famous historical collection, the Dead Sea Scrolls, to propose a novel method to classify the materials of the manuscripts. The proposed classifier uses the two-dimensional Fourier transform to identify patterns within the manuscript surfaces. Combining a binary classification system employing the transform with a majority voting process is adequate for this classification task. This initial study shows a classification percentage of up to 97% for a confined amount of manuscripts produced from either parchment or papyrus material. In the extended work, this study proposes a hierarchical k-means clustering method to group image fragments that are highly likely to originate from a similar source using color and texture features calculated on the image patches, achieving 77% and 68% for color and texture clustering with 100% accuracy on primary material classification. Finally, this study explores a convolutional neural network model in a self-supervised Siamese setup with a large number of images that obtains an accuracy of 85% on the pretext task and an accuracy of 66% on the goal task to classify the materials of the Dead Sea Scrolls images.","A startup is a recently established business venture led by entrepreneurs, to create and offer new products or services. The discovery of promising startups is a challenging task for creditors, policymakers, and investors. Therefore, the startup survival rate prediction is required to be developed for the success/failure of startup companies. In this paper, the feature selection using the Convex Least Angle Regression Least Absolute Shrinkage and Selection Operator (CLAR-LASSO) is proposed to improve the classification of startup survival rate prediction. The Swish Activation Function based Long Short-Term Memory (SAFLSTM) is developed for classifying the survival rate of startups. Further, the Local Interpretable Model-agnostic Explanations (LIME) model interprets the predicted classification to the user. Existing research such as Hyper Parameter Tuning (HPT)-Logistic regression, HPT-Support Vector Machine (SVM), HPT-XGBoost, and SAFLSTM are used to compare the CLAR-LASSO. The accuracy of the CLAR-LASSO is 95.67% which is high when compared to the HPT-Logistic regression, HPT-SVM, HPT-XGBoost, and SAFLSTM.","This paper focuses on the impact of rule representation in Michigan-style Learning Fuzzy-Classifier Systems (LFCSs) on its classification performance. A well-representation of the rules in an LFCS is crucial for improving its performance. However, conventional rule representations frequently need help addressing problems with unknown data characteristics. To address this issue, this paper proposes a supervised LFCS (i.e., Fuzzy-UCS) with a self-adaptive rule representation mechanism, entitled Adaptive-UCS. Adaptive-UCS incorporates a fuzzy indicator as a new rule parameter that sets the membership function of a rule as either rectangular (i.e., crisp) or triangular (i.e., fuzzy) shapes. The fuzzy indicator is optimized with evolutionary operators, allowing the system to search for an optimal rule representation. Results from extensive experiments conducted on continuous space problems demonstrate that Adaptive-UCS outperforms other UCSs with conventional crisp-hyperrectangular and fuzzy-hypertrapezoidal rule representations in classification accuracy. Additionally, Adaptive-UCS exhibits robustness in the case of noisy inputs and real-world problems with inherent uncertainty, such as missing values, leading to stable classification performance.","Quantum computing is a rapidly growing field of science with many potential applications. One such field is machine learning applied in many areas of science and industry. Machine learning approaches can be enhanced using quantum algorithms and work effectively, as demonstrated in this paper. We present our experimental attempts to explore Quantum Support Vector Machine (QSVM) capabilities and test their performance on the collected well-known images of handwritten digits for image classification called the MNIST benchmark. A variational quantum circuit was adopted to build the quantum kernel matrix and successfully applied to the classical SVM algorithm. The proposed model obtained relatively high accuracy, up to 99%, tested on noiseless quantum simulators. Finally, we performed computational experiments on real and recently setup IBM Quantum systems and achieved promising results of around 80% accuracy, demonstrating and discussing the QSVM applicability and possible future improvements.","Algal blooms pose a significant threat to aquatic ecosystems and human health. To address this issue, this paper proposes a machine learning-based approach for predicting harmful algal blooms (HABs) by analyzing environmental features. Algae, as primary organic matter and oxygen producers, play a vital role in the biosphere. However, the exponential increase in algal growth worldwide poses significant challenges to economic development and long-term sustainability. The paper employs three popular machine learning algorithms: Artificial Neural Network (ANN), Gradient Boosting Decision Tree (GBDT), and Support Vector Machine (SVM) to predict algal blooms. The research utilizes real-time data from two locations: the Sassafras River in the United States Chesapeake Bay and Lake Okeechobee in Florida, USA. These locations have experienced frequent HABs due to factors like chemical runoff and nutrient-rich conditions. By analyzing the collected data, the paper identifies and selects the most important features to optimize the prediction models\u2019 accuracy. Preliminary results demonstrate promising accuracy in predicting algal growth and identifying key characteristics associated with HABs. These findings contribute to a better understanding of algal blooms and pave the way for effective mitigation strategies to combat this global environmental challenge.","Semi-supervised learning (SSL) is a successful paradigm that can use unlabelled data to alleviate the labelling cost problem in supervised learning. However, the excellent performance brought by SSL does not transfer well to the task of class imbalance. The reason is that the class bias of pseudo-labelling further misleads the decision boundary. To solve this problem, we propose a new plug-and-play approach to handle the class imbalance problem based on a theoretical extension and analysis of distribution alignment. The method, called Basis Transformation Based Distribution Alignment (BTDA), efficiently aligns class distributions while taking into account inter-class relationships.BTDA implements the basis transformation through a learnable transfer matrix, thereby reducing the performance loss caused by pseudo-labelling biases. Extensive experiments show that our proposed BTDA approach can significantly improve performance in class imbalance tasks in terms of both accuracy and recall metrics when integrated with advanced SSL algorithms. Although the idea of BTDA is not complex, it can show advanced performance on datasets such as CIFAR and SVHN.","In recent years, the interpretive this looks like that structure has gained significant attention. It refers to the human tendency to break down images into key parts and make classification decisions by comparing them to pre-existing concepts in their minds. However, most existing prototypical-based models assign prototypes directly to each category without considering that key parts with the same meaning may appear in images from different categories. To address this issue, we propose dividing prototypes with the same meaning into the same latent space (referred to as Basic Feature Domain) since different category parts only slightly affect the corresponding prototype vectors. This process of integrating prototypes based on the feature domain is referred to as prototype alignment. Additionally, we introduce the concept of part-aware optimization, which prioritizes prototypical parts of images over simple category labels during optimizing prototypes. Moreover, we present two feature aggregation methods, by row and by cluster, for the basic feature domain. We demonstrate competitive results compared to other state-of-the-art prototypical part methods on the CUB-2011-200 dataset and Stanford Cars dataset using our proposed self-explanatory part-aware proto-aligned network (PaProtoPNet).","Emotion plays a dominant role in speech. The same utterance with different emotions can lead to a completely different meaning. The ability to perform various of emotion during speaking is also one of the typical characters of human. In this case, technology trends to develop advanced speech emotion classification algorithms in the demand of enhancing the interaction between computer and human beings. This paper proposes a speech emotion classification approach based on the paralinguistic and spectral features extraction. The Mel-frequency cepstral coefficients (MFCC) are extracted as spectral feature, and openSMILE is employed to extract the paralinguistic feature. The machine learning techniques multi-layer perceptron classifier and support vector machines are respectively applied into the extracted features for the classification of the speech emotions. We have conducted experiments on the Berlin database to evaluate the performance of the proposed approach. Experimental results show that the proposed approach achieves satisfied performances. Comparisons are conducted in clean condition and noisy condition respectively, and the results indicate better performance of the proposed scheme.","In multi-dimensional classification (MDC), each training example is associated with multiple class variables from different class spaces. However, it is rather costly to collect labeled MDC examples which have to be annotated from several dimensions (class spaces). To reduce the labeling cost, we attempt to deal with the MDC problem under the semi-supervised learning setting. Accordingly, a novel MDC approach named PLAP is proposed to solve the resulting semi-supervised MDC problem. Overall, PLAP works under the label propagation framework to utilize unlabeled data. To further consider dependencies among class spaces, PLAP deals with each class space in a progressive manner, where the previous propagation results will be used to initialize the current propagation procedure, and all processed class spaces and the current one will be regarded as an entirety. Experiments validate the effectiveness of the proposed approach.","The significant rise in the amount of satellite images that have become available in recent years makes large-scale analysis of this data difficult. To make meaningful inferences from such images, one must have a thorough comprehension of the information they convey. Deep learning advances recently make it possible to train powerful machine learning models that can recognise several objects in a shot regardless of their attributes or distinct points of view. In this study, it is investigated if it's possible to identify monuments in satellite pictures using deep learning models. More specifically, the TensorFlow and Keras packages are used to build a model based on Indian monuments. Using Google Colab, the VGG16 model is trained on a variety of offline and online images. In order to enhance the performance of the model, the data augmentation technique is also used. Overall accuracy for VGG16 is 100 percent, which is extremely good. With the help of data augmentation on the model, a marginal improvement in accuracy is achieved. Lastly, this study's findings show that deep learning can be used to train a model, resulting in quite good outcomes even when trained on small and low-quality data sets.","Domain Generalization (DG) requires a model to learn a hypothesis from multiple distributions that generalizes to an unseen distribution. Recent explorations show that, for neural networks, the choice of hyper-parameters and model architecture significantly affects DG performance, and making the right choice is non-trivial. In this paper, we show evidence suggesting that the models that perform better at DG, might be implicitly learning a low dimensional representation in the feature space. Furthermore, we take forward this idea and employ explicit feature learning to improve DG. To this end, we propose a DG specific supervised contrastive loss. We show how this performance improvement correlates to reduced dimensionality of the representation. Our work establishes new state-of-the-art on five different DG benchmarks, compared against over two dozen existing approaches in DomainBed. We show how this performance improvement correlates to reduced dimensionality of the representation.","Increasing privacy concerns have led to decentralized and federated machine learning techniques that allow individual clients to consult and train models collaboratively without sharing private information. Some of these applications, such as medical and healthcare, require the final decisions to be interpretable. One common form of data in these applications is multivariate time series, where deep neural networks, especially convolutional neural networks based approaches, have established excellent performance in their classification tasks. However, promising results and performance of deep learning models are a black box, and their decisions cannot always be guaranteed and trusted. While several approaches address the interpretability of deep learning models for multivariate time series data in a centralized environment, less effort has been made in a federated setting. In this work, we introduce FLAMES2Graph, a new horizontal federated learning framework designed to interpret the deep learning decisions of each client. FLAMES2Graph extracts and visualizes those input subsequences that are highly activated by a convolutional neural network. Besides, an evolution graph is created to capture the temporal dependencies between the extracted distinct subsequences. The federated learning clients only share this temporal evolution graph with the centralized server instead of trained model weights to create a global evolution graph. Our extensive experiments on various datasets from well-known multivariate benchmarks indicate that the FLAMES2Graph framework significantly outperforms other state-of-the-art federated methods while keeping privacy and augmenting network decision interpretation.","We introduce Robust Training with Trust Scores (RT2S), a framework to train machine learning classifiers with potentially noisy labels. RT2S calculates a trust score for each training sample, which indicates the quality of its corresponding label. These trust scores are employed as sample weights during training and optionally during threshold optimization. The trust scores are generated from two sources: (i) the model's confidence in the observed label, leveraging out-of-fold prediction scores to detect anomalous labels in the training data, and (ii) the probability of the correct label, ascertained by a Large Language Model with the ability to identify biased label noise. We evaluate RT2S by training machine learning models on 6 product classification datasets that utilize low-quality labels generated by a rule-based classification engine acting as a surrogate labeler. Our experimental findings indicate that RT2S outperforms all baselines, and achieves an average accuracy improvement of 4.38% (max 7.18%) over rule-based classifiers in particular.","Highlights\n\u2022\nPropose an improved random forest based on the improvement of decision trees.\n\u2022\nImprove the evaluation mechanism for the classification effect of decision trees.\n\u2022\nPropose a method for quantifying the diversity between decision trees.\n\u2022\nMultiple tests verify the superiority of the proposed improved random forest.\nAbstract\nRandom forest is one of the most widely used machine learning algorithms. Decision trees used to construct the random forest may have low classification accuracies or high correlations, which affects the comprehensive performance of the random forest. Aiming at these problems, the authors proposed an improved random forest based on the classification accuracy and correlation measurement of decision trees in this paper. Its main idea includes two parts, one is retaining the classification and regression trees (CARTs) with better classification effects, the other is reducing the correlations between the CARTs. Specifically, in the classification effect evaluation part, each CART was applied to make predictions on three reserved data sets, then the average classification accuracies were achieved, respectively. Thus, all the CARTs were sorted in descending order according to their achieved average classification accuracies. In the correlation measurement part, the improved dot product method was proposed to calculate the cosine similarity, i.e., the correlation, between CARTs in the feature space. By using the achieved average classification accuracy as reference, the grid search method was used to find the inner product threshold. On this basis, the CARTs with low average classification accuracy among CART pairs whose inner product values are higher than the inner product threshold were marked as deletable. The achieved average classification accuracies and correlations of CARTs were comprehensively considered, those with high correlation and weak classification effect were deleted, and those with better quality were retained to construct the random forest. Multiple experiments show that, the proposed improved random forest achieved higher average classification accuracy than the five random forests used for comparison, and the lead was stable. The G-means and out-of-bag data (OBD) score obtained by the proposed improved random forest were also higher than the five random forests, and the lead was more obvious. In addition, the test results of three non-parametric tests show that, there were significant diversities between the proposed improved random forest and the other five random forests. This effectively proves the superiority and practicability of the proposed improved random forest.","The rawly collected training data often comes with separate noisy labels collected from multiple imperfect annotators (e.g., via crowdsourcing). A typical way of using these separate labels is to first aggregate them into one and apply standard training methods. The literature has also studied extensively on effective aggregation approaches. This paper revisits this choice and aims to provide an answer to the question of whether one should aggregate separate noisy labels into single ones or use them separately as given. We theoretically analyze the performance of both approaches under the empirical risk minimization framework for a number of popular loss functions, including the ones designed specifically for the problem of learning with noisy labels. Our theorems conclude that label separation is preferred over label aggregation when the noise rates are high, or the number of labelers/annotations is insufficient. Extensive empirical results validate our conclusions.","Existing intelligent classification methods could be inefficient to deal with the hybrid environments including hesitant fuzzy information and real numbers. With respect to this real issue, in this study, we propose some new intelligent methods to achieve deep learning and intelligent classification under this hybrid environment. To do this, we construct the hesitant fusion bidirectional recurrent neural network (HF-BiRNN) based on the hesitant fusion mechanism. Then, the twice-cycle mechanism is designed, which includes the extension mechanism and the decomposition-reorganization mechanism, to fully utilize the original data and optimize the classification results. Meanwhile, the overlap degree algorithm is constructed to filter the optimal outputs. After that, we further propose the hesitant expansion BiRNN (HE-BiRNN) by combining with the twice-cycle mechanism, overlap degree algorithm, and BiRNN. Lastly, these new methods are used to the problems of driving route classification and red wine quality assessment. The derived optimal results and comparison analysis fully show the effectiveness and feasibility of the new proposed mechanisms and developed models.","Pest control is essential for crop planting as crops are highly susceptible to pest damage. In general, pest recognition is a fundamental element of pest control. Previous works have used computer vision to achieve automatic pest recognition. However, only a few of them have focused on the open-world pest recognition problem. That is, most methods cannot process new pest categories without expensive network retraining. To fill the gap, this paper proposes an open-world pest image classifier based on two observations: (1) convolutional features learned from previous pest classes are generally applicable to new pest categories, and (2) removing fully-connected neural layers allows a deep network to be exempted from model fine-tuning in case of a new class. First, an optimized lightweight ResNet8-based matching network is developed as the image feature extractor, which saves computational resources. To prevent model collapse, the proposed ResNet8-based matching network is trained with the normalized temperature-scaled cross-entropy loss function instead of the triplet loss function. The trained ResNet8-based matching network is then used to compute similarities between support class prototypes and query image representations for the pest classification. Compared with the state-of-the-arts, the proposed method has achieved the highest 40-way 5-shot classification accuracy of 84 . 29 \u00b1 0 . 23 % with 14.18 frames per second on the D0 dataset. It is significantly superior to the ResNet12-based baseline. These suggest that the proposed method is a technically feasible solution to the open-world pest recognition problem. The Python code can be accessed at https://github.com/scau-gqw1993.\nHighlights\n\u2022\nThis work is, to our best knowledge, the first one on open-world pest classification.\n\u2022\nA lightweight matching network was obtained using ResNet8 and NT-Xent loss function.\n\u2022\nThe method achieved the best 40-way 5-shot accuracy of 84.29% on the D0 dataset.","Highlights\n\u2022\nGrading modeling and decision-making framework were proposed for yield estimation.\n\u2022\nNormalized weight decision-making strategy improved the estimation precision.\n\u2022\nDeep learning network ConvNeXt was compared for modeling performance.\n\u2022\nProposed framework performs precisely and robustly using UAV RGB images.\nAbstract\nRice yield estimation is of great significance for ensuring food security and breeding new varieties with high yield and good stress resistance. The popular yield estimation method is to combine unmanned aerial vehicle (UAV) images to extract vegetation index (VI) for multi-variable regression, whose application is always limited by expensive equipment and complex data processing. In this study, based on the deep learning network, ConvNeXt, a robust framework developed by grading modeling and normalized weight decision-making strategy was innovatively proposed to estimate the rice yield, only using RGB images collected by UAVs. The main results are: (1) the yield estimation performance of yield grading model was better than that of regression model, and R2, mean absolute error (MAE), and mean absolute percentage error (MAPE) on the test dataset using the grading model were 0.97, 410.94 kg/ha, and 3.96 % respectively; (2) the confidence scores of the grading model were adopted as the weights, which could correct the estimated yield of the misclassified samples and further reduce the estimated error. The normalized weight decision-making after optimization had obvious advantages, the performance of 2-weight strategy was the best, whose R2, MAE, and MAPE reached 0.98, 386.08 kg/ha, and 3.79 %, respectively; (3) the MAPE results of generalization assessment showed that the generalization of the grading (12.98 %) and regression (10.88 %) models was inferior to the proposed framework (8.71 %), which could reduce the MAPE on the generalization evaluation dataset to less than 10 %. Furthermore, the framework exhibited good adaptability when applied to the rice yield estimation of the new data in 2022, with an MAPE of 4.54 %. Considering both application potential and adaptability, this framework constructs a novel strategy and method for rice yield estimation using grading modeling and normalized weight decision-making strategy, which provides a reference for future real-time and precise yield estimation using UAV remote sensing.","Due to numerous deaths, colon cancer treatment and diagnosis are viewed as societal and financial challenges. The most severe reason for death worldwide is colorectal cancer. The classification of colon cancer tissues through images is presented in this paper as a multifaceted task. Classifying an illness at a premature stage increases its chances of existence, as late detection can be mortal which results in metastasis and a poor prognosis. The microscopic examination and classification of infected colon tissue sample images is a complex task. Also, the failure to manually detect the abnormality in the tissue by a pathologist might increase the severity of the disease. With the aid of intelligent machines, and automated diagnosis the classification of tissues from images can be done in much less time. These algorithms can learn by analyzing the patterns in the images and support the pathologist in completing the task with greater accuracy. In this research article, we proposed a tuned machine learning model, with the application of five machine learning techniques (K-Nearest Neighbor, Decision Trees, Random Forest, Categorical Boosting, and Gaussian Naive Bayes) for accurately classifying histopathological colon cancer tissues images of National Center for Tumor diseases Bank. The results demonstrate that the Categorical Boosting model has the best performance and is the most viable approach (accuracy: 0.9067, F1-Score: 0.9053, specificity: 0.9739, and sensitivity: 0.9757).","Graph Neural Networks (GNNs) have revolutionized graph learning through efficiently learned node embeddings and achieved promising results in various graph-related tasks such as node and graph classification. Within GNNs, a pooling operation reduces the size of the input graph by grouping nodes that share commonalities intending to generate more robust and expressive latent representations. For this reason, pooling is a critical operation that significantly affects downstream tasks. Existing global pooling methods mostly use readout functions like max or sum to perform the pooling operations, but these methods neglect the hierarchical information of graphs. Clique-based hierarchical pooling methods have recently been developed to overcome global pooling issues. Such clique pooling methods perform a hard partition between nodes, which destroys the topological structural relationship of nodes, assuming that a node should belong to a single cluster. However, overlapping clusters widely exist in many real-world networks since a node can belong to more than one cluster. Here we introduce a new hierarchical graph pooling method to address this issue. Our pooling method, named Quasi-CliquePool, builds on the concept of a quasi-clique, which generalizes the notion of cliques to extract dense incomplete subgraphs of a graph. We also introduce a soft peel-off strategy to find the overlapping cluster nodes to keep the topological structural relationship of nodes. For a fair comparison, we follow the same procedure and training settings used by state-of-the-art pooling techniques. Our experiments demonstrate that combining the Quasi-Clique Pool with existing GNN architectures yields an average improvement of 2% accuracy on four out of six graph classification benchmarks compared to other existing pooling methods.","Classification of brain haemorrhage is a challenging task that needs to be solved to help advance medical treatment. Recently, it has been observed that efficient deep learning architectures have been developed to detect such bleeding accurately. The proposed system includes two different transfer learning strategies to train and fine-tune ImageNet pre-trained state-of-the-art architecture such as that VGG 16, Inception V3 and DenseNet121. The evaluation metrics have been calculated based on the performance analysis of the employed networks. Experimental results show that the modified fine-tuned Inception V3 performed well and achieved the highest test accuracy.","In the multi-label text classification task, a text usually corresponds to multiple label categories, and the labels have correlation and hierarchical structure. However, when the label hierarchy is unknown, the number of various labels is not balanced, which makes it difficult for the model to classify low-frequency labels. At the same time, due to the existence of similar labels, the model will be difficult to distinguish similar labels. In this paper, we propose a multi-label text classification model based on multi-level constraint augmentation and label association attention. Compared with traditional methods, our method has two contributions: (1) In order to alleviate the problem of unbalanced number of different label categories and ensure the rationality of sample generation, we propose a data augmentation method based on multi-level constraints. In the process of sample generation, this method uses historical generation information, sample original text information and sample topic to constrain the generated text. (2) In order to make the model recognize the associated labels accurately, we propose an interaction mechanism based on label association attention and filter gate. This method combines text information and label weight information. At the same time, our classification model considers the important weights of text sentences and effectively utilizes the co-occurrence relationship between labels. Experimental results on three benchmark datasets show that our model outperforms state-of-the-art methods on all main evaluation metrics, especially on low-frequency label prediction with sparse samples.","The homophily assumption in graph theory posits that nodes with similar characteristics have a higher tendency to form connections. This principle has rendered Graph Neural Networks (GNNs) as vital tools for graph representation learning. However, many real-world graphs may exhibit a phenomenon often termed as neighbor class imbalance, which is characterized by frequent connections between dissimilar nodes, a scenario reflecting low homophily. Classical GNNs tend to overlook this issue, leading to a significant decline in performance. Prior research has attempted to address this challenge by employing high-order neighborhoods and filtering out dissimilar neighbors, yet they have paid little attention to homophily degree estimation and label utilization. In this work, we initially explore the performance of classical GNNs on a synthetic graph with varying homophily degrees, designated as SynG-N. Following this, we introduce a novel method, HLA-GNN, which integrates homophily degree estimation and label utilization to enhance classical GNNs. The degrees of homophily between node pairs are estimated using a limited set of ground-truth labels, which can be integrated into classic GNNs to guide the message aggregation process. Drawing on the label propagation algorithm, we combine the partially observed class labels to enhance the original feature space. Here, the observed class labels are randomly masked as a feature augmentation and training signal. Our experimental results on eight datasets with varying degrees of homophily underscore the effectiveness of our method. HLA-GNN achieves a 12.69%\u223c34.19% improvement on low-homophily graphs, while maintaining competitive results in homophilous settings.\nHighlights\n\u2022\nHLA-GNN assigns weights by homophily in latent space.\n\u2022\nHLA-GNN enhances feature space with label propagation algorithm.\n\u2022\nOur method Boosts low-homophily performance by 12.69% to 34.19%.","Recently, Convolution Neural Networks (CNN) have achieved excellent performance in some areas of computer vision, including face recognition, character recognition, and autonomous driving. However, there are still many CNN-based models that cannot be deployed in real-world scenarios due to poor robustness. In this paper, focusing on the classification task, we attempt to evaluate and optimize the robustness of CNN-based models from a new perspective: the convolution kernel. Inspired by the discovery that the root cause of the model decision error lies in the wrong response of the convolution kernel, we propose a convolution kernel robustness evaluation metric based on the distribution of convolution kernel responses. Then, we devise the Convolution Kernel Robustness Calibrator, termed as CKR-Calibrator, to optimize key but not robust convolution kernels. Extensive experiments demonstrate that CKR-Calibrator improves the accuracy of existing CNN classifiers by 1%\u20134% in clean datasets and 1%\u20135% in corrupt datasets, and improves the accuracy by about 2% over SOTA methods. The evaluation and calibration source code is open-sourced at https://github.com/cym-heu/CKR-Calibrator.","We present part of Huawei's efforts in building a Product Knowledge Graph (PKG). We want to identify which product attributes (i.e. properties) are relevant and important in terms of shopping decisions to product categories (i.e. classes). This is particularly challenging when the attributes and their values are mined from online product catalogues, i.e. HTML pages. These web pages contain semi-structured data, which do not follow a concerted format and use diverse vocabulary to designate the same features. We propose a system for key attribute identification (KATIE) based on fine-tuning pre-trained models (e.g., DistilBERT) to predict the applicability and importance of an attribute to a category. We also propose an attribute synonyms identification module that allows us to discover synonymous attributes by considering not only their labels' similarities but also the similarity of their values sets. We have evaluated our approach to Huawei categories taxonomy and a set of internally mined attributes from web pages. KATIE guarantees promising performance results compared to the most recent baselines.","Semi-supervised learning (SSL) addresses the lack of labeled data by exploiting large unlabeled data through pseudolabeling. However, in the extremely low-label regime, pseudo labels could be incorrect, a.k.a. the confirmation bias, and the pseudo labels will in turn harm the network training. Recent studies combined finetuning (FT) from pretrained weights with SSL to mitigate the challenges and claimed superior results in the low-label regime. In this work, we first show that the better pretrained weights brought in by FT account for the state-of-the-art performance, and importantly that they are universally helpful to off-the-shelf semi-supervised learners. We further argue that direct finetuning from pretrained weights is suboptimal due to covariate shift and propose a contrastive target pretraining step to adapt model weights towards target dataset. We carried out extensive experiments on both classification and segmentation tasks by doing target pretraining then followed by semi-supervised finetuning. The promising results validate the efficacy of target pretraining for SSL, in particular in the low-label regime.","In the semiconductor manufacturing process, analyzing the defect patterns on a wafer map is crucial for identifying the causes of the defects. The advent of convolutional neural networks (CNNs) has significantly increased the accuracy of automated wafer map pattern classification. Generally, the use of a larger training dataset results in higher classification accuracy. However, collecting a large number of wafer maps and labeling them with their defect categories is expensive and time-consuming. In this paper, we present an improved training method under data insufficiency for wafer map pattern classification. We apply supervised contrastive learning to train a CNN by exploiting the rotational-invariant characteristic of wafer map labeling. The CNN is trained by simultaneously minimizing two loss functions: classification loss and contrastive loss. The first loss function is to classify the rotational variants of wafer maps accurately. The second loss function is to align the representation vectors for the rotational variants of wafer maps with similar labels to be close to each other. Using two benchmark datasets, WM-811K and MixedWM38, we demonstrate that the proposed method enhances classification accuracy compared with existing methods, particularly when the training dataset is small.","Severe limitations in data and technological availability have vastly affected NLP research into African languages. With Africa having over 2000 languages, the lack of NLP research is a massive flaw within the NLP field. African languages can hold the key to the next significant advancement in NLP research because some researchers suggest that 30% of current-day languages are derived from African languages. With Sentiment Analysis being a foundational part of NLP research, the release of the AfriSenti-SemEval Shared Task 12, hosted as a part of The 17th International Workshop on Semantic Evaluation, has provided 14 new annotated datasets for Sentiment Analysis on African languages. We utilize these datasets to evaluate our approach: Delta TF-IDF features with conventional machine learning models. Delta TF-IDF results showed that our approach could provide promising results with the low resource task of sentiment analysis on African Languages. Since it utilized a significantly less data than its transformer counter parts.","In recent years, class-imbalanced learning has become an important branch of machine learning. Synthetic Minority Oversampling Technique (SMOTE) is known as a benchmark method to address imbalanced learning. Although SMOTE performs well on many data, it also has the drawback of generating noisy samples. There are many SMOTE variants to solve this problem. Specifically, these methods are hybrid sampling methods, that is, carrying out an undersampling stage after SMOTE to remove noisy samples. It requires a method that can accurately identify noise to provide reliable performance. In this paper, a hybrid re-sampling method based on SMOTE and a two-layer nearest neighbor classifier (SMOTE-kTLNN) is proposed. SMOTE-kTLNN recognition noise is realized by an Iterative-Partitioning Filter (IPF). Specifically, SMOTE is performed on the original data to balance the data, then the data is divided into n equal parts, establishing kTLNN on each part to predict the whole data. And noisy samples are removed according to the majority voting rule. In the last, the balanced data sets are used to train kNN, AdaBoost, and SVM to verify whether SMOTE-kTLNN is irrelevant to the classifier. The experiment results demonstrate that SMOTE-kTLNN performs better than the comparisons in 25 binary data sets, including Recall, AUC, F1-measure, and G-mean.","This study develops an end\u2010to\u2010end deep learning framework to learn and analyze ground motions (GMs) through their latent features, and achieve reliable GM classification, selection, and generation of simulated motions. The framework is composed of an analysis workflow that transforms and reconstructs GMs through short\u2010time Fourier transform (STFT), encodes and decodes their latent features through convolutional variational autoencoder (CVAE), and classifies and generates GMs by grouping and interpolating latent variables. A benchmark study is established to confirm the minor difference between original GMs and the corresponding reconstructed accelerograms. The encoded latent space reveals that certain latent variables are directly linked to the dominant physical features of GMs. Resultantly, clustering latent variables using the k\u2010means algorithm successfully classifies GMs into different groups that vary in earthquake magnitude, soil type, field distance, and fault mechanism. By linearly interpolating two parent latent variables, simulated GMs are generated with consistent class information and matching response spectra. Furthermore, seismic fragility models are developed for a steel frame building and a concrete bridge using different sets of GMs. Using five classified, top\u2010ranked motions, regardless of recorded or simulated accelerograms, can achieve reasonable and efficient fragility estimates compared to the case that adopts 230 GMs. The proposed deep learning framework addresses two compelling questions regarding seismic fragility assessment: How many GMs are sufficient and what types of motions should be selected.","Yellow rust is a devastating disease that causes significant losses in wheat production worldwide and significantly affects wheat quality. It can be controlled by cultivating resistant cultivars, applying fungicides, and appropriate agricultural practices. The degree of precautions depends on the extent of the disease. Therefore, it is critical to detect the disease as early as possible. The disease causes deformations in the wheat leaf texture that reveals the severity of the disease. The gray-level co-occurrence matrix(GLCM) is a conventional texture feature descriptor extracted from gray-level images. However, numerous studies in the literature attempt to incorporate texture color with GLCM features to reveal hidden patterns that exist in color channels. On the other hand, recent advances in image analysis have led to the extraction of data-representative features so-called deep features. In particular, convolutional neural networks (CNNs) have the remarkable capability of recognizing patterns and show promising results for image classification when fed with image texture. Herein, the feasibility of using a combination of textural features and deep features to determine the severity of yellow rust disease in wheat was investigated. Textural features include both gray-level and color-level information. Also, pre-trained DenseNet was employed for deep features. The dataset, so-called Yellow-Rust-19, composed of wheat leaf images, was employed. Different classification models were developed using different color spaces such as RGB, HSV, and L*a*b, and two classification methods such as SVM and KNN. The combined model named CNN-CGLCM_HSV, where HSV and SVM were employed, with an accuracy of 92.4% outperformed the other models.","Recently, MLP-based architectures achieved impressive results in image classification against CNNs and ViTs. However, there is an obvious limitation in that their parameters are related to image sizes, allowing them to process only fixed image sizes. Therefore, they cannot directly adapt dense prediction tasks (e.g., object detection and semantic segmentation) where images are of various sizes. Recent methods tried to address it but brought two new problems, long-range dependencies or important visual cues are ignored. This paper presents a new MLP-based architecture, Region-aware MLP (RaMLP), to satisfy various vision tasks and address the above three problems. In particular, we propose a well-designed module, Region-aware Mixing (RaM). RaM captures important local information and further aggregates these important visual clues. Based on RaM, RaMLP achieves a global receptive field even in one block. It is worth noting that, unlike most existing MLP-based architectures that adopt the same spatial weights to all samples, RaM is region-aware and adaptively determines weights to extract region-level features better. Impressively, our RaMLP outperforms state-of-the-art ViTs, CNNs, and MLPs on both ImageNet-1K image classification and downstream dense prediction tasks, including MS-COCO object detection, MS-COCO instance segmentation, and ADE20K semantic segmentation. In particular, RaMLP outperforms MLPs by a large margin (around 1.5% Apb or 1.0% mIoU) on dense prediction tasks. The training code could be found at https://github.com/xiaolai-sqlai/RaMLP.","Skip Abstract Section\nAbstract\nAir quality prediction is considered one of complex problems. This is due to volatility, dynamic nature, and high variability in space and time of particulates and pollutants. Meanwhile, designing an automated model for monitoring and predicting air quality becomes more and more relevant, particularly in urban regions. Air pollution can significantly affect the environment and eventually citizens\u2019 health. In this paper, one of the popular machine learning algorithms, the neural network algorithm, is employed to classify different species of air pollutants. To boost the performance of the traditional neural network, the war strategy optimization algorithm tunes the neural network\u2019s parameters. The experimental results demonstrate that the proposed optimized neural network based on the war strategy algorithm can accurately classify air pollutant species.","In image classification task, imbalanced dataset is a problem that often occurs. Batik pattern data also suffers this problem, mainly because of the poor quality of available images and rarity of certain patterns. In this research, we employed a novel ad- vanced augmentation and oversampling techniques on the imbalanced dataset to address this issue. This approach enhanced the diversity of the images, encompassing variations in color, contrast, wrinkles, and warps that may be present in batik garments. We employed two CNN models, DenseNet169 and VGG-16, along with three different training methods for our study. These methods included training without oversampling and advanced augmentation, training with oversampling, and training with both oversampling and advanced augmentation. The results showed that the best accuracy was achieved with DenseNet169 with our oversampled and augmented dataset, with an accuracy of 84.62%. Additionally, VGG-16 also performed well on said dataset, achieving an accuracy of 82.56%.Our results suggested that by using our oversampling &amp; advanced augmentation on the dataset,the model performance improved compared to plain data and oversampled data.","For a long time, images have proved perfect at both storing and conveying rich semantics, especially human emotions. A lot of research has been conducted to provide machines with the ability to recognize emotions in photos of people. Previous methods mostly focus on facial expressions but fail to consider the scene context, meanwhile scene context plays an important role in predicting emotions, leading to more accurate results. In addition, Valence-Arousal-Dominance (VAD) values offer a more precise quantitative understanding of continuous emotions, yet there has been less emphasis on predicting them compared to discrete emotional categories. In this paper, we present a novel Multi-Branch Network (MBN), which utilizes various source information, including faces, bodies, and scene contexts to predict both discrete and continuous emotions in an image. Experimental results on EMOTIC dataset, which contains large-scale images of people in unconstrained situations labeled with 26 discrete categories of emotions and VAD values, show that our proposed method significantly outperforms state-of-the-art methods with 28.4% in mAP and 0.93 in MAE. The results highlight the importance of utilizing multiple contextual information in emotion prediction and illustrate the potential of our proposed method in a wide range of applications, such as effective computing, human-computer interaction, and social robotics.","This paper features convolutional neural network (CNN) models on Clifford algebras applied to a medical image classification task, namely the diagnosis of acute lymphoblastic leukemia (ALL). ALL is a type of cancer identified by malformed lymphocytes, known as lymphoblasts, in the bloodstream. The image classification task aims to discriminate healthy cells from lymphoblasts. This work shows that CNNs featuring parameters in Clifford algebras significantly outperform real-valued networks of equivalent size in this application. Indeed, the real-valued and a Clifford CNN achieved an average accuracy of 94.60% and 97.02%, respectively, in the ALL-IDB dataset with a 50% train-test split. Moreover, we present smaller versions of Clifford CNNs with roughly 75% fewer parameters that yielded a 96.50% average accuracy. The results reported in this work are comparable to high-end models in the literature despite having several orders of magnitude fewer parameters.","This work constitutes the first approach for automatically classifying the surface that the voiding flow impacts in non-invasive sound uroflowmetry tests using machine learning. Often, the voiding flow impacts the toilet walls (traditionally made of ceramic) instead of the water in the toilet. This may cause a reduction in the strength of the recorded audio signal, leading to a decrease in the amplitude of the extracted envelope. As a result, just from analysing the envelope, it is impossible to tell if that reduction in the envelope amplitude is due to a reduction in the voiding flow or an impact on the toilet wall. In this work, we study the classification of sound uroflowmetry data in male subjects depending on the surface that the urine impacts within the toilet: the three classes are water, ceramic and silence (where silence refers to an interruption of the voiding flow). We explore three frequency bands to study the feasibility of removing the human-speech band (below 8 kHz) to preserve user privacy. Regarding the classification task, three machine learning algorithms were evaluated: the support vector machine, random forest and k-nearest neighbours. These algorithms obtained accuracies of 96%, 99.46% and 99.05%, respectively. The algorithms were trained on a novel dataset consisting of audio signals recorded in four standard Spanish toilets. The dataset consists of 6481 1-s audio signals labelled as silence, voiding on ceramics and voiding on water. The obtained results represent a step forward in evaluating sound uroflowmetry tests without requiring patients to always aim the voiding flow at the water. We open the door for future studies that attempt to estimate the flow parameters and reconstruct the signal envelope based on the surface that the urine hits in the toilet.","Face attribute classification (FAC) is a high-profile problem in biometric verification and face retrieval. Although recent research has been devoted to extracting more delicate image attribute features and exploiting the inter-attribute correlations, significant challenges still remain. Wavelet scattering transform (WST) is a promising non-learned feature extractor. It has been shown to yield more discriminative representations and outperforms the learned representations in certain tasks. Applied to the image classification task, WST can enhance subtle image texture information and create local deformation stability. This paper designs a scattering-based hybrid block, to incorporate frequency-domain (WST) and image-domain features in a channel attention manner (Squeeze-and-Excitation, SE), termed WS-SE block. Compared with CNN, WS-SE achieves a more efficient FAC performance and compensates for the model sensitivity of the small-scale affine transform. In addition, to further exploit the relationships among the attribute labels, we propose a learning strategy from a causal view. The cause attributes defined using the causality-related information can be utilized to infer the effect attributes with a high confidence level. Ablative analysis experiments demonstrate the effectiveness of our model, and our hybrid model obtains state-of-the-art results in two public datasets.","Diabetic retinopathy, a condition characterized by retinal damage and vision loss, is a prevalent complication of diabetes arising from elevated blood sugar levels. With a growing number of individuals affected, efficient and accurate diagnosis is crucial. This study aims to implement and compare the Local Binary Pattern (LBP) and Gray Level Co-occurrence Matrix (GLCM) feature extraction techniques, which have demonstrated success in prior research. The comparison will provide a comprehensive under- standing of the image features, extract relevant data, and improve the performance of the image analysis pipeline for diabetic retinopathy classification. The result showed that from three scenarios the best accuracy provided by Support Vector Machine with the accuracy score between 73% until 74%, however, other algorithm have little difference which the result on 73%.","The recognition and classification of wire melted marks is crucial in modern fire investigation. The existing technology mainly uses physical or chemical methods to deal with wire melted marks and draws conclusions through manual observation, or manually extracts the features and train classification model, both of which consume excessive manpower and resources. The research on automatic feature extraction and recognition of wire weld marks by artificial intelligence technology is still blank. Based on the data set of wire melted mark metallographic images provided by a city fire research institute, we proposed an algorithm to recognize the type of wire melted mark metallographic images based on artificial intelligence which can help fire fighters efficiently speculate the cause of fire. In the algorithm, the TransUnet network is used to segment the melted zone by semantic segmentation to extract the melted zone containing the main features, and the mIOU reaches 92.2%. Then, the features of wire melted mark are extracted based on the melted zone image. Finally, XGBoost is used for feature modeling for classification. The F1 Score of model is 82.9%.","Skewed class proportions in real-world datasets present a challenge for machine learning algorithms, as they have a tendency to correctly categorize the majority class while incorrectly classifying the minority class. Such classification disparities hold significant implications, particularly in predictive scenarios involving minority groups, where misclassifying minority instances could lead to adverse outcomes. To tackle this, class imbalance learning has gained attention, with the Synthetic Minority Oversampling Technique (SMOTE) being a notable approach that addresses class imbalance by generating synthetic instances for the minority class based on their feature space neighbors. Despite its effectiveness and simplicity, SMOTE is known to suffer from a noise propagation issue where noisy and uninformative samples are introduced. While various SMOTE variants, including hybrids with undersampling, have been developed to tackle this problem, identifying noisy samples in complex real-world datasets remains a challenge. To address this, our study introduces a new SMOTE-based hybrid approach called SMOTE-centroid displacement-based k-NN (SMOTE-CDNN). SMOTE-CDNN employs centroid displacement for class prediction, which is more robust against noisy data. After SMOTE is applied, noise instances are detected and removed for clearer decision boundaries if their labels predicted by our centroid displacement-based k-NN algorithm are different from the real ones. While our experiments on 24 imbalance datasets demonstrate the resilience and efficiency of our proposed algorithm, which outperforms state-of-art resampling algorithms with various classification models, we acknowledge the need for further investigation into specific dataset characteristics and classification scenarios to determine the generalizability of our approach.\nHighlights\n\u2022\nSkewed class proportions pose a challenge for machine learning.\n\u2022\nSMOTE is widely used but has a noise propagation issue.\n\u2022\nA novel hybrid variant, SMOTE-CDNN, uses k-NN with centroid displacement.\n\u2022\nIt detects and removes noise instances after SMOTE is applied.\n\u2022\nExperiments show its efficiency and outperformance of other algorithms.","With the exponential growth of various data interactions on network systems, network intrusions are also increasing. The emergence of edge computing technology brings a new solution to network security. However, due to the difficulty of processing massive and unbalanced data at the edge, higher accuracy requirements are necessary for deployed detection models. This paper proposes a multi-classification model for network intrusion detection based on reconstruction and feature matching. This model can be deployed on small-scale edge nodes, effectively identifying various attack behaviors through the utilization of reconstruction errors and adaptive scaling. Furthermore, we proposed a model transfer method based on feature matching to enhance the training and detection efficiency of multi-classification models under different data distribution conditions. The proposed model has been evaluated on the CICIDS2017 dataset in terms of accuracy, recall, precision and F1 score. The model demonstrates high accuracy for normal flows in the network, majority class attacks, and minority class attacks, achieving an overall multi-class accuracy of 99.81%, outperforming similar models. Furthermore, this model demonstrates faster convergence and training speed after feature matching, exhibiting better robustness and outstanding performance at the edge.","Ordinal classification of imbalanced datasets is a challenging problem that occurs in many real-world applications. The main challenge is to simultaneously consider the classes ordering and imbalanced distribution. Although the classic synthetic instances oversampling techniques can improve the identification of minority classes, they easily incur the damage of the classes ordering when the synthetic instances fall in non-adjacent classes regions. In this paper, we propose a powerful method for handling the imbalanced problem embedded in the ordinal classification, namely Iterative Minority oversampling technique for imbalanced Ordinal Classification (IMOC). Concretely, we first develop an iterative identification procedure to select the minority instance that is hardest to learn. Then, a weighted oversampling probability distribution that respects the ordinal nature is used to generate synthetic minority instances to balance the skewed distribution. Furthermore, two novel ensemble versions are developed to boost the capability of our proposed IMOC. In order to verify the effectiveness and robustness of our proposed methods, an extensive experimental study is carried out on a large number of datasets from real-world applications. The experimental results supported by proper statistical tests indicate that our proposed methods outperform state-of-the-art algorithms in terms of the most frequently used performance measures.","Human Multimodal Sentiment Analysis (MSA) is an attractive research that studies sentiment expressed from multiple heterogeneous modalities. While transformer-based methods have achieved great success, designing an effective \u201cco-attention\u201d model to associate text modality with nonverbal modalities remains challenging. There are two main problems: 1) the dominant role of the text in modalities is underutilization, and 2) the interaction between modalities is not sufficiently explored. This paper proposes a deep modular Co-Attention Shifting Network (CoASN) for MSA. A Cross-modal Modulation Module based on Co-attention (CMMC) and an Advanced Modality-mixing Adaptation Gate (AMAG) are constructed. The CMMC consists of the Text-guided Co-Attention (TCA) and Interior Transformer Encoder (ITE) units to capture inter-modal features and intra-modal features. With text modality as the core, the CMMC module aims to guide and promote the expression of emotion in nonverbal modalities, and the nonverbal modalities increase the richness of the text-based multimodal sentiment information. In addition, the AMAG module is introduced to explore the dynamical correlations among all modalities. Particularly, this efficient module first captures the nonverbal shifted representations and then combines them to calculate the shifted word embedding representations for the final MSA tasks. Extensive experiments on two commonly used datasets, CMU-MOSI and CMU-MOSEI, demonstrate that our proposed method is superior to the state-of-the-art performance.","Based on the network structure and training methods of extreme learning machines, extreme learning machine combining hidden-layer feature weighting and batch training (ELM-WB) is proposed to make full use of representation-level features for object images and human action videos classification. To solve the problem of insufficient fusion of multiple representation-level features in most classification methods, a double hidden layer structure in which the input layer and the second hidden layer are directly connected is designed. A loop training method of weighting coefficients and output weights is proposed based on the advantages of this structure. The proposed network structure and training method are combined to construct an extreme learning machine combining hidden-layer feature weighting (ELM-W), which can effectively fuse representation-level features to enhance the classification ability of representation-level features. On this basis, the principle of online sequential ELM (OS-ELM) is introduced to update the loop training formula of the two weights to reduce the memory consumption during the operation of the overall algorithm. ELM-WB is proposed by combining the loop training formula of two weight matrices with batch training. In order to test the feasibility of ELM-WB, experiments are conducted on Caltech 101, MSRC, UCF11 and UCF101 databases. Experimental results prove that the proposed ELM-WB can improve classification accuracy by fusing representation-level features. At the same time, ELM-WB can be used to perform classification tasks on databases of any size in a general-purpose computer without specific hardware.","The article provides a description of the most frequent bigrams and trigrams obtained using the n-gram analysis technique on a representative sample of Russian spoken language. N-gram analysis allows identifying frequent lists of sequences consisting of n graphical words, which is important for describing corpus material in various theoretical and applied aspects. The source data for applying this technique was a sample of 388 episodes of everyday speech communication from the ORD corpus (about 110 hours of audio). The results of the n-gram analysis in the form of frequency lists of word sequences allow constructing a typology of the most common bigrams and trigrams in Russian oral communication and lead the study equally to the levels of grammar, pragmatics, lexicon, and phraseology. The list of the most frequent bigrams and trigrams contains grammatical structures (U TEBYA, YA NE PONIMAYU, MNE KAZHETSYA), idioms (in a broad sense of the term) (VSYO RAVNO, TO ZHE SAMOE), introductory units (TAK SKAZAT\u2019, S DRUGOY STORONY), as well as a number of sequences typical only for oral speech, such as one-word pragmatic markers (NU VOT, KAK BY, NU V OBSHCEM), amplifications (DA-DA, TAK-TAK-TAK), and hesitations-vocalizations (E-E, M-M-M). The obtained frequency lists can be useful for solving many modern applied natural language processing tasks.","Abstract: In the data stream learning scenario, the whole picture of the data can't be observed, and the data may change dynamically, thus increasing the complexity and imbalance of the data. Aiming at the characteristics of data class changes (appearance, disappearance, and reappearance) of multi-class data stream, a Matthews Adaptive XGBoost algorithm based on One-Vs-Rest strategy is proposed. For the three cases of class change, the One-Vs-Rest strategy is used to build the model, and a binary classification model is created for each class. Aiming at the problem that the model gradually forgets the knowledge of the class after the class disappears, a management mechanism based on class frequency is proposed. In view of the problem that the restarted model affects the overall performance of the ensemble after the class is reproduced, the sliding window is used to initialize it. Aiming at the problem of ensemble classifiers, a mechanism to adapt the number of base classifiers is proposed. Experiments on real and synthetic datasets show that the improved algorithm improves Kappa and PMAUC indicators by 1.03% and 0.82%, respectively.\nCCS CONCEPTS \u2022 Computing methodologies \u2022 Machine learning \u2022 Machine learning algorithms","The Gene Ontology (GO) project is a major bioinformatics initiative with the aim of standardizing the representation of gene and gene product attributes across species and databases. The classes in GO are hierarchically structured in the form of a directed acyclic graph (DAG), what makes its prediction more complex. This work proposes an adapted Learning Classifier Systems (LCS) in order to predict protein functions described in the GO format. Hence, the proposed approach, called HLCS (Hierarchical Learning Classifier System) builds a global classifier to predict all classes in the application domain and its is expressed as a set of IF-THEN classification rules, which have the advantage of representing more comprehensible knowledge. The HLCS is evaluated in four different ion-channel data sets structured in GO terms and compared with a Ant Colony Optimisation algorithm, named hAnt-Miner. In the tests realized the HLCS outperformed the hAnt-Miner in two out of four data sets.","Few-shot learning datasets contain a large number of classes with only a few examples in each. Existing datasets may contain thousands of classes, but very simple images (e.g. handwritten characters) such that a naive baseline can perform very well. Or they may be so complex, with large within-class variation and distracting background, that they are too difficult to enable meaningful learning with so few examples. To construct a customizable dataset of consistent natural images, we assemble a new dataset with each class containing a small subset from each of the 1000 classes of ImageNet-1k. To select subsets with clear within-class consistency we use an evolutionary approach to minimize the pairwise cosine-distance between features generated by a pre-trained VGG model. We train a classifier on these evolved image cliques and find that our evolved dataset provides a greater challenge than hand written digits, but not the extreme difficulty of a non-evolved subset of ImageNet. We find that pre-training our classifier on these evolved prototypical classes significantly improves performance on classifying random subsets ImageNet (relative to pre-training on similar random-class subsets), and conjecture that these prototypical classes may be beneficial for seeding concept learning. Dataset and code is publicly available at: https://github.com/lfrati/OmnImage","Highlights\n\u2022\nOrigin and variety identification of Chrysanthemum were studied by NIR-HSI.\n\u2022\nAdvanced deep learning and visualization methods were utilized for classification.\n\u2022\nFew-shot Class-Incremental learning using the Replay training strategy was studied.\n\u2022\nGood performances were obtained by Few-shot Class-Incremental learning approach.\nAbstract\nChrysanthemum, a traditional Chinese medicine, possesses diverse pharmacological effects with a myriad of origins and varieties. Due to the difficulty of acquiring and modeling all Chrysanthemum varieties comprehensively, it becomes imperative to establish models based on the available samples in order to swiftly identify newly emerging Chrysanthemum categories from a limited dataset. In this study, hyperspectral imaging combined with deep learning was exploited for the classification of fourteen Chrysanthemum categories by origin and variety. Leveraging the convolutional neural network, the few-shot class-incremental learning (class-IL) method was applied to the detection of few-shot Chrysanthemum categories. By employing a Replay training strategy, the challenges associated with severely sample-limited and unbalanced classes can be effectively addressed. When incrementally expanding from four to fourteen categories, with each new category consisting of only 30 samples, the achieved accuracy on the test dataset reached 80.13 %. This remarkable performance exhibited a narrow margin of 15.75 % compared to conventional supervised learning, which utilized an incremental training sample size nearly 100 times larger. This approach consistently outperforms conventional supervised learning methods, thereby showcasing its remarkable scalability. It facilitates the practical implementation of few-shot learning and deep learning models, providing a substantiated framework to tackle real-world scenarios in various domains using hyperspectral imaging and related techniques.","Recently, transfer learning has generated promising performance in few-shot classification by pre-training a backbone network on base classes and then applying it to novel classes. Nevertheless, there lacks a theoretical analysis on how to reduce the generalization error during the learning process. To fill this gap, we prove that the classification error bound on novel classes is mainly determined by the base-class generalization error, given the base-novel domain divergence and the novel-class generalization error produced by an incremental learner using novel samples. The novel-class generalization error is further decided by the base-class empirical error and the VC-dimension of the hypothesis space. Based on this theoretical analysis, we propose a Born-Again Networks under Self-supervised Label Augmentation (BANs-SLA) method to improve the generalization capability of classifiers. In this method, cross-entropy and supervised contrastive losses are simultaneously used to minimize the base-class empirical error in the expanded space with SLA. Afterward, BANs are adopted to transfer the knowledge sequentially across generations, which acts as an effective regularizer to trade-off the VC-dimension. Extensive experimental results have verified the effectiveness of our method, which establishes the new state-of-the-art performance on popular few-shot classification benchmark datasets.\nGraphical abstract\nDisplay Omitted\nHighlights\n\u2022\nThis is the first theoretical study on FSC in the context of the transfer learning paradigm.\n\u2022\nWe propose a Born-Again Networks under Self-supervised Label Augmentation method.\n\u2022\nWe conduct experiments on multiple benchmarks to demonstrate the effectiveness.","Learning with Noisy Labels (LNL) has become an appealing topic, as imperfectly annotated data are relatively cheaper to obtain. Recent state-of-the-art approaches employ specific selection mechanisms to separate clean and noisy samples and then apply Semi-Supervised Learning (SSL) techniques for improved performance. However, the selection step mostly provides a medium-sized and decent-enough clean subset, which overlooks a rich set of clean samples. To fulfill this, we propose a novel LNL framework ProMix that attempts to maximize the utility of clean samples for boosted performance. Key to our method, we propose a matched high confidence selection technique that selects those examples with high confidence scores and matched predictions with given labels to dynamically expand a base clean sample set. To overcome the potential side effect of excessive clean set selection procedure, we further devise a novel SSL framework that is able to train balanced and unbiased classifiers on the separated clean and noisy samples. Extensive experiments demonstrate that ProMix significantly advances the current state-of-the-art results on multiple benchmarks with different types and levels of noise. It achieves an average improvement of 2.48% on the CIFAR-N dataset.","To increase classification accuracy, a variety of feature extraction techniques have been presented. A pre-processing method called superpixel segmentation divides an image into meaningful sub-regions, which simplifies the image. This substantially reduces single-pixel misclassification. In this work, a texture-based superpixel segmentation technique is developed for the accurate classification of hyperspectral images (HSI). Initially, the local binary pattern and Gabor filters are employed to extract local and global image texture information. The extracted texture features are then provided as input to the simple linear iterative clustering (SLIC) algorithm for segmentation map generation. The final classification map is constructed by utilising a majority vote strategy between the superpixel segmentation map and the pixel-wise classification map. The proposed method was validated on standard HSI datasets. In terms of classification performance, it outperformed other state-of-the-art algorithms. Furthermore, the algorithm may be incorporated into the UAV's onboard camera to automatically classify HSI.","To address the problem of low classification accuracy of liquid dangerous goods in daily security screening technology, we propose a two-layer feature extraction classification algorithm based on Ultra-Wideband centimeter wave detection, which is composed of shallow Wavelet Transform-Autoencoder (WT-AE) and deep Attention-Gated Recurrent Unit (Attention-GRU) network. In order to abstract the best description feature, the shallow autoencoder adds a classification constraint. In the classification stage, the deep algorithm Attention-GRU algorithm can further abstract the sequence composed of shallow features into deep features to improve the accuracy of classification. The experimental results show that the WT-AE algorithm with shallow constraint is more suitable for feature extraction of UWB centimeter-wave signals in this experimental scene than PCA and ICA feature extraction algorithms. Compared with KNN, Linear kernel SVM, Gaussian kernel SVM and decision tree algorithms for sequence processing, Attention-GRU has better processing effect and higher accuracy of classification. By comparing the test accuracy of other algorithms, the double-layer feature classification algorithm performs better in this experimental scene. The final test accuracy can reach 95.8%.","With the development of scientific research techniques, drug discovery has shifted from the serendipitous approach of the past to more targeted models based on an understanding of the underlying biological mechanisms of disease. However, there are hundreds or more of mechanism of action (MoA) data in the known drugs, which makes this process faced with complicated multi-label classification of text data. Traditional multi-label text classification algorithms will increase the complexity of the model and reduce the accuracy as the number of labels increases. Although deep learning algorithms can solve the problem of model complexity, they are currently only suitable for processing image format data. To overcome these problems, this study proposes a multi-label classification method based on Bayesian deep learning, which can convert non-image data format into image data, making it suitable for Convolutional neural network algorithm requirements. Then in the PyTorch environment, the Bayesian deep learning algorithm and the EfficientNet convolutional neural network are perfectly combined using the BLiTZ library to construct the Bayesian convolutional neural network model which named BCNNM. Not only improves the classification efficiency, this method also solves the problem of imbalanced classification of multi-label data, and fully considers the uncertainty in the neural network. In the process of drug development, this method has important practical significance for processing the multi-label classification of MoA data.","Social media text can be classified in different ways, viz sentiment analysis, humour detection, hate speech detection and hope speech detection. Multitask learning (MTL) models built on Large Language Models (LLMs) eliminate the need to build separate models for each of these tasks. However, building MTL models by fully fine-tuning the LLM has limitations such as catastrophic forgetting and requiring complete retraining to add a new task. AdapterFusion was introduced to address these limitations. However, existing AdapterFusion techniques have not been experimented with code-mixed or code-switched text. Moreover, they only considered task-based AdapterFusion on monolingual LLMs. However, using monolingual LLMs is sub-optimal in classifying code-mixed or code-switched text. A better alternative is multilingual LLMs. In this paper, we present an MTL model that combines task AdapterFusion with language adapters on top of a multilingual LLM. We combine language adapters sequentially, in parallel, and as a fusion with task adapters to capture cross-lingual knowledge in code-mixed and code-switched text. We believe that this is the first research to introduce language-based AdapterFusion.","Convolutional neural network (CNN) and its variants have been widely applied to hyperspectral classification for their excellent ability to extract local features. However, as research on hyperspectral imaging (HSI) has progressed, CNNs have been proven to struggle in extracting and representing the sequential properties of spectral characteristics. Recently, some researchers have demonstrated the feasibility of transformer architecture in HSI classification due to its powerful ability to characterize spectral information. The lack of suitable pre-processing and optimization methods which are used for the transformer's application in HSI becomes a major limitation to model's performance. Therefore, to enhance model's performance and practicality, we propose an efficient transformer backbone for HSI classification, named Efficient-Spectralformer. In the proposed framework, we rethink the input form and design the Split Grouping Embedding (SGE) module that requires much less computational resources. Additionally, to maximize the use of attentional feature information from different layers, we have used the Multi-layer Feature Fusion (MFF) module is used to learn multi-layer spectral attention information. The experiments conducted on five HSI datasets demonstrate that the proposed method achieves better performance under much less memory usage (about 30% of the original on average) by comparing with the original Spectralformer.","Support vector machine (SVM) is widely recognized as an effective classification tool and has demonstrated superior performance in diverse applications. However, for large-scale pattern classification problems, it may require much memory and incur prohibitive computational costs. Motivated by this, we propose a new SVM model with novel generalized ramp loss (L R-SVM). The first-order optimality conditions for the non-convex and non-smooth L R-SVM are developed by the newly developed P-stationary point, based on which, the L R support vectors and working set of L R-SVM are defined, interestingly, which shows that all of the L R support vectors are on the two support hyperplanes under mild conditions. A fast proximal alternating direction method of multipliers with working set (L R-ADMM) is developed to handle L R-SVM and L R-ADMM has been demonstrated to achieve global convergence while maintaining a significantly low computational complexity. Numerical comparisons with nine leading solvers show that L R-ADMM demonstrates outstanding performance, particularly when applied to large-scale pattern classification problems with fewer support vectors, higher prediction accuracy and shorter computational time.\nHighlights\n\u2022\nThe new sparse and robust SVM model. We construct a new sparse and robust generalized ramp loss SVM.\n\u2022\nThe novel support vectors. To reduce the scale of the training set, we define the support vectors of generalized ramp loss SVM.\n\u2022\nThe efficient new algorithm. To solve the generalized ramp loss SVM, we design a new alternating direction method of multipliers with working set.\n\u2022\nHigh numerical performance. Numerical experiments show that the proposed algorithm has excellent performance.","License Plate Recognition (LPR) plays a critical role in various applications, such as toll collection, parking management, and traffic law enforcement. Although LPR has witnessed significant advancements through the development of deep learning, there has been a noticeable lack of studies exploring the potential improvements in results by fusing the outputs from multiple recognition models. This research aims to fill this gap by investigating the combination of up to 12 different models using straightforward approaches, such as selecting the most confident prediction or employing majority vote-based strategies. Our experiments encompass a wide range of datasets, revealing substantial benefits of fusion approaches in both intra- and cross-dataset setups. Essentially, fusing multiple models reduces considerably the likelihood of obtaining subpar performance on a particular dataset/scenario. We also found that combining models based on their speed is an appealing approach. Specifically, for applications where the recognition task can tolerate some additional time, though not excessively, an effective strategy is to combine 4\u20136 models. These models may not be the most accurate individually, but their fusion strikes an optimal balance between accuracy and speed.","In this paper, an analysis of convolutional neural network (CNN) models to classify the quality of dried chili pepper is described. The classifier models can determine the categories of a set of images that could be encountered in a sorting machine, such as \u201cExtra\u201d, \u201cFirst class\u201d, and \u201cSecond class\u201d which correspond to different qualities of dried chili peppers. Additionally, two more classes were added as \u201cTrash\u201d and \u201cEmpty\u201d which corresponds to cases that could occur in a sorting machine. To determine the best model for image classification, a set of state-of-the-art architectures were compared from the Torchvision library, including ResNet, ResNeXt, Wide ResNet, EfficientNet, and RegNet. The models were trained using feature extraction on the transfer learning approach, and were evaluated using cross-validation method and various advanced metrics such as Precision, Recall, Specificity, F1-score, Geometric mean, and Index of Balanced Accuracy. The results of the cross-validation process indicate that ResNet-152 is the best CNN model for implementation in a sorting machine, with a mean validation accuracy of 95.04%. By using this model, agricultural producers can ensure that their products are sorted according to international standards.","Among the causes of reduced production is a chicken disease, which can negatively affect consumer health. With the advancement of computer vision technology and profound innovations in the field of research, it has become increasingly important to analyze disease images collected by sensors in chickens to analyze the possibility of infection conveniently and efficiently. Consequently, research proposes to identify lesions using the Autoencoder and Yolov6 model to classify and detect diseases in chicken flocks. This model is suitable for different chicken breeds from many countries and regions. This method helps improve and enhance image recognition accuracy by incorporating the data enhancement method in the data preprocessing step. The results show that the value of val/mAP (average accuracy) obtained by the method proposed in this paper is 99.15%. Moreover, hit over 90% on the test dataset. This method can be applied to the early detection of disease-carrying chickens in the captive population, ensuring a quality food source for humans.","Data classification is a core component of many intelligent systems, and it has been almost monopolizing the interest of the scientific community for decades. However, developing classifiers capable of explaining how a classification result was derived, in a way that is compatible to the human perception, is still a challenge. Steps towards this direction have been made via interpretable fuzzy classifiers capable of extracting linguistically expressible rules from data. Motivated by the need for interpretable data classification, this study proposes a novel interpretable fuzzy classification framework based on Fuzzy Similarity Phrases (FSPs), aiming to provide an improved tradeoff between interpretability and classification performance. This framework incorporates the following novel components: a) a generic vocabulary-based feature extraction scheme which considers similarity features and fuzzy sets to construct FSPs; b) a rule generation methodology based on FSPs; c) an embedded feature selection methodology targeting to keep both the number of extracted rules and their length low; and an interpretable class prediction mechanism based on the interpretation of the FSPs. The experimental evaluation of the proposed framework on various publicly available datasets, in comparison with well-known and state-of-the-art classifiers, validate that it can provide a better average classification performance with fewer rules.","In this research, a method was developed for utilizing voice commands with programmable logic controllers (PLCs) and supervisory control and data acquisition (SCADA) systems, which are commonly utilized in industrial automation. This approach incorporates artificial intelligence to enable human\u2013machine interaction, aligning with the trends of Industry 4.0. A deep neural network was specifically designed for speech recognition, eliminating the need for reliance on any pre-existing speech-to-text engines. The objective was to create a model that is accurate and compact in size, making it suitable for embedded systems within industrial systems. To train the deep learning network, 21,600 sound files were generated. These files combined real factory noise with a synthetic dataset of human speech, forming a dataset comprising 60 different classes of voice commands. These commands encompassed actions like starting, stopping, and operating at various speeds for 10 motors controlled by the automation system. After applying the Mel-frequency cepstral coefficient (MFCC) to the voice commands, the resulting data was directly fed into the proposed network. The network achieved an impressive accuracy rate of 99.73%. Notably, the proposed network outperformed even networks several times its size.","Neighborhood rough set theories are commonly used in global feature selection to achieve high performance in continuous data classification. However, selecting a single feature subset to represent the entire dataset may degrade the performance when there are intra-class dissimilarities among objects. Therefore, this paper proposes a novel feature-selection method, Granule-specific Feature Selection (GFS) to select local feature subsets for continuous data classification. The feature selection approach constitutes a novel feature selection algorithm and a novel feature evaluation function and uses existing approaches for granule identification and classification with some adjustments. The neighborhood rough set theories are used in granule (subclass) identification within each class when there are no subclass label information available in the training data, while an improved k-Nearest Neighbors approach is used in classification with granule-specific feature subsets. Experimental results show GFS outperforms most of the global, class-specific, and local feature selection baselines in terms of classification performance.\nHighlights\n\u2022\nGranule-specific feature selection using neighborhood rough set theories.\n\u2022\nFeature selection while managing intra-class dissimilarities of objects.\n\u2022\nHandle data uncertainty of continuous data when selecting features.\n\u2022\nImprove classification performance using granule-specific feature subsets.","Pathological complete response (pCR) after neoadjuvant che-motherapy (NAC) in patients with breast cancer was found to improve survival, and it has a great prognostic value in the aggressive tumor subtype. This study aims to predict pCR before NAC treatment with a radiomic feature-based ensemble learning model using both positron emission tomography/computed tomography (PET/CT) images taken from the online QIN-Breast dataset. It studies the problem of constructing an end-to-end classification pipeline that includes a large-scale radiomic feature extraction, a hybrid iterative feature selection and a heterogeneous weighted ensemble classification. The proposed hybrid feature selection procedure can identify significant radiomic predictors out of 2153 features extracted from delineated tumour regions. The proposed weighted ensemble approach aggregates the outcomes of four weak classifiers (Decision tree, Naive Bayes, K-nearest neighbour, and Logistics regression) based on their importance. The empirical study demonstrates that the proposed feature selection-cum-ensemble classification method has achieved 92% and 88.4% balanced accuracy in PET and CT, respectively. The PET/CT aggregated model performed better and achieved 98% balanced accuracy and 94.74% F1-score. Furthermore, this study is the first classification work on the online QIN-Breast dataset.","This paper presents a novel framework that enables the generation of unbiased estimates for test loss using fewer labeled samples, effectively evaluating the predictive performance of classification models in data-limited applications. The framework\u2019s key innovation lies in developing an adaptive sampling distribution that iteratively identifies influential testing samples based on interactions between learner and evaluator agents. Notably, the adaptive distribution dynamically adjusts the evaluator agent\u2019s supervisory role by prioritizing inputs with discrepancies between the agents and considering the evaluator\u2019s uncertainty. Comprehensive experimental analyses on synthetic data and two sparse data sets from material extrusion additive manufacturing problems validate the framework\u2019s superiority over uniform and fixed sampling distributions. First, the proposed framework provides unbiased estimates of the test loss across various data sets, sampling ratios, and evaluator models. Second, the introduced adaptive sampling distribution significantly reduces the standard deviation of the test loss estimator compared to uniform sampling, achieving a 50% reduction for a 10% sampling ratio in the filament selection benchmark. Third, the framework demonstrates its efficacy in model selection to determine the optimal number of hidden units with a reduced number of test samples. Overall, this work offers a promising framework for evaluating classification models in applications where acquiring labeled data is time-consuming and resource-intensive, including materials science and engineering.","Internet traffic classification plays a key role in network visibility, Quality of Services (QoS), intrusion detection, Quality of Experience (QoE) and traffic-trend analyses. In order to improve privacy, integrity, confidentiality, and protocol obfuscation, the current traffic is based on encryption protocols, e.g., SSL/TLS. With the increased use of Machine-Learning (ML) and Deep-Learning (DL) models in the literature, comparison between different models and methods has become cumbersome and difficult due to a lack of a standardized framework. In this paper, we propose an open-source framework, named OSF-EIMTC, which can provide the full pipeline of the learning process and simulation reproducibility. From well-known datasets to extracting new and well-known features, it provides implementations of well-known ML and DL models (from the traffic classification literature) as well as experimental test-beds and their evaluation. By providing a standardized platform, OSF-EIMTC enables repeatable, reproducible, and accurate comparisons of both established and novel features and models. As part of our framework evaluation, we demonstrate the reproducibility of a variety of cases where the framework can be of use, utilizing multiple datasets, models, and feature sets. We show analyses of publicly available datasets and invite the community to participate in our open challenges using OSF-EIMTC, fostering collaborative advancements in encrypted traffic classification.","Of all the terminal cancers that plague men, prostate cancer remains one of the most prevalent and ubiquitous. Data shows prostate cancer is the second leading cause of cancer death worldwide among men. About 11% of men have prostate cancer at some time during their lives. As it happens, we have dedicated our entire research to developing an approach that can improve the existing precision of prostate cancer diagnosis. In our research, we have dedicated a Transfer Learning approach for the Deep Learning model to compare the accuracy in results using Machine Learning classifiers. In addition, we evaluated individual performance in classifications with different evaluation measures using a Deep Learning pre-trained network, VGG16. During our evaluation, we assessed several performance metrics such as Precision, Recall, F1 Score, and Loss Vs. Accuracy for performance analysis. Upon implementing the Transfer Learning approach, we recorded the optimum performance using the VGG16 architecture compared to other popular Deep learning models such as MobileNet and ResNet. It is important to note that we have used the convolutional block and dense layers of VGG16 architecture to extract features from our image dataset. Afterward, we forwarded those features to Machine Learning classifiers to tabulate the final classification result. Upon successful tabulation, we have secured significant accuracy in prognostication using the Deep Machine Learning method in our research.","Legal judgment prediction (LJP) is a significant task in legal intelligence, which aims to assist the judges and determine the judgment result based on the case's fact description. The judgment result consists of law articles, charge, and prison term. The law articles serve as the basis for the charge and the prison term, which can be divided into two types, named as charge-related law article and term-related law article, respectively. Recently, many methods have been proposed and made tremendous progress in LJP. However, the existing methods only focus on the prediction of the charge-related law articles, ignoring the term-related law articles (e.g., laws about lenient treatment), which limits the performance in the prison term prediction. In this paper, following the actual legal process, we expand the law article prediction as a multi-label classification task that includes both the charge-related law articles and term-related law articles and propose a novel multi-law aware LJP (ML-LJP) method to improve the performance of LJP. Given the case's fact description, firstly, the label (e.g., law article and charge) definitions in the Code of Law are used to transform the representation of the fact into several label-specific representations and make the prediction of the law articles and the charge. To distinguish the similar content of different label definitions, contrastive learning is conducted in the training. Then, a graph attention network (GAT) is applied to learn the interactions among the multiple law articles for the prediction of the prison term. Since numbers (e.g., amount of theft and weight of drugs) are important for LJP but often ignored by conventional encoders, we design a corresponding number representation method to locate and better represent these effective numbers. Extensive experiments on real-world dataset show that our method achieves the best results compared to the state-of-the-art models, especially in the task of prison term prediction where ML-LJP achieves a 10.07% relative improvement over the best baseline.","This paper explores how machine learning can help classify aid activities by sector using the OECD Creditor Reporting System (CRS). The CRS is a key source of data for monitoring and evaluating aid flows in line with the United Nations Sustainable Development Goals (SDGs), especially SDG17 which calls for global partnership and data sharing. To address the challenges of current labor-intensive practices of assigning the code and the related human inefficiencies, we propose a machine learning solution that uses ELECTRA to suggest relevant five-digit purpose codes in CRS for aid activities, achieving an accuracy of 0.9575 for the top-3 recommendations. We also conduct qualitative research based on semi-structured interviews and focus group discussions with SDG experts who assess the model results and provide feedback. We discuss the policy, practical, and methodological implications of our work and highlight the potential of AI applications to improve routine tasks in the public sector and foster partnerships for achieving the SDGs.","Handwriting is widely investigated to mark emotional states and personality. However, the majority of the studies are based on graphology, and do not utilise personality factor models. We use the well-known five-factor model which says that people possess five basic traits, together known as big-five. Hence the problem of personality prediction from handwriting is essentially a multi-label problem. In addition to that, the predicted values should be non-binary decimal numbers since the model says people possess the traits in various degrees. Multi-label classifiers have not been explored for personality assessment using handwriting features. The current work aims to bridge the gap. Multi-label classifiers are trained by trait scores obtained by big-five inventory as well as handwriting features. A number of classifiers including classifier chain, binary relevance and label power-set are employed in the work. Best accuracies of 95.9% with non-binary label values and 97.9% with binary label values are achieved.","Virtual reality technology provides a strong sense of immersion and interactivity. It is widely used in the fields of anxiety relief, fear therapy, and depression regulation. However, objectively evaluating the emotional intervention effect of virtual reality technology is a difficult problem. The main purpose of this paper is to explore the use of EEG signals to identify individual emotional states in virtual reality scenarios and to improve the computational efficiency and recognition accuracy of emotional valence. To induce the target emotional state of the participants, we established a relatively standard emotion-induced virtual reality video library. The EEG data of the participants were collected synchronously as they watched the virtual reality video. The results show that the emotion recognition performance of multiple features (energy spectrum, differential entropy, differential asymmetry, and rational asymmetry) is better than that of a single feature. The radial basis function neural network (RBFNN) performed better than the deep belief network (DBN). RBFNN achieves the highest average classification accuracy of 91.1%. By combining the feature selection (F-test) method with the RBFNN, an ideal classification performance can be maintained with computational efficiency improvements. Furthermore, it is demonstrated that the features extracted from the theta band outperform features extracted from other bands in emotional valence decoding. These results may contribute to the application of EEG-based affective computing technology in the field of psychological rehabilitation and assessment.","Active learning has achieved remarkable success in minimizing labeling costs for classification tasks with all data samples drawn from known classes. However, in real scenarios, most active learning methods fail when encountering open-set annotation (OSA) problem, i.e., numerous samples from unknown classes. The main reason for such failure comes from existing query strategies that are unavoidable to select unknown class samples. To tackle such problem and select the most informative samples, we propose a novel active learning framework named OSA-CQ, which simplifies the detection work of samples from known classes and enhances the classification performance with an effective contrastive query strategy. Specifically, OSA-CQ firstly adopts an auxiliary network to distinguish samples using confidence scores, which can dynamically select samples with the highest probability from known classes in the unlabeled set. Secondly, by comparing the predictions between auxiliary network, classification, and feature similarity, OSA-CQ designs a contrastive query strategy to select these most informative samples from unlabeled and known classes set. Experimental results on CIFAR10, CIFAR100 and Tiny-ImageNet show the proposed OSA-CQ can select samples from known classes with high information, and achieve higher classification performance with lower annotation cost than state-of-the-art active learning algorithms.","With the rapid advancement in technology, the constant emergence of new applications and services has resulted in a drastic increase in Internet traffic, making it increasingly challenging for network analysts to maintain network security and classify traffic, especially when encrypted or tunneled. To address this issue, the proposed strategy aims to distinguish between regular traffic and traffic tunneled through a virtual private network and characterize traffic from seven different applications. The proposed approach utilizes various ensemble machine learning techniques, which are efficient and accurate and consume minimal computational time for training and prediction compared to conventional machine and deep learning models. These models were applied for both the classification and characterization of network traffic, deriving efficient results. The extreme and light gradient boosting algorithms performed well in multiclass classification, while AdaBoost and Light GBM performed well in binary classification. However, when all the datasets were merged and categorized into two classes and various feature engineering methods were applied, the proposed system achieved an accuracy of more than 99%, with minimal error scores using light GBM with min\u2013max scaling over stratified fivefold, thereby outperforming all existing approaches. This research highlights the efficiency and potential of the proposed model in detecting network traffic.","Deep neural networks (DNNs) achieve top performance through costly training on large datasets. Such resources may not be available in some scenarios, like IoT or healthcare. Extreme learning machines (ELMs) aim to alleviate this problem using single-layered networks, requiring fewer training resources. Current investigations have found that DNNs are prone to security and privacy threats, where malfunction of the network or training data extraction can be performed.\nDue to the increasing attention to ELMs and their lack of security investigations, we research the security implications of this type of network. Precisely, we investigate backdoor attacks in ELMs. We created a comprehensive experimental setup to evaluate their security in various datasets and scenarios. We conclude that ELMs are vulnerable to backdoor attacks with up to 97% attack success rate. Additionally, we adapt and evaluate the usage fine-pruning to ELMs.","This paper investigates the effectiveness of different deep learning HTR families, including LSTM, Seq2Seq, and transformer-based approaches with self-supervised pretraining, in recognizing ciphered manuscripts from different historical periods and cultures. The goal is to identify the most suitable method or training techniques for recognizing ciphered manuscripts and to provide insights into the challenges and opportunities in this field of research. We evaluate the performance of these models on several datasets of ciphered manuscripts and discuss their results. This study contributes to the development of more accurate and efficient methods for recognizing historical manuscripts for the preservation and dissemination of our cultural heritage.","Node classification is the task of predicting the labels of unlabeled nodes in a graph. State-of-the-art methods based on graph neural networks achieve excellent performance when all labels are available during training. But in real-life, models are often applied on data with new classes, which can lead to massive misclassification and thus significantly degrade performance. Hence, developing open-set classification methods is crucial to determine if a given sample belongs to a known class. Existing methods for open-set node classification generally use transductive learning with part or all of the features of real unseen class nodes to help with open-set classification. In this paper, we propose a novel generative open-set node classification method, i.e., G2Pxy, which follows a stricter inductive learning setting where no information about unknown classes is available during training and validation. Two kinds of proxy unknown nodes, inter-class unknown proxies and external unknown proxies are generated via mixup to efficiently anticipate the distribution of novel classes. Using the generated proxies, a closed-set classifier can be transformed into an open-set one, by augmenting it with an extra proxy classifier. Under the constraints of both cross entropy loss and complement entropy loss, G2Pxy achieves superior effectiveness for unknown class detection and known class classification, which is validated by experiments on benchmark graph datasets. Moreover, G2Pxy does not have specific requirement on the GNN architecture and shows good generalizations.","Deep Neural Network (DNN) inferences have been proven highly susceptible to carefully engineered adversarial perturbations, presenting a pivotal hindrance to real-world Computer Vision tasks. Most of the existing defenses have poor generalization ability due to their dependence on relatively limited Adversarial Examples (AE). Furthermore, the existing adversarial training necessitates continually retraining a target network with the sort of attack required to be repelled. The defense strategies that are primarily based on processing the perturbed image eventually fall short when pitted against constantly developing threats. Protection of DNN against adversarial attacks remains a difficult challenge on challenging datasets such as Fashion MNIST and CIFAR10. This paper proposes a GAN-based two-stage adversarial training model named Globally Connected and Trainable Hierarchical Fine Attention (GCTHFA). The first stage of the proposed GCTHFA GAN is to create a reconstructed image that is a purified version of an adversarial example. The proposed approach has used a trainable and globally linked attention map to teach the Generator about the different types of representations an image might have in different convolutional layers located at different levels in a network. The discriminator\u2019s reliance on feature vectors produced by transfer learning eliminates the traditional dependency on standard image pixels. The second step involves adversarial training of a target classifier to provide resistance to such attacks. Extensive testing on the MNIST, Fashion MNIST, and CIFAR10 datasets with different classifiers and attacks show that the proposed model can handle adversarial attack settings for various target models. The proposed model uses only one type of adversarial training, with no requirement for retraining based on the type of attack.","Electronic nose (e-nose) is composed of a set of gas sensors combined with a series of algorithmic models. The practical application of the electronic nose system can prove that the electronic nose is more widely used in the classification problems, and always has a good performance. Moreover, it can be inferred that classification methods significantly influence e-nose. So far, the classification models proposed in e-nose can generally be divided into two categories. One is the linear classifier, representing the model of the Bayesian classifier, principal component analysis (PCA), and K-nearest neighbour (KNN), etc. The other is the nonlinear classifier, including support vector machine (SVM), random forest (RF), and extreme learning machine (ELM), etc. This review aims to supply a summary of the various classification methods used in e-nose, and provides a reference for the choice of an appropriate classification model used in e-nose in the specific application.","With rapid development of single-cell multi-modal sequencing technologies, more and more multi-omics data come into being and provide a unique opportunity for the identification of distinct cell types at the single-cell level. Therefore, it is important to integrate different modalities which are with high-dimensional features for boosting final multi-omics data classification performance. However, existing multi-omics data classification methods mainly focus on exploiting the complementary information of different modalities, while ignoring the learning confidence and cross-modal sample relationship during information fusion. In this paper, we propose a multi-omics data classification network via global and cross-modal feature aggregation, referred to as GCFANet. On one hand, considering that a large number of feature dimensions in different modalities could not contribute to final classification performance but disturb the discriminability of different samples, we propose a feature confidence learning mechanism to suppress some redundant features, as well as enhancing the expression of discriminative feature dimensions in each modality. On the other hand, in order to capture the inherent sample structure information implied in each modality, we design a graph convolutional network branch to learn the corresponding structure preserved feature representation. Then the modal-specific feature representations are concatenated and input to a transformer induced global and cross-modal feature aggregation module for learning consensus feature representation from different modalities. In addition, the consensus feature representation used for final classification is enhanced via a view-specific consistency preserved contrastive learning strategy. Extensive experiments on four multi-omics datasets are conducted to demonstrate the efficacy of the proposed GCFANet.\nHighlights\n\u2022\nA feature aggregation network is proposed for multi-omics classification.\n\u2022\nA contrastive learning strategy is designed for feature representation alignment.\n\u2022\nBoth complementary information and sample structure are used for consensus learning.\n\u2022\nThe proposed network is successfully used for drug response prediction.","Cancer is a complicated illness that is caused by numerous gene mutations or deregulation of gene interactions. This study, on the other hand, proposes a unique method for cancer categorization. Cancer is the major reason of death in this era. Appropriate methods are required to diagnose it as early as possible so that accurate treatment should be started to save human lives. Heuristic Class Topper Optimization describes a vital role in the detection of cancer for classification. A large dataset of tumors has been taken and Naive Bayes classifier exported to categorize them. The Heuristic Class Topper Optimization method (HCTO) is planted to extract the features. The optimization technique is based on the intelligent learning of pupils in a classroom. Weak students are learning from the class topper. There are various class toppers based upon the number of sections. Thus, the characteristics are refined with the aid of HCTO. The HCTO algorithm is a novel artificial intelligence technology that is rapidly converging. The HCTO-NB technique is simple, less complex, accurate, and has a low error rate, all of which are important characteristics in cancer categorization. The recommended method\u2019s achieved parameters are accuracy of 97.6%, precision of 98.4, error rate decreased by 3% on 1000 iterations, and classification efficacy are all demonstrated. The results are also compared to the KNN classifier, which has been used to classify cancer by a number of studies in the past. Experiments on a range of datasets demonstrated that this novel method was more accurate and dependable by\u2009~\u200914% compared to KNN. The findings shows that the suggested approach is both rapid and accurate, making it a great alternative for cancer diagnosis in the real world. In this paper 4 types of cancers datasets with relevant features like age, Gender, Tumor size, Tumor area and smoker or non-smoker etc. have been used for real time validation.","Skin cancer is regarded as the hazardous as well as widespread disease. Worldwide, there is been a 53% increment in present melanoma cases annually, and the mortality rate is also expected to be increasing in the coming decade. Hence, it is an urgent requirement to design a new early-detection model so that skin cancer can be more treatable without many complications. This work focuses on recognising skin cancer. The model includes the median filter (MF)-based pre-processing. The pre-processed image is subjected to a modified fuzzy C means (FCM)-based segmentation process. Finally, the recognition is done by employing a hybrid model with bi-LSTM and ANN. The proposed model's error rate was 0.091694, whereas the greatest error values for the other approaches were 0.20377 for BOA, 0.62192 for BRO, 0.170028 for ALO, 0.17168 for AOA, and 0.187915 for FIREFLY.","In this study, we show the advantages of incorporating multi-source knowledge from publicly available sources, such as ChatGPT and Wikipedia, into existing datasets to enhance the performance of machine learning models for routine tasks, such as classification. specifically, we propose the utilization of supplementary data from external sources and demonstrate the utility of widely accessible knowledge in the context of the Forest Cover Type Prediction task launched by the Roosevelt National Forest of Northern Colorado. Additionally, we exhibit an improvement in classification accuracy for the Isolated Letter Speech Recognition dataset when incorporating information on regional accents in the prediction of spoken English letter names.","Pose-based approaches for sign language recognition provide light-weight and fast models that can be adopted in real-time applications. This article presents a framework for isolated Arabic sign language recognition using hand and face keypoints. We employed MediaPipe pose estimator for extracting the keypoints of sign gestures in the video stream. Using the extracted keypoints, three models were proposed for sign language recognition: Long-Term Short Memory, Temporal Convolution Networks, and Transformer-based models. Moreover, we investigated the importance of non-manual features for sign language recognition systems and the obtained results showed that combining hand and face keypoints boosted the recognition accuracy by around 4% compared with only hand keypoints. The proposed models were evaluated on Arabic and Argentinian sign languages. Using the KArSL-100 dataset, the proposed pose-based Transformer achieved the highest accuracy of 99.74% and 68.2% in signer-dependent and -independent modes, respectively. Additionally, the Transformer was evaluated on the LSA64 dataset and obtained an accuracy of 98.25% and 91.09% in signer-dependent and -independent modes, respectively. Consequently, the pose-based Transformer outperformed the state-of-the-art techniques on both datasets using keypoints from the signer\u2019s hands and face.","Recently, introducing nonconvex loss functions in support vector machine (SVM) to improve the robustness against varies noises has been drawing much attention. In this paper, we first construct a new robust capped asymmetric elastic net (CaEN) loss function. Second, we describe a novel robust Huberized kernel-based (HK) loss function and theoretically demonstrate several important properties, such as smoothness, boundness and the trade-off between the standard least squares and the truncated least squares. Finally, we apply the CaEN loss and the HK loss into elastic net nonparallel hyperplane SVM (ENNHSVM) to develop a fused robust geometric nonparallel SVM (FRGNHSVM). The proposed FRGNHSVM not only inherits the advantages of ENNHSVM but also improves the robustness of classification problems. An efficient Pegasos-based DC (difference of convex functions) algorithm is implemented to solve the FRGNHSVM optimization problem. In comparison with four famous SVMs, including Lagrangian SVM, twin SVM, pinball SVM and C-loss twin SVM, experimental results on simulations and twelve UCI datasets show that the proposed FRGNHSVM can often improve more than 5% average prediction accuracy. Moreover, the performance of the high prediction accuracy of FRGHNSVM is more significant along with the ratio of label noise increasing, indicating its superiority in dealing with label-contaminated datasets.\nHighlights\n\u2022\nA novel FRGNHSVM is proposed for robust binary learning problems.\n\u2022\nFRGNHSVM is stable for re-sampling and robust to outliers.\n\u2022\nThe designed Pegasos-based DC algorithm is scalable and applicable to large data.\n\u2022\nExperimental results demonstrate the effectiveness of FRGNHSVM.","Deep learning has shown promise in accurate medical image analysis, but challenges remain. Data privacy concerns hinder the availability of large, high-quality medical datasets. Traditional deep learning approaches are computationally intensive and lack efficiency. This paper proposes the use of Federated Learning (FL) with ResNet-18, a deep neural network architecture. ResNet-18 addresses gradient issues using residual blocks and skip connections. FL enables collaborative training while preserving data privacy. The training process utilizes stochastic gradient descent and techniques such as data augmentation and regularization for improved model performance.","Ensemble learning consists of combining the prediction of different learners to obtain a final output. One key step for their success is the diversity among the learners. In this paper, we propose to reach the diversity in terms of the classification complexity by guiding the sampling of instances in the Bagging algorithm with complexity measures. The proposed Complexity-driven Bagging algorithm complements the classic Bagging algorithm by considering training samples of different complexity to cover the complexity space. Besides, the algorithm admits any complexity measure to guide the sampling. The proposal is tested in 28 real datasets and for a total of 9 complexity measures, providing satisfactory and promising results and revealing that training with samples of different complexity, ranging from easy to hard samples, is the best strategy when sampling based on complexity.","Skip BACKGROUND: Section\nBACKGROUND:\nAlzheimer\u2019s disease (AD) endangers the physical and mental health of the elderly, constituting one of the most crucial social challenges. Due to lack of effective AD intervention drugs, it is very important to diagnose AD in the early stage, especially in the Mild Cognitive Impairment (MCI) phase.\nSkip OBJECTIVE: Section\nOBJECTIVE:\nAt present, an automatic classification technology is urgently needed to assist doctors in analyzing the status of the candidate patient. The artificial intelligence enhanced Alzheimer\u2019s disease detection can reduce costs to detect Alzheimer\u2019s disease.\nSkip METHODS: Section\nMETHODS:\nIn this paper, a novel pre-trained ensemble-based AD detection (PEADD) framework with three base learners (i.e., ResNet, VGG, and EfficientNet) for both the audio-based and PET (Positron Emission Tomography)-based AD detection is proposed under a unified image modality. Specifically, the effectiveness of context-enriched image modalities instead of the traditional speech modality (i.e., context-free audio matrix) for the audio-based AD detection, along with simple and efficient image denoising strategy has been inspected comprehensively. Meanwhile, the PET-based AD detection based on the denoised PET image has been described. Furthermore, different voting methods for applying an ensemble strategy (i.e., hard voting and soft voting) has been investigated in detail.\nSkip RESULTS: Section\nRESULTS:\nThe results showed that the classification accuracy was 92% and 99% on the audio-based and PET-based AD datasets, respectively. Our extensive experimental results demonstrate that our PEADD outperforms the state-of-the-art methods on both audio-based and PET-based AD datasets simultaneously.\nSkip CONCLUSIONS: Section\nCONCLUSIONS:\nThe network model can provide an objective basis for doctors to detect Alzheimer\u2019s Disease.","The core objective of this research is to develop a methodology for selecting a supervised machine learning classification technique based on the specific categories of objects that need to be classified. The study focuses on product categories extracted from Amazon's Product Reviews database, which are utilized to evaluate the subjectivity of post-purchase feedback. The primary supervised machine learning methods are utilized to efficiently perform the classification task. The resulting insights will enable the prioritization and choice of the best approach based on the selected categories. In the context of accelerated technological adoption due to the COVID-19 pandemic, this research contributes by showcasing how AI/ML can play a pivotal role in enhancing decision-making processes across various sectors and highlighting the significance of adapting to emerging technologies for sustainable growth.","A common method to perform the object classification with different images being taken at different views is to extract the features from each image without performing the fusion. On the other hand, this paper proposes a multivariate two dimensional singular spectrum analysis (M2DSSA) based approach to fuse the features in different images together to perform the object classification. First, a four channel two dimensional signal is formed using four images taken at four different views. Second, the M2DSSA is applied to the four channel two dimensional signal. Next, the histogram of the oriented gradient (Hog) is computed on each channel of each M2DSSA component. Then, the selection of the M2DSSA components is performed based on the correlation coefficients among these Hogs and the fusion of these images is performed via the M2DSSA. Next, the Hog of each reconstructed image is recomputed and these Hogs are employed as the features for the support vector machine to perform the object classification. Our proposed method yields the classification accuracies at 92.5925% and 97.8723% for the images in the first dataset and the second dataset, respectively. Since the information of the objects in different images is fused together, the computer numerical simulation results show that the classification accuracies of our proposed method are higher than those of the baseline method without performing the fusion and those of the other fusion methods.","Faults in photovoltaic (PV) systems significantly reduce their efficiency and can pose safety risks. Nevertheless, most residential PV systems are not actively monitored, because existing methods often require expensive sensors, which are only cost-effective for large PV systems. Therefore, we propose a graph neural network (GNN) to monitor a group of nearby PV systems without relying on dedicated sensors. Instead, the GNN compares 24 h of current and voltage measurements obtained from the inverters. Four GNN variants are experimentally compared using simulated data of six different PV systems in Colorado. Results show that all GNN variants outperform a state-of-the-art PV fault diagnosis method based on gradient boosted trees. Moreover, some GNN variants can even generalize to PV systems which were not in the training data, enabling monitoring of new PV systems without retraining.","The liver is a key organ in the human body that aids in the digestion of food, the elimination of toxins, and the storage of energy. Patients with liver disorders are on the rise all over the world. However, because the disorder's symptoms are unclear, it is difficult to diagnose it, which raises the disease's death rate. The study introduces novel fuzzy twin models for liver disease classification. In the first model, the membership is calculated based on the quadratic function called fuzzy twin kernel ridge regression-quadratic (FTKRR-Q). In the second model, we have calculated the fuzzy membership based on the centroid and named the model as fuzzy twin kernel ridge regression-centroid (FTKRR-C). For our research, the BUPA or liver disease dataset has been used from the UCI machine learning repository. Experimental results are compared with the twin support vector machine, kernel ridge regression classifier and twin kernel ridge regression classifier. The accuracy, sensitivity, F1-score, and Mathew's correlation coefficient are used to evaluate the suggested model's performance. Experiments are also carried out on some real-world benchmark datasets. The results reveal the applicability of the proposed models.","Skin cancer is the most prevalent type of cancer worldwide. Early detection is essential as it could be fatal at later stages. The classification of skin lesions is challenging since there are many variations, including changes in color, shape, size, high intra-class variation, and high inter-class similarity. In this paper, a unique class-wise attention method is proposed that considers each class equally while extracting additional discriminative information of skin lesions. The proposed attention mechanism is employed in a progressive manner to incorporate discriminative feature information from multiple scales. The proposed approach obtained competitive performance against more than 15 state-of-the-art methods including HAM1000 and ISIC 2019 leaderboard winners. The proposed method achieved 97.40% accuracy on the HAM10000 and 94.9% accuracy on the ISIC 2019 dataset.\nHighlights\n\u2022\nA novel attention based mechanism is proposed for skin lesions classification.\n\u2022\nThe problem of significant intra-class variance, high inter-class similarity, and class imbalance is addressed by a class-wise attention mechanism.\n\u2022\nThe important features for the classification are extracted without the burden of additional parameters using a progressive class-wise attention mechanism.\n\u2022\nThe final three layers of the baseline model are discarded and the global average pooling (GAP) and classification output layers are added to reduce the number of parameters, while maintaining performance.\n\u2022\nThe proposed network is robust, end-to-end trainable and has good generalization on unseen data.","Previously, single classification models were mainly studied to classify human protein cell images, i.e., to identify a certain protein based on a set of different cells. However, a classifier can identify only one protein, in fact, a single cell usually consists of multiple proteins, and the proteins are not completely independent of each other. In this paper, we build a human protein cell classification model by multi-label learning. The logical relationship and distribution characteristics among the labels are analyzed to determine the different proteins contained in a set of different cells (i.e., containing multiple elements in the output space). In this paper, using human protein image data, we conducted comparison experiments on pre-trained Xception and InceptionResnet V2 to optimize the two models in terms of data augmentation, channel settings, and model structure. The results show that the Optimized InceptionResnet V2 model achieves high performance in the classification task. The final accuracy of the Optimized InceptionResnet V2 model we obtained reached 96.1%, which is a 2.82% improvement relative to that before the optimized model.","Deep learning has been increasingly incorporated into various computational pathology applications to improve its efficiency, accuracy, and robustness. Although successful, most previous approaches for image classification have crucial drawbacks. There exist numerous tasks in pathology, but one needs to build a model per task, i.e., a task-specific model, thereby increasing the number of models, training resources, and cost. Moreover, transferring arbitrary task-specific model to another task is still a challenging problem. Herein, we propose a task-agnostic generative and general pathology image classifier, so called GPC, that aims at learning from diverse kinds of pathology images and conducting numerous classification tasks in a unified model. GPC, equipped with a convolutional neural network and a Transformer-based language model, maps pathology images into a high-dimensional feature space and generates pertinent class labels as texts via the image-to-text classification mechanism. We evaluate GPC on six datasets for four different pathology image classification tasks. Experimental results show that GPC holds considerable potential for developing an effective and efficient universal model for pathology image analysis.","Intelligent Transportation Systems (ITS) have experienced significant growth over the past decade thanks to advances in control, communication, and information technology applied to vehicles, roads, and traffic control systems. Vehicle type classification plays a vital role in implementing ITS because of its ability to collect useful traffic information, enable future development of transport infrastructures, and increase human comfort. As a branch of machine learning, deep learning represents a frontier for artificial intelligence, which seeks to be closer to its primary goal. Deep learning is a powerful tool for classifying vehicle types because it can capture complex traffic data characteristics and learn from large amounts of data. This means that it can be used to accurately classify traffic data and generate valuable insights that can be used to improve traffic management. Researchers have successfully adopted these algorithms as a solution to propose optimal vehicle-type classification strategies. This paper highlights the role of deep learning algorithms in solving the vehicle type classification problem, reviewing the state-of-the-art approaches in this field.","In this paper, we consider the problem of Novel Class Discovery (NCD) in Open Set Recognition (OSR). Given a labeled and an unlabeled set for training, NCD aims to discover the novel categories in the unlabeled set with prior knowledge learned from the labeled set. Existing approaches tackle the NCD problems under a close-set setting, where only the existing categories from the labeled set and the novel categories from the unlabeled set will occur during the inference. This paper considers a more realistic open-set scenario. In the open-set setting, in addition to the existing and novel categories, some unknown categories absent from the training could be present during inference. To address NCD in the open-set scenario, we propose the General Inter-Intra (GII) loss, a unified approach for learning representations from both labeled and unlabeled samples. The proposed approach discovers novel categories in the training set (NCD) meanwhile recognizes the unknown categories (OSR). We evaluate GII with image and graph datasets, and the results indicate that our proposed approach is more effective than other NCD and OSR approaches.","The problem of long-tailed recognition (LTR) has received attention in recent years due to the fundamental power-law distribution of objects in the real-world. Most recent works in LTR use softmax classifiers that are biased in that they correlate classifier norm with the amount of training data for a given class. In this work, we show that learning prototype classifiers addresses the biased softmax problem in LTR. Prototype classifiers can deliver promising results simply using Nearest-Class-Mean (NCM), a special case where prototypes are empirical centroids. We go one step further and propose to jointly learn prototypes by using distances to prototypes in representation space as the logit scores for classification. Further, we theoretically analyze the properties of Euclidean distance based prototype classifiers that lead to stable gradient-based optimization which is robust to outliers. To enable independent distance scales along each channel, we enhance Prototype classifiers by learning channel-dependent temperature parameters. Our analysis shows that prototypes learned by Prototype classifiers are better separated than empirical centroids. Results on four LTR benchmarks show that Prototype classifier outperforms or is comparable to state-of-the-art methods. Our code is made available at https://github.com/saurabhsharma1993/prototype-classifier-ltr.","Occupant presence and their behaviour in the built environment significantly impact energy consumption in buildings. Currently, building systems are often operated based on assumed occupancy and fixed schedules, or occupants manually adjust them for their comfort, which sometimes leads to energy wastage. Also, the inherent complexity and unpredictability of occupancy patterns can contribute to disparities between simulated and actual energy consumption, underscoring the importance of selecting suitable methods for occupancy prediction. Various methods, such as occupancy cameras, thermal imagers, Passive Infrared Sensors, and Radio-Frequency Identification, can collect occupancy information. However, they often come with limitations including cost, complexity, and invasiveness. Hence, there is a growing interest in creating occupancy prediction models using an indirect approach based on indoor air quality (IAQ) data. However, this indirect approach must be further explored within the building simulation field. In this study, we apply an approach based on the novel QLattice algorithm for occupancy detection, utilizing a minimal sensing strategy with a comprehensive set of IAQ data. Furthermore, we compare the QLattice algorithm\u2019s performance with that of traditional machine learning (ML) algorithms such as Support Vector Machines (SVM), Decision Trees (DT), and XGBoost using metrics including accuracy, precision, recall, F1 score, AUC-ROC values, and computational time. The QLattice algorithm outperforms traditional ML algorithms in all evaluation metrics, achieving over 90% accuracy on the test dataset. Additionally, compared to traditional black-box ML algorithms, QLattice stands out for its explainability and interpretability, providing insights useful in decision-making.","This paper introduces a novel approach to address the challenges of transfer learning, which aims to efficiently train a classifier for a new domain using supervised information from similar domains. Traditional transfer learning methods may fail to maintain the discriminative features of the target domain due to the scarcity of labelled data and the use of irrelevant source domain data distribution subspace, resulting in poor metrics. To overcome these challenges, the proposed approach, called KDADP, transforms the data distribution of both the source and target domains into a lower-dimensional subspace while preserving their discriminatory information. The KDADP model maximizes between-class variance and minimizes within-class variance with L1 penalization, enabling the recovery of the most useful characteristics and reducing the model\u2019s complexity. Experimental results on three real-world domain adaptation datasets demonstrate that the proposed KDADP model significantly improves classification performance and outperforms state-of-the-art primitive, shallow, and deeper domain adaptation methods.","Support vector classification (SVC) is a well-known statistical technique for classification problems in machine learning and other fields. An important question for SVC is the selection of covariates (or features) for the model. Many studies have considered model selection methods. As is well-known, selecting one winning model over others can entail considerable instability in predictive performance due to model selection uncertainties. This paper advocates model averaging as an alternative approach, where estimates obtained from different models are combined in a weighted average. We propose a model weighting scheme and provide the theoretical underpinning for the proposed method. In particular, we prove that our proposed method yields a model average estimator that achieves the smallest hinge risk among all feasible combinations asymptotically. To remedy the computational burden due to a large number of feasible models, we propose a screening step to eliminate the uninformative features before combining the models. Results from real data applications and a simulation study show that the proposed method generally yields more accurate estimates than existing methods.","Graph neural networks (GNNs) have emerged as a powerful tool for analyzing graph data, where data are represented by nodes and edges. However, the conventional methods have limitations in analyzing graphs with diverse attributes and preserving crucial information during the graph embedding. As a result, there is a possibility of losing crucial information during the integration of individual nodes. To address this problem, we propose an attention-based readout with subgraphs for graph embedding that partitions the graph according to unique node attributes. This method ensures that important attributes are retained and prevents dilution of distinctive node features. The adjacency matrices and node feature matrices for the partitioned graphs go into a graph isomorphism network (GIN) to aggregate the features, where the attention mechanism merges the partitioned graphs to construct the whole graph embedding vector. Extensive experiments on six graph datasets demonstrate that the proposed method captures various local patterns and produces superior performance against the state-of-the-art methods for graph classification. Especially, on the challenging IMDB-MULTI dataset, our method achieves a significant performance gain of 27.87%p over the best method called MA-GCNN.","Abstract\u2014The implementation of computational approaches for protein glycosylation site prediction is becoming popular since the experimental-validated glycosylation data became more abundant. Some of the data were found to be wrong after the experiment was again carried out with more sophisticated technology. To solve this issue, the latest state-of-the-art model trained the model based on a positive-unlabelled algorithm. The aim of this research is to explore the possibility of an approach applying a simple neural network algorithm and still achieve high classification performance. The model proposed in this research gave competitive results with fewer preprocessing steps. Increasing the accuracy of glycosylation site prediction can complement laboratory-based methods and is very useful for understanding the role of glycosylation.","Time series classification exists in widespread domains such as EEG/ECG classification, device anomaly detection, and speaker authentication. Although many methods have been proposed, efficient selection of intuitive temporal features to accurately classify time series remains challenging. Therefore, this paper presents TSC-RTF, a new time series classification method using random temporal features. First, to ensure the intuitiveness of the features, TSC-RTF selects subsequences containing important data points as candidates for intuitive temporal features. Then, TSC-RTF uses random sampling to reduce the number of candidates significantly. Next, TSC-RTF selects the final temporal features using a random forest to ensure the validity of the final temporal features. Finally, a deep learning classifier is trained by TSC-RTF to achieve high accuracy. The experimental results show that the proposed method can compete with the state-of-the-art methods.","With the enhancement of people's living standards and the rapid evolution of cyber-physical systems, residential environments are becoming smart and well-connected, causing a significant raise in overall energy consumption. As household appliances are major energy consumers, their accurate recognition becomes crucial to avoid unattended usage and minimize peak-time load on the smart grids, thereby conserving energy and making smart environments more sustainable. Traditionally, an appliance recognition model is trained at a central server (service provider) by collecting electricity consumption data via smart plugs from the clients (consumers), causing a privacy breach. Besides that, the data are susceptible to noisy labels that may appear when an appliance gets connected to a non-designated smart plug. While addressing these issues jointly, we propose a novel federated learning approach to appliance recognition, called FedAR+, enabling decentralized model training across clients in a privacy-preserving way even with mislabeled training data. FedAR+ introduces an adaptive noise handling method, essentially a joint loss function incorporating weights and label distribution, to empower the appliance recognition model against noisy labels. By deploying smart plugs in an apartment complex, we collect a labeled dataset that, along with two existing datasets, are utilized to evaluate the performance of FedAR+. Experimental results show that our approach can effectively handle up to 30% concentration of noisy labels while outperforming the prior solutions by a large margin on accuracy.","Often pieces of information are received sequentially over time. When did one collect enough such pieces to classify? Trading wait time for decision certainty leads to early classification problems that have recently gained attention as a means of adapting classification to more dynamic environments. However, so far results have been limited to unimodal sequences. In this pilot study, we expand into early classifying multimodal sequences by combining existing methods. Spatial-temporal transformers trained in the supervised framework of Classifier-Induced Stopping outperform exploration-based methods. We show our new method yields experimental AUC advantages of up to 8.7%.","Occupancy sensing and estimation in large commercial buildings has become a significant problem to be solved, with applications ranging from occupancy-based HVAC control to space planning, and security, etc. Thermal sensing is a promising technology to solve this problem, being easy to deploy in practice and allowing an actual occupancy count in a particular room without violating the data and privacy concerns. While initial strides have been made to solve this problem with thermal arrays, there are many problems that remain unsolved, including accuracy performance, overlapping of sensing areas that lead to under/over-counting, and data training requirements for different zones.\nIn this paper, we introduce TODOS 1, a novel system for estimating occupancy in intelligent buildings. TODOS uses a low-cost, low-power thermal sensor array along with a passive infrared sensor. We introduce a novel data processing pipeline that allows us to automatically extract features from the thermal images using an artificial neural network. Through an extensive experimental evaluation2, we show that TODOS provides occupancy detection accuracy of 98% to 100% under different scenarios. In addition, it solves the issue of occupancy over/under-counting by overlapping sensing areas when using multiple thermal sensors in large rooms. This is done by treating the entire area as a single input thermal image instead of partitioning the area into multiple thermal images individually processed. Furthermore, TODOS introduces a data augmentation technique that allows the generation of training data for rooms of different sizes and shapes, without requiring specific training data from each room. Using these data, TODOS can train specifically designed neural networks optimized for any room size and shape, and achieve almost the same level of occupancy detection accuracy in rooms where experimental labeled training data is available, making it a viable solution that generalizes to the different rooms in large buildings.","Emitter classification plays a crucial role in electronic support measurement systems. A data-driven model named Gaussian dynamic recurrent unit is proposed to accomplish the end-to-end emitter classification tasks, which is simplified based on the long short-term memory unit by using a Gaussian function to characterize the relationship between the input and the network state, and a learnable exponentially weighted average to update the states. The Gaussian function and the dynamic exponentially weighted average amplify the difference between the input signals from different classes. The parameter size and computational time of many emitter classification methods are measured. The results show that the model proposed in this paper has the highest parameter efficiency, and low computational and storage costs. The results on a real-world dataset show that the proposed model has the highest accuracy and stability. These advantages have important significance for deploying the model in practical applications.","Performance of the pseudo-label (PL)-based self-supervised training depends greatly on the quality of estimated PLs. Recent studies have shown that label noise can remarkably impact downstream performance. Recently, research has demonstrated that mixup regularization is effective against noise memorization. In this work, we extend this previous study by exploring several recent forms of mixup, namely 2-step interpolation double mixup to enhance model robustness, mixup over speech frames for better recognition at the frame-level, moment exchange mixup to encourage utilization of moment information of speaker speech as they can reveal speaker style, and virtual mixup training to regularize the areas in-between training points to be locally-Lipschitz and enforce consistent predictions. We analyze their effect on the generalization of some state-of-the-art speaker verification (SV) systems and explore their combination via different multi-task learning-based approaches. Our results show that the proposed mixup formulations are aligned with the SV task and that our proposed multi-task learning-based approach can be beneficial to improve the performance and robustness of SV systems.","Abstract: The electromyogram (EMG), also known as an EMG, is used to assess nerve impulses in motor nerves, sensory nerves, and muscles. EMS is a versatile tool used in various biomedical applications. It is commonly employed to determine physical health, but it also finds utility in evaluating emotional well-being, such as through facial electromyography. Classification of EMG signals has attracted the interest of scientists since it is crucial for identifying neuromuscular disorders (NMDs). Recent advances in the miniaturization of biomedical sensors enable the development of medical monitoring systems. This paper presents a portable and scalable architecture for machine learning modules designed for medical diagnostics. In particular, we provide a hybrid classification model for NMDs. The proposed method combines two supervised machine learning classifiers with the discrete wavelet transform (DWT). During the online testing phase, the class label of an EMG signal is predicted using the classifiers\u2019 optimal models, which can be identified at this stage. The simulation results demonstrate that both classifiers have an accuracy of over 98%. Finally, the proposed method was implemented using an embedded CompactRIO-9035 real-time controller.","Highlights\n\u2022\nExploring the effect of locally weighted learning with machine learning model.\n\u2022\nGain ratio are used to select the most important environmental factor.\n\u2022\nLWL-RS-ADT appears as an accurate model in assessing landslide susceptibility.\nAbstract\nAssessing landslide susceptibility and predicting the possibility of landslide event is the foundation and prerequisite for emergency response and management of landslide disaster. The target of current paper is to propose five integration models based on integrating locally weighted learning (LWL) with a radial basis function classifier (RBF), Fisher's linear discriminant (FLDA), quadratic discriminant analysis (QDA), a Credal decision tree (CDT), an alternating decision tree (ADT) and random subspace (RS) and the performance of five integration models were compared for modeling landslide susceptibility. Yongxin County from China was employed as a study area, 364 landslide locations and fifteen environmental factors were applied. The results demonstrate that the proposed LWL-RS-ADT model is more reliable and stable than the other models. Among the fifteen environmental factors, NDVI, lithology, and altitude are the very significant factors in the six models. It is concluded that the proposed integration models provide an effective way to predict the susceptibility of landslides.","Fine-grained visual classification (FGVC) is a difficult task due to the challenges of discriminative feature learning. Most existing methods directly use the final output of the network which always contains the global feature with high-level semantic information. However, the differences between fine-grained images are reflected in subtle local regions which often appear in the front of the network. When the texture of the background and object are similar or the proportion of the background is too large, the prediction will be greatly affected. In order to solve the above problems, this paper proposes multi-granularity feature fusion module (MGFF) and two-stage classification based on Vision-Transformer (ViT). The former comprehensively represents images by fusing features of different granularities, thus avoiding the limitations of single-scale features. The latter leverages the ViT model to separate the object from the background at a very small cost, thereby improving the accuracy of the prediction. We conduct comprehensive experiments and achieves the best performance in two fine-grained tasks on CUB-200-2011 and NA-Birds.\nHighlights\n\u2022\nA multi-granularity feature fusion module is proposed to solve the limitations of single-scale features.\n\u2022\nA two-stage classification based on Vision-Transformer is proposed to reduce background interference on predictions. By leveraging the ViT model, the object can be separated from the background and the details can be enlarged.\n\u2022\nExtensive experiments prove the superiority of our model. The visualization results illustrate that our two-stage classification can accurately localize objects and facilitate correct predictions.","Once novel malware is detected, threat reports are written by security companies that discover it. The reports often vary in the terminology describing the behavior of the malware making comparisons of reports of the same malware from different companies difficult. To aid in the automated discovery of novel malware, it was recently proposed that novel malware could be detected by identifying behaviors. This assumes that a core set of behaviors are present in most, if not all, malware variants. However, there is a lack of malware datasets that are labeled with behaviors. Motivated by a need to label malware with a common set of behaviors, this work examines automating the process of labeling malware with behaviors identified in malware threat reports despite the variability of terminology. To do so, we examine several techniques from the natural language processing (NLP) domain. We find that most state-of-the-art word embedding NLP methods require large amounts of data and are trained on generic corpora of text data\u2014missing the nuances related to information security. To address this, we use simple feature selection techniques. We find that simple feature selection techniques generally outperform word embedding methods and achieve an increase of 6% in the F.5-score over prior work when used to predict MITRE ATT&amp;CK tactics in threat reports. Our work indicates that feature selection, which has commonly been overlooked by sophisticated methods in NLP tasks, is beneficial for information security related tasks, where more sophisticated NLP methodologies are not able to pick out relevant information security terms.","Conversation disentanglement aims to identify and group utterances from a conversation into separate threads. Existing methods primarily focus on disentangling multi-party conversations with three or more speakers, explicitly or implicitly incorporating speaker-related feature signals to disentangle. Most existing models require a large amount of human annotated data for model training, and often focus on pairwise relations between utterances, not accounting much for the conversational context. In this work, we propose a multi-task learning approach with a contrastive learning objective, DiSC, to disentangle conversations between two speakers -- a user and a virtual speech assistant, for a novel domain of e-commerce. We analyze multiple ways and granularities to define conversation \"threads''. DiSC jointly learns the relation between pairs of utterances, as well as between utterances and their respective thread context. We train and evaluate our models on multiple multi-threaded conversation datasets that were automatically created, without any human labeling effort. Experimental results on public datasets as well as real-world shopping conversations from a commercial speech assistant show that DiSC outperforms state-of-the-art baselines by at least 3%, across both automatic and human evaluation metrics. We also demonstrate how DiSC improves downstream dialog response generation in the shopping domain.","Alzheimer's disease (AD) represents a prevalent, progressive neurodegenerative ailment marked by the gradual deterioration of memory and cognitive faculties. Resting-state functional magnetic resonance imaging (rs-fMRI) offers good specificity in AD by reflecting the early changes in the brain network. As a result, combining the popular deep learning methods with rs-fMRI brain network features has attracted a wide attention. In our experiment, A cohort comprising 325 participants, sourced from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database, was stratified into three distinct groups: Alzheimer's Disease (AD, 53), mild cognitive impairment (MCI, 140) and normal control (NC, 152). With the preprocessed rs-fMRI data, the functional brain networks were constructed. Though the obtained features of rs-fMRI network and clinical scales, one improved BrainNet-graph convolutional network (GCN) was proposed for AD classification. In the realm of performance assessment, we conducted a comparative analysis between our BrainNet-GCN model and the GCN model. Our proposed BrainNet-GCN demonstrated better capability than those of GCN with high accuracies (ACCs) of AD vs.MCI of 91.89%, MCI vs.NC of 91.38%, and AD vs.NC of 92.50% for binary classification, and with an improved ACC of 83.58% for multi-class classification. The proposed BrainNet-GCN using the combined features of rs-fMRI network and clincal scales demonstrated robust capability in AD classification owing to its high sensitivity and specificity.","\u2014Graph convolutional network (GCN) has attracted much attention in the field of hyperspectral image classification for its excellent feature representation and convolution on arbitrarily structured non-Euclidean data. However, most state-of-the-art methods build a graph utilize the distance measure, which makes it challenging to fully characterize the complex relationship of hyperspectral remote sensing data. Moreover, the hyperspectral image usually has uncertainty introduced by the problems of the spectral variability and noise interference. This article uses fuzzy theory to optimize the GCN and thus solve the uncertainty problem in hyperspectral images, and presents a novel fuzzy graph convolutional network (F-GCN) for hyperspectral image classification. By calculating the fuzzy similarity of samples, a robust graph is first built rather than using the traditional Euclidean distance method, which allows a better representation of the complex relationship between hyperspectral remote sensing data. Furthermore, the proposed network introduces fuzzy layers into the model to cope with the ambiguity of the hyperspectral image. Finally, the classification results for three real-world hyperspectral data sets to show its feasibility and effectiveness in hyperspectral image classification.","In texture classification, local binary pattern (LBP) is currently one of the most widely-concerned feature encoding models. Most existing LBP-based texture classification methods are usually limited to single-kind texture features. In fact, an across-domain fusion of LBP features with other features, such as image contours, could be another potential path to promote texture classification. To enhance the feature modeling ability of LBP-based methods, this paper firstly designs a Cellular Neural Network (CellNN) with recurrent convolutions, initially trained by a simplified simulated-annealing algorithm, to extract informative image contours. For better reliability, a new three-channel contour extractor of deep CellNNs (i . e ., dCellNNs) is proposed. This extractor contains the initially-trained CellNNs of more than three layers, and it is further optimized by fine-tuning parameters. Moreover, a new weighted-base algorithm is designed to fulfill the fusion of the multi-scale texture features by LBPs and the contour features by dCellNNs to enhance feature representation. Finally, these enhanced features are concatenated together to generate the final multi-scale features of given texture image. On texture datasets KTH, Brodatz, OTC12 and UIUC, experiment results verify that the across-domain fusion of multi-scale LBPs and dCellNNs is efficient in capturing &amp; enhancing texture features. With moderate feature dimensionality and computational costs, it could improve texture classification, acquiring an obvious accuracy increase on previous state-of-the-art ones, e.g., a rise of 2.58% on KTH-TIPS2b, a rise of 3.11% on Brodatz, a rise of 0.71% on OTC12 and a rise of 0.42% on UIUC.\nHighlights\n\u2022\nA multi-scale across-domain feature fusion of textures and contours is proposed.\n\u2022\nThe first deep model of CellNN (dCellNNs) with two-stage training is proposed.\n\u2022\nThe three-channel texture contour extractor of dCellNNs is designed.\n\u2022\nA weighted-base fusing is designed for the across-domain fusion of features.","A classification is a problem of identifying the category (or the class) of an unknown-class observation using past historical data. One important issue in a classification is a class imbalanced problem which typically finds in a classification where the proportion of the target class is significantly smaller than others. A traditional classifier normally misclassifies an instance from this target class, called the minority class, as noise due to the small number of instances. Modification of the classification algorithm to handle a class imbalanced problem is a challenging task, especially for a random forest. In the random forest algorithm, the bootstrapping step is used to generate several subsets from a training data by random sampling uniformly with replacement. Most bootstrapping subsets may not even contain instances from the minority class which guarantee decision tree components to misclassify instances from the minority class. A random tree algorithm that needs to generate the bootstrapping subsets for each decision tree must assure the distribution of minority instances. This paper proposes a random forest algorithm using quartile-pattern bootstrapping by leveraging mass-ratio-variance outlier factor and minority condensation decision tree to handle this problem. The mass-ratio-variance outlier factor is a score assigned to each instance that will give a large value to an outlier and give a low value to instances surrounded by other instances in the same class. To evaluate the performance of this proposed algorithm, two synthesized datasets are used in the experiments. The experimental results show significant improvement when a dataset is imbalanced. The performance from the test dataset via F1 with the proposed algorithm is better than the performance from the traditional random forest algorithm.","Deep Learning (DL) has enabled considerable increases in the accuracy of classification tasks in several domains, including Human Activity Recognition (HAR). It is well-known that when data distribution changes between the training and test datasets, the accuracy can drop, sometimes significantly. However, some variability sources in HAR, such as sensor orientation, are only sometimes considered when evaluating these models. Therefore, we must understand how much such changes could impact current DL architectures. In this paper, under an orientation variability scenario, we evaluate three common DL architectures, DeepConvLSTM, TinyHAR, and Attend-and-Discriminate, to quantify the performance drop attributed to this shift. Our results show that all architectures show performance drops on average, as expected, but participants are affected differently from them, so they would fall short for some in classification accuracy in real-life settings where orientation can change across the wearing sessions of one participant or across participants. The performance change is related to the difference in distribution distance.","Automated Machine Learning (AutoML) is a promising direction for democratizing AI by automatically deploying Machine Learning systems with minimal human expertise. The core technical challenge behind AutoML is optimizing the pipelines of Machine Learning systems (e.g. the choice of preprocessing, augmentations, models, optimizers, etc.). Existing Pipeline Optimization techniques fail to explore deep interactions between pipeline stages/components. As a remedy, this paper proposes a novel neural architecture that captures the deep interaction between the components of a Machine Learning pipeline. We propose embedding pipelines into a latent representation through a novel per-component encoder mechanism. To search for optimal pipelines, such pipeline embeddings are used within deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters of the pipeline embedding network using existing evaluations of pipelines on diverse collections of related datasets (a.k.a. meta-datasets). Through extensive experiments on three large-scale meta-datasets, we demonstrate that pipeline embeddings yield state-of-the-art results in Pipeline Optimization.","Hyperspectral image (HSI) classification has attracted significant interest among researchers owing to its diverse practical applications. Convolutional neural networks (CNNs) have been extensively utilized for HSI classification. However, the effectiveness of CNN-based approaches is constrained by the fixed size and structure of the convolutional kernels, as well as their incapacity to capture global features. Moreover, these networks are inadequate in modeling the sequential characteristics of data. Recently, a promising approach, window-based multi-head self-attention has emerged to address the limitations of CNNs and incorporate efficient sequence modeling capabilities. This paper introduces a novel method, multiscale 3D atrous convolution with a lightweight swin transformer (MACLST), that effectively combines the strengths of two networks to capture both local and global features at different scales in HSI classification. The MACLST is designed to process HSI cubes as input and employs a spectral\u2013spatial features extraction module based on multiscale 3D atrous convolution. This module involves parallel branches of 3D layers with varying atrous rates, enabling the extraction of features at multiple scales and resolutions. The extracted spectral\u2013spatial features are fused and passed to the lightweight Swin transformer module as linear embeddings. This module captures long-range dependencies and learns effective feature representations of HSI. To reduce computational complexity, the swin transformer module is simplified and consists of only two stages, offering a more efficient version of the original swin transformer. The proposed MACLST model is extensively evaluated on five widely used benchmark HSI datasets, and the experimental results validate its superiority over state-of-the-art approaches with an overall accuracy of 99.00%, 99.59%, 99.95%, 98.71%, and 94.98% on the Indian Pines, University of Pavia, Salinas Valley, Houston University 2013, and Houston University 2018 datasets, respectively.","The problem of biometric person identification on the basis of component-based face recognition is considered. It is shown that the face recognition system can be represented as a hierarchically organized multilevel system, in which an ensemble of local classifiers forms \u201csoft\u201d decisions about the images of individual components of a face belonging to given classes. Then, based on the integration of these decisions, the final decision on whether the recognized face belongs to one of the given classes is formed. The problems of constructing a local classifier model, as well as choosing an integrator of intermediate solutions of local classifiers, are formulated and solved.","Imbalanced datasets are commonly observed in various real-world applications, presenting significant challenges in training classifiers. When working with large datasets, the imbalanced issue can be further exacerbated, making it exceptionally difficult to train classifiers effectively. To address the problem, over-sampling techniques have been developed to linearly interpolating data instances between minorities and their neighbors. However, in many real-world scenarios such as anomaly detection, minority instances are often dispersed diversely in the feature space rather than clustered together. Inspired by domain-agnostic data mix-up, we propose generating synthetic samples iteratively by mixing data samples from both minority and majority classes. It is non-trivial to develop such a framework, the challenges include source sample selection, mix-up strategy selection, and the coordination between the underlying model and mix-up strategies. To tackle these challenges, we formulate the problem of iterative data mix-up as a Markov decision process (MDP) that maps data attributes onto an augmentation strategy. To solve the MDP, we employ an actor-critic framework to adapt the discrete-continuous decision space. This framework is utilized to train a data augmentation policy and design a reward signal that explores classifier uncertainty and encourages performance improvement, irrespective of the classifier's convergence. We demonstrate the effectiveness of our proposed framework through extensive experiments conducted on seven publicly available benchmark datasets using three different types of classifiers. The results of these experiments showcase the potential and promise of our framework in addressing imbalanced datasets with diverse minorities.","With the development of internet technology, cloud computing is becoming increasingly popular, and it has a wide range of applications in various fields, such as mobile payments and the Internet of Things. The big data model is a very important and valuable set of useful and unique information. This article mainly introduces the establishment of an object-oriented architecture-based machine learning system classification model using big data analysis methods, as well as the use of neural network algorithms to construct machine learning system classification patterns. Through examples, a comparative experiment is conducted to verify the effectiveness of traditional manual annotation modeling methods combined with parallel processing. Its experimental results show that the model has high accuracy, with an accuracy rate above 92% and a recall rate above 94%, and its F1 value is infinitely close to 1, indicating that the average accuracy and precision of the model is very high.","Diabetes is considered as one of the deadliest and chronic diseases which causes an increase in blood sugar. Many complications occur if diabetes remains untreated and unidentified. The tedious identifying process results in visiting of a patient to a diagnostic center and consulting doctor. But the rise in machine learning approaches solves this critical problem. The motive of this study is to design a model which can prognosticate the likelihood of diabetes in patients with maximum accuracy. Therefore three machine learning classification algorithms namely Decision Tree, SVM and Naive Bayes are used in this experiment to detect diabetes at an early stage. Experiments are performed on Pima Indians Diabetes Database (PIDD) which is sourced from UCI machine learning repository. The performances of all the three algorithms are evaluated on various measures like Precision, Accuracy, F-Measure, and Recall. Accuracy is measured over correctly and incorrectly classified instances. Results obtained show Naive Bayes outperforms with the highest accuracy of 76.30% comparatively other algorithms. These results are verified using Receiver Operating Characteristic (ROC) curves in a proper and systematic manner.","With the game market growing year by year, game developers find themselves in an extremely competitive scenario. To draw players attention towards their game and to engage them even more during gameplay, one alternative is to apply a Dynamic Difficulty Adjustment algorithm. But the problem of the DDA approach is usually not the algorithm itself, but the player classification step. Therefore, we created a generic Unity Plugin that, allied with a Python API, will be able to classify players, using unsupervised and supervised Machine Learning techniques, based on game telemetry. We also implemented our own simple DDA algorithm, to test how it would work allied with the online classification process. The results show that the DDA version outperforms the standard one in the Video-Game category (CEGE Framework). The resultant classification was 63% completely accurate and 100% partially accurate. Moreover, no other work was able to create a generic plugin that simplified the use of ML in the game development context, allowing to test 28 different algorithm combinations.","Infertility is a global issue. Total fertility rate declined from over 5 live births per woman in 1950\u20131955 to 2.5 births per woman in 2010\u20132015. Female infertility is 37% globally and 12.5% in India. Female infertility can be reduced by identifying and treating the underlying cause early. Ovulatory diseases contribute 25% globally to female infertility. Various female pelvic imaging methods can diagnose ovulatory problems. Diagnostic ultrasound is chosen because it is radiation- and contrast-free and cost-effective. The intensity-based grouping and textural data were used for the detection of follicles and cysts in the ovary, which is based on machine learning (ML). Ovarian diagnosis was given a major boost thanks to the application of machine-learning algorithms, which permitted a success rate of 97% and significantly improved the overall quality of the process. Standard machine-learning strategies have been looked into for the purpose of ovarian classification. In order to determine which method of classification produces the most accurate findings, we constructed three distinct models utilising artificial neural networks, discriminant classifiers, and support vector machines. When the results of the various created classifiers were compared, it was discovered that SVM had the highest accuracy (98.5%). This ingenious tool, which may be classified as a decision support system, will assist the attending physician in reaching the appropriate determination and preventing an error in his or her interpretation.","Brain computer interface (BCI), has been one of the most popular domains in computing in the recent years. BCI is a pathway which allows communication between computers and the human brain. We acquire real time EEG data with the device, Neurosky Mindwave Mobile, which uses a single dry electrode. Experiment for acquisition of data is carried on 40 subjects (33 male and 7 female). Feature extraction of EEG signals are done by statistical measures such as mean, standard deviation, maximum and minimum amplitudes. In this paper we explore the approach of ensemble learning with classifiers such as random forest classifier to build a BCI model to predict mental states as concentration and meditation. Analysis and results of our proposed model shows an accuracy of 75% using the above methodologies. This model is further implemented in the field of Internet of Things (IoT), for the application of home automation.","Highlights\n\u2022\nWe present a mathematical framework to learn invariance to certain image transformations.\n\u2022\nThe method is computationally efficient, data-efficient, and has no hyper-parameters.\n\u2022\nThe method is robust where the training and testing distributions are different.\n\u2022\nFreely available software implementing the proposed method is provided.\nAbstract\nDeep convolutional neural networks (CNNs) are broadly considered to be state-of-the-art generic end-to-end image classification systems. However, they are known to underperform when training data are limited and thus require data augmentation strategies that render the method computationally expensive and not always effective. Rather than using a data augmentation strategy to encode invariances as typically done in machine learning, here we propose to mathematically augment a nearest subspace classification model in sliced-Wasserstein space by exploiting certain mathematical properties of the Radon Cumulative Distribution Transform (R-CDT), a recently introduced image transform. We demonstrate that for a particular type of learning problem, our mathematical solution has advantages over data augmentation with deep CNNs in terms of classification accuracy and computational complexity, and is particularly effective under a limited training data setting. The method is simple, effective, computationally efficient, non-iterative, and requires no parameters to be tuned. Python code implementing our method is available at https://github.com/rohdelab/mathematical_augmentation. Our method is integrated as a part of the software package PyTransKit, which is available at https://github.com/rohdelab/PyTransKit.","To provide researcher and operation personnel with recommendations on the condition of equipment so as to ensure the safe, reliable, and smooth operation of the EAST-NBI (Experimental Advanced Superconducting Tokamak Neutral Beam Injection) power system, we propose a memory attention mechanism MacBERT (MLM as correction Bidirectional Encoder Representation from Transformers) text classification model. Firstly, we use MacBERT to generate word vectors containing context, which alleviates the masking differences in pre-training and fine-tuning phases. Secondly, the deep features are further extracted and important parts are highlighted through the memory attention module. Finally, the Linear layer and Softmax layer are used to find the label with the highest predicted probability. Experimental results show that the proposed model performs well in the classification of maintenance records for the EAST-NBI power system, which shows certain research significance.","Large-scale natural soundscapes are remarkably complex and offer invaluable insights into the biodiversity and health of ecosystems. Recent advances have shown promising results in automatically classifying the sounds captured using passive acoustic monitoring. However, the accuracy performance and lack of transferability across diverse environments remains a challenge. To rectify this, we propose a robust and flexible ecoacoustics sound classification grid search-based framework using optimised machine learning algorithms for the analysis of large-scale natural soundscapes. It consists of four steps: pre-processing including the application of spectral subtraction denoising to two distinct datasets extracted from the Australian Acoustic Observatory, feature extraction using Mel Frequency Cepstral Coefficients, feature reduction, and classification using a grid search approach for hyperparameter tuning across classifiers including Support Vector Machine, k-Nearest Neighbour, and Artificial Neural Networks. With 10-fold cross validation, our experimental results revealed that the best models obtained a classification accuracy of 96% and above in both datasets across the four major categories of sound (biophony, geophony, anthrophony, and silence). Furthermore, cross-dataset validation experiments using a pooled dataset highlight that our framework is rigorous and adaptable, despite the high variance in possible sounds at each site.","Crop disease is a major threat to agricultural production. Reduced yield due to crop diseases can lead to immeasurable economic losses. Therefore, the detection and classification of crop diseases are of great significance. Based on AlexNet, VggNet, ResNet, and DenseNet, this paper presents an Ensemble Network improve the recognition accuracy. In this study, firstly training four CNN models by randomly sampling the dataset. Before that, these CNN were improved by batch normalization and global average pooling to accelerate convergence, designed a dynamic concatenated ReLU, an improved activation function on ReLU, to improved detection performance. We use focal loss to solve data imbalance. Then weighted voting is used to fuse the four CNN models. Finally, we verify that the EnsembleNet can effectively improve the recognition performance compared with a single network. Verified improvement in recognition performance on our datasets, obtained from PlantVillag.org, containing 4577 citrus leaf images of three categories. The maximum test accuracy in identifying citrus leaf diseases was as high as 93.58\n%\n. Compared with single network, our EnsembleNet can significantly performance. The experimental results showed that this method can be practically applied to the identification of citrus leaf diseases and provides a basis for the identification of other plant leaf diseases.","Few-shot open-set recognition (FSOSR) has become a great challenge, which requires classifying known classes and rejecting the unknown ones with only limited samples. Existing FSOSR methods mainly construct an ambiguous distribution of known classes from scarce known samples without considering the latent distribution information of unknowns, which degrades the performance of open-set recognition. To address this issue, we propose a novel loss function called multirelation margin (MRM) loss that can plug in few-shot methods to boost the performance of FSOSR. MRM enlarges the margin between different classes by extracting the multi-relationship of paired samples to dynamically refine the decision boundary for known classes and implicitly delineate the distribution of unknowns. Specifically, MRM separates the classes by enforcing a margin while concentrating samples of the same class on a hypersphere with a learnable radius. In order to better capture the distribution information of each class, MRM extracts the similarity and correlations among paired samples, ameliorating the optimization of the margin and radius. Experiments on public benchmarks reveal that methods with MRM loss can improve the unknown detection of AUROC by a significant margin while correctly classifying the known classes.","When employing supervised machine learning to analyze network traffic, the heart of the task often lies in developing effective features for the ML to leverage. We develop GGFAST, a unified, automated framework that can build powerful classifiers for specific network traffic analysis tasks, built on interpretable features. The framework uses only packet sizes, directionality, and sequencing, facilitating analysis in a payload-agnostic fashion that remains applicable in the presence of encryption.\nGGFAST analyzes labeled network data to identify n-grams (\"snippets\") in a network flow's sequence-of-message-lengths that are strongly indicative of given categories of activity. The framework then produces a classifier that, given new (unlabeled) network data, identifies the activity to associate with each flow by assessing the presence (or absence) of snippets relevant to the different categories.\nWe demonstrate the power of our framework by building---without any case-specific tuning---highly accurate analyzers for multiple types of network analysis problems. These span traffic classification (L7 protocol identification), finding DNS-over-HTTPS in TLS flows, and identifying specific RDP and SSH authentication methods. Finally, we demonstrate how, given ciphersuite specifics, we can transform a GGFAST analyzer developed for a given type of traffic to automatically detect instances of that activity when tunneled within SSH or TLS.","Deep learning-based incipient fault diagnostic techniques have achieved surprisingly well in wind turbines. Due to component failures, wind turbines must undergo active maintenance, substantially influencing revenue and power generation. Unfortunately, there are consistently uneven data distributions between samples with faults and those without faults, resulting in incorrect fault classification. Wind turbine fault classification has a significant data imbalance problem, compromising learning attention for majority and minority classes. Machine learning methodologies based on Generative Adversarial Networks (GAN), over-sampling, and under-sampling techniques for generating synthetic data have been widely employed to address the imbalance data problem. However, the traditional synthetic minority oversampling technique (SMOTE) accomplishes oversampling using linear interpolation between close minority class samples, which could be confusing, subpar, and indistinguishable from the majority class. This study suggests combining over and under-sampling using adaptive SMOTE and edited nearest neighbors (ASMOTE-ENN) that incorporate over-sampling with adaptive SMOTE and under-sampling with ENN to improve the quality of the generated samples. With this resampling technique, noise in an imbalanced dataset is reduced on three levels by using an adaptive nearest neighbor selection algorithm to find the nearest neighbors that are visible. Then use SMOTE to create samples that precisely fall into the minority class, and later use the ENN technique to eliminate instances that contribute to noise afterwards. Resampling data created by combining over- and under-sampling approaches to match the data distribution over all classes is the foundation of the suggested method\u2019s efficacy. A hybrid ensemble method is used for effective classification, including boosting, bagging, and stacking techniques. The original unbalanced and balanced data using the ASMOTE-ENN algorithm were classified using the proposed hybrid ensemble method. The classification results show that the proposed strategy is more accurate than a few imbalanced fault diagnosis techniques.\nHighlights\n\u2022\nTo gain complete knowledge, characteristics of SCADA data are obtained using data analysis.\n\u2022\nWe present the adaptive SMOTE-ENN algorithm-based data resampling technique to deal with imbalanced data.\n\u2022\nCreate a hybrid ensemble classification technique to identify faulty and no-fault events effectively.\n\u2022\nThe results demonstrate that the suggested method outperforms the most popular ML techniques.","Speech emotion recognition (SER) is a crucial aspect of affective computing and human-computer interaction, yet effectively identifying emotions in different speakers and languages remains challenging. This paper introduces SER-Fuse, a multi-modal SER application that is designed to address the complexities of multiple speakers and languages. Our approach leverages diverse audio/speech embeddings and text embeddings to extract optimal features for multi-modal SER. We subsequently employ multi-feature fusion to integrate embedding features across modalities and languages. Experimental results archived on the English-Chinese emotional speech (ECES) dataset reveal that SER-Fuse attains competitive performance in the multi-lingual approach compared to the single-lingual approaches. Furthermore, we provide the implementation of SER-Fuse for download at https://github.com/nhattruongpham/SER-Fuse to support reproducibility and local deployment.","Artificial neural networks are being used in many fields for different purposes. Medical diagnosis is one of the major purposes. In the field of medical, classification plays an important role as the main aim of the doctor is to classify whether a person is suffering from the disease or not. The objective of this paper is to evaluate neural network for the detection of alopecia in human beings and to find the accuracy. With the help of proposed model, the clinical experts will be able to get a second opinion that will help them to take proper decisions for diagnosing the presence of this disease in patients. This second opinion is crucial due to many factors while doing disease identification. These factors include increased population, environmental pollution, growing demands for proper medication, and less availability of medical experts to cope up with this increasing demand. Also, the dynamic nature of disease symptoms plays an important role in correct diagnosis of a certain disease. The proposed system uses a feedforward artificial neural network and backpropagation algorithm to classify patients with alopecia and without alopecia. The evaluation of the proposed system is done with the help of performance plot as well as regression plot. Experimental results show that the accuracy of proposed system is 91% which is reliable enough for a clinical expert to make his decisions.","Skip Abstract Section\nAbstract\nThe earth\u2019s ecology is well balanced and protected by forests. On the other hand, forest fires affect forest resources, thus causing both economical and ecological losses. Hence, preserving forest resources from fires is very essential to reduce environmental disasters. Controlling forest fire at an early stage is necessary to control their spread. This requirement enforces the necessity of fast and reliable fire detection algorithms. In this paper, a color models aware dynamic feature extraction for forest fire detection using machine learning classifiers is proposed to achieve early detection of fire and reduced false alarm rate. The proposed algorithm extracts fire detection index, wavelet energy, and gray level co-occurrence matrix features from RGB, L*a*b*, and YCbCr color models respectively to train the machine learning classifiers. The performance of the proposed model is analysed using various machine learning algorithms and the standard classification metrics. The proposed color-aware feature extraction gives precision, recall, F1-score, and accuracy of 99, 95, 94, and 97% respectively for the K-nearest neighbourhood model. The support vector machine model delivers 98, 95, 93, and 96.5% respectively. The accuracy of the proposed model is improved by a minimum of 3%, and a maximum of 11% than other color models. Similarly, the false rate reduction is a minimum of 5% and a maximum of 17% than other models.","Multi-label feature selection, which addresses the challenge of high dimensionality in multi-label learning, has wide applicability in pattern recognition, machine learning, and related domains. Most existing studies on multi-label feature selection assume that all labels have the same importance with respect to features, however, they overlook the differences between labels and candidate features relative to selected features and the internal influence of the label space. To address this issue, we propose a novel method for multi-label feature selection that accounts for both the strongly relevant label gain and the label mutual aid. Firstly, we advance two new potential relationships between labels and candidate features relative to selected features, and the label discriminant function is introduced. Secondly, the mutual aid information between labels is presented to describe the internal correlation of the label space. Thirdly, the concept of strongly relevant label gain is defined based on the label discriminant function, which allows better exploration of positive correlation between features. Finally, the experimental results on sixteen multi-label benchmark datasets indicate that the proposed method outperforms other compared representative multi-label feature selection methods.\nHighlights\n\u2022\nTwo relationships are proposed from the perspective of fuzzy information measures.\n\u2022\nA label discriminant function is defined according to two proposed relationships.\n\u2022\nStrongly relevant label gain is proposed based on the label discriminant function.\n\u2022\nThe label mutual aid is defined based on fuzzy conditional mutual information.\n\u2022\nA novel multi-label feature selection algorithm is proposed.","Psychological changes in humans are the result of emotions which occur due to activities in daily life. To understand these changes in behavioral pattern, research on a ective computing has emerged. Emotions are an integral part of our daily lives, based on which in this paper an investigation have been made to analyze the impact of positive and negative emotions using Electroencephalogram (EEG). Three classes of emotions namely calm, anger and happiness have been studied. The EEG signals are recorded in real time from 10 subjects while watching di erent emotions video clips of 2 minutes each. Next, the fractal dimension feature has been extracted from raw EEG. To further detect emotional states, the extracted features have been classified using Support Vector Machine (SVM) with radial basis function (RBF) kernel with an average accuracy of 60%. The proposed methodology shows that emotions recognition is possible from EEG signals.","Large training data and expensive model tweaking are standard features of deep learning with images. As a result, data owners often utilize cloud resources to develop large-scale complex models, which also raises privacy concerns. Existing cryptographic solutions for training deep neural networks (DNNs) are too expensive, cannot effectively utilize cloud GPU resources, and also put a significant burden on client-side pre-processing. This article presents an image disguising approach: DisguisedNets, which allows users to securely outsource images to the cloud and enables confidential, efficient GPU-based model training. DisguisedNets uses a novel combination of image blocktization, block-level random permutation, and block-level secure transformations: random multidimensional projection (RMT) or AES pixel-level encryption (AES) to transform training data. Users can use existing DNN training methods and GPU resources without any modification to training models with disguised images. We have analyzed and evaluated the methods under a multi-level threat model and compared them with another similar method\u2014InstaHide. We also show that the image disguising approach, including both DisguisedNets and InstaHide, can effectively protect models from model-targeted attacks.","With the exceeding advancement in technology, the sophistication of attacks is considerably increasing. Standard security methods fall short of achieving the security essentials of IoT against physical attacks due to the nature of IoTs being resource-constrained elements. Physical Unclonable Functions (PUFs) have been successfully employed as a lightweight memoryless solution to secure IoT devices. PUF is a device that exploits the integrated circuits\u2019 inherent randomness originated during the fabrication process to give each physical entity a unique identifier. Nevertheless, because PUFs are vulnerable to mathematical clonability, Feed-Forward Arbiter PUF (FF PUF) was introduced to withstand potential attack methods. Motivated by the necessity to expose a critical vulnerability of the standard FF PUFs design, we introduce a problem-tailored adversarial model to attack FF PUF design using a carefully engineered loop-specific neural network-based design calibrated and trained using FPGA-based in-silicon implementation data to exhibit real-world attacking scenarios posed on FF PUFs, in addition to applying simulated data. The empirical results show that the proposed adversarial model adds outperforming results to the existing studies in attacking FF PUFs, manifesting the improved efficiency in breaking FF PUFs. We demonstrate our high-performing results in numerical experiments of language modeling using the deep Neural Networks method.","As pests can cause heavy crop losses, integrated pest management is a vital aspect of agriculture. In general, pest recognition is essential to the integrated pest management. Many studies have explored how to achieve automatic pest recognition using computer vision and artificial intelligence techniques. However, most existing methods did not consider the class ambiguity problem. That is, a pest image may belong to multiple possibly true categories, but only one possible class label is assigned to the pest image. To close the above gap, this study converted the conventional one-label pest classification task into a multi-label one. In detail, the state-of-the-art deep network, Swin Transformer, was first modified to enable the predicted scores of possible classes to approximate one simultaneously by replacing the fully connected soft-max layer with a sigmoid activation layer. Then, a two-stage supervised learning algorithm using the binary cross entropy loss and the novel soft binary cross entropy loss was designed to train the Swin-Transformer-based multi-label classification model with single-label images. Experiments on the IP102 image dataset showed that the proposed method obtained the highest F 1-score value of 60.83%. It outperformed the second-best one by a margin of 7.52%. In conclusion, the proposed method can tackle the pest class ambiguity problem on IP102 better.\nHighlights\n\u2022\nExploit the multi-label classification to tackle the pest class ambiguity problem.\n\u2022\nDevelop a modified Swin-Transformer-based multi-label classification model.\n\u2022\nPropose the soft binary cross entropy loss to train the model with single-label images.","Multiple instance learning (MIL) is a classic weakly supervised learning approach, in which samples are grouped into bags that may contain varying numbers of instances. A bag is designated as positive if it contains at least one positive instance; otherwise, it is considered negative. Previous studies have consistently assumed that the bag labels are completely known. In fact, labeling every bag can be extremely challenging or even unfeasible due to the exorbitant expenses in terms of time and labor. Fortunately, it is much easier to obtain the similarity confidence, which represents the probability of two bags sharing the same label. How to employ it in MIL is worthy of study. Inspired by the above study, we present the first attempt to investigate MIL from similarity-confidence bags. Therefore, this paper proposes a new framework for training bag-level classifiers that adheres to the principle of empirical risk minimization. Moreover, we theoretically derive a generalization error bound to guarantee model convergence. Finally, we implement risk correction to mitigate potential over-fitting problem and provide theoretical consistency. Numerical experiments on eight datasets further validate the effectiveness of the proposed bag-level classifier.\nHighlights\n\u2022\nWe first explore MIL from similarity-confidence bags that makes sense in many scenes.\n\u2022\nWe propose an unbiased estimator at bag-level that does not rely on loss or optimizer.\n\u2022\nWe introduce a method for estimating unknown prior probability.\n\u2022\nWe derive a theoretical error bound and a optimal parameter convergence rate.\n\u2022\nWe employ risk correction methods to mitigate over-fitting and derive the consistency.","Multi-view data containing complementary and consensus information can facilitate representation learning by exploiting the intact integration of multi-view features. Because most objects in the real world often have underlying connections, organizing multi-view data as heterogeneous graphs is beneficial to extracting latent information among different objects. Due to the powerful capability to gather information of neighborhood nodes, in this article, we apply Graph Convolutional Network (GCN) to cope with heterogeneous graph data originating from multi-view data, which is still under-explored in the field of GCN. In order to improve the quality of network topology and alleviate the interference of noises yielded by graph fusion, some methods undertake sorting operations before the graph convolution procedure. These GCN-based methods generally sort and select the most confident neighborhood nodes for each vertex, such as picking the top-k nodes according to pre-defined confidence values. Nonetheless, this is problematic due to the non-differentiable sorting operators and inflexible graph embedding learning, which may result in blocked gradient computations and undesired performance. To cope with these issues, we propose a joint framework dubbed Multi-view Graph Convolutional Network with Differentiable Node Selection (MGCN-DNS), which is constituted of an adaptive graph fusion layer, a graph learning module, and a differentiable node selection schema. MGCN-DNS accepts multi-channel graph-structural data as inputs and aims to learn more robust graph fusion through a differentiable neural network. The effectiveness of the proposed method is verified by rigorous comparisons with considerable state-of-the-art approaches in terms of multi-view semi-supervised classification tasks, and the experimental results indicate that MGCN-DNS achieves pleasurable performance on several benchmark multi-view datasets.","Neurodegenerative disorders like Alzheimer\u2019s disease (AD) are irreversible and show atrophies in the area of the cerebral cortex of brain. AD leads to loss of memory and other cognitive impairments. The AD subjects are evaluated based on magnetic resonance imaging scans. The data may have the problem of class imbalance, noise and outliers which is a great challenge for classification. Support vector machines and twin support vector machine-based classifiers may not effectively deal with these problems as both these models assume that all the samples are equally important for the separating hyperplane. To overcome these issues, we propose intuitionistic fuzzy least square twin support vector machine for class imbalance problems (IFLSTSVM) and class specific-IFLSTSVM (CS-IFLSTSVM). To minimize the effects of class imbalance, the samples are appropriately weighted to minimize their effect on the optimal hyperplane. Moreover, we use intuitionistic fuzzy scores to overcome the issues of noise and outliers. Intuitionistic fuzzy score values generate appropriate weights by considering both the distance of the samples from the class centroid as well as the heterogeneity of the samples. The proposed models IFLSTSVM and CS-IFLSTSVM are efficient as they need to solve a system of linear equations. In Alzheimer\u2019s disease diagnosis, the proposed IFLSTSVM and CS-IFLSTSVM models showed better performance in MCI_vs_AD and CN_vs_MCI cases, respectively. Moreover, the proposed models showed better performance in the diagnosis of breast cancer classification. The statistical analysis carried out over KEEL and UCI data leads to the superiority of the proposed models. The source code of the proposed model is available at https://github.com/mtanveer1/Diagnosis-of-Alzheimer-s-disease-via-Intuitionistic-fuzzy-least-squares-twin-SVM.\nHighlights\n\u2022\nTo handle the CIL issue, training data are assigned weights based on imbalance ratio.\n\u2022\nThe regularization term improves the generalization performance of proposed models.\n\u2022\nThe proposed models solve system of linear equations. Hence, it is very efficient.\n\u2022\nThe weights reduce the impact of noise/outliers in classifying imbalanced data.\n\u2022\nThe results on biomedical and UCI data show the superiority of proposed models.","This paper provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.","Classification of normal vs. pathological infant cry is a socially relevant and challenging problem. Many feature sets, such as Mel Frequency Cepstral Coefficients (MFCC), Linear Frequency Cepstral Coefficients (LFCC), and Constant Q Cepstral Coefficients (CQCC) have been used for this task. However, an effective representation of the spectral and pitch components of a spectrum together is not achieved leaving scope for improvement. Also, the infant cry can be considered a melodic sound implying that the fundamental frequency and timbre-based features also carry vital information. This work proposes Constant Q Harmonic Coefficients (CQHC), and Constant Q Pitch Coefficients (CQPC) extracted by the decomposition of the Constant Q Transform (CQT) spectrum for the infant cry classification. This work uses Convolutional Neural Network (CNN) as the classifier along with traditional classifiers, such as Gaussian Mixture Models (GMM) and Support Vector Machines (SVM). The results using the CNN classifier are compared by considering the MFCC, LFCC, and CQCC feature sets as the baseline features. The feature-level fusion of MFCC with log-CQHC and MFCC with log-CQPC achieved a 5-fold accuracy of 98.73% and 98.96% respectively, surpassing the baseline MFCC. Furthermore, the fusion of MFCC with log-CQHC and log-CQPC feature sets resulted in improved classification accuracy of 3%, 4.7%, and 5.85% when compared with the baseline MFCC, LFCC, and CQCC feature sets, respectively. Further, our intensive experiments using three classifiers structures, namely, GMM, SVM, and CNN indicate superior results using the proposed feature extraction techniques.","Multi-view learning aims to leverage data acquired from multiple sources to achieve better performance compared to using a single view. However, the performance of multi-view learning can be negatively impacted by noisy or corrupted views in certain real-world situations. As a result, it is crucial to assess the confidence of predictions and obtain reliable learning outcomes. In this paper, we introduce CALM, an enhanced encoding and confidence evaluation framework for trustworthy multi-view classification. Our method comprises enhanced multi-view encoding, multi-view confidence-aware fusion, and multi-view classification regularization, enabling the simultaneous evaluation of prediction confidence and the yielding trustworthy classifications. Enhanced multi-view encoding takes advantage of cross-view consistency and class diversity to improve the efficacy of the learned latent representation, facilitating more reliable classification results. Multi-view confidence-aware fusion utilizes a confidence-aware estimator to evaluate the confidence scores of classification outcomes. The final multi-view classification results are then derived through confidence-aware fusion. To achieve reliable and accurate confidence scores, multivariate Gaussian distributions are employed to model the prediction distribution. The advantage of CALM lies in its ability to evaluate the quality of each view, reducing the influence of low-quality views on the multi-view fusion process and ultimately leading to improved classification performance and confidence evaluation. Comprehensive experimental results demonstrate that our method outperforms other trusted multi-view learning methods in terms of effectiveness, reliability, and robustness.","Recently meta-learning-based few-shot learning methods have been widely used for relation classification. Previous work reveals that meta-learning performs poorly in scenarios where the edge probability distribution of the target domain dataset appears to be significantly different from the source domain. In this paper, we enhance the meta-learning framework with high-dimensional semantic feature extraction and hyperplane projection metrics for meta-tasks. First, we enhance the focus of BERT on entity words by adding entity markers and vector pooling. After that, the high-dimensional semantic features of the support set are extracted and transformed into hyperplanes. Finally, we obtain the classification results by calculating the projection distance between the query sample and the hyperplane. In addition, we design a auxiliary function with a plane correction factor, which can better amplify the plane spacing and reduce the degree of category confusion, which is important for solving the problem of metric spatial loss. Experiments on two real-world few-shot datasets show that our model HPN is more effective in classifying few-shot relations in the same domain and domain-adapted scenarios. And HPN is more stable on NOTA tasks.\nHighlights\n\u2022\nA hyperplane projection network is proposed for few shot relation classification.\n\u2022\nPropose an effective entity encoder that extracts better features.\n\u2022\nFirst apply a novel hyperplane module to generate class-level feature.","Face shape classification plays a crucial role in various applications, including facial recognition and personalized beauty rec- ommendations like hairstyles. In some cases, it is tricky to establish one's genuine facial shape, making it difficult to further process this information. This paper attempts to harness the advantages of the Swin Transformer to classify face shapes with higher accuracy. We also compared the test results with augmentation to evaluate the improvement. Our proposed method obtained 86.34% accuracy with augmentation, which is decent for further processing in various applications that require face shape recognition.","Heart disease is a major health issue, and accurate diagnosis of irregular heartbeats and heart failure is crucial. Current diagnostic processes can be time-consuming, requiring significant effort from clinicians. An effective classifier, ADCGNet: Attention-based Dual Channel Gabor Network is proposed to address this challenge by accurately classifying anomalies. ADCGNet involves pre-processing every ECG beat into two-dimensional images using Analytical Morlet transform and then applying thirty-two Gabor filters and Sobel edge detection to enhance features. ADCGNet comprises three blocks, with the first block using dual channels to extract essential features in the images efficiently. The second block includes a multi-head attention mechanism to focus on relevant features, and the third block uses a SoftMax activation function to perform classification tasks. Extensive experiments with public datasets from PhysioNet, and comparison with several state-of-the-art classifiers indicate ADCGNet is superior. Specifically, ADCGNet achieved an accuracy of 99.17%, 98.98% in precision, a recall of 98.87%, an F1-score of 98.82% and AUC, 98.75% with optimal hyperparameters. Further, a GRAD-CAM visualization of activated areas on the test samples gives graphical insight into the performance of ADCGNet. The proposed ADCGNet classifier has promising potential for enhancing the diagnosis of heart disease, and we believe it will be of much interest to the medical community.","The Internet is a crucial way to share information in both personal and professional areas. Sentiment analysis attracts great interest in marketing, research, and business today. The instability faced by imbalanced datasets on sentiment analysis is examined in this research. Balancing the datasets using techniques based on under-sampling and over-sampling is examined to achieve more efficient classification results as the effects of using BERT as word embedding and ensemble learning methods for classification. The effects of the resampling training set algorithms on different deep learning classifiers were investigated using BERT as a word embedding model and Cohen's kappa, accuracy, ROC-AUC curve, and MCC as evaluation metrics with k-fold validation on three sentiment analysis datasets containing English, Arabic, and Moroccan Arabic Dialect texts. Also, we did those performance metrics for all models when scaling the dataset for training and testing, and we calculated the memory and the execution time for each model. Finally, we analyzed the National Office of Railways of Morocco (ONCF) customers' Facebook comments in Modern Standard Arabic (MSA) and MD to determine customer satisfaction as positive, negative, and neutral comments.","Hyperspectral facial data presents creative information, taken with Hyperspectral camera, as compared to the traditional camera and images. This facial spectral dataset is a rich source of information extraction and analysis over traditional single band data with constant wavelength of Electromagnetic Spectrum (EMS). Herein study, Hyperspectral Image (HSI) classification and recognition have done in Visible to Near Infrared (NIR) region using supervised classifiers: Maximum Likelihood, Minimum Distance and SAM (Spectral Angle Mapper). The experiment is performed on CMU Hyperspectral Face Datasets (HFDS) within the spectral range of 610 to 1050 nm (VIR-NIR), having 45 spectral bands using ENVI 4.8 image processing tool. Supervised classification is performed using conventional supervised classifiers (MLH, MDA and SAM) on pre-processed HSI, further compressed dataset has classified by PCAMLH, PCAMD and PCASAM classifiers.","Protein acetylation refers to a process of adding acetyl groups (CH3CO-) to lysine residues on protein chains. As one of the most commonly used protein post-translational modifications, lysine acetylation plays an important role in different organisms. In our study, we developed a human-specific method which uses a cascade classifier of complex-valued polynomial model (CVPM), combined with sequence and structural feature descriptors to solve the problem of imbalance between positive and negative samples. Complex-valued gene expression programming and differential evolution are utilized to search the optimal CVPM model. We also made a systematic and comprehensive analysis of the acetylation data and the prediction results. The performances of our proposed method aie 79.15% in Sp, 78.17% in Sn, 78.66% in ACC 78.76% in F1, and 0.5733 in MCC, which performs better than other state-of-the-art methods.","With advancement in satellites and remote sensing technology, reflectance data are increasingly being used in agriculture. In this paper, the machine learning models have been explored with three distinct types of properties to classify the hydro-metrological rainfall parameter, Standardized Precipitation Index (SPI), and Vegetation Condition Index (VCI) to monitor the agriculture state of Rajasthan. These three distinct indexes are used to classify the geospatial Rainfall-SPI, Rainfall-VCI, and Rainfall-SPI-VCI models. The K-fold cross validation has been used to evaluate the robustness of the outperforming classification method. The outcome shows that DecisionTree and RandomForest classification model performs outstanding machine learning classification methods for vegetation with sensitivity of 0.798 and accuracy of 95.792% on test dataset with DecisionTree and of 0.796 and accuracy of 95.584% on testing dataset with RandomForest model.","In machine learning, the term \u201dclass imbalanced\u201d is frequently used. This is a crucial part of the field of machine learning. It is quite important in the classification process and has a significant impact on performance. That is why researchers are concentrating on it to overcome this difficulty. Various researchers have devised numerous methods till now. The approaches to addressing this imbalance issue found so far can be broadly categorized into three categories, which are the data-level approach, algorithm-level approach, and hybrid-level approach. To evaluate the most recent developments in resolving the negative effects of class imbalance, this study provides a comparative analysis of research that has been published within the last 5 years with an emphasis on high-class imbalance. In this study, an attempt has been made to provide a concise overview of what imbalance classification is, how it is created, and what the inconveniences are due to it. We have tried to provide a summary of several studies that have been published in the last few years and along with that a comparative analysis of all these approaches has been done.","This article presents a solution for Speech Emotion Recognition (SER) in multilingual setting using a hierarchical approach. The approach involves two levels, the first level identifies the gender of the speaker, while the second level predicts their emotional state. We evaluate the performance of three classifiers of increasing complexity: k-NN, transfer learning based on YAMNet, and Bidirectional Long Short-Term Memory neural networks. The models were trained, validated, and tested on a dataset that includes the big-six emotions and was collected from well-known SER datasets representing six different languages. Our results indicate that there are differences in classification accuracy when considering all data versus only female or male data, across all classifiers. Interestingly, prior knowledge of the speaker\u2019s gender can improve the overall classification performance.","Convolutional Neural Network (CNN) is a widely used neural network in deep learning, and Graph Convolutional Network (GCN) is one of the most effective semi -supervised methods. It spread node information in a conversion way. In this article, we have studied the differences between CNN and GCN in the classification of high -spectrum image. Because the traditional GCN algorithm needs to build an adjacent matrix on all data, the calculation cost is very high, especially in large -scale remote sensing problems. MinigCNS uses a small -batch learning method to solve the problem of CCN calculation costs, and then it has not solved the problem of low efficiency of single model classification. This article studies the advantages of minigcns and CNN, and proposes a weighted fusion network FU-W, which weighs the minigcns and CNN weighted integration to break the bottleneck of single model performance. We experimented with the fusion algorithm on the two high -spectrum data sets, and its overall accuracy can reach 88.8%in Indian Pines. The experiment proves the superiority of the fusion strategy for a single CNN or GCN model.","This paper presents a methodology for developing a volcano-seismic event classification system using a multi-station deep learning approach to support monitoring the Nevados del Chill\u00e1n Volcanic Complex, which has been active since 2017. A convolutional network of multiple inputs processes the information from an event recorded up to five seismic stations. Each record is represented by its normalized spectrogram; thus, the network may receive from one to five spectrograms as input. The design includes entering additional information into the network, like the stations configuration and the event duration, information not provided by the spectrograms. Finally, this work includes the design and implementation of a relational database to access the continuous traces of events, showing different subsets of data quickly and efficiently. The results show that the classification of an event recorded up to five stations is substantially more effective than a single-station strategy. However, incorporating additional information of the signal does not significantly improve the classification performance.","In the foodservice industry, time is a crucial factor that impacts both consumers and management. Machine learning (ML) is increasingly used to improve the quality of services through prediction. In this study, we aim to develop a model for predicting meal duration using Random Forest Classification algorithm. The study uses data from the Point-of-Sale (POS) system of a full-service Thai hotpot restaurant, with a focus on two commercial areas in Bangkok. The variables that we used include the branch, the number of customers, the number of items, the day of the week, and the time of the day. As a result, the overall accuracy of the model was 86% and the F1-score was 0.81. The discussion of the potential use of this approach in connection with the existing system in a restaurant could also be beneficial, aiding the restaurant in planning management more efficiently and gaining a better understanding of consumer behavior. This study will discuss the results of the model along with additional perspectives for future work.","With the emerging of new data collection ways, the features are incremental and accumulated gradually. Due to the expansion of feature spaces, it is more common that there are unknown biases between the distribution of training and testing datasets. It is known as the unknown data selection bias, which belongs to the learning scenario with non-i.i.d samples. The performance of traditional approaches, which need the i.i.d. assumption, will be aggravated seriously. How to design an algorithm to address the problem of data selection bias in this feature incremental scenario is crucial but rarely studied. In this paper, we propose a feature incremental classification algorithm with causality. Firstly, we embed the confounding variable balance algorithm in causal learning into the prediction modeling and utilize the logical regression algorithm with balancing regular terms as a baseline. Then, to satisfy the special requirement of feature increment, we design a new regularizer, which maintains the consistency of the regression coefficients between the data in the current and previous stages. It retains the correlation between the old features and labels. Finally, we propose the Multiple Balancing Logistic Regression model (MBRLR) to jointly optimize the balancing regularizer and weighted logistic regression model with multiple feature sets. We also present theoretical results to show that our proposed algorithm can make precise and stable predictions. Besides, the numerical results also demonstrate that our MBRLR algorithm is superior to other methods.\nHighlights\n\u2022\nWe have pioneered the use of causal inference and proposed a novel method approach, i.e., MBRLR, for achieving stable and accurate classification in the feature increase scenario.\n\u2022\nWe have improved the sample reweighting method by redesigning the loss function and regularizer which could be formulated as a convex optimization problem and could be easily solved.\n\u2022\nWe have proved that the MBRLR algorithm can make a stable classification for feature incremental data in the non-i.i.d case.","Recently, incremental learning has attracted a lot of interest in both research communities and industries. Generally, given a series of data sets sequentially, it tries to achieve good performance on the new data set while maintaining not bad performance on the old ones. Despite the recent success of incremental learning, existing works mainly assume that the coming data set is from the feature space of old ones, i.e., homogeneous feature space. And they adopt one feature extractor to forcibly project different feature spaces into one space. However, this assumption is hard to hold in real-world scenarios. Especially, the attributes of tables may sequentially increase in tabular learning. Thus, classic incremental learning models may hinder their effectiveness. In this paper, we propose a new method, incremental tabular learning on heterogeneous feature space (ILEAHE) to solve this issue. We first propose the ideas that feature extractors should be decomposed into shared and specific extractors to process the shared and specific features across different data sets respectively. Then, we propose a novel measurement named discriminative ability to measure specific extractors. Thus, two kinds of extractors can be discriminated and the specific extractor will more focus on those domain-specific features. We further demonstrate the effectiveness of ILEAHE through empirical studies.","In the classification task, many improved algorithms have been developed based on Support Vector Machines (SVM). Since the recently proposed Fast Support Vector Classifier (FSVC) can handle large scale datasets, this paper improves FSVC by quantile, called QSVC, which uses quantile rather than average value of samples to represent all samples. The advantages of QSVC are as follows: 1) QSVC performs better on the skewed distribution; 2) and the robustness of quantile is better. Experiments show that our QSVC performs better in accuracy and speed than FSVC. For example,Table 2 shows that the average accuracy of QSVC is higher than that of FSVC and Liblinear, and it takes less time.","In this paper, we propose a technique for hierarchical yoga pose classification in a multi-tasking framework. Novelty lies in the proposed supervised contrastive combined loss function. We propose the usage of linear combination of three loss functions: cross entropy, self-supervised contrastive loss and supervised contrastive loss in a multi-tasking manner. We introduce radial and cosine margin into the formulation of self-supervised and supervised contrastive loss to pull feature embeddings of same classes closer together compared to feature embeddings of different classes. We use a two stage transfer learning based end to end training methodology trained over novel supervised contrastive multi-tasking combined loss function in the first stage and later fine tune over cross entropy multi-tasking loss in the second stage. We apply our methodology on the publicly available Yoga-82 large-scale dataset. We report peak Top-1 yoga pose classification accuracy of 94.86% over 6 pose classes (Yoga-6), 91.9% over 20 pose classes (Yoga-20) and 87.17% over 82 pose classes (Yoga-82). Our proposed method achieves 5% improvement over Top-1 classification accuracy in Yoga-6, 7.3% improvement in Yoga-20 and 8.1% improvement in Yoga-82 in comparison with state of the art (SOTA) methodology. We achieve SOTA accuracies in all three hierarchies.","While utilizing machine learning models, one of the most crucial aspects is how bias and fairness affect model outcomes for diverse demographics. This becomes especially relevant in the context of machine learning for medical imaging applications as these models are increasingly being used for diagnosis and treatment planning.\nIn this paper, we study biases related to sex when developing a machine learning model based on brain magnetic resonance images (MRI). We investigate the effects of sex by performing brain age prediction considering different experimental designs: model trained using only female subjects, only male subjects and a balanced dataset. We also perform evaluation on multiple MRI datasets (Calgary-Campinas(CC359) and CamCAN) to assess the generalization capability of the proposed models.\nWe found disparities in the performance of brain age prediction models when trained on distinct sex subgroups and datasets, in both final predictions and decision making (assessed using interpretability models). Our results demonstrated variations in model generalizability across sex-specific subgroups, suggesting potential biases in models trained on unbalanced datasets. This underlines the critical role of careful experimental design in generating fair and reliable outcomes.","Cross-domain sentiment analysis (CDSA) aims to learn transferable knowledge from the source domain to facilitate the sentiment polarity classification on the target domain of lacking labeled data. Currently, two types of unsupervised domain adaptation (UDA) methods are widely used in CDSA tasks. One employs the domain adversarial strategy to extract domain-invariant features, and the other utilizes the distance metric strategy to reduce domain distribution discrepancy. However, the fine-grained domain-specific information related to categories aligned between domains is not preserved, which suppresses the performance of target-domain classification. To overcome the mentioned problem, a unified Domain Adversarial Category-wise Alignment Network (DACAN) was proposed in this paper. An integrated network was constructed with progressive multi-level feature learning. Specifically, a feature extraction module was constructed with parameter sharing between two domains at low-level text feature extraction layers. The domain adversarial module was added to enable shared knowledge transfer by extracting domain-invariant information and by updating the shared parameters at the feature extraction layers. A category-wise alignment module was built to achieve local distribution alignment at the high dimension-level semantic layers guided by fine-grained category structure information. Meanwhile, joint constraint was established with domain-invariant constraint based on domain adversarial, and domain-consistency constraint based on category-wise alignment. Comprehensive experiments were conducted on two standard Amazon review datasets. The results show that DACAN outperforms other state-of-the-art UDA methods by 0.7% and 1.1% on the two- and three-category CDSA tasks, respectively. Also, better performance results are achieved with a synergistic UDA scheme compared with a single UDA scheme.","In order to increase the yield in agricultural stock, its speed of delivery &amp; production plays a crucial role in economic growth of a county. Conventionally, the rice variety classification process were costly, requires intense manual labor and are quite prone to human made error in identification; thereby resulting in inconsistent and slow process. This type of process can be greatly automated with the help of computer vision to result in a non-destructive, quick &amp; nondestructive technique. In this research, we have presented a neural model based semantic segmentation method for classification of agro-morphological characteristics to differentiate the rice varieties &amp; secondly to extract the spikelets per panicle for prediction of its yield. The advantage of using segmentation base method is that it takes in account of shape, color, and texture properties after manually annotating the rice\u2019s agro-morphological images with over 15,000 images of crops for 10 varieties of rice. This research will serve as a major tool for botanist, industrial farmers and food processing industry for rapid rice classification, yield estimation with the help of our presented computer vision technology.","Plagiarism detection (PD) in natural language processing involves locating similar words in two distinct sources. The paper introduces a new approach to plagiarism detection utilizing bidirectional encoder representations from transformers (BERT)-generated embedding, an enhanced artificial bee colony (ABC) optimization algorithm for pre-training, and a training process based on reinforcement learning (RL). The BERT model can be incorporated into a subsequent task and meticulously refined to function as a model, enabling it to apprehend a variety of linguistic characteristics. Imbalanced classification is one of the fundamental obstacles to PD. To handle this predicament, we present a novel methodology utilizing RL, in which the problem is framed as a series of sequential decisions in which an agent receives a reward at each level for classifying a received instance. To address the disparity between classes, it is determined that the majority class will receive a lower reward than the minority class. We also focus on the training stage, which often utilizes gradient-based learning techniques like backpropagation (BP), leading to certain drawbacks such as sensitivity to initialization. In our proposed model, we utilize a mutual learning-based ABC (ML-ABC) approach that adjusts the food source with the most beneficial results for the candidate by considering a mutual learning factor that incorporates the initial weight. We evaluated the efficacy of our novel approach by contrasting its results with those of population-based techniques using three standard datasets, namely Stanford Natural Language Inference (SNLI), Microsoft Research Paraphrase Corpus (MSRP), and Semantic Evaluation Database (SemEval2014). Our model attained excellent results that outperformed state-of-the-art models. Optimal values for important parameters, including reward function are identified for the model based on experiments on the study dataset. Ablation studies that exclude the proposed ML-ABC and reinforcement learning from the model confirm the independent positive incremental impact of these components on model performance.\nHighlights\n\u2022\nBERT-based plagiarism detection with RL and ML-ABC.\n\u2022\nReward function in RL improves detection of minority plagiarism class.\n\u2022\nModel outperforms state-of-the-art on SNLI, MSRP, SemEval2014 datasets.\n\u2022\nAblation studies highlight the impact of ML-ABC and RL on performance.","Aspect-Level Sentiment Classification (ALSC) aims to assign specific sentiments to a sentence toward different aspects, which is one of the crucial challenges in the field of Natural Language Processing (NLP). Despite numerous approaches being proposed and obtaining prominent results, the majority of them focus on leveraging the relationships between the aspect and opinion words in a single instance while ignoring correlations with other instances, which will make models inevitably become trapped in local optima due to the absence of a global viewpoint. Instance representation derived from a single instance, on the one hand, the contained information is insufficient due to the lack of descriptions from other perspectives; on the other hand, its stored knowledge is redundant since the inability to filter extraneous content. To obtain a polished instance representation, we developed a Retrieval Contrastive Learning (RCL) framework to subtly extract intrinsic knowledge across instances. RCL consists of two modules: (a) obtaining retrieval instances by sparse retriever and dense retriever, and (b) extracting and learning the knowledge of the retrieval instances by using Contrastive Learning (CL). To demonstrate the superiority of RCL, five ALSC models are employed to conduct comprehensive experiments on three widely-known benchmarks. Compared with the baselines, ALSC models achieve substantial improvements when trained with RCL. Especially, ABSA-DeBERTa with RCL obtains new state-of-the-art results, which outperform the advanced methods by 0.92%, 0.23%, and 0.47% in terms of Macro F1 gains on Laptops, Restaurants, and Twitter, respectively.\nHighlights\n\u2022\nWe proposed RCL to enable ALSC models to generate polished representations.\n\u2022\nRCL has two modules: obtain retrieval instances and learn common features by CL.\n\u2022\nThe sparse and dense retrievers are used to obtain high-quality retrieval instances.\n\u2022\nThe ALSC model can be enhanced greatly by training with RCL.\n\u2022\nABSA-DeBERTa obtains new state-of-the-art results by being trained with RCL.","Early classification of longitudinal data remains an active area of research today. The complexity of these datasets and the high rates of missing data caused by irregular sampling present data-level challenges for the Early Longitudinal Data Classification (ELDC) problem. Coupled with the algorithmic challenge of optimising the opposing objectives of early classification (i.e., earliness and accuracy), ELDC becomes a non-trivial task. Inspired by the generative power and utility of the Generative Adversarial Network (GAN), we propose a novel context-conditional, longitudinal early classifier GAN (LEC-GAN). This model utilises informative missingness, static features, and earlier observations to improve the ELDC objective. It achieves this by incorporating ELDC as an auxiliary task within an imputation optimization process. Our experiments on several datasets demonstrate that LEC-GAN outperforms all relevant baselines in terms of F1 scores while increasing the earliness of prediction.","The histopathological analysis of a suspected region is critical for cancer diagnosis, treatment, and management. Histopathological diagnosis consists in analyzing the characteristics of the lesions using tissue sections stained with hematoxylin and eosin. Classification of digital tumor pathology images, called whole slide images (WSIs), is a great challenge since WSIs usually have huge resolutions while lacking localized annotations. Multiple instance learning (MIL) is a commonly used method applied to pathological image analysis. However, most MIL methods often focus only on the global representation of WSIs, ignoring whether the category labels play other roles in the model training besides being a supervision signal. In addition, feature confusion is also a problem that should be avoided for the analysis of WSIs with weakly supervised methods. To address these problems, we propose a novel algorithm of classifying WSI for cancer diagnosis. The proposed model, ProMIL, uses only slide-level labels rather than localized annotations for analysis. There are three innovations in this work. Firstly, we present the concept of class proxy which is the representation of the intrinsic feature of each category, and plays a key role in guiding the training of the model. Secondly, we design a novel WSI representation learning module that utilizes a multi-scale feature extraction strategy to represent each patch in a WSI and then aggregates these representations using an attention mechanism to encode the WSI. Thirdly, we design a metric-learning-based weakly supervised multiclass-classifier by measuring the similarity between each WSI embedding and class proxies. The proposed ProMIL can effectively alleviate the side effect of feature confusion, and carry intuitive interpretability and scalability. To evaluate the performance of ProMIL, we conduct a series of experiments on several datasets of WSIs with different types of cancer from open data sources. It can be observed from the experimental results that ProMIL outperforms most of the compared methods and achieves better performance on a various type of cancer image data for classification, thus suggesting the proposed method is suitable for classifying different categories of cancer rather than a specific kind of cancer. Therefore, it is expected to act as a general framework to be extended to more cancer diagnoses.\nHighlights\n\u2022\nThe class proxy is the representation of the intrinsic feature of each category.\n\u2022\nA multi-scale feature extraction strategy is proposed to represent each patch.\n\u2022\nEncoding the whole slide image by aggregating and gated-attention mechanism.\n\u2022\nWSI classification performs by metric-learning-based weakly supervised MIL.","Various ensemble machine learning techniques have been widely studied and implemented to construct the predictive models in different sciences, including bagging, boosting, and stacking. However, bagging and boosting concentrate on minimizing variance or bias, stacking techniques aimed at reducing both by identifying the optimal integration of base learners. Moreover, while most ensemble methods simply combine identical machine learning models, stacking utilizes a meta-machine learning model to combine different base learning models, aiming to enhance the overall accuracy of generalization. Therefore, this research showed the utilization of stacking, an ensemble approach, to develop mineral prospectivity models for Pb-Zn mineralization in the Varcheh District, west Iran. To end this, various exploration evidence layers, including geochemical data, remote sensing data, geological and tectonic controls were used to construct the stacking structure. In the following, a set of five base learners were applied, containing support vector regression (SVR) using RBF, linear and polynomial kernels, the K-nearest neighbor (KNN), and linear regression. Ridge, SVR-RBF and XGBoost were used as a meta-learner to integrate the outputs of basic learners. To measure how well each model performed, ROC, F1-score and Precision metrics was carried out. Moreover, compared to the separate algorithms, the stacking-based ensemble model showed a better prediction accuracy. The findings of this study demonstrated that the ensemble model based on stacking achieved a 95% prediction rate for Pb-Zn deposits, covering only 9% of the study area. As a result, this model holds promise as an effective tool for predicting mineral prospectivity in other study areas, regardless of whether they exhibit similar or different types of mineralization.","Mixing data augmentation methods have been widely used in text classification recently. However, existing methods do not control the quality of augmented data and have low model explainability. To tackle these issues, this paper proposes an explainable text classification solution based on attentive and targeted mixing data augmentation, ATMIX. Instead of selecting data for augmentation without control, ATMIX focuses on the misclassified training samples as the target for augmentation to better improve the model's capability. Meanwhile, to generate meaningful augmented samples, it adopts a self-attention mechanism to understand the importance of the subsentences in a text, and cut and mix the subsentences between the misclassified and correctly classified samples wisely. Furthermore, it employs a novel dynamic augmented data selection framework based on the loss function gradient to dynamically optimize the augmented samples for model training. In the end, we develop a new model explainability evaluation method based on subsentence attention and conduct extensive evaluations over multiple real-world text datasets. The results indicate that ATMIX is more effective with higher explainability than the typical classification models, hidden-level, and input-level mixup models.","Multi-class classification can be solved by decomposing it into a set of binary classification problems according to some encoding rules, e.g., one-vs-one, one-vs-rest, error-correcting output codes. Existing works solve these binary classification problems in the original feature space, while it might be suboptimal as different binary classification problems correspond to different positive and negative examples. In this paper, we propose to learn label-specific features for each decomposed binary classification problem to consider the specific characteristics containing in its positive and negative examples. Specifically, to generate the label-specific features, clustering analysis is respectively conducted on the positive and negative examples in each decomposed binary data set to discover their inherent information and then label-specific features for one example are obtained by measuring the similarity between it and all cluster centers. Experiments clearly validate the effectiveness of learning label-specific features for decomposition-based multi-class classification.","One of the significant challenges in Brain\u2013Computer Interface (BCI) is to develop a classifier that can decode users\u2019 mental states based on electroencephalogram (EEG) data collected from independent subjects. The focus of such subject-independent (SI) classification is justified because it can lead to BCIs that do not require a user-specific calibration process. In recent years, the emergence of deep neural networks (DNNs) has significantly improved the performance of EEG classification. Among various deep learning techniques, the training efficiency and the performance of Convolutional Neural Networks (CNNs), in particular, have led to several state-of-the-art architectures for accurate classification of EEG. Not surprisingly, the efforts to improve the performance of these architectures for EEG classification have been ramped up in recent years. In this regard, a trivial approach is to train and tune a large number of architectures and hyperparameters and hope to improve upon the existing results. In contrast with this ad hoc approach, here we put forward a systematic method inspired by the jackknife estimation to improve the performance of existing CNN architectures. Using EEGNet and ShallowConvNet as archetypical, our empirical results show that the proposed \u201cDelete-a-Subject Jackknife\u201d (DASJ) technique can potentially improve the performance of existing CNN architectures for SI classification of EEG.\nHighlights\n\u2022\nProposes DASJ-CNN which is a jackknife-inspired approach with Convolutional Neural Network (CNN) base classifiers.\n\u2022\nPresents an analytical motivation of the DASJ ensemble classification.\n\u2022\nEvaluates the effectiveness of the method using two state-of-the-art CNN architectures for EEG classification.\n\u2022\nDemonstrates the capability of the method to improve the performance of existing CNN architectures.","Although Graph Neural Networks (GNNs) have been successful in node classification tasks, their performance heavily relies on the availability of a sufficient number of labeled nodes per class. In real-world situations, not all classes have many labeled nodes and there may be instances where the model needs to classify new classes, making manual labeling difficult. To solve this problem, it is important for GNNs to be able to classify nodes with a limited number of labeled nodes, known as few-shot node classification. Previous episodic meta-learning based methods have demonstrated success in few-shot node classification, but our findings suggest that optimal performance can only be achieved with a substantial amount of diverse training meta-tasks. To address this challenge of meta-learning based few-shot learning (FSL), we propose a new approach, the Task-Equivariant Graph few-shot learning (TEG) framework. Our TEG framework enables the model to learn transferable task-adaptation strategies using a limited number of training meta-tasks, allowing it to acquire meta-knowledge for a wide range of meta-tasks. By incorporating equivariant neural networks, TEG can utilize their strong generalization abilities to learn highly adaptable task-specific strategies. As a result, TEG achieves state-of-the-art performance with limited training meta-tasks. Our experiments on various benchmark datasets demonstrate TEG's superiority in terms of accuracy and generalization ability, even when using minimal meta-training data, highlighting the effectiveness of our proposed approach in addressing the challenges of meta-learning based few-shot node classification. Our code is available at the following link: https://github.com/sung-won-kim/TEG","Utilizing classical convolutional networks results in lackluster performance in certain classification tasks. To address this problem, recent solutions add extra layers or sub-networks to increase the classification performance of existing networks. More recent methods employ multiple networks coupled with varying learning strategies. However, these approaches demand larger memory and computational requirement due to additional layers, prohibiting usage in devices with limited computing power. In this paper, we propose an efficient convolutional block which minimizes the computational requirements of a network while maintaining information flow through concatenation and element-wise addition. We design a classification architecture, called Half-Append Half-Add Network (HAHANet), built using our efficient convolutional block. Our approach achieves state-of-the-art accuracy on several challenging fine-grained classification tasks. More importantly, HAHANet outperforms top networks while reducing parameter count by at most 54 times. Our code and trained models are publicly available at https://github.com/dlsucivi/HAHANet-PyTorch.","This work proposes a novel approach to object recognition, particularly for human faces, based on the principle of human cognition. The suggested approach can handle a dataset or problem with a large number of classes for classification more effectively. The model for the facial recognition-based object detection system was constructed using a combination of decision tree clustering based multi-level Backpropagation neural network classifier-TFMLBPNN-DTC and hybrid texture feature (ILMFD+GLCM) and applied on NS and ORL databases. This model produced the classification accuracy (\u00b1standard deviation) of 95.37 \u00b10.951877% and 90.83 \u00b1 1.374369% for single input and 96.58 \u00b10.5604582% and 91.50 \u00b1 2.850439% for group-based decision for NS and ORL database respectively. The better classification results encourage its application to other object recognition and classification issues. This work's basic idea also makes it easier to improve classification management for a wide range of classes.","Electroencephalography (EEG) motor imagery (MI) signals has recently attracted a great deal of attention as these signals encrypt a person's desire of executing a command. MI signals are used to assist disabled people and even for autonomous driving through some control devices like wheelchairs just by thinking about it. Therefore, an accurate MI tasks classification from EEG signals is cricial to get a reliable Brain Computer Interface (BCI) system. In this paper, we proposed a new method of classifying MI tasks based on Convolutional Neural Network (CNN) methods. We applied a simple preprocessing to the data followed by a feature extraction step using Common Spatial Pattern (CSP) to extract spatial features and Wavelet Packet Decomposition (WPD) to extract frequency-time features. We then tested our four proposed models: CNN, CNN+LSTM, CNN-SVM and CNN+LSTM-SVM using BCI Competition IV 2a dataset. The obtained experimental results show that the proposed CNN-SVM gives the best results. Our results are really promising achieving interesting accuracy, precision, recall, and F1 score of 64.33%, 65.05%, 66.11%, et 64.11%, respectively.","Graph Neural Networks (GNNs) have emerged as one of the most prominent research areas in accomplishing machine learning tasks over graphical networks. GNNs are prominently used in performing tasks like semi-supervised node classification, link prediction, and community detection. GraphSAGE is one of the most recent GNN models which is being used to accomplish these tasks. A floor plan is an architectural design of a building that represents various floor compartments. In this paper, we represent floor plan(s) as graph(s). We characterize floor room (compartment) classification as a node classification problem. We propose a variation of the traditional GraphSAGE (sample and aggregation) algorithm: Centrality based GraphSAGE (CB-SAGE), which captures the structural properties of the network. We use the average clustering coefficient and average betweenness centrality to capture structure properties. We compute CB scores for all the floor plan graphs. Top 70% nodes (based on CB scores) are selected for the training. During the training, we append the betweenness centrality score of each node as an additional feature in the feature matrix for the embedding process. We conduct experiments on the House-GAN dataset, which contains 1,43,184 vectorized floor plan images. The proposed method outperforms the current state-of-art models in accomplishing the task of floor plan classification. We compare our results with the traditional machine learning approach (MLP) and other GNN-based methods. Our approach achieves an accuracy of 96.70%, which is significantly (approximately 16%) higher than other state-of-the-art methods.\nHighlights\n\u2022\nCB-SAGE: Achieves 96 . 70 % accuracy, outperforming state of the art methods.\n\u2022\nOur innovative GraphSAGE training method relies on CB scores, not random training.\n\u2022\nUtilized three different centrality measures for diverse floor plan insights.\n\u2022\nWe show the statistical significance of our CB-SAGE model compared to other methods.\n\u2022\nOur versatile framework is applicable to various domains\u2019 problem-solving.","Sentiment analysis is an essential task in understanding human-generated textual documents. While most research into sentiment analysis focuses on monolingual sentences, in multilingual communities, a significant proportion of social media text contains a mixture of languages or code-switching. Thus, it has become vital to research and build models that handle code-switched data. However, despite significant research and custom expert neural architectures proposed, the current literature is mainly limited to modeling single language pairs. To expand on existing work and baseline performance for this particular task, we perform multiple experiments: fine-tuning pre-trained multilingual models and fine-tuning monolingual BERT models on sentence and word-level translations. The experiments are performed across five datasets where English is code-switched with Spanish, Tamil, Telugu, Hindi, and Malayalam. Our best model outperforms the current best single model that works with multiple code-switched language pairs on standard classification metrics on a binary sentiment classification task. We further expand our experiment with a ternary sentiment classification task and produce results comparable to single language-pair-specific models.","For imbalanced data, classification efficiency degrades significantly due to the missing information for the positive class, and existing sampling schemes do not consider the distributions of samples. Additionally, the global parameters of fuzzy neighborhoods are set manually. These defects affect the effectiveness of classifier. To address these problems, we offer an adaptive fuzzy multi-neighborhood feature selection methodology with intercluster distance-based hybrid sampling for class-imbalanced data. First, the number of clusters can be defined in terms of the number of samples in the negative or positive class. The initial centers of the clusters are determined according to the number of clusters, and the dissimilarity and similarity measures are calculated by using the intercluster distances between samples. Then, the cluster center, fuzzy membership matrix, and intercluster distance are studied, and then the optimization objective function is designed. The hybrid sampling scheme can be used to combine the generated positive class samples and negative class samples and obtain a class-balanced system. Second, according to the sample distribution, the standard deviation and a set of adaptive fuzzy multi-neighborhood radii are designed. A fuzzy multi-neighborhood similarity relation is defined by introducing a Gaussian kernel model to obtain a fuzzy multi-neighborhood granule, and an improved fuzzy multi-neighborhood rough set model is provided. Uncertain measures of fuzzy neighborhood systems are evaluated by the positive region and dependency. Third, by integrating fuzzy dependence with fuzzy complementary condition entropy, fuzzy multi-neighborhood complementary mutual information is provided on two viewpoints of algebra and information. Finally, a heuristic feature subset selection methodology for imbalanced classification with hybrid sampling using fuzzy c-means clustering is studied to obtain this excellent set of features. Experiments on 26 imbalanced datasets show the effectiveness of our designed algorithm.\nHighlights\n\u25cf\nThe optimization objective function of hybrid sampling via intercluster distance is designed to get a class-balanced system.\n\u25cf\nA set of adaptive fuzzy multi-neighborhood radii is designed to study the fuzzy multi-neighborhood similarity relation.\n\u25cf\nAn adaptive fuzzy multi-neighborhood rough set model is provided to assess uncertain measures of fuzzy neighborhood systems.\n\u25cf\nFuzzy multi-neighborhood complementary mutual information is constructed from the two viewpoints of algebra and information.","Arbitrary, inconsistent, or faulty decision-making raises serious concerns, and preventing unfair models is an increasingly important challenge in Machine Learning. Data often reflect past discriminatory behavior, and models trained on such data may reflect bias on sensitive attributes, such as gender, race, or age. One approach to developing fair models is to preprocess the training data to remove the underlying biases while preserving the relevant information, for example, by correcting biased labels. While multiple label noise correction methods are available, the information about their behavior in identifying discrimination is very limited. In this work, we develop an empirical methodology to systematically evaluate the effectiveness of label noise correction techniques in ensuring the fairness of models trained on biased datasets. Our methodology involves manipulating the amount of label noise and can be used with fairness benchmarks but also with standard ML datasets. We apply the methodology to analyze six label noise correction methods according to several fairness metrics on standard OpenML datasets. Our results suggest that the Hybrid Label Noise Correction [20] method achieves the best trade-off between predictive performance and fairness. Clustering-Based Correction [14] can reduce discrimination the most, however, at the cost of lower predictive performance.","Meta-learning is one of the important methods to solve the challenging few-shot learning setting by using previous knowledge and experience to guide the learning of new tasks. Model-agnostic meta-learning (MAML) is one of the most popular meta-learning algorithms, and many variants of MAML have appeared in recent years. However, the performance of this algorithm for few-shot classification falls behind some other algorithms working on this problem. Therefore, its generalization performance needs to be further explored and improved. In view of the generalization problem, we found that MAML always shares an initialization in the process of parameter update, ignoring the bias between different tasks, resulting in limited generalization performance. On the other hand, the sample diversity of meta-learning model is low, and shallow network training is generally used, so it is difficult to obtain good performance based on deep neural network models. Based on these problems, we propose a hybrid optimization meta-learning method based on data augmentation, initialization attenuation, and resolution increase, called Mix-MAML. Experimental results show that our method reaches 76.93% classification accuracy on mini-ImageNet with 100 \u00d7 100 resolution, and 83.62% classification accuracy on CIFAR-FS with 80 \u00d7 80 resolution in the 5-way 5-shot settings under ResNet12, which achieves comparable or even better performance than other algorithms in some standard few-shot learning benchmarks without changing MAML simplicity and model-agnostic.","Recent advance in linear support vector machine with the 0-1 soft-margin loss (L 0 / 1-SVM) shows the ability to solve the 0-1 loss problem directly. However, its theoretical and algorithmic requirements restrict us from directly extending the linear solving framework to its nonlinear kernel form. The lack of an explicit expression of the Lagrangian dual function of L 0 / 1-SVM is a major shortcoming among them. By applying the nonparametric Representation Theorem, we propose a nonlinear model for support vector machine with 0-1 soft-margin loss, called L 0 / 1-KSVM, which skillfully incorporates the kernel technique, and more importantly, follows the success in systematically solving its linear problem. The optimal condition is theoretically explored and a working set selection alternating direction method of multipliers (ADMM) algorithm is introduced to obtain its numerical solution. Furthermore, we first introduce a closed-form definition to the support vector (SV) of L 0 / 1-KSVM. Theoretically, we prove that all SVs of L 0 / 1-KSVM are only located on the parallel decision surfaces. The experimental results show that L 0 / 1-KSVM has much fewer SVs compared to its linear counterpart and the other six nonlinear benchmark SVM classifiers, while maintaining good prediction accuracy.","Data stream classification is of great significance to numerous real-world scenarios. Nevertheless, the prevalent data stream classification techniques are influenced by concept drift and demonstrate unreliability in non-stationary environments. Ensemble models are typically successful when they increase diversity among their members. Several ensembles that enhance diversity have been proposed in literatures. Regrettably, there is no established method to verify that cooperativity indeed improves performance. In response to this knowledge gap, we have developed an innovative ensemble learning framework driven by diversity and cooperativity, termed EDDC, to address the issue. EDDC first dynamically maintains multiple groups of classifiers, with primary classifier in each group chosen to enhance diversity. Next, cooperativity is employed to update groups and replace outdated members. Finally, when environment changes, EDDC adaptively selects either diversity or cooperativity as the strategy for predicting labeling of new instances, while also establishing an excellent performance guarantee. Through simulation experiments, we assessed the performance of EDDC and the benefits of cooperativity for enhancing prediction. The results demonstrated that EDDC is efficient and robust in most scenarios, particularly when dealing with gradual drift. Furthermore, EDDC maintains a competitive edge in terms of classification accuracy and other metrics.\nHighlights\n\u2022\nThis paper proposes an online ensemble model driven by diversity and cooperativity for data stream classification called EDDC.\n\u2022\nAn adaptive voting-strategy is proposed in this paper, which selects diversity or cooperativity as voting methods in ever-changing environment.\n\u2022\nAccording to simulation results, EDDC works superior to the-state-of-art ensembles, especially on gradual drifting stream.","The increasing availability of quantitative data in archaeological studies has prompted the research of Machine Learning methods to support archaeologists in their analysis. This paper considers in particular the problem of automatic classification of 3D surface patches of \u201crubble stones\u201d and \u201cwedges\u201d obtained from Prehistorical and Protohistorical walls in Crete. These data come from the W.A.L.(L) Project aimed to query 3D photogrammetric models of ancient architectonical structures in order to extract archaeologically significant features. The principal aim of this paper is to address the issue of a clear semantically correspondence between data analysis concepts and archaeology. Classification of stone patches has been performed with several Machine Learning methods, and then feature relevance has been computed for all the classifiers. The results show a good correspondence between the most relevant features of the classification and the qualitative features that human experts adopt typically to classify the wall facing stones.","This paper presents methods of prediction of casting mechanical parameters based on direct microstructure image analysis using deep neural networks and graphite forms recognition and classification. These methods are applied to predict tensile strength of iron-carbon alloys based on microstructure photos taken with the light-optical microscopy technique, but are general and can be adapted to other applications. In the first approach EfficientNet architecture is used. In the second approach graphite structures are separated, recognized using VGG19 network, counted and classified using support vector machines, decision trees, random forest, logistic regression, multi-layer perceptron and AdaBoost. Accuracy of the first approach is better. However, the second allows to create a classifier, for which the accuracy is also high, and can be easily analyzed by human expert.","Partial-label learning (PLL) relies on a key assumption that the true label of each training example must be in the candidate label set. This restrictive assumption may be violated in complex real-world scenarios, and thus the true label of some collected examples could be unexpectedly outside the assigned candidate label set. In this paper, we term the examples whose true label is outside the candidate label set OOC (Out-Of-Candidate) examples, and pioneer a new PLL study to learn with OOC examples. We consider two types of OOC examples in reality, i.e., the closed-set/open-set OOC examples whose true label is inside/outside the known label space. To solve this new PLL problem, we first calculate the wooden cross-entropy loss from candidate and non-candidate labels respectively, and dynamically differentiate the two types of OOC examples based on specially designed criteria. Then, for closed-set OOC examples, we conduct reversed label disambiguation in the non-candidate label set; for open-set OOC examples, we leverage them for training by utilizing an effective regularization strategy that dynamically assigns random candidate labels from the candidate label set. In this way, the two types of OOC examples can be differentiated and further leveraged for model training. Extensive experiments demonstrate that our proposed method outperforms state-of-the-art PLL methods.","The deployment of Deep Neural Networks (DNNs) on edge devices is hindered by the substantial gap between performance requirements and available computational power. While recent research has made significant strides in developing pruning methods to build a sparse network for reducing the computing overhead of DNNs, there remains considerable accuracy loss, especially at high pruning ratios. We find that the architectures designed for dense networks by differentiable architecture search methods are ineffective when pruning mechanisms are applied to them. The main reason is that the current methods do not support sparse architectures in their search space and use a search objective that is made for dense networks and does not focus on sparsity.\nThis paper proposes a new method to search for sparsity-friendly neural architectures. It is done by adding two new sparse operations to the search space and modifying the search objective. We propose two novel parametric SparseConv and SparseLinear operations in order to expand the search space to include sparse operations. In particular, these operations make a flexible search space due to using sparse parametric versions of linear and convolution operations. The proposed search objective lets us train the architecture based on the sparsity of the search space operations. Quantitative analyses demonstrate that architectures found through DASS outperform those used in the state-of-the-art sparse networks on the CIFAR-10 and ImageNet datasets. In terms of performance and hardware effectiveness, DASS increases the accuracy of the sparse version of MobileNet-v2 from 73.44% to 81.35% (+7.91% improvement) with a 3.87\u00d7 faster inference time.","Gradient Boosting Decision Tree (GBDT) has achieved remarkable success in a wide variety of applications. The split finding algorithm, which determines the tree construction process, is one of the most crucial components of GBDT. However, the split finding algorithm has long been criticized for its bias towards features with a large number of potential splits. This bias introduces severe interpretability and overfitting issues in GBDT. To this end, we provide a fine-grained analysis of bias in GBDT and demonstrate that the bias originates from 1) the systematic bias in the gain estimation of each split and 2) the bias in the split finding algorithm resulting from the use of the same data to evaluate the split improvement and determine the best split. Based on the analysis, we propose unbiased gain, a new unbiased measurement of gain importance using out-of-bag samples. Moreover, we incorporate the unbiased property into the split finding algorithm and develop UnbiasedGBM to solve the overfitting issue of GBDT. We assess the performance of UnbiasedGBM and unbiased gain in a large-scale empirical study comprising 60 datasets and show that: 1) UnbiasedGBM exhibits better performance than popular GBDT implementations such as LightGBM, XGBoost, and Catboost on average on the 60 datasets and 2) unbiased gain achieves better average performance in feature selection than popular feature importance methods. The codes are available at https://github.com/ZheyuAqaZhang/UnbiasedGBM.","Idiomatic expressions are important natural parts of all languages and prominent parts of our daily speech. Idioms cannot be interpreted from the words that they are formed with directly and people may not understand the meaning. From past literature, it was noted that idiom affects Natural Language Processing research like machine translation, semantic analysis, and sentiment analysis. Other languages like English, Chinese, and Indian idioms are recognized through different methods in different research. As there is no standard method and research to identify Amharic idioms, this study is aimed to build a model to identify idioms for the Amharic language using a supervised machine learning approach. The study used 800 labeled expressions for training and 200 expressions for testing from Amharic idiom books \u201c\u12e8\u12a0\u121b \u1228\u129b \u1348\u120a\u1326\u127d\u201d and different Amharic documents. To measure the performance of the model, we used accuracy, precision, recall, and F-score. Finally, a 97.5% accuracy result was achieved from the testing dataset showing a promising result. The study contributes to the information systems discourse about improving the awareness and knowledge of researchers on Amharic idioms.","To better understand how accurate opaque black box models work, it is necessary to explain their internal workings in terms of human-interpretable image sub-regions known as concepts. This explanation will provide insights into how these models perceive the sharedness of concepts across related classes, as frequently observed in the real world. With this objective in mind, the proposed work aims to leverage an incremental Non-negative Matrix Factorization technique to extract shared concepts in a memory-efficient manner, thereby reflecting the sharedness of concepts across classes. The relevance of the extracted concepts towards prediction, as well as the encoding of primitive image aspects such as color, texture, and shape by the concept, will be estimated after training the concept extractor. This approach reduces training overhead and simplifies the explanation pipeline, enabling the elucidation of various concepts - some genuine, some spurious - on which different black box architectures trained on the Imagenet dataset group and distinguish related classes.","Normal blood supply to the human brain may be marred by the presence of a clot inside the blood vessels. This clot structure called emboli inhibits normal blood flow to the brain. It is considered as one of the main sources of stroke. Presence of emboli in human\u2019s can be determined by the analysis of transcranial Doppler signal. Different signal processing and machine learning algorithms have been used for classifying the detected signal as an emboli, Doppler speckle, and an artifact. In this paper, we sought to make use of the wavelet transform based algorithm called Wavelet Scattering Transform, which is translation invariant and stable to deformations for classifying different Doppler signals. With its architectural resemblance to Convolutional Neural Network, Wavelet Scattering Transform works well on small datasets and subsequently was trained on a dataset consisting of 300 Doppler signals.\nTo check the effectiveness of extracted Scattering transform based features for Doppler signal classification, learning algorithms that included multi-class Support vector machine, k-nearest neighbor and Naive Bayes algorithms were trained. Comparative analysis was done with respect to the handcrafted Continuous wavelet transform features extracted from samples and Wavelet scattering with Support vector machine achieved an accuracy of 98.89%. Also, with set of extracted scattering coefficients, Gaussian process regression was performed and a regression model was trained on three different sets of scattering coefficients with zero order scattering coefficients providing least prediction loss of 34.95%.\nHighlights\n\u2022\nA white-box network Wavelet scattering transform is used for Doppler signal classification.\n\u2022\nWith architecture similarity to convolutional neural network, Wavelet scattering transform is well suited for small datasets.\n\u2022\nContinuous wavelet transform based handcrafted features are extracted for comparison with Wavelet scattering transform.\n\u2022\nRegression and classification results are presented for Doppler signal dataset.","Protein sequence classification is a crucial research field in bioinformatics, playing a vital role in facilitating functional annotation, structure prediction, and gaining a deeper understanding of protein function and interactions. With the rapid development of high-throughput sequencing technologies, a vast amount of unknown protein sequence data is being generated and accumulated, leading to an increasing demand for protein classification and annotation. Existing machine learning methods still have limitations in protein sequence classification, such as low accuracy and precision of classification models, rendering them less valuable in practical applications. Additionally, these models often lack strong generalization capabilities and cannot be widely applied to various types of proteins. Therefore, accurately classifying and predicting proteins remains a challenging task. In this study, we propose a protein sequence classifier called Multi-Laplacian Regularized Random Vector Functional Link (MLapRVFL). By incorporating Multi-Laplacian and L 2,1 \u2212 norm regularization terms into the basic Random Vector Functional Link (RVFL) method, we effectively improve the model's generalization performance, enhance the robustness and accuracy of the classification model. The experimental results on two commonly used datasets demonstrate that MLapRVFL outperforms popular machine learning methods and achieves superior predictive performance compared to previous studies. In conclusion, the proposed MLapRVFL method makes significant contributions to protein sequence prediction.\nHighlights\n\u2022\nMLapRVFL improves protein sequence prediction.\n\u2022\nEnhanced generalization and accuracy with Multi-Laplacian and L 2,1 \u2212 norm regularization terms.\n\u2022\nMLapRVFL outperforms in protein sequence classification.","Amidst the critical role that high-quality labeled data plays in advancing machine learning, the persistence of noise within widely-used datasets remains a challenge. While noise learning has gained traction within machine learning, particularly in computer vision, its exploration in text and multimodal classification domains has lagged. Furthermore, a comprehensive comparison of noise learning techniques in text and multimodal classification has been lacking, partly due to variations in experimental noise settings across prior studies. Addressing these gaps, this research introduces a pioneering Multimodal Infusion Joint Training (MinJoT) framework featuring a novel co-regularized loss function that seamlessly integrates multimodal information during joint training. This framework notably excels in maintaining model robustness amidst noisy data environments. Adapting established noise learning methods from computer vision to text classification, the study conducts extensive experiments across five English and Chinese textual and multimodal datasets, involving four methods, five noise modes, and seven noise rates. Critically, this work challenges the implicit assumption that widely-used datasets are devoid of noise, revealing that these datasets indeed encompass noise levels ranging from 0.61% to 15.77% which is defined as intrinsic noise in this study. For the first time, the study investigates the impact of intrinsic noise on model performance, categorizing it into distinct levels of ambiguity. To facilitate accurate method comparison, a new dataset, Golden-Chnsenticorp (G-Chnsenticorp), is introduced, carefully crafted to be free of intrinsic noise. This research establishes the inaugural noise learning benchmark for text classification, while simultaneously pioneering the first noise learning framework tailored for multimodal sentiment classification. Through these contributions, the study advances the understanding of noise learning in text and multimodal contexts, providing a novel framework, benchmarks, and insights to propel the field forward.\nHighlights\n\u2022\nIntroducing MinJoT, a novel noise learning framework for multimodal classification.\n\u2022\nStudying intrinsic noise in text classification and its impacts.\n\u2022\nCreating G-Chnsenticorp, a noise-free dataset, for reliable research in this area.","The ability to classify images is dependent on having access to large labeled datasets and testing on data from the same domain of which the model was trained on. Classification becomes more challenging when dealing with new data from a different domain, where gathering and especially labeling a larger image dataset for retraining a classification model requires a labor-intensive human effort. Cross-domain classification frameworks were developed to handle this data domain shift problem by utilizing unsupervised image-to-image translation models to translate an input image from the unlabeled domain to the labeled domain. The problem with these unsupervised models lies in their unsupervised nature. For lack of annotations, it is not possible to use the traditional supervised metrics to evaluate these translation models to pick the best-saved checkpoint model. This paper introduces a new method called Domain-knowledge Inspired Pseudo Supervision (DIPS) which utilizes Gaussian Mixture Models and domain knowledge to generate pseudo annotations to enable the use of traditional supervised metrics. This method was designed specifically to support cross-domain classification applications contrary to other typically used metrics such as the Fr\u00e9chet Inception Distance (FID) which were designed to evaluate the model in terms of the quality of the generated image from a human-eye perspective. DIPS outperforms state-of-the-art GAN evaluation metrics when selecting the optimal saved checkpoint. Furthermore, DIPS showcases its robustness and interpretability by demonstrating a strong correlation with truly supervised metrics, highlighting its superiority over existing state-of-the-art alternatives The boiling crisis problem has been approached as a case study. The code and data to replicate the results can be found on the official GitHub-repository https://github.com/Hindawi91/DIPS. .\nHighlights\n\u2022\nDIPS utilizes domain knowledge and a GMM model to provide pseudo supervision.\n\u2022\nDIPS introduces a metric for evaluating UI2I models in cross-domain classification.\n\u2022\nDIPS outperforms SOTA unsupervised metrics such as the FID, KID, IS and MMD.\n\u2022\nDIPS correlates highly with true supervision, making it robust and explainable.\n\u2022\nDIPS real-world applicability is demonstrated through the boiling crisis problem.","Eosinophilic Esophagitis (EoE) is an allergic condition increasing in prevalence. To diagnose EoE, pathologists must find 15 or more eosinophils within a single high-power field (400X magnification). Determining whether or not a patient has EoE can be an arduous process and any medical imaging approaches used to assist diagnosis must consider both efficiency and precision. We propose an improvement of Adorno et al\u2019s approach for quantifying eosinphils using deep image segmentation. Our new approach leverages Monte Carlo Dropout, a common approach in deep learning to reduce overfitting, to provide uncertainty quantification on current deep learning models. The uncertainty can be visualized in an output image to evaluate model performance, provide insight to how deep learning algorithms function, and assist pathologists in identifying eosinophils.","In this paper, we address an issue of finding explainable clusters of class-uniform data in labeled datasets. The issue falls into the domain of interpretable supervised clustering. Unlike traditional clustering, supervised clustering aims at forming clusters of labeled data with high probability densities. We are particularly interested in finding clusters of data of a given class and describing the clusters with the set of comprehensive rules. We propose an iterative method to extract high-density clusters with the help of decision-tree-based classifiers as the most intuitive learning method, and discuss the method of node selection to maximize quality of identified groups.","Nature inspired algorithms have become popular for discovering classification rules due to their ability to effectively handle large and complex search spaces. However, nature inspired algorithms have to compute the fitness of individuals (candidate classification rules) over successive generations repeatedly. Each fitness computation requires scanning the training data. Since the database scan is computationally expensive operation, the execution time for nature inspired algorithms for discovering classification rules grows unreasonably faster for bulky datasets. This paper proposes a novel fitness computation framework for nature inspire algorithms by using a list structure. The indices of instances, covered by every possible attribute-value pair with respect to each class in the training data, are stored in the suggested list structure. The list is prepared only once in advance and stores all information to compute the fitness of any rule that may come up in the life time of the nature inspired algorithm. The existence of the pre-maintained list eliminates the need of scanning training data again and again for fitness computation. We have conducted experiments on 12 datasets from UCI machine learning repository. The results show that the suggested fitness computational framework brings significant speed gain without compromising predictive accuracy. Although, a Genetic Algorithm is used for classification rule discovery as the nature inspired algorithm in this paper, the fitness computation framework is general and can be used with any other nature inspired algorithm.","Although the high number of bands in hyperspectral remote sensing images increases their usefulness, it also causes some processing difficulty. In supervised classification, one problem is decreasing classification accuracy due to the insufficient training samples against the bands. A way to deal with this problem is the selection of appropriate bands by the metaheuristic methods. Because of the stochastic search, the selected bands differ in any implementation of a metaheuristic method. So, the results obtained from the classification of these different band subsets will also have some differences. In this study, a fusion-based approach has been proposed to improve the classification of hyperspectral remote sensing images by multiple implementations of a metaheuristic method for band selection. We have tested the proposed method using ten metaheuristic methods with different objective functions on four well-known datasets. The results show the proposed fusion-based approach successfully improves the classification accuracy in all experiments. The accuracy improvement varies depending on the metaheuristic method, the objective function, and the dataset and ranges from 0.4% to 15.7%. The proposed method improves the classification of complex datasets more and affects weaker objective functions considerably. The results also show the proposed method brings the accuracy of different metaheuristic methods close to each other and reduces the sensitivity of selecting the proper ones. Thus, an automated classification system can be obtained using a parameter-less method.\nHighlights\n\u2022\nA new fusion-based classification is proposed for hyperspectral images based on stochastic nature of metaheuristic methods.\n\u2022\nA fully automated classification system is developed to classify hyperspectral remote sensing images.\n\u2022\nMany Traditional and new metaheuristic methods include PSO, CSO, GWO, GEO, JSA, \u2026 are examined in the proposed framework.\n\u2022\nThe experiments are done in both case of filter and wrapper band selection with different objective function.","Granular computing involves a comprehensive process that encompasses theories, methodologies, and techniques to solve complex problems, rather than being just an algorithm. As the volume of generated data continues to grow rapidly, data-driven problems have become increasingly complex. Although deep learning models have outperformed traditional machine learning models in solving complex problems, there is still room for enhancing their performance. In this paper, we propose a granular computing-based deep learning model, aimed at enhancing classifier accuracy in complex natural language-based problems. The proposed approach involves a new granulation method, which comprises a novel algorithm built on combinatorial concepts and ten rule-based numerical granules. By utilizing this granulation method, each granule adds a new representation and concept to the existing data. The proposed model consists of multiple models that perform learning separately in a granular view. In the final step, the model pays attention to the granulated matrices generated by various models. The proposed model is evaluated using datasets related to cyberbullying and two hate speech datasets, resulting in significant improvements in accuracy compared to state-of-the-art models.\nHighlights\n\u2022\nProposing a granular computing-based deep learning model for text classification.\n\u2022\nUsing granular computing for data augmentation from a new representation in the context of deep learning-based text classification.\n\u2022\nUtilizing different representations of the existing texts.\n\u2022\nProposing the first stacked-BILSTM-SVM model in granular computing.","This study conducts a thorough evaluation of deep learning architectures, pretraining methods, and finetuning approaches for mammogram classification for tissue density. No architecture was distinctly superior. However, models pretrained on ImageNet consistently surpassed those trained on custom mammogram datasets. Finetuning strategies played a crucial role in model performance. In particular, finetuning the entire model yielded better results. Investigation of confusion matrices revealed that most misclassifications occurred within a one-grade difference, but severe misclassifications were observed in certain configurations. While some architectures offered comparable performance, trade-offs between model performance and computational efficiency were observed, with convolutional neural networks showing faster inference times on CPUs compared to vision transformers.","Smart buildings are generally equipped with thousands of heterogeneous sensors and control devices that impact the operation of their electrical systems. Analytical tools that aim to optimise the energy efficiency within such complex systems requires prior mapping or (classification) of diverse set of sensors according to a standard. Prior research primarily focuses on exploiting the similarities in sensor names (text metadata) to categorise them into identical classes (or groups). However, the sensors within and across buildings often follow distinct naming conventions by different vendors. In addition the definition of the classes or groups also varies significantly amongst researchers. This limits the usability and portability of prior techniques when applied across buildings. There are standard ontologies (Brick, Haystack etc.) that provide a set of standardized classes for the sensors in the buildings. The work herein follows a new avenue to address this challenging classification problem by (i) utilizing only time-series data of sensors and not text metadata, (ii) developing a simple, effective and hitherto unexplored Machine Learning (ML) model to classify the sensors into a set of standard Brick classes, and (iii) evaluating the model on a large proprietary dataset comprising of 129 buildings. Experimental results demonstrate promising performance of the presented data driven model, with average classification accuracy in terms of weighted F-score at 0.78 (\u00b10.14), and statistically significant improvements over prior methods.","Existing studies have recognized the effect of noise of granulated datasets on classification performance. Whether this effect continues an aid in generating decisional rules for the tree-based learning models needs to be disclosed. This study conducts an experiment that investigates the effect of noisy data on rule generation performance (RGP). The unsupervised (equal-width interval, EWI) and 28 supervised (minimum description length, MDL) techniques were used to granulate datasets. The decision-tree based classification model that either included or did not include 24 EWI and 28 MDL noisy granulated datasets were used, followed by testing and comparison on classification accuracy and RGP. Main results are as follows. Removal of noisy granulated datasets with EWI is advantageous to decision tree generation when original classification accuracy (OCA) of datasets is higher than 90% or less than 70%, but not obvious between 70% and 90%. Contrariwise, those with MDL is neither highly related to improvement of generation rate nor simplicity for scales of both higher than 90% and less than 70%, but slightly related to those with OCA between 70% and 90%.","Over the past two decades, an increasing number of large-scale structures have been built around the world. Constructing these structures has been a time consuming and highly expensive process. Thus, providing a structural health monitoring system to guarantee their proper functionality is important. In recent years, the advancement of technology and artificial intelligence methods based on signal processing and machine learning has attracted the attention of researchers. The challenges currently exist in the field of structural health monitoring to identify and classify damages to achieve high accuracy in a health-monitoring program. The presence of noise in measurement, various exciting load types, and varying environmental conditions cause difficulty in the practical identification and classification of damage in structures. Recent studies have employed finite element modeling to test the effectiveness of proposed methods for identifying damages in structures. However, detecting damage in real-world structures as mentioned above, presents unique difficulties, and the effectiveness of the proposed methods for damage detection in real-world structures remains uncertain. In order to improve the performance of damage detection methods and increase the accuracy of these methods as much as possible, the most important action is to identify damage sensitive data in the structure. The next challenge is to choose a high performance algorithm for damage identification and classification. One of the advanced algorithms, which has a very high ability to extract the desired features from the measured data, is the XGBoost algorithm. This algorithm has recently attracted the attention of researchers and has been used in different fields. So far, the ability of this algorithm has not been examined in the field of damage detection in order to extract desirable features. This article deals with the identification, classification, and severity of damages in the SMC benchmark bridge, which is an existing megastructure in the real world, as well as the IASC-ASCE benchmark structure, whose responses were taken under applied loads in the laboratory environment. First, using the XGBoost algorithm, the importance of the features extracted from the sensors' data is evaluated, and then the features, which are effective in the damage detection process, are selected. The results of this algorithm indicate that only by selecting 6 features from a large volume of data, the best performance can be achieved and selecting more does not help increase efficiency. In the next step, the Stacking method, which is a hybrid machine learning algorithm for damage classification, is evaluated and compared with some conventional machine learning algorithms that have been used in previous studies. The Stacking method stands out as the top performer with an average accuracy rate of 93.1%, leading to the conclusion that it is the most effective approach. Finally, by applying the presented algorithm to the two mentioned structures, its validation is appraised.","Ensemble learning is a technique of combining multiple base machine learning models and using the blended results as the final classification output. Such models provide a unique perspective on the classification results as it produces a more comprehensive and encompassing output. As such ensemble learning techniques are widely used for classification in today. Hence it is important that any ensemble learning model be robust and resilient to any type of data and not just applicable to one dataset. This research investigates and evaluates the robustness and the resilience of the proposed Legitimacy ensemble learning model. This ensemble learning model was previously proposed for Credibility Based Fake News Detection. This research evaluates Legitimacy\u2019s performance with a variety of datasets. In the first scenario, the Legitimacy ensemble learning model is evaluated with 3 different binary classification datasets for training and testing purposes, respectively. In the second scenario, the Legitimacy model is assessed where one dataset is used for training whilst another dataset is used for testing. In the final scenario the Legitimacy ensemble learning model is evaluated against a multiclass dataset for multiclass classification. The results of all the above tests are assimilated and evaluated. The results suggest that the Legitimacy ensemble learning model performs well in all three scenarios giving AUC values all equal to or greater than 0.500. As such it can be concluded that the Legitimacy model is a robust and resilient ensemble learning technique and can be employed for the task of classification with any dataset.","Changes to a software project are inevitable as the software requires continuous adaptations, improvements, and corrections throughout maintenance. Identifying the purpose and impact of changes made to the codebase is critical in software engineering. However, manually identifying and characterizing software changes can be a time-consuming and tedious process that adds to the workload of software engineers. To address this challenge, several attempts have been made to automatically identify and demystify intents of software changes based on software artifacts such as commit change logs, issue reports, change messages, source code files, and software documentation. However, these existing approaches have their limitations. These include a lack of data, limited performance, and an inability to evaluate compound changes. This paper presents a doctoral research proposal that aims to automate the process of identifying commit-level changes in software projects using software repository mining and code representation learning models. The research background, state-of-the-art, research objectives, research agenda, and threats to validity are discussed.","The Antinuclear Antibody (ANA) test is a valuable diagnostic tool for autoimmune disorders that uses Indirect Immunofluorescence (IIF) microscopy with HEp-2 cells as the substrate to identify antibodies and their distinct staining patterns. Machine learning-based approaches have shown promise in automating this diagnosis process, with Data Augmentation (DA) techniques playing a crucial role in improving performance. Even though traditional DA methods have yielded positive results, generative techniques like Variational AutoEncoders (VAEs) have shown potential in exploring the input distribution and generating new images. To address the limitations of traditional DA and explore the potential of generative approaches, this paper focuses on applying Conditional Variational AutoEncoders (CVAEs) to HEp-2 cell image classification. A customized CVAE architecture is proposed, considering multiple labels during generation to enhance versatility. Extensive experiments were conducted with the largest publicly available dataset of HEp-2 cell images, the I3A dataset. The performance of traditional and generative data augmentation techniques were compared while investigating potential synergies between them. The findings highlight the benefits of combining these techniques, especially in scenarios with class imbalance. Thorough statistical analysis provides valuable insights from the experimental results.","In recent years, numerous machine learning-based systems have actively propagated discriminatory effects and harmed historically disadvantaged groups through their decision-making. This undesired behavior highlights the importance of research topics such as fairness in machine learning, whose primary goal is to include fairness notions into the training process to build fairer models. In parallel, Differential Item Functioning (DIF) is a mathematical tool often used to identify bias in test preparation for candidate selection; DIF detection assists in identifying test items that disproportionately favor or disadvantage candidates solely because they belong to a specific sociodemographic group. This paper argues that transposing DIF concepts into the machine learning domain can lead to promising approaches for developing fairer solutions. As such, we propose DIF-SR, the first DIF-based Sample Reweighting method for weighting samples so that the assigned values help build fairer classifiers. DIF-SR can be seen as a data preprocessor that imposes more importance on the most auspicious examples in achieving equity ideals. We experimentally evaluated our proposal against two baseline strategies by employing twelve datasets, five classification algorithms, four performance measures, one multicriteria measure, and one statistical significance test. Results indicate that the sample weight computed by DIF-SR can guide supervised machine learning methods to fit fairer models, simultaneously improving group fairness notions such as demographic parity, equal opportunity, and equalized odds.","With advances in sensing technology, multi-modal data collected from different sources are increasingly available. Multi-modal classification aims to integrate complementary information from multi-modal data to improve model classification performance. However, existing multi-modal classification methods are basically weak in integrating global structural information and providing trustworthy multi-modal fusion, especially in safety-sensitive practical applications (e.g., medical diagnosis). In this paper, we propose a novel Dynamic Poly-attention Network (DPNET) for trustworthy multi-modal classification. Specifically, DPNET has four merits: (i) To capture the intrinsic modality-specific structural information, we design a structure-aware feature aggregation module to learn the corresponding structure-preserved global compact feature representation. (ii) A transparent fusion strategy based on the modality confidence estimation strategy is induced to track information variation within different modalities for dynamical fusion. (iii) To facilitate more effective and efficient multi-modal fusion, we introduce a cross-modal low-rank fusion module to reduce the complexity of tensor-based fusion and activate the implication of different rank-wise features via a rank attention mechanism. (iv) A label confidence estimation module is devised to drive the network to generate more credible confidence. An intra-class attention loss is introduced to supervise the network training. Extensive experiments on four real-world multi-modal biomedical datasets demonstrate that the proposed method achieves competitive performance compared to other state-of-the-art ones.","The wide acceptance of decision tree classifiers lies with their fast performance and simple nature. The J48 group of decision tree classifiers are widely used for classification and decision-making process. In this paper, three popular J48 group classifiers, namely J48, J48Consolidated and J48Graft are evaluated using both binary and multi-class datasets across thirteen performance matrices, which is unique in its area. In order to come across a versatile classifier, the evaluated results of these classifiers are nourished to a prominent multi-criteria decision-making module called Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) for suitable rank allocation.","Recently, the prompt tuning technique, which incorporates prompts into the input of the pre-training language model (like BERT, GPT), has shown promise in improving the performance of language models when facing limited annotated data. However, the equivalence of template semantics in learning is not related to the effect of prompts and the prompt tuning often exhibits unstable performance, which is more severe in the domain of the scientific domain. To address this challenge, we propose to enhance prompt tuning using data augmentation with L2 regularization. Namely, pairing-wise training for the pair of the original and transformed data is performed. Our experiments on two scientific text datasets (ACL-ARC and SciCite) demonstrate that our proposed method significantly improves both accuracy and robustness. By using 1000 samples out of 1688 in the ACL-ARC training set, our method achieved an F1 score 3.33% higher than the same model trained on all 1688-sample data. In the SciCite dataset, our method surpassed the same model with labeled data reduced by over 93%. Our method is also proved to have high robustness, reaching F1 scores from 1% to 8% higher than those models without our method after the Probability Weighted Word Saliency attack.","This study introduces an ensemble methodology, namely, hybrid feature ranking and classifier aggregation (HyFraCa), to integrate ensemble feature selection and ensemble classification in a composite framework. The proposed HyFraCa is embedded in a multi-criteria decision-making (MCDM)-based scheme for feature ranking and classifier weighting, with an effective aggregation rule that yields a consensus feature ranking from ensembles of heterogeneous classifiers and feature selectors. Experimental evaluations on 20 public UCI datasets demonstrated the superiority of HyFraCa in producing a more accurate and generalizable classification compared with state-of-the-art benchmark ensemble methods. HyFraCa also provides robust and reliable consensus feature rankings, which are favorable for real-world classification problems in which feature interpretability is emphasized.","As brain-related research presents increasing importance, the requirement for automatic spike detection algorithms also emerges. Traditional spike detection algorithms, including amplitude thresholding and wavelet transformation, show several shortcomings that impede the practical application. Here, we propose an artificial neural network-assisted amplitude thresholding algorithm and conduct experiments with raw signals collected from the primary somatosensory cortex and primary motor cortex of macaques. Using F1 score as an evaluation index, artificial neural networks, as well as its lightweight version, effectively help the amplitude thresholding to achieve better performance, showing enormous potential for real-time spike detection application.","A time series is a sequence of sequentially ordered real values in time. Time series classification (TSC) is the task of assigning a time series to one of a set of predefined classes, usually based on a model learned from examples. Dictionary-based methods for TSC rely on counting the frequency of certain patterns in time series and are important components of the currently most accurate TSC ensembles. One of the early dictionary-based methods was WEASEL, which at its time achieved SotA results while also being very fast. However, it is outperformed both in terms of speed and accuracy by other methods. Furthermore, its design leads to an unpredictably large memory footprint, making it inapplicable for many applications. In this paper, we present WEASEL 2.0, a complete overhaul of WEASEL based on two recent advancements in TSC: Dilation and ensembling of randomized hyper-parameter settings. These two techniques allow WEASEL 2.0 to work with a fixed-size memory footprint while at the same time improving accuracy. Compared to 15 other SotA methods on the UCR benchmark set, WEASEL 2.0 is significantly more accurate than other dictionary methods and not significantly worse than the currently best methods. Actually, it achieves the highest median accuracy over all data sets, and it performs best in 5 out of 12 problem classes. We thus believe that WEASEL 2.0 is a viable alternative for current TSC and also a potentially interesting input for future ensembles.","Clinical text classification allows assigning labels to content-based data using machine learning algorithms. However, unlike other study domains, clinical texts present complex linguistic diversity, including abbreviations, typos, and numerical patterns that are difficult to represent by the most-used classification algorithms. In this sense, sequences of character strings and symbols, known as Regular Expressions (RegExs), offer an alternative to represent complex patterns from the texts and could be used jointly with the most commonly used classification algorithms for accurate text classification. Thus, a classification algorithm can label test texts when RegExs produce no matches. This work proposes a method that combines automatically-generated RegExs and supervised algorithms for classifying clinical texts. RegExs are automatically generated using alignment algorithms in a supervised manner, filtering out those that do not meet a minimum confidence threshold and do not contain specific keywords for the classification problem. At prediction time, our method assigns the class of the most confident RegEx that matches a test text. When no RegExs matches a test text, a supervised algorithm assigns a class. Three clinical datasets with textual information on obesity and smoking habits were used to assess the performance of four classifiers based on Random Forest (RF), Support Vector Machine (SVM), Naive Bayes (NB), and Bidirectional Encoder Representations from Transformers (BERT). Classification results indicate that our method, on average, improved the classifiers\u2019 performance by up to 12% in all performance metrics. These results show the ability of our method to generate confident RegExs that capture representative patterns from the texts for use with supervised algorithms.","Highlights\n\u2022\nA fault diagnosis method based on the ADTC model is proposed.\n\u2022\nThe ADTC model can extract and verify the features of unlabeled data.\n\u2022\nThe proposed model provides a method for solving the insufficient data problem.\n\u2022\nExperiment results demonstrate the high performance of the proposed method.\nAbstract\nFault diagnosis of mechanical equipment using data-driven machine learning methods has been developed recently as a promising technique for improving the reliability of industrial systems. However, these methods suffer from data sparsity due to the difficulty in data collection, which limits the feature extraction of anomalies. To solve this problem, we propose the mel spectrogram-based advanced deep temporal clustering (ADTC) model, which can extract and verify the features of unlabeled data through an unsupervised learning based autoencoder and the K-means. In addition, the ADTC model uses the proposed centroid based learning to obtain calibrated unsupervised learning data by minimizing the data point and target centroid distances for misclustered encoder output features in ensemble-based unsupervised learning. The classifier of the ADTC model uses a supervised learning based deep support vector machine network model, which is robust to nonlinear data, to diagnose the faults of the mechanical equipment. The proposed ADTC model was validated using mechanical equipment dataset with data augmentation to address the imbalanced dataset problem. During experiments, the mel spectrogram-based ADTC model exhibited the best performance in the various industrial environment with a prediction accuracy as high as 98.06%, outperforming other compared algorithms.","Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to the increasing complexity of attacks and CPS themselves, anomaly detection in CPS is becoming more and more challenging. In our previous work, we proposed a digital twin-based anomaly detection method, called ATTAIN, which takes advantage of both historical and real-time data of CPS. However, such data vary significantly in terms of difficulty. Therefore, similar to human learning processes, deep learning models (e.g., ATTAIN) can benefit from an easy-to-difficult curriculum. To this end, in this paper, we present a novel approach, named digitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), which extends ATTAIN by introducing curriculum learning to optimize its learning paradigm. LATTICE attributes each sample with a difficulty score, before being fed into a training scheduler. The training scheduler samples batches of training data based on these difficulty scores such that learning from easy to difficult data can be performed. To evaluate LATTICE, we use five publicly available datasets collected from five real-world CPS testbeds. We compare LATTICE with ATTAIN and two other state-of-the-art anomaly detectors. Evaluation results show that LATTICE outperforms the three baselines and ATTAIN by 0.906%-2.367% in terms of the F1 score. LATTICE also, on average, reduces the training time of ATTAIN by 4.2% on the five datasets and is on par with the baselines in terms of detection delay time.","Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBERT, and (3) proposing a systematic way to measure and mitigate biases. Our results show the better performance of our approach on zero-shot and full-training settings in comparison with strong baseline models, while also revealing the existence of biases in the resulting LLMs. Utilizing a targeted counterfactual data augmentation approach, we significantly reduce these biases without compromising performance.","Ensembling is a popular and effective method for improving machine learning (ML) models. It proves its value not only in classical ML but also for deep learning. Ensembles enhance the quality and trustworthiness of ML solutions, and allow uncertainty estimation. However, they come at a price: training ensembles of deep learning models eat a huge amount of computational resources. A snapshot ensembling collects models in the ensemble along a single training path. As it runs training only one time, the computational time is similar to the training of one model. However, the quality of models along the training path is different: typically, later models are better if no overfitting occurs. So, the models are of varying utility. Our method improves snapshot ensembling by selecting and weighting ensemble members along the training path. It relies on training-time likelihoods without looking at validation sample errors that standard stacking methods do. Experimental evidence for Fashion MNIST, CIFAR-10, and CIFAR-100 datasets demonstrates the superior quality of the proposed weighted ensembles c.t. vanilla ensembling of deep learning models. The suggested approach spends on training of N models N times less time than classical ensemble and provides significantly higher quality compared to the single model."],"author":["Sotero, Roberto C and Sanchez-Bornot, Jose M and Shaharabi-Farahani, Iman and Iturria-Medina, Yasser","Ankit and Saleena, Nabizath","Li, Jingbo and Yang, Guijun and Yang, Hao and Xu, Weimeng and Feng, Haikuan and Xu, Bo and Chen, Riqiang and Zhang, Chengjian and Wang, Han","El Hlouli, Fatima Zohra and Riffi, Jamal and Mahraz, Mohamed Adnane and Yahyaouy, Ali and El Fazazy, Khalid and Tairi, Hamid","Manivannan, Siyamalan","NaN","Hu, Zhenda and Wang, Zhaoxia and Wang, Yinglin and Tan, Ah-Hwee","Senthil Kumar, Prathyusha","NaN","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","Kalb, Thorsten and Kushibar, Kaisar and Cintas, Celia and Lekadir, Karim and Diaz, Oliver and Osuala, Richard","Ahmed, Abdelfatah and Velayudhan, Divya and Hassan, Taimur and Bennamoun, Mohammed and Damiani, Ernesto and Werghi, Naoufel","Kim, Seonjun and Kim, Minjae and Lee, Youngki","Lv, Yan and Yin, Yu Jia and Guo, Wenwen and Bai, Lan","Sotero, Roberto Carlos and Sanchez-Bornot, Jose Miguel and Iturria-Medina, Yasser","NaN","Dantas, Cassio F. and Drumond, Thalita F. and Marcos, Diego and Ienco, Dino","Miftahushudur, Tajul and Sahin, Halil Mertkan and Grieve, Bruce and Yin, Hujun","NaN","Chen, Benwei and Zhang, Xianyong and Yang, Jilin","Shi, Yu and Xu, Ning and Yuan, Hua and Geng, Xin","Verbiest, Nele and Ramentol, Enislay and Cornelis, Chris and Herrera, Francisco","NaN","Mohiuddin, Karishma and Alam, Mirza Ariful and Alam, Mirza Mohtashim and Welke, Pascal and Martin, Michael and Lehmann, Jens and Vahdati, Sahar","Liu, Ruiqi and Xu, Ganggang and Shang, Zuofeng","Ueda, Ryosuke and Takeuchi, Koh and Kashima, Hisashi","Fan, Jinfu and Jiang, Zhencun and Xian, Yuanqing and Wang, Zhongjie","Asmita, Sharma and Pranshul, Lakhanpal and Marin, Litoiu and Lauren E., Sergio and Sumona, Mukhopadhyay","Kamali Lassem, Nima and Gaafar, Obai Mohamed Hisham Abdelmohsen and Ali, Seyid Amjad","Mamdouh Farghaly, Heba and Abd El-Hafeez, Tarek","Chen, Jinqian and Zhu, Jihua and Zheng, Qinghai","NaN","Bhope, Rahul Atul and Jayaram, K. R. and Venkatasubramanian, Nalini and Verma, Ashish and Thomas, Gegi","Ritesh and Bhagvati, Chakravarthy","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","NaN","Mishra, Aakriti and Ramanathan, A. and Batta, Vineet and Malathy, C. and Kundu, Soumya Snigdha and Gayathri, M. and Vathana, D. and Kamineni, Srinath","Dharwada, Sriram and Tembhurne, Jitendra and Diwan, Tausif","Chen, Xu and Marazopoulou, Katerina and Lee, Wesley and Agarwal, Christine and Sukumaran, Jason and Hofleitner, Aude","NaN","Zhou, Jing-Wen and Fu, Shao-Feng and Li, Long-Hai and Dong, Jun-Zhe","Huang, Linqing and Zhao, Wangbo and Liew, Alan Wee-Chung and You, Yang","Liu, Dan and Zhong, Shisheng and Lin, Lin and Zhao, Minghang and Fu, Xuyun and Liu, Xueyun","Amgoud, Leila and Muller, Philippe and Trenquier, Henri","Gupta, Rohan Kumar and Sinha, Rohit","NaN","Li, Ximing and Wang, Bing and Wang, Yang and Wang, Meng","Rajalakshmi, A. and Sridhar, S. S.","Xia, Tian and Shao, Yabin and Xia, Shuyin and Xiong, Yiping and Lian, Xiaoyu and Ling, Wu","Chen, Zhikui and Lou, Kai and Liu, Zhenjiao and Li, Yue and Luo, Yiming and Zhao, Liang","Koottungal, Akash and Pandey, Shailesh and Nambiar, Athira","Airao, Jay and Gupta, Abhishek and Saraf, Gaurav and Nirala, Chandrakant K","Tripathi, Diwakar and Edla, Damodar Reddy and Kuppili, Venkatanareshbabu and Bablani, Annushree and Dharavath, Ramesh","Viana, Talles B. and Souza, Victor L.F. and Oliveira, Adriano L.I. and Cruz, Rafael M.O. and Sabourin, Robert","Gyasi-Agyei, Amoakoh","Shen, Yuhao and Li, Bo and Xu, Xinlan and Luo, Bing and Zhang, Chao and Hao, Fei","Zhu, Jianjian and Su, Zhongqing and Wang, Qingqing and Lan, Zifeng and Siu-fai Chan, Frankie and Han, Zhibin and Wang, Zhaokun and Wing-fai Wong, Sidney and Chi-fung Ngan, Andy","NaN","Behera, Adarsh Prasad and Morabito, Roberto and Widmer, Joerg and Champati, Jaya Prakash","Firdous, Naira and Din, Nusrat Mohi Ud and Assad, Assif","Gillala, Rekha and Mishra, Anand Kumar and Tyagi, Amit Kumar","Putzu, Lorenzo and Loddo, Andrea","Matorin, S. I. and Gul, S. V. and Shcherbinina, N. V.","Shi, Shengnan and Li, Jie and Zhu, Dan and Yang, Fang and Xu, Yong","Lu, Ting and Ding, Kexin and Fu, Wei and Li, Shutao and Guo, Anjing","Nouri, Zahra and Kiani, Vahid and Fadishei, Hamid","Xu, Zhongguo and Jha, Naresh and Mehadi, Syed and Mandal, Mrinal","Sharma, Arnav and Sharma, Subhanjali and Bhardwaj, Utkarsh and Mistry, Sajib and Deb, Novarun and Krishna, Aneesh","Chen, Jianting and Ding, Ling and Yang, Yunxiao and Xiang, Yang","Zhuang, Yuchen and Yu, Yue and Kong, Lingkai and Chen, Xiang and Zhang, Chao","Li, Li and Han, Qihong and Li, Jiayao and Cui, Zhanqi","Jaiswal, Dibyanshu and Chatterjee, Debatri and B s, Mithun and Ramakrishnan, Ramesh Kumar and Pal, Arpan","Bisen, Tejasvee and Javed, Mohammed and Kirtania, Shashank and Nagabhushan, P.","Sabitha, P. and Meeragandhi, G.","Jhee, Jong Ho and Yeon, Jeongheun and Kwak, Yoonshin and Shin, Hyunjung","Adel, Alti and Farid, Ayeche","Wu, Hanrui and Li, Nuosi and Zhang, Jia and Chen, Sentao and Ng, Michael K. and Long, Jinyi","Sithungu, Siphesihle Philezwini and Ehlers, Elizabeth Marie","Ghosh, Bishwamittra","Etemadi, Sepideh and Khashei, Mehdi and Tamizi, Saba","Fu, Rui and Wu, Yuncheng and Xu, Quanqing and Zhang, Meihui","Chahi, Abderrazak and El-merabet, Youssef and Ruichek, Yassine and Touahni, Raja","Liu, Jingyi and Li, Sheng","Wang, Huaduo and Gupta, Gopal","NaN","Yao, Jianping and Tran, Son N. and Sawyer, Samantha and Garg, Saurabh","Zhang, Han and Wang, Xinyu and Liu, Junxiu and Zhang, Lei and Ji, Lixia","Ali, Muhammad and Zhu, Peimin and Jiang, Ren and Huolin, Ma and Ehsan, Muhsan and Hussain, Wakeel and Zhang, Hao and Ashraf, Umar and Ullaah, Jared","Li, Hao-Tian and Wei, Tong and Yang, Hao and Hu, Kun and Peng, Chong and Sun, Li-Bo and Cai, Xun-Liang and Zhang, Min-Ling","Jang, Jun-Gi and Shim, Sooyeon and Egay, Vladimir and Lee, Jeeyong and Park, Jongmin and Chae, Suhyun and Kang, U","Jo, Nathanael and Aghaei, Sina and Benson, Jack and Gomez, Andres and Vayanos, Phebe","Huang, Yingcheng and Xiao, Fuyuan","Mushava, Jonah and Murray, Michael","Zhang, Liu and Wei, Yaoguang and Liu, Jincun and Wu, Jianwei and An, Dong","NaN","Ozkaya, Suat Gokhan and Baygin, Mehmet and Barua, Prabal Datta and Tuncer, Turker and Dogan, Sengul and Chakraborty, Subrata and Acharya, U. Rajendra","Zeng, Jie and Xiao, Fuyuan","Han, Feiyang and Miao, Yun and Sun, Zhaoyi and Wei, Yimin","Zhang, Bo and Ming, Zuheng and Liu, Yaqian and Feng, Wei and He, Liang and Zhao, Kaixing","He, Jiahui and Zia, Haris Bin and Castro, Ignacio and Raman, Aravindh and Sastry, Nishanth and Tyson, Gareth","Shrivastava, Saurabh and Shukla, Sanyam and Khare, Nilay","NaN","Abeyrathna, K. Darshana and Abouzeid, Ahmed A. O. and Bhattarai, Bimal and Giri, Charul and Glimsdal, Sondre and Granmo, Ole-Christoffer and Jiao, Lei and Saha, Rupsa and Sharma, Jivitesh and Tunheim, Svein A. and Zhang, Xuan","Purwar, Archana and Manju, Ms.","Gundawar, Atharva and Lodha, Srishti and Vijayarajan, V. and Iyer, Balaji and Prasath, V. B. Surya","Yamaguchi, Akihiro and Ueno, Ken and Kashima, Hisashi","Ma, Guanghui and Hu, Chunming and Ge, Ling and Zhang, Hong","Erceg, Mirjana and Palamas, Georgios","Li, Jianqiang and Cheng, Wenxiu and Xu, Xi and Zhao, Linna and Liu, Suqin and Gao, Zhengkai and Ye, Caihua and You, Huanling","Kuljeet Singh and Shastri, Sourabh and Kumar, Sachin and Mansotra, Vibhakar","Yuan, Yage and Wei, Jianan and Huang, Haisong and Jiao, Weidong and Wang, Jiaxin and Chen, Hualin","Oh, Se Won and Jeong, Hyuntae and Chung, Seungeun and Lim, Jeong Mook and Noh, Kyoung Ju","NaN","Nancy, V. Auxilia Osvin and Prabhavathy, P. and Arya, Meenakshi S. and Ahamed, B. Shamreen","Sahu, Sushanta Kumar and Chowdhury, Ananda S.","Singh, Onkar and Kashyap, Kanchan Lata and Singh, Koushlendra Kumar","Mu, Tengxiao and Liang, Yaru and Liu, Lingzhi","Paul, Jackson H. and Digh, Andy D.","Tang, Jun and Chen, Wenhui and Wang, Ke and Zhang, Yan and Liang, Dong","NaN","Roy, Debaditya and Lekssays, Ahmed and Girdzijauskas, Sarunas and Carminati, Barbara and Ferrari, Elena","Wang, Rui and Huang, Weiguo and Zhang, Xiao and Wang, Jun and Ding, Chuancang and Shen, Changqing","Raza, Rehan and Zulfiqar, Fatima and Khan, Muhammad Owais and Arif, Muhammad and Alvi, Atif and Iftikhar, Muhammad Aksam and Alam, Tanvir","NaN","Kim, Taeheung and Lee, Jong-Seok","NaN","Liu, Lingzhi and Qiang, Baohua and Wang, Yuanchun and Yang, Xianyi and Tian, Jubo and Zhang, Shihao","Yi, Liping and Wang, Gang and Liu, Xiaoguang and Shi, Zhuan and Yu, Han","Ashraf, Mudasir and Zaman, Majid and Ahmed, Muheet","Grina, Fares and Elouedi, Zied and Lefevre, Eric","Qawqzeh, Yousef K and Ashraf, Mahwish","Sun, Siqi and Wang, Yongyu","Deng, Jiakang and Xing, De and Chen, Cheng and Han, Yongguo and Chen, Jianqiang","Langenecker, Sven and Sturm, Christoph and Schalles, Christian Schalles and Binnig, Carsten","Dai, Lulu and Han, Mingyue","NaN","Li, Chen and Shao, Yabin and Xia, Shuyin and Wang, Cheng and Xia, Tian and Peng, Xiaoli","Ma, Xi-Ao and Jiang, Wentian and Ling, Yun and Yang, Bailin","Yin, Xiuye and Chen, Liyong","Sun, Pengbo and Zuo, Yi and Wang, Yudi","Ren, He and Wang, Jun and Huang, Weiguo and Jiang, Xingxing and Zhu, Zhongkui","Alshayeji, Mohammad H. and Sindhu, Silpa ChandraBhasi and Abed, Sa'ed","NaN","NaN","Hechen, Zhenzhe and Huang, Wei and Yin, Le and Xie, Wenjing and Zhao, Yixin","Zhang, Zhuo and Wang, Hongfei and Jiang, Wen and Geng, Jie","Khatri, Sabita and Arora, Deepak and Kumar, Anil","Kulkarni, Atharva and Masud, Sarah and Goyal, Vikram and Chakraborty, Tanmoy","Qian, Wenbin and Xiong, Yinsong and Ding, Weiping and Huang, Jintao and Vong, Chi-Man","Geng, Zengmin and Lin, Bijun and Yuan, Ye and Liu, Shiyu and Gao, Dandan and Du, Jianxia","Mu, Qiaoxu and Zhang, Meng","Chen, Mingcai and Zhao, Yu and Wang, Zhonghuang and He, Bing and Yao, Jianhua","Christen, Peter and Hand, David J. and Kirielle, Nishadi","NaN","Hu, Mingzhi and Zhang, Xin and Li, Yanhua and Zhou, Xun and Luo, Jun","Zhao, Konghao and Bhandari, Sapan and Whitener, Nathan P and Grayson, Jason M and Khuri, Natalia","Barzinji, Ala Othman and Ma, Jixin and Ma, Chaoying","Wang, Lin and Gjoreski, Hristijan and Ciliberto, Mathias and Lago, Paula and Murao, Kazuya and Okita, Tsuyoshi and Roggen, Daniel","Chen, Xiangbo and Nishiyama, Masashi and Iwai, Yoshio","Wang, Yijin and Peng, Yali and Liu, Shigang and Ge, Bao and Li, Jun","Payntar, Nicole D.","Mirzaei, Sayeh","Hu, Boren and Zhu, Yun and Li, Jiacheng and Tang, Siliang","Liang, Chunhui and Ma, Wenqing","Jayanthi, B. and Kumar, Lakshmi Sutha","Kathuria, Charu and Mehrotra, Deepti and Misra, Navnit Kumar","Ke, Ting and Ge, Xuechun and Yin, Feifei and Zhang, Lidong and Zheng, Yaozong and Zhang, Chuanlei and Li, Jianrong and Wang, Bo and Wang, Wei","Kai, Yang and Miao, Zhang and Peng, Sun and Miaomiao, Qi","Xu, Bo and Bhatti, Uzair Aslam and Tang, Hao and Yan, Jialin and Wu, Shulei and Sarhan, Nadia and Awwad, Emad Mahrous and M. S., Syam and Ghadi, Yazeed Yasin","Debnath, Chandrima and Guha, Debashree and Hait, Swati Rani and Guria, Soumita and Chakraborty, Debjani","Singhal, Abhishek and Sharma, Devendra Kumar","Jeune, Hayden and Pechan, Niklas and Reitsma, Sharn-Konet and Kempa-Liehr, Andreas W.","Andersen, Lasse R. and Jacobsen, Lukas J. and Campos, David","Akritidis, Leonidas and Bozanis, Panayiotis","Lee, Eunji and Kim, Sihyeon and Kim, Sundong and Jung, Soyeon and Kim, Heeja and Cha, Meeyoung","Abdulnagimov, Ansaf and Lopukhova, Ekaterina and Alektorov, Gleb and Klyavlin, Nail","Mougan, Carlos and Alvarez, Jose Manuel and Ruggieri, Salvatore and Staab, Steffen","Wasi, Nesar Ahmad and Abulaish, Muhammad","Yao, Rujing and Wu, Ou","Koga, Tsukasa and Maruyama, Osamu","Diep, Tuong-Nghiem and Tran, Thien-Phuc and Ho-Ngoc, Vinh-Phat and Yang, Tuan-Anh and Do, Trong-Le","Baroni, Giulia L. and Rasotto, Laura and Roitero, Kevin and Siraj, Ameer Hamza and Della Mea, V.","Du, Yanrui and Yan, Jing and Chen, Yan and Liu, Jing and Zhao, Sendong and She, Qiaoqiao and Wu, Hua and Wang, Haifeng and Qin, Bing","Philips, James and Tabrizi, Nasseh","Besharati Moghaddam, Fatemeh and Lopez, Angel J. and Van Gheluwe, Casper and De Vuyst, Stijn and Gautama, Sidharta","Bahri, Shivani and Bahri, Pranav and Lal, Sangeeta","Zhao, Yifeng and Yang, Liming","NaN","Chen, Qiong and Huang, Tianlin and Liu, Qingfa","Li, Mingxiang and Xing, Huange and Wang, Tengyun and Xiao, Kaiming","NaN","Liang, Xiayu and Gao, Ying and Xu, Shanrong","Sloan, Derek and Dombay, Evelin and Sabiiti, Wilber and Mtafya, Bariki and Arandelovic, Ognjen and Zachariou, Marios","Hasan, Ali M. and Al-Waely, Noor K.N. and Aljobouri, Hadeel K. and Jalab, Hamid A. and Ibrahim, Rabha W. and Meziane, Farid","Chhabra, Parth and Neerkaje, Atula Tejaswi and Agarwal, Shivam and Sawhney, Ramit and Thakkar, Megh and Nakov, Preslav and Chava, Sudheer","Gao, Yi and Xu, Miao and Zhang, Min-Ling","Ding, Biyun and Zhang, Tao and Wang, Chao and Liu, Ganjun and Liang, Jinhua and Hu, Ruimin and Wu, Yulin and Guo, Difei","Sun, Zhigang and Wang, Guotao and Zhai, Guofu and Li, Pengfei and Liang, Qi and Zhang, Min","Nariswari, Rinda and Pudjihastuti, Herena","Banoth, Ravi Kumar and Murthy, B. V. Ramana","Rao, Talgan Kumar and Darapaneni, Narayana and Paduri, Anwesh Reddy and S, Amarnath G and Kumar, Arun and Ps, Guruprasad","Sharma, Rohit and Mahanti, Gautam Kumar and Chakraborty, Chinmay and Panda, Ganapati and Rath, Adyasha","Zhang, Jiayun and Zhang, Xiyuan and Zhang, Xinyang and Hong, Dezhi and Gupta, Rajesh K. and Shang, Jingbo","Zheng, Jian and Hu, Xin","Corbara, Silvia and Moreo, Alejandro and Sebastiani, Fabrizio","Spinnato, Francesco and Guidotti, Riccardo and Monreale, Anna and Nanni, Mirco and Pedreschi, Dino and Giannotti, Fosca","Damarla, Seshu Kumar","Tariq, Muhammad Arham and Sargano, Allah Bux and Iftikhar, Muhammad Aksam and Habib, Zulfiqar","Bond, Jacob and Gupta, Siddhartha and Elvitigala, Thanura","Teng, Zeyu and Cao, Peng and Huang, Min and Gao, Zheming and Wang, Xingwei","Chandana Mani, R.K. and Kamalakannan, J.","Blachnik, Marcin and undefinedciegienka, Piotr and Da\u0327browski, Daniel","Edla, Damodar Reddy and Ansari, Md Fahim and Chaudhary, Nikhil and Dodia, Shubham","Lung, Rodica Ioana and Suciu, Mihai-Alexandru","Ojo, Akinlolu Oluwabusayo and Bouguila, Nizar","Xiang, Yu and Bai, Lei","NaN","Sun, Yanjie and Xu, Kele and Liu, Chaorun and Dou, Yong and Qian, Kun","NaN","Xu, Ping and Zhao, Yang and Xue, Lingyun and Liu, Yian and Yan, Ming and Zhu, Lei and Weng, Lin and Hu, Shundi and Wen, Luhong","NaN","Akash, Bathini Sai and Kumar, Lov and Singh, Vikram and Patel, Anoop Kumar and Krishna, Aneesh","Trieu, Nguyen Minh and Thinh, Nguyen Truong","Niranjan, Ranjani and Rao, Sachit","Bahala, Renante G. and Sagum, Ria A.","Han, Fenggang and Zhang, Xiao and He, Linjie and Kong, Liru and Chen, Yumin","NaN","Site, Aditi and Nurmi, Jari and Lohan, Elena Simona","Azizi, Afshin and Zhang, Zhao and Rui, Zhaoyu and Li, Yunxi and Igathinathane, C. and Flores, Paulo and Mathew, Jithin and Pourreza, Alireza and Han, Xiongzhe and Zhang, Man","Negru, Vlad-Andrei and Lemnaru, Camelia and Potolea, Rodica","Caliskan, Abdullah and O'Brien, Conor and Panduru, Krishna and Walsh, Joseph and Riordan, Daniel","Roussinov, Dmitri and Sharoff, Serge and Puchnina, Nadezhda","NaN","NaN","Rozendo, Guilherme Botazzo and Roberto, Guilherme Freire and do Nascimento, Marcelo Zanchetta and Alves Neves, Leandro and Lumini, Alessandra","Zhou, Yu Sheng","He, Xiaoxu","Saha, Sourajit and Saha, Nisha","NaN","Zeng, Meng and Zhang, Zhonglin","Duan, Jicong and Gu, Yan and Yu, Hualong and Yang, Xibei and Gao, Shang","Mao, Jun-Xiang and Wang, Wei and Zhang, Min-Ling","Wang, Hewen and Yang, Renchi and Huang, Keke and Xiao, Xiaokui","Tian, Yuchen and Wang, Jiacheng and Jin, Yueming and Wang, Liansheng","Che, Xiaoya and Chen, Degang and Deng, Jiang and Mi, Jusheng","Yumang, Analyn N and Banguilan, Dave Emilson S and Veneracion, Clark Kent S","Fan, Caoyun and Chen, Wenqing and Tian, Jidong and Li, Yitian and He, Hao and Jin, Yaohui","Gu, Qiangqiang and Shaikh, Nazim and Lin, Ping-chang and Jayachandran, Srinath and Porwal, Prasanna and Li, Xiao and Nie, Yao","Khater, Tarek and Tawfik, Hissam and Singh, Balbir","Pan, Haiyang and Xu, Haifeng and Zheng, Jinde and Tong, Jinyu","Manisha and Clifford, William and McLaughlin, Eugene and Stynes, Paul","Sun, Guoying and Cheng, Yanan and Zhang, Zhaoxin and Tong, Xiaojun and Chai, Tingting","Islam, MD. Sajjatul and Sang, Yongsheng and Mohammed, Adam A.Q. and Yuan, Lei and Lv, Jiancheng","Calzavara, Stefano and Cazzaro, Lorenzo and Pibiri, Giulio Ermanno and Prezza, Nicola","Alcacer, Aleix and Martinez-Garcia, Marina and Epifanio, Irene","Mehak, Shakra and Leva, Maria Chiara and Kelleher, Jhon De and Guilfoyle, Michael","Lv, Jia and Song, Kaikai and Ye, Qiang and Tian, Guangjian","Zhong, Mingwei and Yi, Siqi and Fan, Jingmin and Zhang, Yikang and He, Guanglin and Cao, Yunfei and Feng, Lutao and Tan, Zhichao and Mo, Wenjun","NaN","Mcdonald, Denisa Qori and Sariyanidi, Evangelos and Zampella, Casey J. and Dejardin, Ellis and Herrington, John D. and Schultz, Robert T. and Tunc, Birkan","Wei, Jianan and Wang, Jiaxin and Huang, Haisong and Jiao, Weidong and Yuan, Yage and Chen, Hualin and Wu, Rui and Yi, Junhui","Luo, Kaiwen and Wang, Xiaomin and Sun, Fan","Kansal, Liza and Pandey, Anoushka and Shukla, Sanidhya Madhav and Dhaliwal, Parneeta","Elaraby, Nagwa and Barakat, Sherif and Rezk, Amira","Huti, Mohamed and Lee, Tiarna and Sawyer, Elinor and King, Andrew P.","Gunaratna, Kalpa and Srinivasan, Vijay and Jin, Hongxia","Shati, Pouya and Cohen, Eldan and McIlraith, Sheila","NaN","NaN","Baci, Alkid and Heindorf, Stefan","Wang, Juanyan and Bilgic, Mustafa","Dihingia, Leena and Bannulmath, Prashant and Chowdhury, Amartya Roy and Prasanna, S.R.M and Deepak, K.T and Sheikh, Tehreem","Putro, Nur Achmad Sulistyo and Avian, Cries and Prakosa, Setya Widyawan and Leu, Jenq-Shiou","Hong, Jung-Sik and Lee, Jeongeon and Sim, Min K.","Kou, Yi and Lin, Guoping and Qian, Yuhua and Liao, Shujiao","La Cava, William G","Xia, Jing and Li, Xiaolong and Tan, Yongbin and Zhang, Wu and Li, Dajun and Xiong, Zhengkun","NaN","Wu, Haiyan and Zhou, Di and Sun, Chaoqun and Zhang, Zhiqiang and Ding, Yong and Chen, Yanhong","Ou, Liang and Do, Thomas and Tran, Xuan-The and Leong, Daniel and Chang, Yu-Cheng and Wang, Yu-Kai and Lin, Chin-Teng","Yao, Ruihan and Zhang, Yufeng and Li, Zhiyao and Zhu, Jingying","Wu, Peishu and Wang, Zidong and Li, Han and Zeng, Nianyin","Mousa, Yehia and Taha, Radwa and Kaur, Ranpreet and Afifi, Shereen","Zhao, Shiman and Chen, Wei and Wang, Tengjiao","Simsek, Furkan and Pfitzmann, Brian and Raetz, Hendrik and Otholt, Jona and Yang, Haojin and Meinel, Christoph","He, Zhengxiang and Jia, Mingtao and Wang, Liguan","Zheng, Huilin and Sherazi, Syed Waseem Abbas and Arif, Saba and Lee, Myung Jin and Lee, Jong Yun","Liang, Qiao and Hu, Cheng and Huang, Haiyan","Li, Dantong and Li, Guixin and Li, Shuang and Bang, Ashley","Wang, Tianle and Wang, Zihan and Liu, Weitang and Shang, Jingbo","Shrihari, A. and Guha, Prithwijit and Kulkarni, Rishikesh Dilip","NaN","NaN","Ma, Shengjin and Yuan, Wang and Wang, Yiting and Tan, Xin and Zhang, Zhizhong and Ma, Lizhuang","Park, Jaewoo and Park, Hojin and Jeong, Eunju and Teoh, Andrew Beng Jin","Guan, Yunchuan and Liu, Yu and Zhou, Ke and Huang, Junyuan","Nirbhav and Malik, Anand and Maheshwar and Prasad, Mukesh","Zhang, Yu and Zuo, Xin and Zheng, Xuxu and Gao, Xiaoyong and Wang, Bo and Hu, Weiming","Zhang, Wei and Zhang, Pengye and Zhang, Bo and Wang, Xingxing and Wang, Dong","Li, Huan and Wang, Yue","Hendro, Hendro and Shiddiqi, Ary Mazharuddin","Gou, Hongyuan and Zhang, Xianyong and Yang, Jilin and Lv, Zhiying","Sadafi, Ario and Hehr, Matthias and Navab, Nassir and Marr, Carsten","Yuan, Gaoteng and Lu, Lu and Zhou, Xiaofeng","Hadjadj, Lies and Amini, Massih-Reza and Louhichi, Sana","Semwal, Vijay Bhaskar and Prajapat, Yogesh Kumar and Jain, Rahul","Xi, Liang and Liang, Yujia and Huang, Xunhua and Liu, Han and Li, Ao","Anand, Sidharth and Devulapally, Naresh Kumar and Bhattacharjee, Sreyasee Das and Yuan, Junsong","NaN","Li, Jingyu and Ma, Haokai and Li, Xiangxian and Qi, Zhuang and Meng, Xiangxu and Meng, Lei","Liu, Hankai and Huang, Xianying and Liu, Xiaoyang","Kim, Hayeon and Cho, Myeongji and Son, Hyeon S.","NaN","Kolipaka, Venkata Rama Rao and Namburu, Anupama","T., Prabhavathy and Elumalai, Vinodh Kumar and E., Balaji","Testa, Brian and Xiao, Yi and Sharma, Harshit and Gump, Avery and Salekin, Asif","Nasayreh, Ahmad and Al Mamlook, Rabia Emhamed and Samara, Ghassan and Gharaibeh, Hasan and Aljaidi, Mohammad and Alzu'Bi, Dalia and Al-Daoud, Essam and Abualigah, Laith","Dhakshayani, J. and Surendiran, B.","Saremi, Mohammad and Amirani, Mehdi Chehel","Panigrahi, Lipismita and Chandra, Tej Bahadur and Srivastava, Atul Kumar and Varshney, Neeraj and Singh, Kamred Udham and Mahato, Shambhu and Rajamohan, Vasudevan","NaN","Ma, Yanbiao and Jiao, Licheng and Liu, Fang and Yang, Shuyuan and Liu, Xu and Li, Lingling","Hamed, Ahmed and Tahoun, Mohamed and Nassar, Hamed","Mojtahedi, Ramtin and Hamghalam, Mohammad and Jarnagin, William R. and Do, Richard K. G. and Simpson, Amber L.","El Balghiti, Othman and Elmachtoub, Adam N. and Grigas, Paul and Tewari, Ambuj","Yu, Ziru and Cui, Wei","Chen, Lu and Luo, Xinwei and Zhou, Hanlu","Zhao, Wei and Zhao, Hong","Wang, Xu and Yang, Guangxiang and Xiao, Zhenqi and Yu, Guangling","Li, Xin and Xu, Qi and Li, Xingxing and Xin, Hao and Yuan, Yilong and Shen, Zhiheng and Zhou, Yuxuan","Liu, Yahui and Li, Bin and Yang, Shuai and Li, Zhen","Prasad, Amit and Garg, Rahul and Sabharwal, Yogish","Wu, Xin-Jian and Ao, Xiang and Zhang, Rui-Song and Liu, Cheng-Lin","Ming, Yuhang and Shao, Haidong and Cai, Baoping and Liu, Bin","Sudha, S. Baby and Dhanalakshmi, S.","NaN","Dahiya, Kunal and Yadav, Sachin and Sondhi, Sushant and Saini, Deepak and Mehta, Sonu and Jiao, Jian and Agarwal, Sumeet and Kar, Purushottam and Varma, Manik","Graham Ram, Billy and Zhang, Yu and Costa, Cristiano and Raju Ahmed, Mohammed and Peters, Thomas and Jhala, Amit and Howatt, Kirk and Sun, Xin","Park, Sunghong and Son, Sang Joon and Park, Kanghee and Nam, Yonghyun and Shin, Hyunjung","NaN","Zhao, Jianhua and Liang, Haiye and Li, Shulan and Yang, Zhiji and Wang, Zhen","Anjali Rajak and Rakesh Tripathi","Solatorio, Aivin V.","Khlifi, Ghaith and Jenhani, Ilyes and Messaoud, Montassar Ben and Mkaouer, Mohamed Wiem","Zhang, Dell and Taneva-Popova, Bilyana","Meng, Yao and Xu, Mingle and Kim, Hyongsuk and Yoon, Sook and Jeong, Yongchae and Park, Dong Sun","Wang, Lewen and Zhao, Haozhe and Feng, Cunguang and Liu, Weiqing and Huang, Congrui and Santoni, Marco and Cristofaro, Manuel and Jafrancesco, Paola and Bian, Jiang","Wang, Yifei and Zhou, Yiyang and Zhu, Jihua and Liu, Xinyuan and Yan, Wenbiao and Tian, Zhiqiang","Mior, Michael J","Rai, Prakhar and Gehlot, Shiv and Gupta, Ritu and Gupta, Anubha","Liang, Pei and Cao, Wanying and Hu, Junhua","Su, Yulin and Chen, Boan and Feng, Ziming and Yan, Junchi","NaN","Yu, Haitao and Xiong, Feng and Chen, Zuhui","Wu, Shengli and Li, Jinlong and Ding, Weimin","NaN","Kumar, Rachit and Romano, Joseph and Ritchie, Marylyn and Moore, Jason","Cho, Sungmin and Jung, Raehyuk and Kwon, Junseok","Huang, Xiaoming and Zhu, Peihu and Chen, Yuwen and Ma, Jian","Wang, Chenyu and Endo, Toshio and Hirofuchi, Takahiro and Ikegami, Tsutomu","Gordon, Lucia and Behari, Nikhil and Collier, Samuel and Bondi-Kelly, Elizabeth and Killian, Jackson A. and Ressijac, Catherine and Boucher, Peter and Davies, Andrew and Tambe, Milind","Jiang, Minghua and Liu, Shuqing and Shi, Yankang and Du, Chenghu and Tang, Guangyu and Liu, Li and Peng, Tao and Hu, Xinrong and Yu, Feng","Luo, Jueling and Long, Hui and Xie, Si and Zhang, Yalu and Ma, Haodong and Meng, Guangyao","Pavlovski, Martin and Ravindran, Srinath and Gligorijevic, Djordje and Agrawal, Shubham and Stojkovic, Ivan and Segura-Nunez, Nelson and Gligorijevic, Jelena","Gao, Bingjie and Zhou, Qianli and Deng, Yong","Debnath, Chandrima and Aishwaryaprajna and Hait, Swati Rani and Guha, Debashree and Chakraborty, Debjani","Sharma, Neha and Jain, Vibhor and Mishra, Anju","NaN","Kumari, Madhu and Singh, Vijendra","Ping, Mingtian and Pi, Dechang and Chen, Zhiwei and Wang, Junlong","Huang, Jiande and Chen, Ping and Lu, Lijuan and Deng, Yuhui and Zou, Qiang","Aruna Sri, P. and Santhi, V.","Fu, Zhiling and Wang, Zhe and Xu, Xinlei and Yang, Mengping and Chi, Ziqiu and Ding, Weichao","NaN","Upadhyay, Rishabh and Pasi, Gabriella and Viviani, Marco","Bhoi, Akash Kumar and Sherpa, Karma Sonam and Khandelwal, Bidita","Srivastava, Rajshree and Kumar, Pardeep","Channing, Georgia and Patel, Ria and Olaya, Paula and Rorabaugh, Ariel and Miyashita, Osamu and Caino-Lores, Silvina and Schuman, Catherine and Tama, Florence and Taufer, Michela","Zhang, Jianan and Wu, Yongfei and Hao, Fang and Liu, Xueyu and Li, Ming and Zhou, Daoxiang and Zheng, Wen","Konduru, S. and Amiruzzaman, M. and Avina, V. and Islam, M. R.","Abd-Alhalem, Samia M. and Marie, Hanaa Salem and El-Shafai, Walid and Altameem, Torki and Rathore, Rajkumar Singh and Hassan, Tarek M.","Pandey, Suraj Kumar and Nair, Shivashankar B","Isnan, Mahmud and Hidayat, Alam Ahmad and Pardamean, Bens","Fang, Xiaoqi and Zhang, Guoyun and Zhang, Guifeng and Zhou, Xuhui and Wu, Jianhui and Zhao, Lin","Mo, Gao","Wang, Ye and Wang, Yaxiong and Zhao, Guoshuai and Qian, Xueming","Li, Xintian and Culotta, Aron","Zhang, Xiaoming and Yu, Lean","Shi, Jue and Chen, Xiaofang and Xie, Yongfang and Zhang, Hongliang and Cen, Lihui and Sun, Yubo","Su, Yawen","Wang, Hengbin and Ye, Zijing and Wang, Yan and Liu, Xueyi and Zhang, Xindan and Zhao, Yuanyuan and Li, Shaoming and Liu, Zhe and Zhang, Xiaodong","Chen, Junming","NaN","Khan, Murtaza Ali and AlGhamdi, Mohammed","Zhang, Yong and Jiang, Yuqing and Zhang, Qi and Liu, Da","Zheng, Zhe and Zhou, Yu-Cheng and Chen, Ke-Yin and Lu, Xin-Zheng and She, Zhong-Tian and Lin, Jia-Rui","Raja Sekaran, Sarmela Ap and Pang, Ying Han and Ooi, Shih Yin","Puri, Ashishi and Kumar, Sanjeev","Ravikiran, H. K. and Jayanth, J. and Sathisha, M. S. and Bindu, K.","Kingphai, Kunjira and Moshfeghi, Yashar","Ukanchanakitti, Phatsakorn and Winaichatsak, Nattapong and Cho, Natthawin and Sumetpipat, Kanes","Retta, Ephrem Afele and Almekhlafi, Eiad and Sutcliffe, Richard and Mhamed, Mustafa and Ali, Haider and Feng, Jun","Ma, Shihan and Yang, Jidong J. and Chorzepa, Mi Geum and Morris, Clint and Kim, S. Sonny and Durham, Stephan A.","NaN","Xie, Wentao and Liu, Qian and Su, Yongye and Yan, Yi and Huang, Shujun and Kuang, Qin and Hu, Pingzhao","Gao, Qi and Long, Teng and Zhou, Zhangbing","Zhu, Qi and Li, Sen and Li, Zhantao and Min, Xianjun and Li, Qian","Lu, Menglong and Huang, Zhen and Tian, Zhiliang and Zhao, Yunxiang and Fei, Xuanyu and Li, Dongsheng","NaN","Dash, Amanda and Albu, Alexandra Branzan","Bushnell, Justin and Unverzagt, Frederick and Wadley, Virginia G. and Kennedy, Richard and Gaizo, John Del and Clark, David Glenn","Zhang, Liu and Zhang, Shubin and Liu, Jincun and Wei, Yaoguang and An, Dong and Wu, Jianwei","Wei, Yuanxi and liu, Yinan and Wang, Haibo","Merchant, Arpit and Castillo, Carlos","Berghouse, Marc and Bebis, George and Tavakkoli, Alireza","Wang, Ziquan and Li, Hui and Zhang, Zikai and Chen, Feng and Zhai, Jia","Teixeira, Ana Clara and Yazdanpanah, Hamed and Pezente, Aline and Ghassemi, Mohammad","Zou, Yizhang and Hu, Xuegang and Li, Peipei","NaN","NaN","Zhao, Ziye","Lopez Uroz, Lorenzo and Benoit, Alexandre and Yan, Yajing and Lin-Kwong-Chon, Christophe and Giffard-Roisin, Sophie and Rabatel, Antoine","Lalor, John P. and Abbasi, Ahmed and Oketch, Kezia and Yang, Yi and Forsgren, Nicole","Tzudir, Moakala and Sadashiv T.N., Rishith and Agarwal, Ayush and Prasanna, S. R. Mahadeva","Sarlas, Athanasios and Kalafatelis, Alexandros and Alexandridis, Georgios and Kourtis, Michail-Alexandros and Trakadas, Panagiotis","Stanciu, Dan-Cristian and Ionescu, Bogdan","Yang, Qiujuan and Zhang, Jiaxiao","Li, Jichang and Li, Guanbin and Yu, Yizhou","Park, Hyunseo and Lee, Gyeong Ho and Han, Jaeseob and Choi, Jun Kyun","Biggs, Mikayla and Wang, Yaohua and Soni, Neetu and Priya, Sarv and Bathla, Girish and Canahuate, Guadalupe","NaN","Shaik, Janbhasha and Bhavanam, S. Nagakishore","NaN","Ramasamy, Karthikeyan and Balakrishnan, Kiruthika and Velusamy, Durgadevi","NaN","Balamurugan, R. and Mohite, Saurabh and Raja, S. P.","Xu, Ying and Liu, Honglei and Shi, Yi and Li, Ao and Wang, Minghui","Din, Nusrat Mohi Ud and Assad, Assif and Dar, Rayees Ahmad and Rasool, Muzafar and Sabha, Saqib Ul and Majeed, Tabasum and Islam, Zahir Ul and Gulzar, Wahid and Yaseen, Aamir","John, Vijay and Kawanishi, Yasutomo","Lo, Lun-Jou and Yang, Chao-Tung and Chiang, Wen-Chung and Lin, Hsiu-Hsia","Vo, Anh H. and Nguyen, Bao T.","NaN","Guo, Yeang and Tao, Tan and Ronglin, Ronglin and Xiao, Liangfen and Ding, Lijuan and Li, Qing and Xie, Hui","Samui, Suman and Garai, Soumen and Ghosh, Anindya and Mukhopadhyay, Anand Kumar","Karimi Monsefi, Amin and Shiri, Pouya and Mohammadshirazi, Ahmad and Karimi Monsefi, Nastaran and Davies, Ron and Moosavi, Sobhan and Ramnath, Rajiv","Huang, Yan and Zhang, Zhang and Huang, Yan and Wu, Qiang and Huang, Han and Zhong, Yi and Wang, Liang","NaN","Hoang, Ngan Dao and Tran-Anh, Dat and Luong, Manh and Tran, Cong and Pham, Cuong","Hast, Anders","Zhang, Dell and Sensoy, Murat and Makrehchi, Masoud and Taneva-Popova, Bilyana and Gui, Lin and He, Yulan","Fatima, Zainab and Doulani, Khushbu and Adhikari, Mainak","Jiang, Chenzhi and Jin, Yin and Wang, Ningtao and Wu, Ruofan and Fu, Xing and Wang, Weiqiang","Duong, Huong T. and Ho, Van H. and Do, Phuc","Junttila, Jukka and Raunio, Kalle and Kokkonen, Petteri and Saarela, Olli","Zheng, Huilin and Waqar, Malik Muhammad and Arif, Saba and Sherazi, Syed Waseem Abbas and Son, Sang Hyeok and Lee, Jong Yun","Shi, Xintong and Cao, Wenzhi and Raschka, Sebastian","Wang, Jianhui and Jie, Biao and Zhang, Xingyu and Li, Wen and Wu, Zhaoxiang and Yang, Yang","Fanai, Hosein and Abbasimehr, Hossein","Bandi, Raswitha and Likhit, M. Sai Surya and Reddy, S. Rajavardhan and Bodla, Sathwik Raj and Venkat, Vempati Sai","K R, Pradeep and N C, Naveen","NaN","Zhao, Ruirui and Sun, Jianbin and Tu, Li and Jiang, Jiang","Liu, Yanchen and Lai, King Wai Chiu","Ye, Ze and Liu, Dantong and Pavani, Kaushik and Dasgupta, Sunny","Zhou, Wenjie and Li, Piji and Han, Zhaoyang and Lu, Xiaozhen and Li, Juan and Ren, Zhaochun and Liu, Zhe","Messa, Letizia and Testa, Carolina and Carelli, Stephana and Rey, Federica and Cereda, Cristina and Raimondi, Manuela Teresa and Ceri, Stefano and Pinoli, Pietro","Cui, Yuwei and Song, Qingzeng and Xue, Yongjiang and Yu, Jing","Doonyapisut, Dulyawat and Kim, Byeongkyu and Kim, Jung Kyu and Lee, Eunseok and Chung, Chan-Hwa","Zielinski, Kallil M.C. and Ribas, Lucas C. and Machicao, Jeaneth and Bruno, Odemir M.","Okkalioglu, Murat","Hikmawati, Erna and Maulidevi, Nur Ulfa and Surendro, Kridanto","Arasaki, Caio and Wolschick, Lucas and Freire, Willian and Amaral, Aline","Zhou, Jun Yu and Fei, Chun Qing and Zou, Bing Guo","Liu, Jinjun","NaN","Chen, Junze","Sharma, Mayukh and Kandasamy, Ilanthenral and Vasantha, W.B.","Liu, Bo and Li, Weibin and Xiao, Yanshan and Chen, Xiaodong and Liu, Laiwang and Liu, Changdong and Wang, Kai and Sun, Peng","Atmakuru, Akhila and Di Fatta, Giuseppe and Nicosia, Giuseppe and Varzandian, Ali and Badii, Atta","Celik, Muhammed and Inik, Ozkan","Sachan, Shivangi and Doulani, Khushbu and Adhikari, Mainak","Huang, Siteng and Wei, Qiyao and Wang, Donglin","Fu, Hui and Zhang, Ke and Wang, Jingyu","Ping, Zhichao and Sang, Guoming and Liu, Zhi and Zhang, Yijia","Babu, K. N. Surendra and Kodabagi, Mallikarjun M.","Wang, Kang and Zhang, Ji and Zhang, Jie","Jiao, Jiajia and Chen, Bo","Sim, Jinwoo and Min, Jinhong and Kim, Seokgoo and Lee, Seok Woo and Choi, Joo-Ho","Revanasiddappa, M B and Harish, B S and Kumar, S V Aruna","Dhali, Maruf A. and Reynolds, Thomas and Alizadeh, Aylar Ziad and Nijdam, Stephan H. and Schomaker, Lambert","Allu, Ramakrishna and Padmanabhuni, Venkata Nageswara Rao","Shiraishi, Hiroki and Hayamizu, Yohei and Hashiyama, Tomonori","NaN","Tiwary, Sanjeeb and Darshana, Subhashree and Mohanty, Debabrata and Dash, Adyasha and Rupsa, Potnuru and Barik, Rabindra K","Ye, Jinhuang and Wu, Jiawei and Li, Zuoyong and Zheng, Xianghan","Li, Liangping and Gong, Xun and Wang, Chenzhong and Kong, Weiji","Liu, Tong and Yuan, Xiaochen","Huang, Teng and Jia, Bin-Bin and Zhang, Min-Ling","Jadhav, Preet and Wanjale, Kirti and Chitre, Abhijit and Vaidya, Vedmani","Dave, Saransh and Basu, Ritam and Gandhi, Vineet","Younis, Raneen and Ahmadi, Zahra and Hakmeh, Abdul and Fisichella, Marco","Bhattacharya, Indranil and Ye, Ze and Pavani, Kaushik and Dasgupta, Sunny","Sun, Zhigang and Wang, Guotao and Li, Pengfei and Wang, Hui and Zhang, Min and Liang, Xiaowen","Wei, Jiaheng and Zhu, Zhaowei and Luo, Tianyi and Amid, Ehsan and Kumar, Abhishek and Liu, Yang","Zhou, Wei and Luo, Danxue","Guo, Qingwen and Wang, Chuntao and Xiao, Deqin and Huang, Qiong","Yang, Rui and Zhou, Jun and Lu, Xiangyu and Shen, Jianxun and Chen, Huizhe and Chen, Mengyuan and He, Yong and Liu, Fei","Tripathi, Ashish and Misra, Anuradha and Kumar, Kuldeep and Chaurasia, Brijesh Kumar","Ali, Waqar and Vascon, Sebastiano and Stadelmann, Thilo and Pelillo, Marcello","Ghosh, Arpita and Soni, Badal and Baruah, Ujwala","Wei, Xiao and Huang, Jianbao and Zhao, Rui and Yu, Hang and Xu, Zheng","Lv, Dingyang and Xu, Zhengjia and Zhang, Jinghui and Wang, Yuchen and Dong, Fang","Bei, Yijun and Geng, Jinsong and Liu, Erteng and Gao, Kewei and Huang, Wenqi and Feng, Zunlei","Er-Rahmadi, Btissam and Oncevay, Arturo and Ji, Yuanyi and Pan, Jeff Z.","Xu, Xun and Liao, Jingyi and Cai, Lile and Nguyen, Manh Cuong and Lu, Kangkang and Zhang, Wanyue and Yazici, Yasin and Foo, Chuan Sheng","Bae, Youngjae and Kang, Seokho","Aryal, Saurav K. and Prioleau, Howard and Shah, Ujjawal and Acharya, Sameer","Sun, Pengfei and Wang, Zhiping and Jia, Liyan and Xu, Zhaohui","Ning, Chunxiao and Xie, Yazhou","NaN","Lai, Shenqi and Du, Xi and Guo, Jia and Zhang, Kaipeng","Gehad Ismail Sayed and Aboul Ella Hassanein","Filia, Beatrice Josephine and Lienardy, Filbert Fernandes and Laksana, I Kadek Perry Bagus and Jordan, Jayasidhi Ariyo and Siento, Joyceline Graciella and Honova, Shilvia Meidhi and Hasana, Silviya and Permonangan, Ivan Halim","Ninh, Quoc-Bao and Nguyen, Hai-Chan and Huynh, Triet and Tran, Minh-Triet and Le, Trung-Nghia","Vieira, Guilherme and Valle, Marcos Eduardo and Lopes, Wilder","NaN","Liu, Na and Zhang, Fan and Chang, Liang and Duan, Fuqing","Makmur, Nathanael Matthew and Kwan, Felicia and Rana, Astrid Dewi and Kurniadi, Felix Indra","Shi, Wen and Zhao, Hong and Zhang, Haoran and Song, Lipei and Chen, Ke and Zhang, Bin","Wang, Alex X. and Chukova, Stefanka S. and Nguyen, Binh P.","Yang, Yue and Cheng, Jieren and Liu, Zhaowu and Li, Huimin and Xu, Ganglou","Wang, Ning and Zhang, Zhong-Liang and Luo, Xing-Gang","Shi, Piao and Hu, Min and Shi, Xuefeng and Ren, Fuji","Wu, Chao and Sang, Yu and Gao, Yakun","Khokhlova, Maria V. and Blinova, Olga V. and Bogdanova-Beglarian, Natalia and Sherstinova, Tatiana","Luo, Xincheng and Li, Daiwei and Zhang, Haiqing and Xu, Lang and Cai, Bo and Deng, Junyu","NaN","Frati, Lapo and Traft, Neil and Cheney, Nick","Cai, Zeyi and He, Mengyu and Li, Cheng and Qi, Hengnian and Bai, Ruibin and Yang, Jian and Zhang, Chu","Liu, Fan and Yang, Sai and Chen, Delong and Huang, Huaxi and Zhou, Jun","Xiao, Ruixuan and Dong, Yiwen and Wang, Haobo and Feng, Lei and Wu, Runze and Chen, Gang and Zhao, Junbo","Subudhi, Subhashree and Patro, Ramnarayan and Biswal, Pradyut Kumar and Bhuyan, Kanhu Charan","Wang, Siqi and Zhou, Dongmei and Cheng, Yongjian and Jiang, Meiqi","Tong, Xuming and Zhao, Zhisheng and Liang, Junhua and Ding, Lihua and Jia, Caijun and Yuan, Yanhong","Rathnayake, Himashi and Sumanapala, Janani and Rukshani, Raveesha and Ranathunga, Surangika","Huang, Weiliang and He, Wenxuan and Liao, Shuhong and Xu, Zhen and Yan, Jingwen","Wang, Huajun and Shao, Yuanhai","Laroca, Rayson and Zanlorensi, Luiz A. and Estevam, Valter and Minetto, Rodrigo and Menotti, David","NaN","Nguyen, Khang Hoang and Nguyen, Huynh Vu Nhu and Tran, Hoang Ngoc and Quach, Luyl-Da","Vasilakakis, Michael D. and Iakovidis, Dimitris K.","Aydogmus, Omur and Bingol, Mustafa Can and Boztas, Gullu and Tuncer, Turker","Sewwandi, Mahawaga Arachchige Nayomi Dulanjala and Li, Yuefeng and Zhang, Jinglan","Dholey, Moumita and Santosham, Ritesh J. M. and Ray, Soumendranath and Das, Jayanta and Chatterjee, Sanjoy and Ahmed, Rosina and Mukherjee, Jayanta","Pourkamali-Anaraki, Farhad and Nasrin, Tahamina and Jensen, Robert E. and Peterson, Amy M. and Hansen, Christopher J.","Bader, Ofek and Lichy, Adi and Dvir, Amit and Dubin, Ran and Hajaj, Chen","Badhon, Ariful Islam Mahmud and Hasan, Md Sadman and Haque, Md. Samiul and Pranto, Md. Shafayat Hossain and Ghosh, Saurav and Alam, Md. Golam Rabiul","Liu, Yifei and Wu, Yiquan and Zhang, Yating and Sun, Changlong and Lu, Weiming and Wu, Fei and Kuang, Kun","Lee, Junho and Song, Hyeonho and Lee, Dongjoon and Kim, Sundong and Sim, Jisoo and Cha, Meeyoung and Park, Kyung-Ryul","Mukherjee, Salankara and Ghosh, Ishita De","Pei, Guanxiong and Fan, Cunhang and Li, Taihao and Jin, Jia and Wang, Rui","Han, Peng and Chen, Zhiming and Jiang, Fei and Si, Jiaxin","Abbas, Gazy and Farooq, Umar and Singh, Parvinder and Khurana, Surinder Singh and Singh, Paramjeet","Tajalli, Behrad and Abad, Gorka and Picek, Stjepan","NaN","Zhang, Qin and Shi, Zelin and Zhang, Xiaolin and Chen, Xiaojun and Fournier-Viger, Philippe and Pan, Shirui","Kumar, Wahengbam Kanan and Paidimarri, Manoj and Sur, Arijit","Jia, Pengfei and Li, Xiaoyu and Xu, Min and Zhang, Lin","Zheng, Xiao and Wang, Minhui and Huang, Kai and Zhu, En","Kukreja, Sonia and Sabharwal, Munish and Katiyar, Alok and Gill, D. S.","Burada, Sreedhar and Eraiah, Manjunathswamy Byranahalli and Kumar, M. Sunil","Ilani, Arnon and Dolev, Shlomi","Alyami, Sarah and Luqman, Hamzah and Hammoudeh, Mohammad","Gao, Ruiyao and Qi, Kai and Yang, Hu","Wang, Chenhan","NaN","Xu, Fan and Zheng, Qihang and Shi, Jia and Yan, Keyu and Wang, Mingwen","St-Vincent Villeneuve, Alexandre and Plaisent, Michel","Lin, Yuxin and Ling, Bingo Wing-Kuen and Li, Caijun and Liao, Guozhao","Van Gompel, Jonas and Spina, Domenico and Develder, Chris","Gupta, Deepak and Hazarika, Barenya Bikash and Borah, Parashjyoti","Naveed, Asim and Naqvi, Syed S. and Khan, Tariq M. and Razzak, Imran","Dong, Yumin and Che, Xuanxuan and Fu, Yanying and Liu, Hengrui and Sun, Lina","Nguyen, Anh Tien and Kwak, Jin Tae","Wang, Xiaoying and Chen, Xiaohai and Zhang, Zhongwen and He, Haisheng","Jia, Jingyun and Chan, Philip K.","Sharma, Saurabh and Xian, Yongqin and Yu, Ning and Singh, Ambuj","Nair, Ajith N and Tanwar, Harshwardhan and Arjunan, Pandarasamy and Anand, Prashant and Mahdavi, Ardeshir","Prakash, Jainendra and Ghorai, Mrinmoy and Sanodiya, Rakesh","Zou, Jiahui and Yuan, Chaoxia and Zhang, Xinyu and Zou, Guohua and Wan, Alan T. K.","Moon, Hyung-Jun and Cho, Sung-Bae","Mahesworo, Bharuno and Cenggoro, Tjeng Wawan and Lumbanraja, Favorisen Rosyking and Pardamean, Bens","Ji, Cun and Du, Mingsen and Wei, Yanxuan and Hu, Yupeng and Liu, Shijun and Pan, Li and Zheng, Xiangwei","Gupta, Ashish and Gupta, Hari Prabhat and Das, Sajal K.","Cao, Alexander and Utke, Jean and Klabjan, Diego","Rajabi, Hamid and Ding, Xianzhong and Du, Wan and Cerpa, Alberto","Liao, Yilin and Su, Rixin and Wang, Wenhai and Li, Haozhe and Wang, Hao and Liu, Zhaoran and Liu, Xinggao","Fathan, Abderrahim and Alam, Jahangir and Zhu, Xiaolin","Achmamad, Abdelouahad and Elfezazi, Mohamed and Chehri, Abdellah and Ahmed, Imran and Jbari, Atman and Saadane, Rachid","Hong, Haoyuan","Xu, Yang and Wu, Shanshan and Wang, Biqi and Yang, Ming and Wu, Zebin and Yao, Yazhou and Wei, Zhihui","Domschot, Eva and Ramyaa, Ramyaa and Smith, Michael R.","Vedula, Nikhita and Collins, Marcus and Rokhlenko, Oleg","Xu, Xia and Wang, Wenjie and Yuan, Zengbei and Li, Xinlin and Wu, Tao and Yao, Xufeng","Xu, Jindong and Li, Kang and Li, Ziyi and Chong, Qianpeng and Xing, Haihua and Xing, Qianguo and Ni, Mengying","Chang, Mingzhe and Ji, Luping and Zhu, Jiewen","Jitpakdeebodin, Worawit and Sinapiromsaran, Krung","Khaked, Azhar Ali and Oishi, Nobuyuki and Roggen, Daniel and Lago, Paula","Pineda Arango, Sebastian and Grabocka, Josif","Farooque, Ghulam and Liu, Qichao and Sargano, Allah Bux and Xiao, Liang","Opanasenko, V. M. and Fazilov, Sh.Kh. and Radjabov, S. S. and Kakharov, Sh.S.","Lai, Kwei-Herng and Zha, Daochen and Chen, Huiyuan and Bendre, Mangesh and Chen, Yuzhong and Das, Mashweta and Yang, Hao and Hu, Xia","Hu, Tao","Sisodia, Deepti and Sisodia, Dilip Singh","NaN","Athithan, Senthil and Sachi, Savya and Singh, Ajay Kumar","Edla, Damodar Reddy and Mangalorekar, Kunal and Dhavalikar, Gauri and Dodia, Shubham","Shifat-E-Rabbi, Mohammad and Zhuang, Yan and Li, Shiying and Rubaiyat, Abu Hasnat Mohammad and Yin, Xuwang and Rohde, Gustavo K.","Han, Xin and Pan, Junjun and Liu, Zhimin and Zhao, Yuanzhe and Jiang, Caichao and Chen, Shiyong and Liu, Sheng and Xie, Yahong","Napier, Thomas and Ahn, Euijoon and Allen-Ankins, Slade and Lee, Ickjai","Li, Bo and Tang, Jinhong and Xie, Nengke","Che, Yongjuan and An, Yuexuan and Xue, Hui","Piet, Julien and Nwoji, Dubem and Paxson, Vern","Chatterjee, Subhajit and Byun, Yung-Cheol","Pham, Nhat Truong and Phan, Le Thi and Dang, Duc Ngoc Minh and Manavalan, Balachandran","Kapoor, Ishita and Mishra, Anju","Avudaiammal, R. and Rajangam, Vijayarajan and Durai Raji V. and Senthil Kumar S.","Dai, Jianhua and Huang, Weiyi and Zhang, Chucai and Liu, Jie","Kaur, Barjinder and Singh, Dinesh and Roy, Partha Pratim","Chen, Keke and Gu, Yuechun and Sharma, Sagar","Aseeri, Ahmad O.","Guo, Qingwen and Wang, Chuntao and Xiao, Deqin and Huang, Qiong","Zhang, Xuan and Xu, Yitian and Liu, Xuhua","Chen, Zhaoliang and Fu, Lele and Xiao, Shunxin and Wang, Shiping and Plant, Claudia and Guo, Wenzhong","Ganaie, M.A. and Kumari, Anuradha and Girard, Anouck and Kasa-Vubu, Josephine and Tanveer, M.","Hort, Max and Chen, Zhenpeng and Zhang, Jie M. and Harman, Mark and Sarro, Federica","Pusuluri, Aditya and Kachhi, Aastha and Patil, Hemant A.","Zhou, Hai and Xue, Zhe and Liu, Ying and Li, Boang and Du, Junping and Liang, Meiyu and Qi, Yuankai","Wang, Wei and Wei, Xueguang and Wang, Bailing and Li, Yan and Xin, Guodong and Wei, Yuliang","Salim, Brigita Vanessa and Chyntia and Indrawan, Jason Orlando and Hidayat, Jessica and Matthew, Steven and Mangkang, Tesalonika Abigail Eikwine and Hasana, Silviya and Permonangan, Ivan Halim","Arhin, Joseph Roger and Zhang, Xiaoling and Coker, Kenneth and Agyemang, Isaac Osei and Attipoe, Wisdom Kwame and Sam, Francis and Adjei-Mensah, Isaac and Agyei, Emmanuel","Habbat, Nassera and Nouri, Hicham and Anoun, Houda and Hassouni, Larbi","Shwetank and Neeraj and Jitendra and Vikesh and Jain, Kamal","Bao, Wenzheng and Yang, Bin","Goyal, Hemlata and Joshi, Nisheeth and Sharma, Chilka","Ahmed, Zahid and Das, Sufal","Nicolini, Marco and Ntalampiras, Stavros","Shi, Jiechuan and Liu, Kun and Yuan, Hao and Wang, Can and Yang, Bo","Ferreira, Alejandro and Curilem, Millaray and Gomez, Walter and Rios, Ricardo","Kongnim, Pongjit and Cooharojananone, Nagul and Chavarnakul, Thira","Ni, Haotian and Gu, Shilin and Fan, Ruidong and Hou, Chenping","Liu, Hanmo and Di, Shimin and Chen, Lei","Yin, Yu Jia and Lv, Yan and Guo, Wenwen and Bai, Lan","Chakka, Sai Pradeep and Sinha, Neelam","Dibaji, Mahsa and Gianchandani, Neha and Nair, Akhil and Singhal, Mansi and Souza, Roberto and Bento, Mariana","Jia, Xibin and Li, Chen and Zeng, Meng and Wang, Luo and Mi, Qing","Patel, Bharati and Sharaff, Aakanksha","Xiong, Jiale and Yang, Jing and Yan, Lei and Awais, Muhammad and Khan, Abdullah Ayub and Alizadehsani, Roohallah and Acharya, U. Rajendra","Jian, Zhongquan and Li, Jiajian and Wu, Qingqiang and Yao, Junfeng","Pingi, Sharon Torao and Nayak, Richi and Bashar, Md Abul","Li, Xiaoyu and Yang, Bei and Chen, Tiandong and Gao, Zheng and Huang, Mengjie","Hajihosseinlou, Mahsa and Maghsoudi, Abbas and Ghezelbash, Reza","Jiang, Songhao and Chu, Yan and Wang, Zhengkui and Ma, Tianxing and Wang, Hanlin and Lu, Wenxuan and Zang, Tianning and Wang, Bo","Jia, Bin-Bin and Liu, Jun-Ying and Hang, Jun-Yi and Zhang, Min-Ling","Dolzhikova, Irina and Abibullaev, Berdakh and Zollanvari, Amin","Kim, Sungwon and Lee, Junseok and Lee, Namkyeong and Kim, Wonjoong and Choi, Seungyoon and Park, Chanyoung","Antioquia, Arren Matthew C. and Cordel II, Macario O.","Kumar, Upendra","Echtioui, Amira and Zouch, Wassim and Ghorbel, Mohamed and Mhiri, Chokri","Verma, Atul Kumar and Jadeja, Mahipal","Aryal, Saurav K. and Prioleau, Howard and Aryal, Surakshya and Washington, Gloria","Sun, Lin and Li, Mengmeng and Ding, Weiping and Xu, Jiucheng","NaN","Jia, Jinfang and Feng, Xiang and Yu, Huiqun","Liu, Ju and Huang, Ling-Wei and Shao, Yuan-Hai and Chen, Wei-Jie and Li, Chun-Na","Zhang, Kuangyan and Zhang, Tuyi and Liu, Sanmin","Gallo, Giovanni and Atani, Yaser Gholizade and Leotta, Roberto and Stanco, Filippo and Buscemi, Francesca and Figuera, Marianna","NaN","He, Shuo and Feng, Lei and Yang, Guowu","Mousavi, Hamid and Loni, Mohammad and Alibeigi, Mina and Daneshtalab, Masoud","Zhang, Zheyu and Zhang, Tianping and Li, Jian","Abebe Fenta, Anduamlak and Gebeyehu, Seffi","Kamakshi, Vidhya and C Krishnan, Narayanan","Lone, Ab Waheed and Aydin, Nizamettin","Gu, Xingyue and Ding, Yijie and Xiao, Pengfeng","Liu, Bo and He, Lejian and Xie, Yuchen and Xiang, Yuejia and Zhu, Li and Ding, Weiping","Al-Hindawi, Firas and Rahman Siddiquee, Md Mahfuzur and Wu, Teresa and Hu, Han and Sun, Ying","Lin, Kevin and Brown, Donald and Syed, Sana and Greene, Adam","Kokash, Natallia and Makhnist, Leonid","Saroj and Vashishtha, Jyoti and Goyal, Pooja and Ahuja, Jyoti","Aghaee, Reza and Momeni, Mehdi and Moallem, Payman","Behzadidoost, Rashid and Mahan, Farnaz and Izadkhah, Habib","Wang, Kaier and Tikhonov, Aristarkh and Hill, Melissa and Litchfield, Lester","Rana, Mashud and Rahman, Ashfaqur and Almashor, Mahathir and McCulloch, John and Sethuvenkatraman, Subbu","Kuo, Tzu-Ming and Hung, Hsuan-Yu and Wu, Chienhsing","Ahmadian, Vahid and Beheshti Aval, S. Bahram and Noori, Mohammad and Wang, Tianyu and Altabey, Wael A.","Ramkissoon, Amit Neil and Manohar, Kris and Goodridge, Wayne","NaN","Percannella, Gennaro and Petruzzello, Umberto and Tortorella, Francesco and Vento, Mario","NaN","Zou, Xin and Tang, Chang and Zheng, Xiao and Li, Zhenglai and He, Xiao and An, Shan and Liu, Xinwang","Panigrahi, Ranjit and Borah, Samarjeet","Shi, Shijun and Hu, Kai and Xie, Jie and Guo, Ya and Wu, Huayi","Wang, Xuetao and He, Qiang and Jian, Wanwei and Meng, Haoyu and Zhang, Bailin and Jin, Huaizhi and Yang, Geng and Zhu, Lin and Wang, Linjing and Zhen, Xin","Cheng, Xiang and Han, Xuan and Song, Yu and Zhang, Tielin and Xu, Bo","NaN","Flores, Christopher A. and Verschae, Rodrigo","Hong, Geonkyo and Suh, Dongjun","Xu, Qinghua and Ali, Shaukat and Yue, Tao","NaN","Proskura, Polina and Zaytsev, Alexey"],"cluster":[6,2,9,5,1,1,10,1,9,2,6,1,1,1,6,9,1,1,7,1,1,5,1,1,1,1,1,3,8,5,1,1,5,10,9,9,1,6,1,5,9,1,1,1,1,9,9,7,1,4,8,7,5,1,1,2,1,1,1,1,1,1,9,1,4,1,1,3,4,1,4,1,1,5,4,2,4,1,1,1,5,1,2,1,2,9,1,9,1,1,1,9,5,4,1,7,1,3,4,1,7,8,1,5,1,1,10,1,1,6,9,1,7,6,1,6,1,6,4,1,1,9,6,1,1,1,4,1,1,1,5,9,4,10,2,1,1,4,2,1,3,6,1,8,4,9,1,1,5,1,9,1,1,1,1,1,1,1,1,1,9,7,1,1,1,9,7,9,9,5,7,1,9,2,1,9,1,2,1,1,1,8,10,2,1,2,1,1,1,1,1,5,1,6,1,1,1,1,7,9,9,5,1,1,1,1,9,1,1,1,6,1,7,5,1,9,1,1,2,9,1,9,8,1,2,9,6,9,1,1,9,10,9,1,1,10,9,9,1,2,1,10,1,1,4,1,10,6,1,7,2,2,9,1,9,1,9,9,1,2,1,1,7,1,6,1,5,1,8,1,5,1,9,6,4,1,10,10,2,1,6,1,6,10,2,1,5,1,6,1,1,4,1,1,1,1,1,1,3,1,5,1,1,5,1,1,3,1,6,0,1,9,5,1,7,1,2,1,7,6,1,4,1,6,1,4,1,9,9,1,1,1,1,9,1,5,9,1,1,1,1,1,1,2,9,1,1,4,2,3,9,1,5,2,5,1,1,1,1,9,1,9,1,1,9,5,1,1,6,3,9,1,10,8,3,3,7,1,1,6,6,9,9,4,2,10,3,5,1,9,1,1,6,9,4,1,9,1,1,1,1,2,1,1,6,9,6,3,1,9,1,4,1,1,4,1,5,4,1,1,1,9,1,1,1,1,1,3,5,6,1,1,1,7,9,9,6,1,1,9,1,8,6,7,9,1,6,1,1,9,7,1,9,1,1,9,6,9,9,6,1,1,1,2,1,9,3,1,1,1,5,1,9,2,5,7,2,4,6,7,2,1,1,10,5,1,2,1,1,1,1,1,1,1,1,1,1,1,6,1,9,1,9,1,1,1,1,6,1,9,4,1,1,1,8,1,2,1,1,9,8,1,1,2,1,1,4,1,8,1,10,1,2,9,2,5,9,1,1,1,5,8,7,9,2,4,7,9,1,6,1,9,5,6,5,1,6,1,1,1,1,1,9,1,9,1,1,9,4,6,6,9,1,7,9,1,6,1,4,1,1,6,1,1,9,1,1,1,3,5,4,1,9,1,1,1,1,1,1,1,9,1,10,6,4,9,9,1,9,4,1,1,9,1,1,6,9,1,9,1,6,1,1,5,1,9,8,5,7,9,1,1,1,4,1,1,1,4,10,1,1,2,4,1,1,1,1,9,9,9,1,1,1,1,6,3,8,1,1,1,6,5,1,1,9,1,9,9,7,1,2,9,1,1,7,1,1,9,1,1,1,2,1,1,1,1,3,9,1,1,5,9,1,1,1,1,5,1,8,1,4,9,2,5,1,1,1,1,1,1,5],"labels":["C-6","C-2","C-9","C-5","C-1","C-1","C-10","C-1","C-9","C-2","C-6","C-1","C-1","C-1","C-6","C-9","C-1","C-1","C-7","C-1","C-1","C-5","C-1","C-1","C-1","C-1","C-1","C-3","C-8","C-5","C-1","C-1","C-5","C-10","C-9","C-9","C-1","C-6","C-1","C-5","C-9","C-1","C-1","C-1","C-1","C-9","C-9","C-7","C-1","C-4","C-8","C-7","C-5","C-1","C-1","C-2","C-1","C-1","C-1","C-1","C-1","C-1","C-9","C-1","C-4","C-1","C-1","C-3","C-4","C-1","C-4","C-1","C-1","C-5","C-4","C-2","C-4","C-1","C-1","C-1","C-5","C-1","C-2","C-1","C-2","C-9","C-1","C-9","C-1","C-1","C-1","C-9","C-5","C-4","C-1","C-7","C-1","C-3","C-4","C-1","C-7","C-8","C-1","C-5","C-1","C-1","C-10","C-1","C-1","C-6","C-9","C-1","C-7","C-6","C-1","C-6","C-1","C-6","C-4","C-1","C-1","C-9","C-6","C-1","C-1","C-1","C-4","C-1","C-1","C-1","C-5","C-9","C-4","C-10","C-2","C-1","C-1","C-4","C-2","C-1","C-3","C-6","C-1","C-8","C-4","C-9","C-1","C-1","C-5","C-1","C-9","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-9","C-7","C-1","C-1","C-1","C-9","C-7","C-9","C-9","C-5","C-7","C-1","C-9","C-2","C-1","C-9","C-1","C-2","C-1","C-1","C-1","C-8","C-10","C-2","C-1","C-2","C-1","C-1","C-1","C-1","C-1","C-5","C-1","C-6","C-1","C-1","C-1","C-1","C-7","C-9","C-9","C-5","C-1","C-1","C-1","C-1","C-9","C-1","C-1","C-1","C-6","C-1","C-7","C-5","C-1","C-9","C-1","C-1","C-2","C-9","C-1","C-9","C-8","C-1","C-2","C-9","C-6","C-9","C-1","C-1","C-9","C-10","C-9","C-1","C-1","C-10","C-9","C-9","C-1","C-2","C-1","C-10","C-1","C-1","C-4","C-1","C-10","C-6","C-1","C-7","C-2","C-2","C-9","C-1","C-9","C-1","C-9","C-9","C-1","C-2","C-1","C-1","C-7","C-1","C-6","C-1","C-5","C-1","C-8","C-1","C-5","C-1","C-9","C-6","C-4","C-1","C-10","C-10","C-2","C-1","C-6","C-1","C-6","C-10","C-2","C-1","C-5","C-1","C-6","C-1","C-1","C-4","C-1","C-1","C-1","C-1","C-1","C-1","C-3","C-1","C-5","C-1","C-1","C-5","C-1","C-1","C-3","C-1","C-6","C-0","C-1","C-9","C-5","C-1","C-7","C-1","C-2","C-1","C-7","C-6","C-1","C-4","C-1","C-6","C-1","C-4","C-1","C-9","C-9","C-1","C-1","C-1","C-1","C-9","C-1","C-5","C-9","C-1","C-1","C-1","C-1","C-1","C-1","C-2","C-9","C-1","C-1","C-4","C-2","C-3","C-9","C-1","C-5","C-2","C-5","C-1","C-1","C-1","C-1","C-9","C-1","C-9","C-1","C-1","C-9","C-5","C-1","C-1","C-6","C-3","C-9","C-1","C-10","C-8","C-3","C-3","C-7","C-1","C-1","C-6","C-6","C-9","C-9","C-4","C-2","C-10","C-3","C-5","C-1","C-9","C-1","C-1","C-6","C-9","C-4","C-1","C-9","C-1","C-1","C-1","C-1","C-2","C-1","C-1","C-6","C-9","C-6","C-3","C-1","C-9","C-1","C-4","C-1","C-1","C-4","C-1","C-5","C-4","C-1","C-1","C-1","C-9","C-1","C-1","C-1","C-1","C-1","C-3","C-5","C-6","C-1","C-1","C-1","C-7","C-9","C-9","C-6","C-1","C-1","C-9","C-1","C-8","C-6","C-7","C-9","C-1","C-6","C-1","C-1","C-9","C-7","C-1","C-9","C-1","C-1","C-9","C-6","C-9","C-9","C-6","C-1","C-1","C-1","C-2","C-1","C-9","C-3","C-1","C-1","C-1","C-5","C-1","C-9","C-2","C-5","C-7","C-2","C-4","C-6","C-7","C-2","C-1","C-1","C-10","C-5","C-1","C-2","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-6","C-1","C-9","C-1","C-9","C-1","C-1","C-1","C-1","C-6","C-1","C-9","C-4","C-1","C-1","C-1","C-8","C-1","C-2","C-1","C-1","C-9","C-8","C-1","C-1","C-2","C-1","C-1","C-4","C-1","C-8","C-1","C-10","C-1","C-2","C-9","C-2","C-5","C-9","C-1","C-1","C-1","C-5","C-8","C-7","C-9","C-2","C-4","C-7","C-9","C-1","C-6","C-1","C-9","C-5","C-6","C-5","C-1","C-6","C-1","C-1","C-1","C-1","C-1","C-9","C-1","C-9","C-1","C-1","C-9","C-4","C-6","C-6","C-9","C-1","C-7","C-9","C-1","C-6","C-1","C-4","C-1","C-1","C-6","C-1","C-1","C-9","C-1","C-1","C-1","C-3","C-5","C-4","C-1","C-9","C-1","C-1","C-1","C-1","C-1","C-1","C-1","C-9","C-1","C-10","C-6","C-4","C-9","C-9","C-1","C-9","C-4","C-1","C-1","C-9","C-1","C-1","C-6","C-9","C-1","C-9","C-1","C-6","C-1","C-1","C-5","C-1","C-9","C-8","C-5","C-7","C-9","C-1","C-1","C-1","C-4","C-1","C-1","C-1","C-4","C-10","C-1","C-1","C-2","C-4","C-1","C-1","C-1","C-1","C-9","C-9","C-9","C-1","C-1","C-1","C-1","C-6","C-3","C-8","C-1","C-1","C-1","C-6","C-5","C-1","C-1","C-9","C-1","C-9","C-9","C-7","C-1","C-2","C-9","C-1","C-1","C-7","C-1","C-1","C-9","C-1","C-1","C-1","C-2","C-1","C-1","C-1","C-1","C-3","C-9","C-1","C-1","C-5","C-9","C-1","C-1","C-1","C-1","C-5","C-1","C-8","C-1","C-4","C-9","C-2","C-5","C-1","C-1","C-1","C-1","C-1","C-1","C-5"],"publication_date":["2023-10-18","2024-02-27","2024-02-27","2024-01-09","2024-02-27","2023-11-22","2023-05-01","2023-10-21","2023-05-01","2023-11-27","2023-10-12","2023-09-07","2023-10-02","2023-11-03","2024-02-27","2023-09-25","2023-09-18","2023-11-22","2023-10-21","2024-02-27","2023-08-19","2023-12-13","2023-12-13","2023-10-21","2023-07-03","2023-08-29","2023-09-30","2023-09-11","2024-01-22","2023-06-04","2023-10-27","2023-11-22","2023-11-27","2024-02-27","2023-12-22","2024-01-01","2023-12-02","2024-02-06","2023-08-04","2023-10-21","2023-08-20","2023-05-01","2024-02-27","2023-08-19","2023-11-29","2023-07-03","2024-02-13","2024-02-01","2023-09-13","2024-01-01","2023-11-14","2023-11-02","2024-02-27","2023-05-01","2024-02-02","2023-11-02","2024-02-01","2023-11-22","2023-10-02","2024-02-01","2023-09-28","2024-01-21","2024-02-06","2023-05-01","2023-05-01","2024-02-09","2023-10-26","2023-11-28","2024-02-01","2023-08-04","2024-02-27","2023-10-08","2023-08-02","2023-06-27","2024-02-15","2024-01-30","2024-02-01","2024-02-28","2023-08-19","2024-01-10","2023-05-30","2023-07-11","2024-02-27","2024-01-15","2023-11-27","2023-10-18","2023-05-01","2024-02-27","2023-08-19","2023-06-15","2023-08-29","2024-02-27","2024-02-27","2024-02-27","2023-05-03","2024-02-27","2024-02-27","2023-07-21","2024-02-04","2023-10-24","2024-02-27","2024-02-27","2023-08-19","2023-09-28","2023-07-23","2023-10-21","2023-08-19","2024-02-19","2024-02-01","2023-12-01","2024-02-01","2023-10-08","2023-12-13","2023-08-16","2023-12-12","2024-01-20","2024-02-22","2023-11-01","2024-01-01","2023-09-07","2023-10-08","2024-02-01","2024-02-01","2023-11-20","2023-05-01","2024-02-01","2023-05-22","2023-10-27","2024-02-27","2023-11-19","2023-06-20","2023-07-22","2024-02-07","2023-06-20","2024-02-28","2024-02-27","2023-09-13","2023-10-16","2023-11-15","2023-10-16","2024-02-27","2023-05-15","2024-01-03","2023-10-09","2024-02-01","2024-02-01","2024-02-27","2023-08-04","2024-02-01","2024-01-17","2024-02-07","2023-08-19","2023-10-06","2023-10-12","2023-08-04","2023-10-04","2023-06-27","2023-10-08","2024-02-12","2023-05-01","2023-08-09","2023-05-10","2023-08-19","2023-11-15","2024-01-01","2024-02-27","2024-02-01","2023-07-26","2024-01-08","2023-12-12","2023-08-09","2024-02-12","2023-10-11","2023-06-23","2023-12-01","2023-05-09","2023-08-29","2024-02-27","2024-02-03","2023-10-04","2023-12-07","2024-01-21","2023-08-19","2023-10-17","2023-10-21","2024-02-27","2023-08-05","2023-05-01","2024-02-07","2023-08-02","2024-02-27","2024-02-27","2023-06-07","2024-02-01","2023-07-18","2023-08-19","2024-02-27","2024-02-01","2024-02-27","2024-01-12","2023-09-28","2023-12-11","2023-08-04","2024-02-27","2023-09-06","2023-11-13","2024-01-04","2023-11-01","2023-12-01","2024-01-01","2024-02-14","2023-11-22","2024-02-27","2024-02-16","2024-02-01","2024-02-04","2023-10-09","2023-10-27","2023-11-25","2023-05-01","2023-11-27","2023-11-20","2023-08-07","2023-12-12","2024-02-27","2023-10-31","2024-01-20","2023-10-11","2024-02-27","2023-12-04","2023-08-21","2023-07-23","2024-02-27","2023-08-19","2023-11-27","2023-08-20","2024-02-27","2024-02-27","2024-01-20","2023-11-17","2024-02-01","2023-08-19","2023-08-04","2023-12-01","2024-02-01","2023-12-19","2024-02-27","2023-12-01","2023-10-02","2023-05-01","2023-12-07","2024-02-27","2024-01-10","2023-11-21","2024-02-27","2023-06-27","2023-05-01","2024-02-27","2023-11-27","2023-10-18","2024-02-27","2023-11-17","2023-09-28","2024-02-01","2023-10-12","2023-10-21","2023-08-19","2023-12-04","2024-02-27","2023-10-21","2023-08-19","2023-11-29","2024-02-28","2024-02-27","2023-05-01","2023-07-12","2023-05-26","2024-01-01","2024-01-01","2023-11-28","2023-08-20","2024-02-27","2024-02-12","2023-08-19","2023-08-25","2024-02-01","2023-11-16","2023-07-27","2023-11-15","2023-10-21","2023-12-12","2023-05-01","2024-02-27","2024-02-07","2024-01-01","2023-10-21","2024-01-01","2024-02-27","2023-08-04","2024-01-22","2023-07-27","2024-02-27","2023-10-12","2024-02-27","2023-08-19","2023-07-31","2023-05-01","2023-10-27","2023-12-13","2023-10-29","2024-02-27","2024-02-28","2023-11-19","2024-01-15","2024-02-27","2023-09-27","2024-01-15","2023-07-26","2024-02-15","2024-02-17","2024-02-01","2023-10-27","2023-12-01","2024-02-03","2023-11-01","2024-02-27","2024-02-01","2024-01-01","2023-11-02","2023-11-14","2024-02-01","2024-01-04","2024-02-04","2024-02-27","2024-01-16","2023-12-13","2023-08-04","2024-02-27","2024-02-27","2024-01-21","2024-02-27","2023-12-01","2023-11-13","2023-11-19","2023-08-09","2024-02-27","2023-08-04","2023-08-19","2023-07-17","2023-11-11","2024-02-01","2023-09-26","2023-12-13","2023-08-29","2023-09-27","2023-05-01","2023-07-24","2024-02-27","2023-11-04","2023-11-14","2023-08-19","2024-01-20","2023-12-15","2023-08-04","2024-02-01","2023-10-30","2024-02-27","2024-01-01","2024-02-27","2023-11-20","2023-10-23","2024-02-14","2024-02-27","2023-11-27","2023-09-04","2024-02-27","2024-02-19","2023-09-13","2024-02-27","2023-10-01","2024-02-01","2023-07-24","2024-02-27","2023-12-15","2023-06-27","2024-02-27","2023-08-12","2024-02-27","2024-02-27","2024-02-19","2024-02-01","2023-08-09","2024-02-03","2024-02-27","2024-02-27","2024-02-01","2023-06-20","2024-02-27","2024-01-20","2024-02-15","2023-12-06","2023-05-26","2024-01-22","2024-02-27","2023-11-07","2024-02-27","2024-02-03","2023-08-19","2024-01-11","2023-11-14","2024-02-01","2024-02-27","2024-02-01","2023-10-21","2023-12-01","2024-02-05","2023-11-25","2024-01-01","2023-11-22","2023-09-07","2024-02-27","2023-12-30","2024-01-23","2023-11-29","2023-08-29","2023-06-12","2023-07-11","2024-02-01","2024-02-27","2023-08-27","2023-08-19","2023-07-07","2023-10-16","2023-06-16","2024-02-27","2023-06-26","2024-02-28","2024-01-01","2023-06-08","2024-01-01","2024-02-27","2024-02-27","2023-12-15","2023-12-12","2023-11-29","2024-02-01","2024-01-03","2023-09-27","2023-11-14","2023-07-18","2023-09-28","2023-10-21","2023-10-13","2023-10-17","2023-06-26","2023-06-27","2023-06-04","2023-05-01","2023-07-06","2024-02-27","2024-01-01","2024-02-01","2023-05-01","2023-10-21","2023-10-21","2024-02-28","2023-10-03","2024-02-01","2024-02-01","2023-05-01","2023-06-20","2023-09-25","2024-02-13","2023-06-21","2023-06-01","2024-02-27","2024-02-27","2023-05-01","2024-02-15","2024-02-27","2023-09-28","2023-06-12","2024-02-27","2024-02-27","2024-01-05","2023-05-29","2023-12-01","2024-02-27","2024-02-27","2024-02-22","2023-11-01","2023-07-12","2023-07-03","2023-09-28","2024-02-04","2023-11-28","2023-05-15","2023-08-19","2023-05-30","2023-05-12","2023-08-04","2023-10-21","2024-02-01","2023-08-04","2024-02-01","2024-02-27","2024-02-27","2023-06-22","2023-06-07","2024-02-01","2023-05-01","2024-02-01","2023-11-20","2023-07-18","2024-02-27","2024-02-27","2023-10-01","2024-02-27","2024-01-08","2023-05-11","2023-08-19","2023-12-01","2024-02-27","2023-12-07","2024-02-03","2024-02-16","2023-11-25","2024-02-27","2024-02-27","2024-02-27","2024-02-03","2024-02-01","2024-01-11","2023-07-22","2023-11-29","2023-08-20","2023-12-13","2023-07-12","2024-02-27","2024-01-01","2023-08-19","2024-01-25","2023-10-26","2023-06-18","2024-02-01","2024-02-01","2024-02-01","2023-11-27","2024-01-20","2023-07-13","2023-05-01","2024-02-27","2024-02-27","2023-12-12","2024-02-01","2024-02-27","2023-06-26","2023-07-18","2023-08-19","2024-01-01","2023-06-13","2023-11-20","2023-07-29","2023-11-21","2023-08-25","2023-08-19","2023-05-12","2024-01-22","2024-02-01","2024-02-10","2024-01-18","2023-06-20","2024-01-15","2024-02-01","2023-09-20","2023-11-22","2024-01-05","2023-12-06","2023-05-10","2023-06-16","2024-02-01","2024-02-01","2024-02-14","2023-12-01","2024-02-14","2023-09-26","2023-08-19","2023-11-15","2023-12-12","2023-08-08","2023-11-22","2024-02-27","2024-02-01","2023-05-09","2023-10-09","2023-11-15","2024-02-27","2023-11-29","2023-12-14","2024-02-01","2024-02-01","2023-05-17","2023-07-18","2024-01-17","2024-02-01","2024-02-27","2023-06-16","2023-10-08","2023-08-04","2024-02-01","2024-02-08","2023-10-21","2024-02-27","2024-02-27","2024-01-19","2023-07-29","2024-02-27","2023-05-01","2023-08-29","2023-11-28","2024-02-04","2023-08-19","2023-09-01","2024-02-27","2023-12-07","2024-02-27","2023-12-01","2024-01-01","2024-02-27","2023-08-21","2023-05-17","2024-02-01","2024-02-01","2023-08-10","2024-02-01","2023-11-01","2023-11-29","2023-10-27","2024-02-27","2024-02-27","2024-02-01","2024-02-01","2024-02-27","2024-01-22","2024-02-27","2023-11-21","2024-02-22","2023-12-04","2023-09-13","2023-09-13","2024-02-01","2023-05-30","2023-11-03","2023-05-12","2023-10-12","2024-02-27","2023-05-04","2024-02-27","2024-02-01","2024-02-07","2024-02-27","2024-02-01","2023-08-19","2023-07-11","2024-02-27","2023-08-04","2024-02-12","2024-02-27","2023-05-04","2024-02-27","2023-10-01","2024-02-01","2023-11-28","2024-02-01","2024-02-01","2024-02-27","2024-01-21","2023-07-03","2023-08-04","2023-09-09","2023-08-19","2023-08-23","2024-01-04","2024-02-01","2024-02-01","2024-02-01","2024-02-01","2024-02-27","2024-02-15","2024-02-27","2024-02-27","2024-01-01","2024-02-12","2023-11-28","2023-10-16","2024-02-01","2024-01-21","2023-06-14","2024-01-21","2023-11-27","2023-10-27","2024-02-27","2024-02-01","2024-02-27","2023-05-22","2023-09-19","2023-11-22","2023-05-01","2023-07-22","2023-08-19","2023-05-16"],"title":["Examining the Impact of FMRI Preprocessing Steps on Machine Learning-Based Classification of Autism Spectrum Disorder","An Ensemble Classification System for Twitter Sentiment Analysis","Orchard classification based on super-pixels and deep learning with sparse optical images","Credit Card Fraud Detection: Addressing Imbalanced Datasets with a Multi-phase Approach","Semi-supervised imbalanced classification of wafer bin map defects using a Dual-Head CNN","FETCH: A Memory-Efficient Replay Approach for Continual Learning in Image Classification","MSRL-Net: A Multi-Level Semantic Relation-Enhanced Learning Network for Aspect-Based Sentiment Analysis","Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook","Neural Network for Ordinal Classification of Imbalanced Data by Minimizing a Bayesian Cost","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","Revisiting Skin Tone Fairness in Dermatological Lesion Classification","Highly Imbalanced Baggage Threat Classification","A Joint Analysis of Input Resolution and Quantization Precision in Deep Learning","Fast Twin Support Vector Classification for Large Scale Problems","Improving fMRI-based Autism Spectrum Disorder Classification with Random Walks-informed Feature Extraction and Selection","Meta-MMFNet: Meta-Learning-Based Multi-Model Fusion Network for Micro-Expression Recognition","Counterfactual Explanations for Remote Sensing Time Series Data: An Application to Land Cover Classification","Enhanced SVM-SMOTE with Cluster Consistency for Imbalanced Data Classification","Unlocking the Potential of Non-PSD Kernel Matrices: A Polar Decomposition-Based Transformation for Improved Prediction Models","Feature selections based on three improved condition entropies and one new similarity degree in interval-valued decision systems","Unreliable Partial Label Learning with Recursive Separation","Improving SMOTE with Fuzzy Rough Prototype Selection to Detect Noise in Imbalanced Classification Data","On the Estimation of Predictive Evaluation Measure Baselines for Multi-Label Learning","Retention is All You Need","Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory","Mitigating Voter Attribute Bias for Fair Opinion Aggregation","A Multi-Class Partial Hinge Loss for Partial Label Learning","MMF-DRL: Multimodal Fusion-Deep Reinforcement Learning Approach with Domain-Specific Features for Classifying Time Series Data","Capitalizing the Predictive Potential of Machine Learning to Detect Various Fire Types Using NASA's MODIS Satellite Data for the Mediterranean Basin","A High-Quality Feature Selection Method Based on Frequent and Correlated Items for Text Classification","Towards Fast and Stable Federated Learning: Confronting Heterogeneity via Knowledge Anchor","Instance Selection Techniques for Large Volumes of Data","FLIPS: Federated Learning Using Intelligent Participant Selection","Word Representations For Gender Classification Using Deep Learning","Graph-Based Text Classification by Contrastive Learning with Text-Level Graph Augmentation","Evaluation of uncertainty quantification methods in multi-label classification: A case study with automatic diagnosis of electrocardiogram","Harnessing the Potential of Deep Learning for Total Shoulder Implant Classification: A Comparative Study","An Optimal Weighted Ensemble of 3D CNNs for Early Diagnosis of Alzheimer\u2019s Disease","Binary Classifier Evaluation on Unlabeled Segments Using Inverse Distance Weighting with Distance Learning","Beyond Trading Data: The Hidden Influence of Public Awareness and Interest on Cryptocurrency Volatility","Identification of High-Risk Areas for Geological Disasters Using Classification Methods under Complex Environmental Conditions","An Evidential Combination Method with Multi-Color Spaces for Remote Sensing Image Scene Classification","Feature-level SMOTE: Augmenting fault samples in learnable feature space for imbalanced fault diagnosis of gas turbines","Leveraging Argumentation for Generating Robust Sample-Based Explanations","Investigating the Effect of Data Impurity on the Detection Performances of Mental Disorders Through Spoken Dialogues","Multimodal Emotion Classification Supported in the Aggregation of Pre-Trained Classification Models","Graph-based Text Classification by Contrastive Learning with Text-level Graph Augmentation","Classification of yoga, meditation, combined yoga\u2013meditation EEG signals using L-SVM, KNN, and MLP classifiers","GBSMOTE: A Robust Sampling Method Based on Granular-Ball Computing and SMOTE for Class Imbalance","Joint long and short span self-attention network for multi-view classification","Semi-Supervised Classification and Segmentation of Forest Fire Using Autoencoders","Machine Learning Algorithm-Based Prediction of Machined Surface Quality in End Milling Operation","Credit Scoring Model based on Weighted Voting and Cluster based Feature Selection","A Multi-Task Approach for Contrastive Learning of Handwritten Signature Feature Representations","Detection of explosives in dustbins using deep transfer learning based multiclass classifiers","Heterogeneous-Training: A Semi-Supervised Text Classification Method","Surface quality prediction and quantitative evaluation of process parameter effects for 3D printing with transfer learning-enhanced gradient-boosting decision trees","Threshold-Based Classification to Enhance Confidence in Open Set of Legal Texts","Improved Decision Module Selection for Hierarchical Inference in Resource-Constrained Edge Devices","An imbalanced classification approach for establishment of cause-effect relationship between Heart-Failure and Pulmonary Embolism using Deep Reinforcement Learning","An Improved Oversampling Algorithms Based on Informative Sample Selection Strategy Solving Imbalance","Leukocytes Classification Methods: Effectiveness and Robustness in a Real Application Scenario","Three-Dimensional System-Object Classification for Prediction and Control Support","A Hybrid Imbalanced Classification Model Based on Data Density","Coupled Adversarial Learning for Fusion Classification of Hyperspectral and LiDAR Data","Rarity updated ensemble with oversampling: An ensemble approach to classification of imbalanced data streams","Multi-Class Wall Recognition in Complex Architectural Floor Plan Images Using a Convolutional Network","COVID-19 Fake News Detection Using Cross-Domain Classification Techniques","Active diversification of head-class features in bilateral-expert models for enhanced tail-class optimization in long-tailed classification","DyGen: Learning from Noisy Labels via Dynamics-Enhanced Generative Modeling","Two-step multi-view data classification based on dynamic Graph-ELM","GSR Based Generic Stress Prediction System","DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG 2000 Compressed Documents","Optimizing the Selection of Base Learners for Multiple Classifier System in Liver Cancer Identification Using Contribution-Based Iterative Removal Algorithm","Multi-scale Heat Kernel Graph Network for Graph Classification","Performance Evaluation of Machine Learning for Recognizing Human Facial Emotions","Collaborative contrastive learning for hypergraph node classification","SupervisedImmuneNet: Training Artificial Immune Networks using a Supervised Learning Approach for Improved Multi-Class Classification","Interpretability and Fairness in Machine Learning: A Formal Methods Approach","Etemadi reliability-based multi-layer perceptrons for classification and forecasting","FEAST: A Communication-Efficient Federated Feature Selection Framework for Relational Data","An Effective DeepWINet CNN Model for Off-Line Text-Independent Writer Identification","A dependency-based hybrid deep learning framework for target-dependent sentiment classification","FOLD-SE: An Efficient Rule-Based Machine Learning Algorithm with Scalable Explainability","Bipartite Graph Coarsening for Text Classification Using Graph Neural Networks","Machine Learning for Leaf Disease Classification: Data, Techniques and Applications","Chinese Named Entity Recognition Method for the Finance Domain Based on Enhanced Features and Pretrained Language Models","Reservoir characterization through comprehensive modeling of elastic logs prediction in heterogeneous rocks using unsupervised clustering and class-based ensemble machine learning","Stochastic Feature Averaging for Learning with Long-Tailed Noisy Labels","Accurate Open-Set Recognition for Memory Workload","Learning Optimal Fair Decision Trees: Trade-Offs Between Interpretability, Fairness, and Accuracy","Fractal belief Jensen\u2013Shannon divergence-based multi-source information fusion for pattern classification","Flexible loss functions for binary classification in gradient-boosted decision trees: An application to credit scoring","A hyperspectral band selection method based on sparse band attention network for maize seed variety identification","CsFEVER and CTKFacts: Acquiring Czech Data for Fact Verification","An automated earthquake classification model based on a new butterfly pattern using seismic signals","A high order fractal-based Kullback\u2013Leibler divergence with application in classification","T-ADAF: Adaptive Data Augmentation Framework for Image Classification Network Based on Tensor T-Product Operator","RsMmFormer: Multimodal Transformer Using Multiscale Self-attention for Remote Sensing Image Classification","Flocking to Mastodon: Tracking the Great Twitter Migration","Support vector machine with eagle loss function","Class3Dp: A supervised classifier of vegetation species from point clouds","Building Concise Logical Patterns by Constraining Tsetlin Machine Clause Size","Credit Card Fraud Detection Using XGBoost for Imbalanced Data Set","On the Performance of New Higher Order Transformation Functions for Highly Efficient Dense Layers","Time-Series Shapelets with Learnable Lengths","Multi-View Robust Graph Representation Learning for Graph Classification","Towards Harmonious Coexistence: A Bioacoustic-Driven Animal-Computer Interaction System for Preventing Ship Collisions with North Atlantic Right Whales","How to identify pollen like a palynologist: A prior knowledge-guided deep feature learning for real-world pollen classification","BC-Net: Early Diagnostics of Breast Cancer Using Nested Ensemble Technique of Machine Learning","Review of resampling techniques for the treatment of imbalanced industrial data classification in equipment condition monitoring","Multimodal Sensor Data Fusion and Ensemble Modeling for Human Locomotion Activity Recognition","Enhancing the Performance of SVM on Skewed Data Sets by Exciting Support Vectors","Comparative Study and Analysis on Skin Cancer Detection Using Machine Learning and Deep Learning Algorithms","Multi-Modal Multi-Class Parkinson Disease Classification Using CNN and Decision Level Fusion","Lung and Colon Cancer Classification of Histopathology Images Using Convolutional Neural Network","Classification model based on improved K-means clustering algorithm","Checkpoint Classifier for CNN Image Classification","Probability-based label enhancement for multi-dimensional classification","Surrogate Deep Learning to Estimate Uncertainties for Driver Intention Recognition","Private, Fair and Secure Collaborative Learning Framework for Human Activity Recognition","Federated contrastive prototype learning: An efficient collaborative fault diagnosis method with data privacy","Lung-EffNet: Lung cancer classification using EfficientNet from CT-scan images","TwiSP: A Framework for Exploring Polarized Issues in Twitter","Maximizing AUC to Learn Weighted Naive Bayes for Imbalanced Data Classification","Material handling machine activity recognition by context ensemble with gated recurrent units","Object Detection Algorithm Based on Coordinate Attention and Context Feature Enhancement","FedGH: Heterogeneous Federated Learning with Generalized Global Header","Using Ensemble StackingC Method and Base Classifiers to Ameliorate Prediction Accuracy of Pedagogical Data","Evidential Generative Adversarial Networks for Handling Imbalanced Learning","A Fraud Detection System Using Decision Trees Classification in An Online Transactions","A Novel Deep Learning Automatic Modulation Classifier with Fusion of Multichannel Information Using GRU","FFANet: Dual Attention-Based Flow Field Aware Network for 3D Grid Classification and Segmentation","Steered Training Data Generation for Learned Semantic Type Detection","Robust Sentiment Classification Based on the Backdoor Adjustment","Fuzzy classification with distance-based depth prototypes: High-dimensional unsupervised and/or supervised problems","An Adaptive Granular Ball Classifier Based on Natural Neighbor","Multi-Label Feature Selection via Maximum Dynamic Correlation Change and Minimum Label Redundancy","Image and Text Aspect Level Multimodal Sentiment Classification Model Using Transformer and Multilayer Attention Interaction","Classification Model for NAVTEX Navigational Warning Messages Based on Adaptive Weighted TF-IDF","Domain-invariant feature fusion networks for semi-supervised generalization fault diagnosis","Viral Genome Prediction from Raw Human DNA Sequence Samples by Combining Natural Language Processing and Machine Learning Techniques","Feature-Weighted Naive Bayesian Classifier for Wireless Network Intrusion Detection","Performance Exploration of RNN Variants for Recognizing Daily Life Stress Levels by Using Multimodal Physiological Signals","Dilated-Windows-based Vision Transformer with Efficient-Suppressive-self-attention for insect pests classification","A target intention recognition method based on information classification processing and information fusion","Enhancing Decision Tree Classification Accuracy through Genetically Programmed Attributes for Wart Treatment Method Identification","Revisiting Hate Speech Benchmarks: From Data Curation to System Deployment","Label correlations-based multi-label feature selection with label enhancement","Garment Fabric Pattern Classification via ResNet-34","Hybrid compression for LSTM-based encrypted traffic classification model","A Noisy-Label-Learning Formulation for Immune Repertoire Classification and Disease-Associated Immune Receptor Sequence Identification","A Review of the F-Measure: Its History, Properties, Criticism, and Alternatives","Automated Hand Joint Classification of Psoriatic Arthritis Patients Using Routinely Acquired Near Infrared Fluorescence Optical Imaging","ST-IFGSM: Enhancing Robustness of Human Mobility Signature Identification Model via Spatial-Temporal Iterative FGSM","An Ensemble Machine Learning Approach for Benchmarking and Selection of ScRNA-Seq Integration Methods","SCALA: Scaling Algorithm for Multi-Class Imbalanced Classification: A Novel Algorithm Specifically Designed for Multi-Class Multiple Minority Imbalanced Data Problems.","Summary of SHL Challenge 2023: Recognizing Locomotion and Transportation Mode from GPS and Motion Sensors","Comparison of Simplified SE-ResNet and SE-DenseNet for Micro-Expression Classification","A Two-Phase Projective Dictionary Pair Learning-Based Classification Scheme for Positive and Unlabeled Learning","A Multi-Temporal Analysis of Archaeological Site Destruction Using Landsat Satellite Data and Machine Learning, Moche Valley, Peru","Hyperspectral Image Classification Using K-Plane Clustering and Kernel Principal Component Analysis","SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference","Heterogeneous Analysis for Clustered Data Using Grouped Finite Mixture Models","Comparison of Convolutional Neural Networks Architectures for Mango Leaf Classification","Predicting the protein structure using random forest approach","A general maximal margin hyper-sphere SVM for multi-class classification","Automatic Classification of TEDS Monitoring Operation Technology Research","Towards explainability for AI-based edge wireless signal automatic modulation classification","Multi-Criteria Decision-Making Based Classifier Ensemble by Using Prioritized Aggregation Operator","Low Resource Language Analysis Using Deep Learning Algorithm for Gender Classification","Spatial Variation Sequences for Remote Sensing Applications with Small Sample Sizes","Compressed, Real-Time Voice Activity Detection with Open Source Implementation for Small Devices","Low-Dimensional Text Representations for Sentiment Analysis NLP Tasks","Explainable Product Classification for Customs","Intellectual Lidar-Based Object Classification for V2V Communication Technology Implementation","Fairness Implications of Encoding Protected Categorical Attributes","SKEDS \u2014 An external knowledge supported logistic regression approach for document-level sentiment classification","A Taxonomy for Learning with Perturbation and Algorithms","CBOEP: Generating Negative Enhancer-Promoter Interactions to Train Classifiers","Deep Learning Hierarchical Methods for Insect Pest Recognition on Plants","Vision Transformers for Breast Cancer Histology Image Classification","Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation","Bibliographic Reference Classification in Historiographic Documents Using Supervised Machine Learning and Grammatical Features","Data-Driven Operator Functional State Classification in Smart Manufacturing","A Novel approach of Sentiment Classification using Emoticons","A Multi-Metric Small Sphere Large Margin Method for Classification","On the Optimal Binary Classifier with an Application","SWRM: Similarity Window Reweighting and Margin for Long-Tailed Recognition","A Robust Joint-Training Graph Neural Networks Model for Event Detection with Noisy Labels","The verification of hen egg types by the classification of ultra-weak photon emission data","ASE: Anomaly scoring based ensemble learning for highly imbalanced datasets\u25aa","Estimating Phenotypic Characteristics of Tuberculosis Bacteria","Molecular subtypes classification of breast cancer in DCE-MRI using deep features","Learning Through Interpolative Augmentation of Dynamic Curvature Spaces","Unbiased Risk Estimator to Multi-Labeled Complementary Label Learning","Acoustic scene classification: A comprehensive survey","Signal detection and material identification method for loose particles inside sealed relays based on fusion classification model","Support Vector Machine Method for Predicting Non-Linear Data","Soil Image Classification Using Transfer Learning Approach: MobileNetV2 with CNN","Insider Threat Detection: Using Classification Models","An IoT and Deep Learning-Based Smart Healthcare Framework for Thyroid Cancer Detection","Navigating Alignment for Non-Identical Client Class Sets: A Label Name-Anchored Federated Learning Framework","irrelevant attribute resistance approach to binary classification for imbalanced data","Same or Different? Diff-Vectors for Authorship Analysis","Understanding Any Time Series Classifier with a Subsequence-Based Explainer","Electronic Tongue based Classification of Mineral Water Samples using Gramian Angular Field and Deep SAE","Comparing Different Oversampling Methods in Predicting Multi-Class Educational Datasets Using Machine Learning Techniques","Probabilistic Local Equivalence Certification for Robustness Evaluation","Multi-label borderline oversampling technique","Modeling of Aquila Optimizer with Hybrid ResNet-DenseNet enabled Breast Cancer Classification on Histopathological Images","Preliminary Study on Unexploded Ordnance Classification in Underwater Environment Based on the Raw Magnetometry Data","Classification of Facial Expressions from EEG signals using Wavelet Packet Transform and SVM for Wheelchair Control Operations","An Evolutionary Approach to Feature Selection and Classification","A topic modeling and image classification framework: The Generalized Dirichlet variational autoencoder","Feature Fusion Gate: Improving Transformer Classifier Performance with Controlled Noise","Interpreting Sign Language Recognition Using Transformers and MediaPipe Landmarks","Automatic Audio Augmentation for Requests Sub-Challenge","FinBERT-FOMC: Fine-Tuned FinBERT Model with Sentiment Focus Method for Enhancing Sentiment Analysis of FOMC Minutes","Fentanyl Analogs Classification via Siamese Network and Mass Spectral Library Searching","Detection of Covid-19 in Chest X-Ray Images Using Percolation Features and Hermite Polynomial Classification","Empirical Analysis of Multi-Label Classification on GitterCom Using BERT and ML Classifiers","A Study on An Automatic Self-Training Model for Mango Segmentation of Sorting System","Handling Small Disjuncts and Class Skew Using Sequential Ellipsoidal Partitioning","Spider Plus: A Text Classifier for Research Article Components","Multimodal Fuzzy Granular Representation and Classification","Auto Machine Learning Based on Genetic Programming for Medical Image Classification","Classification of Freezing of Gait Using Accelerometer Data: A Systematic Performance Evaluation Approach","Comprehensive wheat lodging detection after initial lodging using UAV RGB images","Multitask, Cross-Lingual Recipe Classification Using Joint Fine-Tuning Mechanisms","Condition Monitoring of an Autonomous Electric Drive Train by Using Machine Learning Methods","Fine-Tuning Language Models to Recognize Semantic Relations","Fault detection and classification with the rebmix R package","Automatic Recognition of the General-Purpose Communicative Functions Defined by the ISO 24617-2 Standard for Dialog Act Annotation (Extended Abstract)","Weeds Classification with Deep Learning: An Investigation Using CNN, Vision Transformers, Pyramid Vision Transformers, and Ensemble Strategy","Fusion Local and Global Aspect-Based Sentiment Analysis","Supervised spectral feature learning for fine-grained classification in small data set","A Lightning fast approach to classify Bangla Handwritten Characters and Numerals using newly structured Deep Neural Network","Use of a Surrogate Model for Symbolic Discretization of Temporal Data Sets Through eMODiTS and a Training Set with Varying-Sized Instances","Text Sentiment Classification Model Based on Fusion of DualChannel Features of CNN and BiLSTM","ECC + +: An algorithm family based on ensemble of classifier chains for classifying imbalanced multi-label data","Label Specific Multi-Semantics Metric Learning for Multi-Label Classification: Global Consideration Helps","Efficient and Effective Edge-Wise Graph Representation Learning","Communication-Efficient Federated Skin Lesion Classification with Generalizable Dataset Distillation","Exploiting local label correlation from sample perspective for multi-label classification via three-way decision theory","Fruit Calories Estimation Using Convolutional Neural Network","Unlock the Potential of Counterfactually-Augmented Data in Out-Of-Distribution Generalization","Cellular Features Based Interpretable Network for Classifying Cell-Of-Origin from Whole Slide Images for Diffuse Large B-Cell Lymphoma Patients","Machine Learning for the Classification of Obesity Levels Based on Lifestyle Factors","Non-Parallel Bounded Support Matrix Machine and Its Application in Roller Bearing Fault Diagnosis","A Deep Learning Emotion Classification Framework for Low Resource Languages","Text classification with improved word embedding and adaptive segmentation","Highly effective end-to-end single-to-multichannel feature fusion and ensemble classification to decode emotional secretes from small-scale spontaneous facial micro-expressions","Verifiable Learning for Robust Tree Ensembles","Ordinal classification for interval-valued data and interval-valued functional data","Action Classification in Human Robot Interaction Cells in Manufacturing: Moving Towards Mutual Performance Monitoring Capacity","Semi-Supervised Node Classification via Fine-Grained Graph Auxiliary Augmentation Learning","Power transformer fault diagnosis based on a self-strengthening offline pre-training model","Presumably Correct Undersampling","Predicting Autism from Head Movement Patterns during Naturalistic Social Interactions","Novel extended NI-MWMOTE-based fault diagnosis method for data-limited and noise-imbalanced scenarios","An Ensemble Pneumonia Prediction and Classification Model Including InceptionNeXtPneumonia Prediction and Classification","Review of Machine Learning Techniques for Crop Recommendation","A generalized ensemble approach based on transfer learning for Braille character recognition","An Investigation into Race Bias in Random Forest Models Based on Breast DCE-MRI Derived Radiomics Features","Explainable and Accurate Natural Language Understanding for Voice Assistants and Beyond","Optimal Decision Trees for Interpretable Clustering with Constraints","A Machine Learning Approach to Enterprise Matchmaking Using Multilabel Text Classification Based on Semi-Structured Website Content","A machine learning-based approach for flames classification in industrial Heavy Oil-Fire Boilers","Accelerating Concept Learning via Sampling","Context-Aware Feature Selection and Classification","Preliminary Analysis of Lambani Vowels and Vowel Classification Using Acoustic Features","Revisiting the K-Fold Approach for a Stable Model on Amyotrophic Lateral Sclerosis Prediction Scheme using LSTM and Attention Mechanism","Concise rule induction algorithm based on one-sided maximum decision tree approach","A Novel Multi-Label Feature Selection Method with Association Rules and Rough Set","Optimizing Fairness Tradeoffs in Machine Learning with Multiobjective Meta-Models","Event Detection via Context Understanding Based on Multi-Task Learning","Semantic augmentation by mixing contents for semi-supervised learning","LSOIT: Lexicon and Syntax Enhanced Opinion Induction Tree for Aspect-based Sentiment Analysis","Improving CCA Algorithms on SSVEP Classification with Reinforcement Learning Based Temporal Filtering","Adaptive Weighted Ensemble Classifier for Improving Breast Tumors Classification Based on Ultrasound RF Data","KD-PAR: A knowledge distillation-based pedestrian attribute recognition model with multi-label mixed feature learning network","Melanoma Classification Using Deep Learning","Learning Few-Shot Sample-Set Operations for Noisy Multi-Label Aspect Category Detection","DocLangID: Improving Few-Shot Training to Identify the Language of Historical Documents","UACNet: A universal automatic classification network for microseismic signals regardless of waveform size and sampling rate","A Voting Ensemble-Based Model to Predict the Risk of Cardiovascular Disease in Ordinary People","Human Activity Classification Based on Data Analysis and Feature Extraction","Classification Prediction of Lung Cancer Based on Machine Learning Method","WOT-Class: Weakly Supervised Open-World Text Classification","A Novel Network Architecture for Microplankton Classification in Digital Holographic Images","Soft Labelling Based on Triangular Distributions for Ordinal Classification","Pattern recognition based on statistical methods combined with machine learning in railway switches","Self-supervised Contrastive Feature Refinement for Few-Shot Class-Incremental Learning","Understanding open-set recognition by Jacobian norm and inter-class separation","Hierarchical Meta-Learning with Hyper-Tasks for Few-Shot Learning","Landslide Susceptibility Assessment along the Major Transport Corridor Using Decision Tree Model: A Case Study of Kullu-Rohtang Pass","Improving metric-based few-shot learning with dynamically scaled softmax loss","A Collaborative Transfer Learning Framework for Cross-Domain Recommendation","An Interpretability Case Study of Unknown Unknowns Taking Clothes Image Classification CNNs as an Example","Feature Selection Using Gravitational Search Algorithm in Customer Churn Prediction","Three-way fusion measures and three-level feature selections based on neighborhood decision systems","A Study of Age and Sex Bias in Multiple Instance Learning Based Classification of Acute Myeloid Leukemia Subtypes","Feature selection using a sinusoidal sequence combined with mutual information","Generalization Guarantees of Self-Training of Halfspaces under Label Noise Corruption","Training a Multi-Task Model for Classification and Grasp Detection of Surgical Tools Using Transfer Learning","Unsupervised Multimodal Domain Adversarial Network for Time Series Classification","Multi-Label Emotion Analysis in Conversation via Multimodal Knowledge Distillation","Detecting Survival Patterns in Women with Invasive Cervical Cancer with Decision Trees","Unsupervised Segmentation of Haze Regions as Hard Attention for Haze Classification","Improve label embedding quality through global sensitive GAT for hierarchical text classification","A Study of Classification Techniques Based on Spike Protein Sequences of MERS-CoV","Cautious Decision-Making for Tree Ensembles","Hybrid Classification Model with Tuned Weights for Crop Yield Prediction","Hand gesture classification framework leveraging the entropy features from sEMG signals and VMD augmented multi-class SVM","Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning","Arabic Sentiment Analysis for ChatGPT Using Machine Learning Classification Algorithms: A Hyperparameter Optimization Technique","GF-CNN: An Enhanced Deep Learning Model with Gabor Filters for Maize Disease Classification","Proposing a novel multi-label mapping approach for use in SVM-based multi-class classification problems","mBCCf: Multilevel Breast Cancer Classification Framework Using Radiomic Features","Multi-instance learning with application to the profiling of multi-victim homicides","Orthogonal Uncertainty Representation of Data Manifold for Robust Long-Tailed Learning","\nKNNHI: Resilient KNN Algorithm for Heterogeneous Incomplete Data Classification and K Identification Using Rough Set Theory","Leveraging Contrastive Learning with SimSiam for the Classification of Primary and Secondary Liver Cancers","Generalization Bounds in the Predict-Then-Optimize Framework","LSCA-net: A lightweight spectral convolution attention network for hyperspectral image processing","A ship-radiated noise classification method based on domain knowledge embedding and attention mechanism","Hierarchical long-tailed classification based on multi-granularity knowledge transfer driven by multi-scale feature fusion","Research on Bayesian Network Garbage Classification Based on Multi-Source Information Fusion","Improving PPP-RTK-Based Vehicle Navigation in Urban Environments via Multilayer Perceptron-Based NLOS Signal Detection","Handling missing values and imbalanced classes in machine learning to predict consumer preference: Demonstrations and comparisons to prominent methods","Union of Convex Separators (UCS)","Structural Recognition of Handwritten Chinese Characters Using a Modified Part Capsule Auto-encoder","rgfc-Forest: An enhanced deep forest method towards small-sample fault diagnosis of electromechanical system","Sentiment analysis using various machine learning algorithms for disaster related tweets classification","Nearest Prototype Classification of Special School Families Based on Hierarchical Compact Sets Clustering","Deep Encoders with Auxiliary Parameters for Extreme Classification","Palmer amaranth identification using hyperspectral imaging and machine learning technologies in soybean field","In-house data adaptation to public data: Multisite MRI harmonization to predict Alzheimer\u2019s disease conversion","Classification of Turkish and Balkan House Architectures Using Transfer Learning and Deep Learning","Matrix-based vs. vector-based linear discriminant analysis: A comparison of regularized variants on multivariate time series data","Classification of Services through Feature Selection and Machine Learning in 5G Networks","GeoFormer: Predicting Human Mobility Using Generative Pre-Trained Transformer (GPT)","Multi-Label Classification of Mobile Application User Reviews Using Neural Language Models","A Theoretical Analysis of Out-of-Distribution Detection in Multi-Label Classification","Known and unknown class recognition on plant species and diseases","Removing Camouflage and Revealing Collusion: Leveraging Gang-Crime Pattern in Fraudster Detection","Contrastive Label Enhancement","Learning from Uncurated Regular Expressions for Semantic Type Classification","LIDACS: A Lightweight Domain Adaptive Cell Segmentation Framework","A sequential three-way classification model based on risk preference and decision correction\u25aa","Adaptive Embedding and Distribution Re-Margin for Long-Tail Recognition","Prototype Selection with Compact Sets and Extended Rough Sets","Text Classification Based on Natural Language Processing and Machine Learning in Multi Label Corpus","A Geometric Framework for Multiclass Ensemble Classifiers","Functional Classification of Bitcoin Addresses","Extending Tree-Based Automated Machine Learning to Biomedical Image and Text Data Using Custom Feature Extractors","Sampling based spherical transformer for 360 degree image classification","A Transfer Learning Approach to Interdisciplinary Document Classification with Keyword-Based Explanation","Pyramid Swin Transformer for Multi-Task: Expanding to More Computer Vision Tasks","Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery of South African Rhino Habitats","COCCI: Context-Driven Clothing Classification Network","Improving Table Tennis Training and Technique Analysis: Accurate Classification of Actions with Informer Encoder","Extreme Multi-Label Classification for Ad Targeting Using Factorization Machines","HIE-EDT: Hierarchical interval estimation-based evidential decision tree","Evolutionary Ensembles Based on Prioritized Aggregation Operator","An Analysis Of Convolutional Neural Networks For Image Classification","Unsupervised classification of the spectrogram zeros with an application to signal detection and denoising","Breast Cancer Prediction system","Cross-Domain Bearing Fault Diagnosis Method Using Hierarchical Pseudo Labels","WCDForest: A Weighted Cascade Deep Forest Model toward the Classification Tasks","The reptile optimized deep learning model for land cover classification of the uppal earth region in telangana state using satellite image fusion","Semantic alignment with self-supervision for class incremental learning","Stingless Bee Classification: A New Dataset and Baseline Results","Leveraging Socio-Contextual Information in BERT for Fake Health News Detection in Social Media","Ischemia and Arrhythmia Classification Using Time-Frequency Domain Features of QRS Complex","Performance comparison of various machine learning classifiers using fusion of LBP, intensity and GLCM feature extraction techniques for thyroid nodules classification","Composable Workflow for Accelerating Neural Architecture Search Using In Situ Analytics for Protein Classification","Double similarities weighted multi-instance learning kernel and its application","Plant Disease Detection and Classification Using Deep Learning Models","Cervical cancer classification based on a bilinear convolutional neural network approach and random projection","Enhancing Siamese Neural Networks for Multi-Class Classification: An Immuno-Inspired Approach","Indonesian Agricultural-crops Classification Using Transfer Learning Model","A Hybrid Self-Supervised Learning Framework For Hyperspectral Image Classification","Random Division: An Effective Method for Chinese Text Classification","Learning to complement: Relation complementation network for few-shot class-incremental learning","Domain Adaptation for Learning from Label Proportions Using Domain-Adversarial Neural Network","Consumer credit risk assessment: A review from the state-of-the-art classification algorithms, data traits, and learning methods","Hybrid-driven BRBCS-BOM with expert intervention and its application for abnormity recognition in electrolytic cell","A Natural Language Processing System for Text Classification Corpus Based on Machine Learning","Improving the crop classification performance by unlabeled remote sensing data","Classification of Theoretical Extracellular Action Potentials Based on Unsupervised Machine-Learning","Multimodal Context-Aware Detection of Glioma Biomarkers Using MRI and WSI","A customized deep learning-based framework for classification and analysis of social media posts to enhance the Hajj and Umrah services","Multi-label learning based on instance correlation and feature redundancy","A text classification-based approach for evaluating and enhancing the machine interpretability of building codes","Cascading Global and Local Deep Features for Smartphone-Based Human Activity Classification","Hybrid Approach for Accurate Fiber Estimation in Brain Tissues: Mixture Model and Deep Learning Technique","Optimizing Sheep Breed Classification with Bat Algorithm-Tuned CNN Hyperparameters","On Channel Selection for EEG-Based Mental Workload Classification","Predicting Blood Drop Height and Volume Using Physics Equations, VGG-19, and XGBoost","A New Amharic Speech Emotion Dataset and Classification Benchmark","Composite Deep Learning Architecture for Vehicle Classification Using Vision Transformers and Wheel Position Features","Machine-learning-assisted classification of construction and demolition waste fragments using computer vision: Convolution versus extraction of selected features\u25aa","Patch-Based Deep Learning Models for Breast Mammographic Mass Classification","Mineral identification based on natural feature-oriented image processing and multi-label image classification","Noisy-Consistent Pseudo Labeling Model for Semi-supervised Skin Lesion Classification","Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification","Malware Classification Using Open Set Recognition and HTTP Protocol Requests","Texture-Based Data Augmentation for Small Datasets","Post-processing automatic transcriptions with machine learning for verbal fluency scoring","Maize seed variety identification using hyperspectral imaging and self-supervised learning: A two-stage training approach without spectral preprocessing","Cooperative distillation with X-ray images classifiers for prohibited items detection","Disparity, Inequality, and Accuracy Tradeoffs in Graph Neural Networks for Node Classification","Investigating the Impact of Attention on Mammogram Classification","Attribute- and attention-guided few-shot classification","Bayesian Networks Improve Out-of-Distribution Calibration for Agribusiness Delinquency Risk Assessment","Gradient-based multi-label feature selection considering three-way variable interaction","Language Models for Automatic Distribution of Review Notes in Movie Production","Uncovering Trauma in Genocide Tribunals: An NLP Approach Using the Genocide Transcript Corpus","Classification tree algorithm and its application in general archives management system","Deep Learning Multimodal Methods for Geophysical Inversion\u202f: Application to Glacier Ice Thickness Estimation","Should Fairness be a Metric or a Model? A Model-based Framework for Assessing Bias in Machine Learning Pipelines","Dialect Identification in Ao Using Modulation-Based Representation","Exploring Federated Learning for Speech-Based Parkinson\u2019s Disease Detection","Autoencoder-Based Data Augmentation for Deepfake Detection","Sentiment Distribution of Topic Discussion in Online English Learning: An Approach Based on Clustering Algorithm and Improved CNN","Inter-domain mixup for semi-supervised domain adaptation","Multiclass autoencoder-based active learning for sensor-based human activity recognition","Evaluating Autoencoders for Dimensionality Reduction of MRI-Derived Radiomics and Classification of Malignant Brain Tumors","Regularisation for Efficient Softmax Parameter Generation in Low-Resource Text Classifiers","Arrhythmia Detection Using ECG-Based Classification with Prioritized Feature Subset Vector-Associated Generative Adversarial Network","Intuitive Human-Swarm Interaction with Gesture Recognition and Machine Learning","Classification of Inter-Patient\u2019s Cardiac Arrhythmias in ECG Signals with Enhanced Jaya Optimized TQWT Parameters and Stacked Ensemble Algorithm","A criminal macrocause classification model: An enhancement for violent crime analysis considering an unbalanced dataset","Protein Sequence Classification Using Bidirectional Encoder Representations from Transformers (BERT) Approach","Cancer Survival Prediction by Multimodal Disentangled Representation Learning","RiceNet: A deep convolutional neural network approach for classification of rice varieties\u25aa","Multimodal Cascaded Framework with Metric Learning Robust to Missing Modalities for Person Classification","A quantitative method for the assessment of facial attractiveness based on transfer learning with fine-grained image classification","A framework-based transformer and knowledge distillation for interior style classification","Tourism destination events classifier based on artificial intelligence techniques","SVM in Classification of Stage 0~II and III~IV with Breast Cancer\u202f: A Retrospective Cohort Study on a Bicentric Cohort","Heterogeneous Stacked Ensemble Framework for Surface Electromyography Signal Classification","CrashFormer: A Multimodal Architecture to Predict the Risk of Crash","Customized meta-dataset for automatic classifier accuracy evaluation","Classification of Brain Tumors: A Comparative Approach of Shallow and Deep Neural Networks","Federated Few-Shot Learning for Cough Classification with Edge Devices","Age-Invariant Face Recognition Using Face Feature Vectors and Embedded Prototype Subspace Classifiers","Uncertainty Quantification for Text Classification","SVM Kernel and It\u2019s Aggregation Using Stacking on Imbalanced Dataset","A Momentum Loss Reweighting Method for Improving Recall","Fact-Checking Vietnamese Information Using Knowledge Graph, Datalog, and KG-BERT","Feature Estimation for Punching Tool Wear at the Edge","An Explainable Machine Learning-Based Prediction Model for In-Hospital Mortality in Acute Myocardial Infarction Patients with Typical Chest Pain","Deep Neural Networks for Rank-Consistent Ordinal Regression Based on Conditional Probabilities","Sparse-Learning-Based High-Order Dynamic Functional Connectivity Networks for Brain Disease Classification","A Novel Combined Approach Based on Deep Autoencoder and Deep Classifiers for Credit Card Fraud Detection","Voting Classifier-Based Crop Recommendation","Lung Cancer Survivability Prediction based on Performance Using Classification Techniques of Support Vector Machines, C4.5 and Naive Bayes Algorithms for Healthcare Analytics","Distance-based one-class time-series classification approach using local cluster balance","Asynchronous optimization approach for evidential reasoning rule-based classifier","The Performance Index of Convolutional Neural Network-Based Classifiers in Class Imbalance Problem","LAMM: Language Aware Active Learning for Multilingual Models","Privacy-Preserving Federated Learning via Disentanglement","Leveraging Non-negative Matrix Tri-Factorization and Knowledge-Based Embeddings for Drug Repurposing: an Application to Parkinson's Disease","Research on Multi-Domain Sample Classification Method Based on Baidu API","Deep generative learning for exploration in large electrochemical impedance dataset","A network classification method based on density time evolution patterns extracted from network automata","TF-IGM Revisited: Imbalance Text Classification with Relative Imbalance Ratio","Improved Classification Accuracy by Feature Selection Using Adaptive Support Method","Feature Selection in an Interactive Search-Based PLA Design Approach","A Case Study on the Generalization of Chinese Text Classification Methods based on Deep Learning","Sentiment Classification of Social Network Text Based on AT-BiLSTM Model in a Big Data Environment","Active Weighted Aging Ensemble for Drifted Data Stream Classification","Classify Human Activities Based On Deepforest","Emotion quantification and classification using the neutrosophic approach to deep learning","Multi-View Multi-Label Learning with High-Order Label Correlation","Sensitivity Analysis for Feature Importance in Predicting Alzheimer\u2019s Disease","Development of hybrid models based on deep learning and optimized machine learning algorithms for brain tumor Multi-Classification","Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model","Reference-Limited Compositional Zero-Shot Learning","An adaptive self-correction joint training framework for person re-identification with noisy labels","Aspect category sentiment analysis based on prompt-based learning with attention mechanism","An Efficient Framework for Predicting Future Retail Sales Using Ensemble DNN-BiLSTM Technique","Discrimination of Seismic and Non-Seismic Signal Using SCOUTER","A GCN- and Deep Biaffine Attention-Based Classification Model for Course Review Sentiment","Construction of bearing health indicator under time-varying operating conditions based on Isolation Forest","Meta-cognitive Neural Network based Sequential Learning Framework for Text Categorization","Pattern Recognition Techniques in Image-Based Material Classification of Ancient Manuscripts","Convex Least Angle Regression Based LASSO Feature Selection and Swish Activation Function Model for Startup Survival Rate","Fuzzy-UCS Revisited: Self-Adaptation of Rule Representations in Michigan-Style Learning Fuzzy-Classifier Systems","Exploring the Capabilities of Quantum Support Vector Machines for Image Classification on the MNIST Benchmark","Prediction of Algae Growth: A Machine Learning Perspective","Rethinking Distribution Alignment for Inter-class Fairness","Part-Aware Prototype-Aligned Interpretable Image Classification with Basic Feature Domain","Paralinguistic and Spectral Feature Extraction for Speech Emotion Classification Using Machine Learning Techniques","Progressive Label Propagation for Semi-Supervised Multi-Dimensional Classification","Monuments Identification Using Satellite Images: A CNN Based Approach","Cross-Domain Class-Contrastive Learning: Finding Lower Dimensional Representations for Improved Domain Generalization","FLAMES2Graph: An Interpretable Federated Multivariate Time Series Classification Framework","RT2S: A Framework for Learning with Noisy Labels","An improved random forest based on the classification accuracy and correlation measurement of decision trees","To Aggregate or Not? Learning with Separate Noisy Labels","The hesitant fuzzy BiRNN based on twice-cycle mechanism and its intelligent applications","A lightweight open-world pest image classifier using ResNet8-based matching network and NT-Xent loss function","A robust rice yield estimation framework developed by grading modeling and normalized weight decision-making strategy using UAV imaging technology","Optimized Machine Learning for Classifying Colorectal Tissues","Quasi-CliquePool: Hierarchical Graph Pooling for Graph Classification","Brain haemorrhage classification from CT scan images using fine-tuned transfer learning deep features","Multi-Label Text Classification Model Based on Multi-Level Constraint Augmentation and Label Association Attention","Imbalanced node classification with Graph Neural Networks: A unified approach leveraging homophily and label information","CKR-Calibrator: Convolution Kernel Robustness Evaluation and Calibration","KATIE: A System for Key Attributes Identification in Product Knowledge Graph Construction","Revisiting pretraining for semi-supervised learning in the low-label regime","Supervised contrastive learning for wafer map pattern classification","Term Frequency Features vs Transformers: A Comparision for Sentiment Classification of African Languages","SMOTE-kTLNN: A hybrid re-sampling method based on SMOTE and a two-layer nearest neighbor classifier","Convolutional variational autoencoder for ground motion classification and generation toward efficient seismic fragility assessment","The Classification of Wheat Yellow Rust Disease Based on a Combination of Textural and Deep Features","RaMLP: Vision MLP via Region-Aware Mixing","Air Pollutants Classification Using Optimized Neural Network Based on War Strategy Optimization Algorithm","Improving Batik Pattern Classification using CNN with Advanced Augmentation and Oversampling on Imbalanced Dataset","Multi-Branch Network for Imagery Emotion Prediction","Clifford Convolutional Neural Networks for Lymphoblast Image Classification","Automatic classification of the physical surface in sound uroflowmetry using machine learning methods","Scattering-Based Hybrid Network for Facial Attribute Classification","Comparing Local Binary Pattern and Gray Level Co-occurrence Matrix for Feature Extraction in Diabetic Retinopathy Classification","Wire melted mark metallographic image recognition and classification based on semantic segmentation\u25aa","Synthetic minority oversampling using edited displacement-based k-nearest neighbors","A multi-classification detection model for imbalanced data in NIDS based on reconstruction and feature matching","Iterative minority oversampling and its ensemble for ordinal imbalanced datasets","Deep Modular Co-Attention Shifting Network for Multimodal Sentiment Analysis","Extreme Learning Machine Combining Hidden-Layer Feature Weighting and Batch Training for Classification","On the Most Frequent Sequences of Words in Russian Spoken Everyday Language (Bigrams and Trigrams): An Experience of Classification","Multi-Classification Data Stream Algorithm Based on One-Vs-Rest Strategy","Hierarchical Classification of Gene Ontology with Learning Classifier Systems","OmnImage: Evolving 1k Image Cliques for Few-Shot Learning","Identification of chrysanthemum using hyperspectral imaging based on few-shot class incremental learning","Few-shot classification guided by generalization error bound","ProMix: Combating Label Noise via Maximizing Clean Sample Utility","Texture-based superpixel segmentation algorithm for classification of hyperspectral images","Classification Algorithm for Liquid Dangerous Goods Based on WT-AE and Attention-GRU Network","A Bayesian Convolutional Neural Network Model with Uncertainty for Multi-Label Text Classification on Mechanisms of Action (MoA) Prediction","AdapterFusion-based multi-task learning for code-mixed and code-switched text classification","Efficient SpectralFormer for hyperspectral image classification","Fast generalized ramp loss support vector machine for pattern classification","Leveraging Model Fusion for Improved License Plate Recognition","Analysis of Convolutional Neural Network Models for Classifying the Quality of Dried Chili Peppers (Capsicum Annuum L)","Combining Autoencoder and Yolov6 Model for Classification and Disease Detection in Chickens","Fuzzy Similarity Phrases for Interpretable Data Classification","An automated voice command classification model based on an attention-deep convolutional neural network for industrial automation system","Granule-specific feature selection for continuous data classification using neighborhood rough sets","Ensemble Methods With [18F]FDG-PET/CT Radiomics In Breast Cancer Response Prediction","Evaluation of classification models in limited data scenarios with application to additive manufacturing","OSF-EIMTC: An open-source framework for standardized encrypted internet traffic classification","Diagnosing Prostate Cancer: An Implementation of Deep Machine Learning Fusion Network in MRI Using a Transfer Learning Approach","ML-LJP: Multi-Law Aware Legal Judgment Prediction","Machine Learning Driven Aid Classification for Sustainable Development","Identification of Personality Traits from Handwritten Text Documents Using Multi-Label Classification Models","EEG-Based Emotion Recognition in Immersive Virtual Reality: Meeting the Requirement of Accuracy and Computational Efficiency","Active Learning for Open-Set Annotation Using Contrastive Query Strategy","Feature Engineering and Ensemble Learning-Based Classification of VPN and Non-VPN-Based Network Traffic over Temporal Features","Poster: Backdoor Attack on Extreme Learning Machines","An Evaluation of Handwritten Text Recognition Methods for Historical Ciphered Manuscripts","G2Pxy: Generative Open-Set Node Classification on Graphs with Proxy Unknowns","A Globally-Connected and Trainable Hierarchical Fine-Attention Generative Adversarial Network Based Adversarial Defense","Classification techniques of electronic nose: a review","Global and cross-modal feature aggregation for multi-omics data classification and application on drug response prediction","NaN","Optimal hybrid classifier with fine-tuned hyper parameter and improved fuzzy C means segmentation: skin cancer detection","Invited Paper: Common Public Knowledge for Enhancing Machine Learning Data Sets","Isolated Arabic Sign Language Recognition Using a Transformer-based Model and Landmark Keypoints","Fused robust geometric nonparallel hyperplane support vector machine for pattern classification","Federated Learning with ResNet-18 for Medical Image Diagnosis","Complexity-Driven Sampling for Bagging","Pre-training and ensembling based Alzheimer\u2019s disease detection","Framework for Choosing a Supervised Machine Learning Method for Classification Based on Object Categories\u202f: Classifying Subjectivity of Online Comments by Product Categories","Multivariate Two Dimensional Singular Spectrum Analysis Based Fusion Method for Four View Image Based Object Classification","Graph Neural Networks for Fault Diagnosis of Geographically Nearby Photovoltaic Systems","Fuzzy twin kernel ridge regression classifiers for liver disorder detection","PCA: Progressive class-wise attention for skin lesions diagnosis","Classification of human protein cell images using deep neural networks","GPC: Generative and General Pathology Image Classifier","Vehicle type classification in intelligent transportation systems using deep learning","GII: A Unified Approach to Representation Learning in Open Set Recognition with Novel Category Discovery","Learning Prototype Classifiers for Long-Tailed Recognition","Explainable Occupancy Prediction Using QLattice","Transfer Learning: Kernel-Based Domain Adaptation with Distance-Based Penalization","Model Averaging for Support Vector Classifier by Cross-Validation","A Subgraph Embedded GIN with Attention for Graph Classification","Standard Multi-Layer Perceptron on Positive - Unlabeled Glycosylation Site Dataset","Time series classification with random temporal features","FedAR+: A Federated Learning Approach to Appliance Recognition with Mislabeled Data in Residential Environments","Early Classifying Multimodal Sequences","TODOS: Thermal SensOr Data-Driven Occupancy Estimation System for Smart Buildings","Gaussian dynamic recurrent unit for emitter classification","Multi-Task Learning over Mixup Variants for the Speaker Verification Task","ML-Based Identification of Neuromuscular Disorder Using EMG Signals for Emotional Health Application","Landslide susceptibility assessment using locally weighted learning integrated with machine learning algorithms","Two-stage fine-grained image classification model based on multi-granularity feature fusion","Improving Automated Labeling for ATT&amp;CK Tactics in Malware Threat Reports","Disentangling User Conversations with Voice Assistants for Online Shopping","Classification of Alzheimer??s Disease using combined features of fMRI Brain Network and clinical scales","Fuzzy graph convolutional network for hyperspectral image classification","Multi-scale LBP fusion with the contours from deep CellNNs for texture classification","Random Forest Algorithm Using Quartile-Pattern Bootstrapping for a Class Imbalanced Problem","Investigating the Effect of Orientation Variability in Deep Learning-Based Human Activity Recognition","Deep Pipeline Embeddings for AutoML","Swin transformer with multiscale 3D atrous convolution for hyperspectral image classification","Multilevel Face Recognition System","Tackling Diverse Minorities in Imbalanced Classification","Software Engineering Classification Model and Algorithm Based on Big Data Technology","Prediction of Diabetes using Classification Algorithms","A Dynamic Difficulty Adjustment Algorithm With Generic Player Behavior Classification Unity Plugin In Single Player Games","Ultrasound-Based Ovarian Cysts Detection with Improved Machine-Learning Techniques and Stage Classification Using Enhanced Classifiers","Classification of EEG data for human mental state analysis using Random Forest Classifier","Invariance Encoding in Sliced-Wasserstein Space for Image Classification with Limited Training Data","MacBERT Classification Model of Memory Attention Mechanism and Its Application to the Power System of EAST Neutral Beam Injection Facility","An Optimised Grid Search Based Framework for Robust Large-Scale Natural Soundscape Classification","Ensemble of Deep Convolutional Network for Citrus Disease Classification Using Leaf Images","Boosting Few-Shot Open-Set Recognition with Multi-Relation Margin Loss","GGFAST: Automating Generation of Flexible Network Traffic Classifiers","Highly imbalanced fault classification of wind turbines using data resampling and hybrid ensemble method approach","SER-Fuse: An Emotion Recognition Application Utilizing Multi-Modal, Multi-Lingual, and Multi-Feature Fusion","Automated Classification Method for Early Diagnosis of Alopecia Using Machine Learning","Color Models Aware Dynamic Feature Extraction for Forest Fire Detection Using Machine Learning Classifiers","Multi-label feature selection by strongly relevant label gain and label mutual aid","EEG Based Emotion Classification Mechanism in BCI","DisguisedNets: Secure Image Outsourcing for Confidential Model Training in Clouds","A Problem-Tailored Adversarial Deep Neural Network-Based Attack Model for Feed-Forward Physical Unclonable Functions","A novel multi-label pest image classifier using the modified Swin Transformer and soft binary cross entropy loss","Multiple instance learning from similarity-confidence bags","Multi-View Graph Convolutional Networks with Differentiable Node Selection","Diagnosis of Alzheimer\u2019s disease via Intuitionistic fuzzy least squares twin SVM","Bias Mitigation for Machine Learning Classifiers: A Comprehensive Survey","Constant-Q Based Harmonic And Pitch Features For Normal vs. Pathological Infant Cry Classification","CALM: An Enhanced Encoding and Confidence Evaluating Framework for Trustworthy Multi-View Learning","Hyperplane projection network for few-shot relation classification","Face Shape Classification Using Swin Transformer Model","ADCGNet: Attention-based dual channel Gabor network towards efficient detection and classification of electrocardiogram images","Sentiment analysis of imbalanced datasets using BERT and ensemble stacking for deep learning","Pixel Based Supervised Classification of Hyperspectral Face Images for Face Recognition","Protein acetylation sites with complex-valued polynomial model","An Empirical Analysis of Geospatial Classification for Agriculture Monitoring","A Comparative Analysis on Recent Methods for Addressing Imbalance Classification","Gender-Aware Speech Emotion Recognition in Multiple Languages","Fu-W:A Hyperspectral Image Classification Algorithm Combining Mini Graph Convolutional Networks and Convolutional Neural Network","NaN","Forecasting Dining Times in a Full-Service Thai Hotpot Restaurant Using Random Forest Classifier","Feature incremental learning with causality","Incremental Tabular Learning on Heterogeneous Feature Space","Fast Support Vector Classifier with Quantile","Supervised Contrastive Multi-Tasking Learning Based Hierarchical Yoga Pose Classification Using CNNs","Studying the Effects of Sex-Related Differences on Brain Age Prediction Using Brain MR Imaging","An improved unified domain adversarial category-wise alignment network for unsupervised cross-domain sentiment classification","Rice Variety Classification \\&amp; Yield Prediction Using Semantic Segmentation of Agro-Morphological Characteristics","Efficient reinforcement learning-based method for plagiarism detection boosted by a population-based algorithm for pretraining weights","Retrieval Contrastive Learning for Aspect-Level Sentiment Classification","Conditional Generative Adversarial Network for Early Classification of Longitudinal Datasets using an Imputation Approach","ProMIL: A weakly supervised multiple instance learning for whole slide image classification based on class proxy","Stacking: A novel data-driven ensemble machine learning strategy for prediction and mapping of Pb-Zn prospectivity in Varcheh district, west Iran","Explainable Text Classification via Attentive and Targeted Mixing Data Augmentation","Learning Label-Specific Features for Decomposition-Based Multi-Class Classification","A Jackknife-Inspired Deep Learning Approach to Subject-Independent Classification of EEG","Task-Equivariant Graph Few-Shot Learning","HAHANet: Towards Accurate Image Classifiers with Less Parameters","A Noval Approach for Object Recognition Using Decision Tree Clustering by Incorporating Multi-Level BPNN Classifiers and Hybrid Texture Features","Convolutional Neural Network with Support Vector Machine for Motor Imagery EEG Signal Classification","CB-SAGE: A novel centrality based graph neural network for floor plan classification","Baselining Performance for Multilingual Codeswitching Sentiment Classification","Adaptive fuzzy multi-neighborhood feature selection with hybrid sampling and its application for class-imbalanced data","Systematic Analysis of the Impact of Label Noise Correction on ML Fairness","Few-shot classification via efficient meta-learning with hybrid optimization","A nonlinear kernel SVM classifier via L 0 / 1 soft-margin loss with classification performance","A novel ensemble framework driven by diversity and cooperativity for non-stationary data stream classification","Feature Relevance in Classification of 3D Stone from Ancient Wall Structures","Prediction of Casting Mechanical Parameters Based on Direct Microstructure Image Analysis Using Deep Neural Network and Graphite Forms Classification","Partial-Label Learning with Mixed Closed-Set and Open-Set Out-of-Candidate Examples","DASS: Differentiable Architecture Search for Sparse Neural Networks","Unbiased Gradient Boosting Decision Tree with Unbiased Feature Importance","Automatic Idiom Identification Model for Amharic Language","SCE: Shared Concept Extractor to Explain a CNN's Classification Dynamics","Wavelet Scattering Transform based Doppler signal classification","MLapRVFL: Protein sequence prediction based on Multi-Laplacian Regularized Random Vector Functional Link","MinJoT: Multimodal infusion Joint Training for noise learning in text and multimodal classification problems","Domain-knowledge Inspired Pseudo Supervision (DIPS) for unsupervised image-to-image translation models to support cross-domain classification","Uncertainty Quantification for Eosinophil Segmentation","Using Decision Trees for Interpretable Supervised Clustering","A Novel Fitness Computation Framework for Nature Inspired Classification Algorithms","A fusion-based approach to improve hyperspectral images\u2019 classification using metaheuristic band selection","Granular computing-based deep learning for text classification","Evaluating Mammogram Image Classification: Impact of Model Architectures, Pretraining, and Finetuning","Automatic Classification of Sensors in Buildings: Learning from Time Series Data","Does Removal of Noisy Granulated Datasets Matter to Performance of Decision Tree Generation?","Comparative study of a newly proposed machine learning classification to detect damage occurrence in structures","Examining the Robustness of an Ensemble Learning Model for Credibility Based Fake News Detection","Automatic Data-Driven Software Change Identification via Code Representation Learning","Combined Data Augmentation for HEp-2 Cells Image Classification","DIF-SR: A Differential Item Functioning-Based Sample Reweighting Method","DPNET: Dynamic Poly-Attention Network for Trustworthy Multi-Modal Classification","Rank Allocation to J48 Group of Decision Tree Classifiers using Binary and Multiclass Intrusion Detection Datasets","Robust scientific text classification using prompt tuning based on data augmentation with L2 regularization","Hybrid feature ranking and classifier aggregation based on multi-criteria decision-making","Artificial Neural Network-Assisted Amplitude Thresholding Improves Spike Detection","WEASEL 2.0: A Random Dilated Dictionary Transform for Fast, Accurate and Memory Constrained Time Series Classification","Combining Regular Expressions and Supervised Algorithms for Clinical Text Classification","Mel Spectrogram-Based Advanced Deep Temporal Clustering Model with Unsupervised Data for Fault Diagnosis","Digital Twin-Based Anomaly Detection with Curriculum Learning in Cyber-Physical Systems","Leveraging Domain Knowledge for Inclusive and Bias-Aware Humanitarian Response Entry Classification","Effective Training-Time Stacking for Ensembling of Deep Neural Networks"],"x":{"__ndarray__":"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","dtype":"float64","shape":[711]},"x_backup":{"__ndarray__":"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","dtype":"float64","shape":[711]},"y":{"__ndarray__":"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","dtype":"float64","shape":[711]},"y_backup":{"__ndarray__":"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","dtype":"float64","shape":[711]}},"selected":{"id":"1072","type":"Selection"},"selection_policy":{"id":"1071","type":"UnionRenderers"}},"id":"1011","type":"ColumnDataSource"},{"attributes":{"overlay":{"id":"1059","type":"BoxAnnotation"}},"id":"1037","type":"BoxZoomTool"},{"attributes":{"children":[{"id":"1076","type":"Div"}]},"id":"1078","type":"Row"},{"attributes":{"text":"&lt;a href=\"clusters_last_half_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Half Year&lt;/button&gt;&lt;/a&gt;"},"id":"1004","type":"Div"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"margin":[15,15,15,15],"sizing_mode":"scale_both","title":"Search:"},"id":"1075","type":"TextInput"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by Text:&lt;/h3&gt;&lt;p1&gt;Search keyword to filter out the plot. It will search abstracts, titles and authors. \n    Press enter when ready. Clear and press enter to reset the plot.&lt;/p1&gt;"},"id":"1007","type":"Div"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"color":"#2e484c","font-family":"Julius Sans One, sans-serif;"},"text":"&lt;h1&gt;Clustering Literature on Supervised Learning by Classification (Last Year)&lt;/h1&gt;"},"id":"1076","type":"Div"},{"attributes":{},"id":"1021","type":"LinearScale"},{"attributes":{},"id":"1026","type":"BasicTicker"},{"attributes":{},"id":"1039","type":"SaveTool"},{"attributes":{"bottom_units":"screen","fill_alpha":{"value":0.5},"fill_color":{"value":"lightgrey"},"left_units":"screen","level":"overlay","line_alpha":{"value":1.0},"line_color":{"value":"black"},"line_dash":[4,4],"line_width":{"value":2},"render_mode":"css","right_units":"screen","top_units":"screen"},"id":"1059","type":"BoxAnnotation"},{"attributes":{"data_source":{"id":"1011","type":"ColumnDataSource"},"glyph":{"id":"1050","type":"Scatter"},"hover_glyph":null,"muted_glyph":null,"nonselection_glyph":{"id":"1051","type":"Scatter"},"selection_glyph":null,"view":{"id":"1053","type":"CDSView"}},"id":"1052","type":"GlyphRenderer"},{"attributes":{"ticker":{"id":"1026","type":"BasicTicker"}},"id":"1029","type":"Grid"},{"attributes":{"callback":null},"id":"1019","type":"DataRange1d"},{"attributes":{"callback":{"id":"1065","type":"CustomJS"}},"id":"1040","type":"TapTool"},{"attributes":{"children":[{"id":"1002","type":"Div"}]},"id":"1080","type":"Row"},{"attributes":{},"id":"1072","type":"Selection"},{"attributes":{"children":[{"id":"1003","type":"Div"},{"id":"1004","type":"Div"},{"id":"1005","type":"Div"}]},"id":"1081","type":"Row"},{"attributes":{"margin":[20,20,20,20],"sizing_mode":"scale_both","style":{"color":"#BF0A30","font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Click on a plot to see the info about the article.","width":150},"id":"1064","type":"Div"},{"attributes":{"callback":null,"point_policy":"follow_mouse","tooltips":[["Title","@title"],["Author","@author"],["Abstract","@abstract{safe}"],["Publication Date","@publication_date"],["Cluster","@cluster"]]},"id":"1012","type":"HoverTool"},{"attributes":{"args":{"current_selection":{"id":"1064","type":"Div"},"source":{"id":"1011","type":"ColumnDataSource"}},"code":"\n        var titles = [];\n        var authors = [];\n        var abstracts = [];\n        var publicationDates = [];\n        var clusters = [];\n\n        cb_data.source.selected.indices.forEach(index =&gt; {\n            titles.push(source.data['title'][index]);\n            authors.push(source.data['author'][index]);\n            abstracts.push(source.data['abstract'][index]);\n            publicationDates.push(source.data['publication_date'][index]);\n            clusters.push(source.data['cluster'][index]);\n        });\n\n        var title = \"&lt;p1&gt;&lt;b&gt;Title:&lt;/b&gt; \" + (titles[0] ? titles[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var author = \"&lt;p1&gt;&lt;b&gt;Author:&lt;/b&gt; \" + (authors[0] ? authors[0].toString() : \"Not available.\") + \"&lt;br&gt;\";\n        var abstract = \"&lt;p1&gt;&lt;b&gt;Abstract:&lt;/b&gt; \" + abstracts[0].toString() + \"&lt;br&gt;\";\n        var publicationDate = \"&lt;p1&gt;&lt;b&gt;Publication Date:&lt;/b&gt; \" + publicationDates[0].toString() + \"&lt;/p1&gt;&lt;br&gt;\";\n        var cluster = \"&lt;p1&gt;&lt;b&gt;Cluster:&lt;/b&gt; \" + clusters[0].toString() + \"&lt;/p1&gt;\";\n\n        current_selection.text = title + author + abstract + publicationDate + cluster;\n        current_selection.change.emit();\n    "},"id":"1065","type":"CustomJS"},{"attributes":{"text":"&lt;a href=\"clusters_last_year.html\" target=\"_blank\"&gt;&lt;button&gt;Last Year&lt;/button&gt;&lt;/a&gt;"},"id":"1005","type":"Div"},{"attributes":{"formatter":{"id":"1058","type":"BasicTickFormatter"},"ticker":{"id":"1031","type":"BasicTicker"}},"id":"1030","type":"LinearAxis"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Filter by the Clusters:&lt;/h3&gt;&lt;p1&gt;The slider below can be used to filter the target cluster. \nSimply slide the slider to the desired cluster number to display the plots that belong to that cluster. \nSlide back to the last cluster to show all the plots.&lt;/p1&gt;"},"id":"1008","type":"Div"},{"attributes":{"callback":{"id":"1063","type":"CustomJS"},"end":11,"margin":[15,15,15,15],"sizing_mode":"stretch_width","start":0,"title":"Cluster #","value":11},"id":"1074","type":"Slider"},{"attributes":{"source":{"id":"1011","type":"ColumnDataSource"}},"id":"1053","type":"CDSView"},{"attributes":{},"id":"1031","type":"BasicTicker"},{"attributes":{"background_fill_alpha":{"value":0.6},"items":[{"id":"1061","type":"LegendItem"}]},"id":"1060","type":"Legend"},{"attributes":{},"id":"1035","type":"PanTool"},{"attributes":{},"id":"1036","type":"WheelZoomTool"},{"attributes":{"high":10,"low":0,"palette":["#1f77b4","#aec7e8","#ff7f0e","#ffbb78","#2ca02c","#98df8a","#d62728","#ff9896","#9467bd","#c5b0d5","#8c564b"]},"id":"1013","type":"LinearColorMapper"},{"attributes":{"label":{"field":"labels"},"renderers":[{"id":"1052","type":"GlyphRenderer"}]},"id":"1061","type":"LegendItem"},{"attributes":{"children":[{"id":"1078","type":"Row"},{"id":"1079","type":"Row"},{"id":"1080","type":"Row"},{"id":"1081","type":"Row"},{"id":"1082","type":"Row"},{"id":"1083","type":"Row"},{"id":"1084","type":"Row"},{"id":"1085","type":"Row"},{"id":"1086","type":"Row"}]},"id":"1087","type":"Column"},{"attributes":{"args":{"out_text":{"id":"1062","type":"Paragraph"},"p":{"id":"1014","subtype":"Figure","type":"Plot"},"slider":{"id":"1074","type":"Slider"},"source":{"id":"1011","type":"ColumnDataSource"},"text":{"id":"1075","type":"TextInput"},"topics":["","study, time, new, different, algorithms, imbalance, smote, distribution, latent, framework, noise, documents, candidate, document, color, software, examples, fairness, images, metric, proposed, soft, transformation, granular, multi, noisy, linear, regions","language, knowledge, text, sentiment, research, expressions, analysis, documents, proposed, sentences, evaluation, extract, human, novel, languages, significant, work, corpus, english, high, standard, outperforms","information, adaptation, domains, framework, unsupervised, problem, state, better, proposed, art, transfer, traditional, time, different, real, high, source, compared, existing","hyperspectral, multi, hsi, view, spectral, different, correlation, attention, confidence, self, long, information, instance, fusion, views, image, end, proposed, representation, graph","multi, base, selection, quality, specific, technique, framework, ensemble, proposed, clustering, function, xgboost, decision, better, real, credit, novel, voting","breast, alzheimer, brain, proposed, image, disease, skin, attention, high, cnn, diseases, deep, research, outcomes, survival, subjects, women, cancer, images, classifying, malignant","matrix, kernel, function, vector, multi, svm, support, proposed, signals, vectors, recognition, average, low, linear, different, decision, efficient, new","image, techniques, process, images, different, state, information, extract, proposed, segmentation, crucial","multi, information, random, forest, text, uncertainty, deep, fault, texture, different, image, study, proposed, layer, work, images, level, disease, point, abstract, high, computing","multi, language, semantic, sentence, relations, relation, existing, word, representation, new, sentiment, information, tasks, words, proposed, introduce, improve, natural, distribution, achieves, art, different"]},"code":"\n\t\t\t\tvar key = text.value;\n\t\t\t\tkey = key.toLowerCase();\n\t\t\t\tvar cluster = slider.value;\n                var clusters_count = slider.end;\n                var data = source.data; \n                \n                \n                x = data['x'];\n                y = data['y'];\n                x_backup = data['x_backup'];\n                y_backup = data['y_backup'];\n                labels = data['cluster'];\n                abstract = data['abstract'];\n                title = data['title'];\n                author = data['author'];\n                if (cluster == clusters_count) {\n                    out_text.text = 'Keywords: Slide to specific cluster to see the keywords.';\n                    for (i = 0; i &lt; x.length; i++) {\n\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key) || \n                        (title[i] &amp;&amp; title[i].toLowerCase().includes(key)) ||\n                        (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t}\n                    }\n                }\n                else {\n                    out_text.text = 'Keywords: ' + topics[Number(cluster)];\n                    for (i = 0; i &lt; x.length; i++) {\n                        if(labels[i] == cluster) {\n\t\t\t\t\t\t\tif(abstract[i].toLowerCase().includes(key)\n                            || (title[i] &amp;&amp; title[i].toLowerCase().includes(key))\n                            || (author[i] &amp;&amp; author[i].toLowerCase().includes(key))) {\n\t\t\t\t\t\t\t\tx[i] = x_backup[i];\n\t\t\t\t\t\t\t\ty[i] = y_backup[i];\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tx[i] = undefined;\n\t\t\t\t\t\t\t\ty[i] = undefined;\n\t\t\t\t\t\t\t}\n                        } else {\n                            x[i] = undefined;\n                            y[i] = undefined;\n                        }\n                    }\n                }\n            source.change.emit();\n            "},"id":"1063","type":"CustomJS"},{"attributes":{"fill_color":{"field":"cluster","transform":{"id":"1013","type":"LinearColorMapper"}},"line_alpha":{"value":0.3},"size":{"units":"screen","value":5},"x":{"field":"x"},"y":{"field":"y"}},"id":"1050","type":"Scatter"},{"attributes":{"children":[{"id":"1008","type":"Div"},{"id":"1007","type":"Div"}]},"id":"1082","type":"Row"},{"attributes":{"children":[{"id":"1064","type":"Div"}]},"id":"1086","type":"Row"},{"attributes":{"below":[{"id":"1025","type":"LinearAxis"}],"center":[{"id":"1029","type":"Grid"},{"id":"1034","type":"Grid"},{"id":"1060","type":"Legend"}],"left":[{"id":"1030","type":"LinearAxis"}],"margin":[5,5,5,5],"plot_height":500,"plot_width":500,"renderers":[{"id":"1052","type":"GlyphRenderer"}],"sizing_mode":"scale_both","title":{"id":"1015","type":"Title"},"toolbar":{"id":"1041","type":"Toolbar"},"toolbar_location":"above","x_range":{"id":"1017","type":"DataRange1d"},"x_scale":{"id":"1021","type":"LinearScale"},"y_range":{"id":"1019","type":"DataRange1d"},"y_scale":{"id":"1023","type":"LinearScale"}},"id":"1014","subtype":"Figure","type":"Plot"},{"attributes":{},"id":"1058","type":"BasicTickFormatter"},{"attributes":{"text":"Clustering of the ACM papers on Supervised Learning by Classification"},"id":"1015","type":"Title"},{"attributes":{},"id":"1038","type":"ResetTool"},{"attributes":{"children":[{"id":"1074","type":"Slider"},{"id":"1075","type":"TextInput"}]},"id":"1083","type":"Row"},{"attributes":{"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"&lt;h3&gt;Time Range:&lt;/h3&gt;&lt;p1&gt;Click on the button to change the time range of the plot.&lt;/p1&gt;"},"id":"1002","type":"Div"},{"attributes":{},"id":"1023","type":"LinearScale"},{"attributes":{"active_drag":"auto","active_inspect":"auto","active_multi":null,"active_scroll":"auto","active_tap":"auto","tools":[{"id":"1012","type":"HoverTool"},{"id":"1035","type":"PanTool"},{"id":"1036","type":"WheelZoomTool"},{"id":"1037","type":"BoxZoomTool"},{"id":"1038","type":"ResetTool"},{"id":"1039","type":"SaveTool"},{"id":"1040","type":"TapTool"}]},"id":"1041","type":"Toolbar"},{"attributes":{},"id":"1071","type":"UnionRenderers"},{"attributes":{"margin":[5,5,5,5],"sizing_mode":"stretch_width","style":{"font-family":"Helvetica Neue, Helvetica, Arial, sans-serif;","font-size":"1.1em"},"text":"Clustering of literature on supervised learning by classification from ACM Digital Library. \n    The dataset is extracted from &lt;a href=\"https://dl.acm.org/topic/ccs2012/10010147.10010257.10010258.10010259.10010263?expand=all&amp;startPage=\"&gt;here&lt;/a&gt;."},"id":"1006","type":"Div"}],"root_ids":["1087"]},"title":"Bokeh Application","version":"1.4.0"}}
        </script>
        <script type="text/javascript">
          (function() {
            var fn = function() {
              Bokeh.safely(function() {
                (function(root) {
                  function embed_document(root) {
                    
                  var docs_json = document.getElementById('1176').textContent;
                  var render_items = [{"docid":"9decfde2-eee6-4faf-bc14-12f7d453bf22","roots":{"1087":"7cb350b3-8823-4263-b4fe-120cd6f673ab"}}];
                  root.Bokeh.embed.embed_items(docs_json, render_items);
                
                  }
                  if (root.Bokeh !== undefined) {
                    embed_document(root);
                  } else {
                    var attempts = 0;
                    var timer = setInterval(function(root) {
                      if (root.Bokeh !== undefined) {
                        clearInterval(timer);
                        embed_document(root);
                      } else {
                        attempts++;
                        if (attempts > 100) {
                          clearInterval(timer);
                          console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                        }
                      }
                    }, 10, root)
                  }
                })(window);
              });
            };
            if (document.readyState != "loading") fn();
            else document.addEventListener("DOMContentLoaded", fn);
          })();
        </script>
    
  </body>
  
</html>